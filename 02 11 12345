12345
"""
ULTRA-MEGA Data Reconciliation Tool
----------------------------------------------
Advanced Data Reconciliation Tool with Modern UI

Key Improvements Implemented:
  - Explicit FilterRule/FilterRules classes with value validation.
  - Robust validation in process_alfa_data (including chunk processing for large files)
    and process_gamma_data (with encoding detection).
  - Comparison functions that validate and normalize data.
  - Excel output formatting with conditional formatting.
  - Enhanced logging: structured logging (using structlog if available) and audit trails.
  - GUI enhancements: tooltips, keyboard shortcuts, and progress indicators.
  - Configuration management with validation and backup.
  - Performance optimizations (DataFrame downcasting and caching for frequent operations).
  - Custom error classes for improved error handling.
  
Author: Al Pacino Dan
Last Updated: February 2025
"""

import os
import sys
import json
import logging
import zipfile
from datetime import datetime
from pathlib import Path
from functools import lru_cache
from typing import List, Dict, Tuple, Set, Union, Optional, Any

import pandas as pd
import numpy as np

import customtkinter as ctk
import tkinter as tk
from tkinter import ttk, filedialog, simpledialog, messagebox

import matplotlib
matplotlib.use("TkAgg")
import matplotlib.pyplot as plt
from matplotlib.figure import Figure
from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg
import mplcursors

from openpyxl import load_workbook
from openpyxl.styles import PatternFill, Font, Alignment
from openpyxl.formatting.rule import CellIsRule

# =============================================================================
# CUSTOM ERROR CLASSES
# =============================================================================

class CustomError(Exception):
    """Custom error with an optional error code."""
    def __init__(self, message, error_code=None):
        super().__init__(message)
        self.error_code = error_code

# =============================================================================
# DATACLASS-BASED RULES CONFIGURATION
# =============================================================================

from dataclasses import dataclass

@dataclass
class FilterRule:
    """
    Single filter rule with column name and explicit set of values.
    """
    column: str
    values: Set[str]

    def __init__(self, column: str, values: Union[List[str], Set[str]]):
        self.column = column
        self.values = set(v.strip() for v in values if v.strip())

    def add_value(self, value: str):
        """Add value validation and cleaning."""
        cleaned = value.strip()
        if not cleaned:
            raise ValueError("Empty values not allowed")
        self.values.add(cleaned)

    def remove_value(self, value: str):
        """Handle removal of non-existent values gracefully."""
        try:
            self.values.remove(value.strip())
        except KeyError:
            logging.warning(f"Value '{value}' not found in rule set for column '{self.column}'")

@dataclass
class FilterRules:
    """Rules for filtering data with explicit value sets."""
    keep_rules: List[FilterRule]
    exclude_rules: List[FilterRule]

@dataclass
class CleaningRules:
    """Rules for cleaning and standardizing data."""
    bad_dimensions: List[str]
    bad_attributes: List[str]
    dimension_renames: Dict[str, str]
    attribute_renames: Dict[str, str]

class RulesConfig:
    """Centralized configuration for data processing rules."""
    def __init__(self):
        self.alfa_filters = FilterRules(
            keep_rules=[
                FilterRule("Category", {"Active", "Pending", "InReview"}),
                FilterRule("Status", {"Valid", "InProgress", "New"}),
                FilterRule("Type", {"Standard", "Premium"})
            ],
            exclude_rules=[
                FilterRule("Region", {"Inactive", "Archived", "Deleted"}),
                FilterRule("Flag", {"Debug", "Test", "Development"}),
                FilterRule("Environment", {"Test", "Dev", "UAT"})
            ]
        )
        self.alfa_cleaning = CleaningRules(
            bad_dimensions=["TempDim", "TestDim", "DevDim"],
            bad_attributes=["DebugAttr", "TestAttr", "TempAttr"],
            dimension_renames={
                "OldDimension1": "NewDimension1",
                "LegacyDim": "ModernDim",
                "HistoricalDim": "CurrentDim"
            },
            attribute_renames={
                "OldAttribute1": "NewAttribute1",
                "LegacyAttr": "ModernAttr",
                "HistoricalAttr": "CurrentAttr"
            }
        )
        self.gamma_filters = FilterRules(keep_rules=[], exclude_rules=[])
        self.gamma_cleaning = CleaningRules(
            bad_dimensions=["GammaTestDim", "GammaDevDim"],
            bad_attributes=["GammaTestAttr", "GammaDebugAttr"],
            dimension_renames={
                "GammaOldDim": "GammaNewDim",
                "GammaLegacyDim": "GammaModernDim"
            },
            attribute_renames={
                "GammaOldAttr": "GammaNewAttr",
                "GammaLegacyAttr": "GammaModernAttr"
            }
        )

    def get_alfa_rules(self) -> Tuple[FilterRules, CleaningRules]:
        return self.alfa_filters, self.alfa_cleaning

    def get_gamma_rules(self) -> Tuple[FilterRules, CleaningRules]:
        return self.gamma_filters, self.gamma_cleaning

    def add_alfa_keep_rule(self, column: str, values: Set[str]):
        self.alfa_filters.keep_rules.append(FilterRule(column, values))

    def add_alfa_exclude_rule(self, column: str, values: Set[str]):
        self.alfa_filters.exclude_rules.append(FilterRule(column, values))

RULES = RulesConfig()

# =============================================================================
# DEFAULT PATHS & UI CONFIGURATION
# =============================================================================

DEFAULT_PATHS = {
    "ALFA_PATH": "data/AlfaData.xlsx",
    "GAMMA_PATH": "data/GammaData.zip",
    "EXCEPTION_PATH": "data/Exception_Table.xlsx",
    "OUTPUT_PATH": "output/Missing_Items.xlsx",
    "CONFIG_PATH": "config/reconciliation_config.json",
    "LOG_PATH": "logs/reconciliation.log"
}

DEFAULT_UI_CONFIG = {
    "WINDOW_SIZE": "1400x1000",
    "FONT_FAMILY": "Arial",
    "FONT_SIZES": {"HEADER": 16, "NORMAL": 14, "SMALL": 12},
    "PADDING": {"LARGE": 20, "MEDIUM": 10, "SMALL": 5},
    "COLORS": {
        "PRIMARY": "#2E86C1", "SECONDARY": "#85C1E9",
        "SUCCESS": "#58D68D", "WARNING": "#F4D03F", "ERROR": "#E74C3C"
    }
}

def load_initial_config() -> Tuple[Dict[str, Any], Dict[str, Any]]:
    config_path = Path(DEFAULT_PATHS["CONFIG_PATH"])
    config = {}
    if config_path.exists():
        try:
            with config_path.open("r", encoding="utf-8") as f:
                config = json.load(f)
            logging.info(f"Loaded configuration from {config_path}")
        except Exception as e:
            logging.error(f"Error loading configuration from {config_path}: {e}")
    else:
        logging.info("Configuration file not found; using defaults.")
    paths = config.get("DEFAULT_PATHS", {})
    for key, val in DEFAULT_PATHS.items():
        if key not in paths:
            paths[key] = val
    ui_config = config.get("UI_CONFIG", {})
    for key, val in DEFAULT_UI_CONFIG.items():
        if key not in ui_config:
            ui_config[key] = val
        elif isinstance(val, dict):
            for sub_key, sub_val in val.items():
                if sub_key not in ui_config[key]:
                    ui_config[key][sub_key] = sub_val
    return paths, ui_config

DEFAULT_PATHS, UI_CONFIG = load_initial_config()

# =============================================================================
# LOGGING ENHANCEMENTS
# =============================================================================

def setup_structured_logging():
    try:
        import structlog
        structlog.configure(
            processors=[
                structlog.processors.TimeStamper(fmt="iso"),
                structlog.processors.JSONRenderer()
            ]
        )
        logging.info("Structured logging configured.")
    except ImportError:
        logging.warning("structlog not installed; using standard logging.")

def setup_logging(log_widget: Optional[ctk.CTkTextbox] = None) -> None:
    log_dir = Path(DEFAULT_PATHS["LOG_PATH"]).parent
    log_dir.mkdir(parents=True, exist_ok=True)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    log_file = log_dir / f"reconciliation_{timestamp}.log"
    
    logger = logging.getLogger()
    logger.setLevel(logging.DEBUG)
    logger.handlers.clear()
    
    fh = logging.FileHandler(log_file, mode="w", encoding="utf-8")
    fh.setLevel(logging.DEBUG)
    fh.setFormatter(logging.Formatter("%(asctime)s - %(levelname)s - [%(filename)s:%(lineno)d] - %(message)s"))
    logger.addHandler(fh)
    
    ch = logging.StreamHandler()
    ch.setLevel(logging.INFO)
    ch.setFormatter(logging.Formatter("%(levelname)s: %(message)s"))
    logger.addHandler(ch)
    
    if log_widget:
        gui_handler = TextHandler(log_widget)
        gui_handler.setLevel(logging.INFO)
        gui_handler.setFormatter(logging.Formatter("%(levelname)s: %(message)s"))
        logger.addHandler(gui_handler)
    
    setup_structured_logging()
    logging.info("Logging system initialized")

class TextHandler(logging.Handler):
    def __init__(self, text_widget: ctk.CTkTextbox):
        super().__init__()
        self.text_widget = text_widget
    def emit(self, record: logging.LogRecord):
        msg = self.format(record) + "\n"
        self.text_widget.after(0, self._append, msg)
    def _append(self, msg: str):
        self.text_widget.configure(state="normal")
        self.text_widget.insert("end", msg)
        self.text_widget.see("end")
        self.text_widget.configure(state="disabled")

# =============================================================================
# PERFORMANCE OPTIMIZATIONS
# =============================================================================

@lru_cache(maxsize=1000)
def normalize_key(key: str) -> str:
    return key.strip().lower()

def optimize_dataframe(df: pd.DataFrame) -> pd.DataFrame:
    for col in df.select_dtypes(include=['float']).columns:
        df[col] = pd.to_numeric(df[col], downcast='float')
    for col in df.select_dtypes(include=['int']).columns:
        df[col] = pd.to_numeric(df[col], downcast='integer')
    for col in df.select_dtypes(include=['object']).columns:
        df[col] = df[col].astype('category')
    return df

# =============================================================================
# HELPER FUNCTIONS: FILTERING & CLEANING
# =============================================================================

def filter_alfa_keep_and_disallow(df: pd.DataFrame,
                                  keep_rules: List[FilterRule],
                                  exclude_rules: List[FilterRule]) -> pd.DataFrame:
    df = df.copy()
    if keep_rules:
        keep_mask = pd.Series(False, index=df.index)
        for rule in keep_rules:
            if rule.column in df.columns:
                current_mask = df[rule.column].isin(rule.values)
                keep_mask |= current_mask
                logging.info(f"[ALFA] Applied keep rule on '{rule.column}': {len(rule.values)} values")
        df = df[keep_mask]
    if exclude_rules and not df.empty:
        exclude_mask = pd.Series(False, index=df.index)
        for rule in exclude_rules:
            if rule.column in df.columns:
                current_mask = df[rule.column].isin(rule.values)
                exclude_mask |= current_mask
                logging.info(f"[ALFA] Applied exclude rule on '{rule.column}': {len(rule.values)} values")
        df = df[~exclude_mask]
    return df

def clean_data(df: pd.DataFrame, cleaning_rules: CleaningRules) -> pd.DataFrame:
    df = df.copy()
    if cleaning_rules.dimension_renames:
        df["Dimension"] = df["Dimension"].replace(cleaning_rules.dimension_renames)
    if cleaning_rules.attribute_renames:
        df["Attribute"] = df["Attribute"].replace(cleaning_rules.attribute_renames)
    if cleaning_rules.bad_dimensions:
        df = df[~df["Dimension"].isin(cleaning_rules.bad_dimensions)]
    if cleaning_rules.bad_attributes:
        df = df[~df["Attribute"].isin(cleaning_rules.bad_attributes)]
    return df

# =============================================================================
# FILE HANDLING FOR GAMMA DATA
# =============================================================================

def detect_encoding(file_path: str) -> str:
    try:
        import chardet
    except ImportError:
        logging.warning("chardet module not installed; defaulting to 'utf-8'")
        return "utf-8"
    with open(file_path, 'rb') as f:
        raw = f.read(1024)
    encoding = chardet.detect(raw)['encoding']
    return encoding or "utf-8"

def handle_compressed_file(file_path: str):
    if file_path.endswith('.gz'):
        import gzip
        return gzip.open
    elif file_path.endswith('.zip'):
        return zipfile.ZipFile
    else:
        return open

# =============================================================================
# DATA PROCESSING FUNCTIONS
# =============================================================================

def process_alfa_data(file_path: Path, rules_config: RulesConfig) -> pd.DataFrame:
    filter_rules, cleaning_rules = rules_config.get_alfa_rules()
    logging.info(f"[ALFA] Processing data from {file_path}")
    try:
        df = pd.read_excel(file_path, sheet_name="Sheet1", skiprows=3, engine="openpyxl")
        df.columns = df.columns.str.strip()
        if "Dimension_Name" not in df.columns and len(df.columns) < 3:
            raise ValueError("ALFA file must have at least 3 columns and a 'Dimension_Name' column")
        if "Enabled_Flag" in df.columns:
            df["Enabled_Flag"] = df["Enabled_Flag"].astype(str).str.lower()
        CHUNK_SIZE = 100000
        if len(df) > CHUNK_SIZE:
            chunks = []
            for i in range(0, len(df), CHUNK_SIZE):
                chunk = df.iloc[i:i+CHUNK_SIZE]
                chunk = filter_alfa_keep_and_disallow(chunk, filter_rules.keep_rules, filter_rules.exclude_rules)
                chunks.append(chunk)
            df = pd.concat(chunks, ignore_index=True)
        else:
            df = filter_alfa_keep_and_disallow(df, filter_rules.keep_rules, filter_rules.exclude_rules)
        if "Enabled_Flag" in df.columns:
            df = df[df["Enabled_Flag"] == "enabled"]
        filter_cols = {rule.column for rule in filter_rules.keep_rules} | {rule.column for rule in filter_rules.exclude_rules} | {"Enabled_Flag"}
        df = df.drop(columns=[col for col in filter_cols if col in df.columns])
        if "Dimension_Name" in df.columns:
            df.rename(columns={"Dimension_Name": "Dimension"}, inplace=True)
        else:
            logging.warning("[ALFA] 'Dimension_Name' column not found; using first column as Dimension")
            first_col = df.columns[0]
            df.rename(columns={first_col: "Dimension"}, inplace=True)
        df["RecordID"] = df.index.astype(str)
        id_vars = ["Dimension", "RecordID"]
        value_vars = [col for col in df.columns if col not in id_vars]
        df_melted = df.melt(id_vars=id_vars, value_vars=value_vars, var_name="Attribute", value_name="Value")
        df_cleaned = clean_data(df_melted, cleaning_rules)
        if "Name" in df_cleaned["Attribute"].unique():
            ref_df = df_cleaned[df_cleaned["Attribute"] == "Name"][["RecordID", "Value"]].drop_duplicates("RecordID")
            ref_df.rename(columns={"Value": "RefName"}, inplace=True)
        else:
            ref_df = pd.DataFrame({"RecordID": df["RecordID"], "RefName": ""})
        df_final = df_cleaned.merge(ref_df, on="RecordID", how="left")
        for col in ["Dimension", "Attribute", "Value", "RefName"]:
            df_final[col] = df_final[col].fillna("").astype(str)
        df_final["Name"] = df_final["RefName"]
        df_final["GroupKey"] = df_final["Dimension"].str.strip() + " | " + df_final["RefName"].str.strip()
        df_final["Key"] = (df_final["Dimension"].str.strip() + " | " +
                           df_final["Name"].str.strip() + " | " +
                           df_final["Attribute"].str.strip() + " | " +
                           df_final["Value"].str.strip())
        df_final.drop_duplicates(inplace=True)
        logging.info(f"[ALFA] Processing complete: {len(df_final)} final rows")
        return optimize_dataframe(df_final)
    except Exception as e:
        logging.exception(f"[ALFA] Error processing data: {e}")
        raise

def process_gamma_data(zip_path: Path, rules_config: RulesConfig) -> pd.DataFrame:
    _, cleaning_rules = rules_config.get_gamma_rules()
    logging.info(f"[GAMMA] Processing data from {zip_path}")
    all_dfs = []
    try:
        with zipfile.ZipFile(zip_path, "r") as z:
            txt_files = [f for f in z.namelist() if f.lower().endswith(".txt")]
            if not txt_files:
                logging.warning("[GAMMA] No .txt files found in the ZIP.")
                return pd.DataFrame()
            for txt_file in txt_files:
                try:
                    base_name = os.path.basename(txt_file)
                    if "_ceaster.txt" in base_name:
                        base_name = base_name.replace("_ceaster.txt", "")
                    else:
                        base_name, _ = os.path.splitext(base_name)
                    dimension = base_name.replace("_", " ").strip()
                    encoding = detect_encoding(txt_file)
                    with z.open(txt_file) as fo:
                        df = pd.read_csv(fo, delimiter=",", encoding=encoding).copy(deep=True)
                    if df.empty:
                        logging.warning(f"[GAMMA] '{txt_file}' is empty; skipping.")
                        continue
                    first_col = df.columns[0]
                    df.rename(columns={first_col: "Name"}, inplace=True)
                    df["Name"] = df["Name"].fillna("Unknown").astype(str)
                    df["Dimension"] = dimension
                    df["RecordID"] = df.index.astype(str)
                    id_vars = ["Dimension", "RecordID"]
                    value_vars = [col for col in df.columns if col not in id_vars]
                    df_melted = df.melt(id_vars=id_vars, value_vars=value_vars, var_name="Attribute", value_name="Value")
                    df_cleaned = clean_data(df_melted, cleaning_rules)
                    ref_df = df_cleaned[df_cleaned["Attribute"] == "Name"][["RecordID", "Value"]].drop_duplicates("RecordID")
                    ref_df.rename(columns={"Value": "RefName"}, inplace=True)
                    df_final = df_cleaned.merge(ref_df, on="RecordID", how="left")
                    for col in ["Dimension", "Attribute", "Value", "RefName"]:
                        df_final[col] = df_final[col].fillna("").astype(str)
                    df_final["Name"] = df_final["RefName"]
                    df_final["GroupKey"] = df_final["Dimension"].str.strip() + " | " + df_final["RefName"].str.strip()
                    df_final["Key"] = (df_final["Dimension"].str.strip() + " | " +
                                       df_final["Name"].str.strip() + " | " +
                                       df_final["Attribute"].str.strip() + " | " +
                                       df_final["Value"].str.strip())
                    df_final.drop_duplicates(inplace=True)
                    logging.info(f"[GAMMA] Processed '{txt_file}' with {len(df_final)} final rows.")
                    all_dfs.append(optimize_dataframe(df_final))
                except Exception as e2:
                    logging.error(f"[GAMMA] Error processing '{txt_file}': {e2}")
                    continue
            if all_dfs:
                df_combined = pd.concat(all_dfs, ignore_index=True)
                logging.info(f"[GAMMA] Combined data has {len(df_combined)} rows.")
                return df_combined
            else:
                logging.warning("[GAMMA] No valid data found; returning empty DataFrame.")
                return pd.DataFrame()
    except Exception as e:
        logging.exception(f"[GAMMA] Error reading ZIP file: {e}")
        return pd.DataFrame()

# =============================================================================
# EXCEPTION TABLE HANDLING
# =============================================================================

def read_exception_table(exc_path: Path) -> pd.DataFrame:
    if not exc_path or not exc_path.is_file():
        logging.warning(f"[Exception] Exception file not found: {exc_path}")
        return pd.DataFrame()
    try:
        df = pd.read_excel(exc_path, sheet_name="Sheet1")
        return df.copy(deep=True)
    except Exception as e:
        logging.exception(f"[Exception] Error reading exception table: {e}")
        return pd.DataFrame()

def merge_exceptions(df_diff: pd.DataFrame, df_exceptions: pd.DataFrame) -> pd.DataFrame:
    if df_exceptions.empty:
        return df_diff
    exc_cols = [col for col in df_exceptions.columns if col in {"Key", "Comments_1", "Comments_2", "hide exception"}]
    exc = df_exceptions[exc_cols].copy()
    exc["Key"] = exc["Key"].astype(str).str.strip()
    df_diff = df_diff.merge(exc, on="Key", how="left", suffixes=("", "_exc"))
    df_diff["hide exception"] = df_diff.get("hide exception", "no").fillna("no").str.lower()
    before_len = len(df_diff)
    df_diff = df_diff[df_diff["hide exception"] != "yes"]
    logging.debug(f"[Exception] Excluded {before_len - len(df_diff)} rows due to hidden exception.")
    return df_diff

# =============================================================================
# COMPARISON FUNCTIONS & NORMALIZATION
# =============================================================================

def validate_comparison_data(data: Dict[str, str]) -> None:
    required_fields = {'Name', 'Dimension'}
    if not required_fields.issubset(data.keys()):
        raise ValueError("Data missing required fields")

def normalize_values(value: str) -> str:
    return value.strip().lower()

def compare_mode_1(dimension: str, group_key: str, 
                   alfa_data: Dict[str, str], 
                   gamma_data: Dict[str, str]) -> List[Dict[str, str]]:
    validate_comparison_data(alfa_data)
    validate_comparison_data(gamma_data)
    differences = []
    all_attrs = set(alfa_data.keys()) | set(gamma_data.keys())
    for attr in all_attrs:
        a_val = normalize_values(alfa_data.get(attr, ""))
        g_val = normalize_values(gamma_data.get(attr, ""))
        if a_val != g_val:
            if not a_val and g_val:
                differences.append({
                    "Dimension": dimension,
                    "Name": alfa_data.get("Name", "").strip(),
                    "Attribute": attr,
                    "Value": g_val,
                    "Missing In": "ALFA"
                })
            elif a_val and not g_val:
                differences.append({
                    "Dimension": dimension,
                    "Name": alfa_data.get("Name", "").strip(),
                    "Attribute": attr,
                    "Value": a_val,
                    "Missing In": "GAMMA"
                })
            else:
                differences.extend([
                    {"Dimension": dimension, "Name": alfa_data.get("Name", "").strip(), "Attribute": attr, "Value": a_val, "Missing In": "GAMMA"},
                    {"Dimension": dimension, "Name": alfa_data.get("Name", "").strip(), "Attribute": attr, "Value": g_val, "Missing In": "ALFA"}
                ])
    return differences

def compare_mode_2(dimension: str, group_key: str,
                   alfa_data: Dict[str, str],
                   gamma_data: Dict[str, str]) -> List[Dict[str, str]]:
    validate_comparison_data(alfa_data)
    validate_comparison_data(gamma_data)
    differences = []
    a_name = normalize_values(alfa_data.get("Name", ""))
    g_name = normalize_values(gamma_data.get("Name", ""))
    if a_name and g_name:
        if a_name != g_name:
            differences.extend([
                {"Dimension": dimension, "Name": a_name, "Attribute": "Name", "Value": a_name, "Missing In": "GAMMA"},
                {"Dimension": dimension, "Name": g_name, "Attribute": "Name", "Value": g_name, "Missing In": "ALFA"}
            ])
        else:
            for attr in set(alfa_data.keys()) | set(gamma_data.keys()):
                if attr == "Name":
                    continue
                a_val = normalize_values(alfa_data.get(attr, ""))
                g_val = normalize_values(gamma_data.get(attr, ""))
                if a_val != g_val:
                    if not a_val and g_val:
                        differences.append({"Dimension": dimension, "Name": a_name, "Attribute": attr, "Value": g_val, "Missing In": "ALFA"})
                    elif a_val and not g_val:
                        differences.append({"Dimension": dimension, "Name": a_name, "Attribute": attr, "Value": a_val, "Missing In": "GAMMA"})
                    else:
                        differences.extend([
                            {"Dimension": dimension, "Name": a_name, "Attribute": attr, "Value": a_val, "Missing In": "GAMMA"},
                            {"Dimension": dimension, "Name": a_name, "Attribute": attr, "Value": g_val, "Missing In": "ALFA"}
                        ])
    else:
        if not a_name and g_name:
            differences.append({"Dimension": dimension, "Name": g_name, "Attribute": "Name", "Value": g_name, "Missing In": "ALFA"})
        elif a_name and not g_name:
            differences.append({"Dimension": dimension, "Name": a_name, "Attribute": "Name", "Value": a_name, "Missing In": "GAMMA"})
        else:
            differences.append({"Dimension": dimension, "Name": "", "Attribute": "Name", "Value": "", "Missing In": "Both"})
    return differences

def compare_mode_3(dimension: str, group_key: str,
                   alfa_data: Dict[str, str],
                   gamma_data: Dict[str, str]) -> List[Dict[str, str]]:
    validate_comparison_data(alfa_data)
    validate_comparison_data(gamma_data)
    differences = []
    all_attrs = set(alfa_data.keys()) | set(gamma_data.keys())
    for attr in all_attrs:
        a_val = normalize_values(alfa_data.get(attr, ""))
        g_val = normalize_values(gamma_data.get(attr, ""))
        if a_val == g_val:
            continue
        if not a_val and g_val:
            differences.append({"Dimension": dimension, "Name": normalize_values(alfa_data.get("Name", "")), "Attribute": attr, "Value": g_val, "Missing In": "ALFA"})
        elif a_val and not g_val:
            differences.append({"Dimension": dimension, "Name": normalize_values(alfa_data.get("Name", "")), "Attribute": attr, "Value": a_val, "Missing In": "GAMMA"})
        else:
            differences.extend([
                {"Dimension": dimension, "Name": normalize_values(alfa_data.get("Name", "")), "Attribute": attr, "Value": a_val, "Missing In": "GAMMA"},
                {"Dimension": dimension, "Name": normalize_values(alfa_data.get("Name", "")), "Attribute": attr, "Value": g_val, "Missing In": "ALFA"}
            ])
    return differences

def build_lookup_dict(df: pd.DataFrame) -> Dict[str, Dict[str, str]]:
    lookup = {}
    for group_key, group_df in df.groupby("GroupKey"):
        lookup[group_key] = dict(zip(group_df["Attribute"], group_df["Value"]))
    return lookup

def compare_data(df_alfa: pd.DataFrame,
                 df_gamma: pd.DataFrame,
                 comparison_mode: int = 2) -> pd.DataFrame:
    logging.info(f"Starting data comparison (Mode {comparison_mode})")
    alfa_lookup = build_lookup_dict(df_alfa)
    gamma_lookup = build_lookup_dict(df_gamma)
    all_keys = set(alfa_lookup.keys()) | set(gamma_lookup.keys())
    
    differences = []
    for key in all_keys:
        parts = key.split(" | ")
        dimension = parts[0] if parts else ""
        a_data = alfa_lookup.get(key, {})
        g_data = gamma_lookup.get(key, {})
        if comparison_mode == 1:
            differences.extend(compare_mode_1(dimension, key, a_data, g_data))
        elif comparison_mode == 2:
            differences.extend(compare_mode_2(dimension, key, a_data, g_data))
        elif comparison_mode == 3:
            differences.extend(compare_mode_3(dimension, key, a_data, g_data))
    df_diff = pd.DataFrame(differences)
    if not df_diff.empty:
        df_diff["Key"] = (df_diff["Dimension"].str.strip() + " | " +
                          df_diff["Name"].str.strip() + " | " +
                          df_diff["Attribute"].str.strip() + " | " +
                          df_diff["Value"].str.strip())
    logging.info(f"Comparison complete: {len(df_diff)} differences found")
    return df_diff

# =============================================================================
# EXCEL OUTPUT WITH CONDITIONAL FORMATTING
# =============================================================================

def format_excel_output(path: Path):
    try:
        wb = load_workbook(path)
        ws = wb.active
        header_font = Font(name=UI_CONFIG["FONT_FAMILY"], size=UI_CONFIG["FONT_SIZES"]["NORMAL"], bold=True)
        data_font = Font(name=UI_CONFIG["FONT_FAMILY"], size=UI_CONFIG["FONT_SIZES"]["NORMAL"])
        header_fill = PatternFill(start_color="E0E0E0", end_color="E0E0E0", fill_type="solid")
        for cell in ws[1]:
            cell.font = header_font
            cell.fill = header_fill
            cell.alignment = Alignment(horizontal="center")
        status_colors = {
            'MATCH': 'E2EFDA',
            'MISMATCH': 'FFEB9C',
            'MISSING': 'FFC7CE'
        }
        for status, color in status_colors.items():
            rule = CellIsRule(operator='equal', formula=[f'"{status}"'], stopIfTrue=True,
                              fill=PatternFill(start_color=color, end_color=color, fill_type='solid'))
            ws.conditional_formatting.add("H2:H1000", rule)
        for row in ws.iter_rows(min_row=2):
            for cell in row:
                cell.font = data_font
                cell.alignment = Alignment(horizontal="left")
        for column in ws.columns:
            max_length = 0
            column = list(column)
            for cell in column:
                try:
                    max_length = max(max_length, len(str(cell.value)))
                except Exception:
                    pass
            ws.column_dimensions[column[0].column_letter].width = max_length + 2
        ws.freeze_panes = "A2"
        wb.save(path)
    except Exception as e:
        logging.exception("Error formatting Excel output")
        raise

# =============================================================================
# CONFIGURATION MANAGEMENT
# =============================================================================

def validate_config(config: Dict) -> None:
    required_keys = {'ALFA_PATH', 'GAMMA_PATH'}
    if not all(key in config for key in required_keys):
        raise ValueError("Missing required configuration keys")

def backup_config():
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    backup_path = f'config_backup_{timestamp}.json'
    try:
        config_path = Path(DEFAULT_PATHS["CONFIG_PATH"])
        if config_path.exists():
            with config_path.open('r', encoding='utf-8') as f:
                config = json.load(f)
            with open(backup_path, 'w', encoding='utf-8') as f:
                json.dump(config, f, indent=4)
            logging.info(f"Configuration backed up to {backup_path}")
    except Exception as e:
        logging.error(f"Error backing up configuration: {e}")

# =============================================================================
# TESTING SUPPORT
# =============================================================================

def generate_test_data() -> Tuple[pd.DataFrame, pd.DataFrame]:
    alfa_data = pd.DataFrame({
        "Dimension_Name": ["Dim1", "Dim2"],
        "Category": ["Active", "Pending"],
        "Status": ["Valid", "InProgress"],
        "Type": ["Standard", "Premium"],
        "Enabled_Flag": ["Enabled", "Enabled"],
        "Name": ["Alice", "Bob"],
        "Extra": ["A", "B"]
    })
    gamma_data = pd.DataFrame({
        "Name": ["Alice", "Bob"],
        "Attribute1": ["A1", "B1"],
        "Attribute2": ["A2", "B2"]
    })
    return alfa_data, gamma_data

def validate_results(df: pd.DataFrame):
    if df.duplicated().any():
        logging.warning("Duplicates found in the result data")
    # Additional validations can be added here.

# =============================================================================
# CUSTOM SCROLLABLE FRAME (Modern)
# =============================================================================

class ModernScrollableFrame(ctk.CTkFrame):
    def __init__(self, container, *args, **kwargs):
        super().__init__(container, *args, **kwargs)
        self.canvas = ctk.CTkCanvas(self)
        self.scrollable_frame = ctk.CTkFrame(self.canvas)
        self.vsb = ctk.CTkScrollbar(self, orientation="vertical", command=self.canvas.yview)
        self.hsb = ctk.CTkScrollbar(self, orientation="horizontal", command=self.canvas.xview)
        self.canvas.configure(yscrollcommand=self.vsb.set, xscrollcommand=self.hsb.set)
        self.canvas.grid(row=0, column=0, sticky="nsew")
        self.vsb.grid(row=0, column=1, sticky="ns")
        self.hsb.grid(row=1, column=0, sticky="ew")
        self.canvas.create_window((0, 0), window=self.scrollable_frame, anchor="nw")
        self.bind("<Configure>", lambda e: self.canvas.configure(scrollregion=self.canvas.bbox("all")))
        self.grid_rowconfigure(0, weight=1)
        self.grid_columnconfigure(0, weight=1)
        self.canvas.bind_all("<MouseWheel>", self._on_mousewheel)
    def _on_mousewheel(self, event):
        self.canvas.yview_scroll(int(-1*(event.delta/120)), "units")

# =============================================================================
# MAIN GUI APPLICATION
# =============================================================================

class ReconciliationGUI(ctk.CTk):
    def __init__(self):
        super().__init__()
        self.title("Data Reconciliation Tool")
        self.geometry(UI_CONFIG["WINDOW_SIZE"])
        self.comparison_mode = tk.IntVar(value=2)
        self.current_config = {}
        self.df_differences = None
        self.rules_config = RULES
        self.setup_tabs()
        self.setup_logging()
        self.load_saved_config()
        self.create_tooltips()
        self.add_keyboard_shortcuts()
        self.log_text = ctk.CTkTextbox(self, height=150, font=(UI_CONFIG["FONT_FAMILY"], UI_CONFIG["FONT_SIZES"]["NORMAL"]))
        self.log_text.configure(state="disabled")
        self.log_text.pack(fill="both", padx=10, pady=(0,10))
        setup_logging(log_widget=self.log_text)

    def setup_tabs(self):
        self.tab_view = ctk.CTkTabview(self)
        self.tab_view.pack(fill="both", expand=True, padx=10, pady=10)
        self.tab_view.add("Settings")
        self.tab_view.add("Rules")
        self.tab_view.add("Process")
        self.tab_view.add("Results")
        self.build_settings_tab()
        self.build_rules_tab()
        self.build_process_tab()
        self.build_results_tab()

    def create_singlecol_tree(self, parent: tk.Widget, label_text: str, row: int) -> ttk.Treeview:
        frame = ctk.CTkFrame(parent)
        frame.grid(row=row, column=0, padx=5, pady=5, sticky="nsew")
        ctk.CTkLabel(frame, text=label_text, font=(UI_CONFIG["FONT_FAMILY"], UI_CONFIG["FONT_SIZES"]["HEADER"])).pack(anchor="w")
        tree_frame = ctk.CTkFrame(frame)
        tree_frame.pack(fill="both", expand=True)
        tv = ttk.Treeview(tree_frame, columns=("Value",), show="headings", height=6)
        tv.heading("Value", text="Value")
        tv.column("Value", width=300, anchor="center")
        style = ttk.Style(tv)
        style.configure("Treeview", font=(UI_CONFIG["FONT_FAMILY"], UI_CONFIG["FONT_SIZES"]["NORMAL"]))
        scroll_y = ttk.Scrollbar(tree_frame, orient="vertical", command=tv.yview)
        tv.configure(yscrollcommand=scroll_y.set)
        scroll_y.pack(side="right", fill="y")
        tv.pack(fill="both", expand=True)
        btn_frame = ctk.CTkFrame(frame)
        btn_frame.pack(pady=2)
        ctk.CTkButton(btn_frame, text="Add", command=lambda: self.on_add_singlecol(tv),
                      font=(UI_CONFIG["FONT_FAMILY"], UI_CONFIG["FONT_SIZES"]["NORMAL"])).pack(side="left", padx=2)
        ctk.CTkButton(btn_frame, text="Edit", command=lambda: self.on_edit_item(tv, 1),
                      font=(UI_CONFIG["FONT_FAMILY"], UI_CONFIG["FONT_SIZES"]["NORMAL"])).pack(side="left", padx=2)
        ctk.CTkButton(btn_frame, text="Remove", command=lambda: self.on_remove_item(tv),
                      font=(UI_CONFIG["FONT_FAMILY"], UI_CONFIG["FONT_SIZES"]["NORMAL"])).pack(side="left", padx=2)
        return tv

    def create_twocol_tree(self, parent: tk.Widget, label_text: str, row: int) -> ttk.Treeview:
        frame = ctk.CTkFrame(parent)
        frame.grid(row=row, column=0, padx=5, pady=5, sticky="nsew")
        ctk.CTkLabel(frame, text=label_text, font=(UI_CONFIG["FONT_FAMILY"], UI_CONFIG["FONT_SIZES"]["HEADER"])).pack(anchor="w")
        tree_frame = ctk.CTkFrame(frame)
        tree_frame.pack(fill="both", expand=True)
        tv = ttk.Treeview(tree_frame, columns=("Old", "New"), show="headings", height=6)
        tv.heading("Old", text="Old")
        tv.heading("New", text="New")
        tv.column("Old", width=150, anchor="center")
        tv.column("New", width=150, anchor="center")
        style = ttk.Style(tv)
        style.configure("Treeview", font=(UI_CONFIG["FONT_FAMILY"], UI_CONFIG["FONT_SIZES"]["NORMAL"]))
        scroll_y = ttk.Scrollbar(tree_frame, orient="vertical", command=tv.yview)
        tv.configure(yscrollcommand=scroll_y.set)
        scroll_y.pack(side="right", fill="y")
        tv.pack(fill="both", expand=True)
        btn_frame = ctk.CTkFrame(frame)
        btn_frame.pack(pady=2)
        ctk.CTkButton(btn_frame, text="Add", command=lambda: self.on_add_rename(tv),
                      font=(UI_CONFIG["FONT_FAMILY"], UI_CONFIG["FONT_SIZES"]["NORMAL"])).pack(side="left", padx=2)
        ctk.CTkButton(btn_frame, text="Edit", command=lambda: self.on_edit_item(tv, 2),
                      font=(UI_CONFIG["FONT_FAMILY"], UI_CONFIG["FONT_SIZES"]["NORMAL"])).pack(side="left", padx=2)
        ctk.CTkButton(btn_frame, text="Remove", command=lambda: self.on_remove_item(tv),
                      font=(UI_CONFIG["FONT_FAMILY"], UI_CONFIG["FONT_SIZES"]["NORMAL"])).pack(side="left", padx=2)
        return tv

    def create_keep_tree(self, parent: tk.Widget, label_text: str, row: int) -> ttk.Treeview:
        frame = ctk.CTkFrame(parent)
        frame.grid(row=row, column=0, padx=5, pady=5, sticky="nsew")
        ctk.CTkLabel(frame, text=label_text, font=(UI_CONFIG["FONT_FAMILY"], UI_CONFIG["FONT_SIZES"]["HEADER"])).pack(anchor="w")
        tree_frame = ctk.CTkFrame(frame)
        tree_frame.pack(fill="both", expand=True)
        tv = ttk.Treeview(tree_frame, columns=("Column", "Values"), show="headings", height=6)
        tv.heading("Column", text="Column")
        tv.heading("Values", text="Values")
        tv.column("Column", width=150, anchor="center")
        tv.column("Values", width=150, anchor="center")
        style = ttk.Style(tv)
        style.configure("Treeview", font=(UI_CONFIG["FONT_FAMILY"], UI_CONFIG["FONT_SIZES"]["NORMAL"]))
        scroll_y = ttk.Scrollbar(tree_frame, orient="vertical", command=tv.yview)
        tv.configure(yscrollcommand=scroll_y.set)
        scroll_y.pack(side="right", fill="y")
        tv.pack(fill="both", expand=True)
        btn_frame = ctk.CTkFrame(frame)
        btn_frame.pack(pady=2)
        ctk.CTkButton(btn_frame, text="Add", command=lambda: self.on_add_keep_rule(tv),
                      font=(UI_CONFIG["FONT_FAMILY"], UI_CONFIG["FONT_SIZES"]["NORMAL"])).pack(side="left", padx=2)
        ctk.CTkButton(btn_frame, text="Edit", command=lambda: self.on_edit_item(tv, 2),
                      font=(UI_CONFIG["FONT_FAMILY"], UI_CONFIG["FONT_SIZES"]["NORMAL"])).pack(side="left", padx=2)
        ctk.CTkButton(btn_frame, text="Remove", command=lambda: self.on_remove_item(tv),
                      font=(UI_CONFIG["FONT_FAMILY"], UI_CONFIG["FONT_SIZES"]["NORMAL"])).pack(side="left", padx=2)
        return tv

    def on_add_singlecol(self, tv: ttk.Treeview):
        val = simpledialog.askstring("Add Value", "Enter new value:")
        if val and val.strip():
            tv.insert("", "end", values=(val.strip(),))

    def on_add_rename(self, tv: ttk.Treeview):
        oldval = simpledialog.askstring("Add Rule", "Enter old value:")
        if not oldval or not oldval.strip():
            return
        newval = simpledialog.askstring("Add Rule", f"Enter new value for '{oldval}':")
        if not newval or not newval.strip():
            return
        tv.insert("", "end", values=(oldval.strip(), newval.strip()))

    def on_add_keep_rule(self, tv: ttk.Treeview):
        column = simpledialog.askstring("Add Rule", "Enter column name:")
        if not column or not column.strip():
            return
        values = self.show_value_entry_dialog("Add Values", "Enter values (one per line):")
        if values:
            values_str = ", ".join(sorted(values))
            tv.insert("", "end", values=(column.strip(), values_str))
            self.rules_config.add_alfa_keep_rule(column.strip(), values)

    def show_value_entry_dialog(self, title: str, prompt: str) -> Set[str]:
        dialog = ctk.CTkToplevel(self)
        dialog.title(title)
        dialog.geometry("400x300")
        label = ctk.CTkLabel(dialog, text=prompt)
        label.pack(pady=10)
        text_area = ctk.CTkTextbox(dialog, width=380, height=200)
        text_area.pack(pady=10)
        values = set()
        def on_ok():
            raw_values = text_area.get("1.0", "end-1c").split("\n")
            values.update(v.strip() for v in raw_values if v.strip())
            dialog.destroy()
        ok_button = ctk.CTkButton(dialog, text="OK", command=on_ok)
        ok_button.pack(pady=10)
        dialog.wait_window()
        return values

    def on_remove_item(self, tv: ttk.Treeview):
        for sel in tv.selection():
            tv.delete(sel)

    def on_edit_item(self, tv: ttk.Treeview, num_columns: int):
        selected = tv.selection()
        if not selected:
            return
        item_id = selected[0]
        current_values = tv.item(item_id, "values")
        if num_columns == 1:
            new_val = simpledialog.askstring("Edit Value", "Enter new value:", initialvalue=current_values[0])
            if new_val and new_val.strip():
                tv.item(item_id, values=(new_val.strip(),))
        elif num_columns == 2:
            new_val1 = simpledialog.askstring("Edit Rule", "Enter new first value:", initialvalue=current_values[0])
            new_val2 = simpledialog.askstring("Edit Rule", "Enter new second value:", initialvalue=current_values[1])
            if new_val1 and new_val1.strip() and new_val2 and new_val2.strip():
                tv.item(item_id, values=(new_val1.strip(), new_val2.strip()))

    def populate_defaults(self):
        for val in self.rules_config.alfa_cleaning.bad_dimensions:
            self.tv_alfa_bad_dims.insert("", "end", values=(val,))
        for val in self.rules_config.alfa_cleaning.bad_attributes:
            self.tv_alfa_bad_attrs.insert("", "end", values=(val,))
        for oldv, newv in self.rules_config.alfa_cleaning.dimension_renames.items():
            self.tv_alfa_dim_ren.insert("", "end", values=(oldv, newv))
        for oldv, newv in self.rules_config.alfa_cleaning.attribute_renames.items():
            self.tv_alfa_attr_ren.insert("", "end", values=(oldv, newv))
        for rule in self.rules_config.alfa_filters.keep_rules:
            values_str = ", ".join(sorted(rule.values))
            self.tv_alfa_keep.insert("", "end", values=(rule.column, values_str))
        for rule in self.rules_config.alfa_filters.exclude_rules:
            values_str = ", ".join(sorted(rule.values))
            self.tv_alfa_neg.insert("", "end", values=(rule.column, values_str))
        for val in self.rules_config.gamma_cleaning.bad_dimensions:
            self.tv_gamma_bad_dims.insert("", "end", values=(val,))
        for val in self.rules_config.gamma_cleaning.bad_attributes:
            self.tv_gamma_bad_attrs.insert("", "end", values=(val,))
        for oldv, newv in self.rules_config.gamma_cleaning.dimension_renames.items():
            self.tv_gamma_dim_ren.insert("", "end", values=(oldv, newv))
        for oldv, newv in self.rules_config.gamma_cleaning.attribute_renames.items():
            self.tv_gamma_attr_ren.insert("", "end", values=(oldv, newv))

    def build_settings_tab(self):
        tab = self.tab_view.tab("Settings")
        paths_frame = ctk.CTkFrame(tab)
        paths_frame.pack(fill="x", padx=10, pady=5)
        self.path_entries = {}
        for key in ["ALFA_PATH", "GAMMA_PATH", "EXCEPTION_PATH", "OUTPUT_PATH"]:
            frame = ctk.CTkFrame(paths_frame)
            frame.pack(fill="x", pady=5)
            label = ctk.CTkLabel(frame, text=f"{key.replace('_', ' ')}:", font=(UI_CONFIG["FONT_FAMILY"], UI_CONFIG["FONT_SIZES"]["NORMAL"]))
            label.pack(side="left", padx=5)
            entry = ctk.CTkEntry(frame, width=400, font=(UI_CONFIG["FONT_FAMILY"], UI_CONFIG["FONT_SIZES"]["NORMAL"]))
            entry.insert(0, DEFAULT_PATHS.get(key, ""))
            entry.pack(side="left", padx=5)
            btn = ctk.CTkButton(frame, text="Browse", command=lambda k=key: self.browse_file(k))
            btn.pack(side="left", padx=5)
            self.path_entries[key] = entry

    def build_rules_tab(self):
        tab = self.tab_view.tab("Rules")
        scroll_frame = ModernScrollableFrame(tab)
        scroll_frame.pack(fill="both", expand=True, padx=10, pady=5)
        inner = scroll_frame.scrollable_frame
        self.tv_alfa_bad_dims = self.create_singlecol_tree(inner, "ALFA Bad Dimensions", 0)
        self.tv_alfa_bad_attrs = self.create_singlecol_tree(inner, "ALFA Bad Attributes", 1)
        self.tv_alfa_dim_ren = self.create_twocol_tree(inner, "ALFA Dimension Renames", 2)
        self.tv_alfa_attr_ren = self.create_twocol_tree(inner, "ALFA Attribute Renames", 3)
        self.tv_alfa_keep = self.create_keep_tree(inner, "ALFA Keep Rules (AND)", 4)
        self.tv_alfa_neg = self.create_keep_tree(inner, "ALFA Do Not Keep Rules (OR)", 5)
        self.tv_gamma_bad_dims = self.create_singlecol_tree(inner, "GAMMA Bad Dimensions", 6)
        self.tv_gamma_bad_attrs = self.create_singlecol_tree(inner, "GAMMA Bad Attributes", 7)
        self.tv_gamma_dim_ren = self.create_twocol_tree(inner, "GAMMA Dimension Renames", 8)
        self.tv_gamma_attr_ren = self.create_twocol_tree(inner, "GAMMA Attribute Renames", 9)
        self.populate_defaults()

    def build_process_tab(self):
        tab = self.tab_view.tab("Process")
        mode_frame = ctk.CTkFrame(tab)
        mode_frame.pack(fill="x", padx=10, pady=5)
        ctk.CTkLabel(mode_frame, text="Comparison Mode:", font=(UI_CONFIG["FONT_FAMILY"], UI_CONFIG["FONT_SIZES"]["HEADER"])).pack(pady=5)
        modes = [("All Missing", 1), ("Missing - Name Special", 2), ("Full Comparison", 3)]
        for text, value in modes:
            ctk.CTkRadioButton(mode_frame, text=text, variable=self.comparison_mode, value=value,
                               font=(UI_CONFIG["FONT_FAMILY"], UI_CONFIG["FONT_SIZES"]["NORMAL"])).pack(pady=2)
        progress_frame = ctk.CTkFrame(tab)
        progress_frame.pack(fill="x", padx=10, pady=10)
        self.progress_bar = ctk.CTkProgressBar(progress_frame)
        self.progress_bar.pack(fill="x", padx=20, pady=5)
        self.progress_bar.set(0)
        self.progress_label = ctk.CTkLabel(progress_frame, text="Ready to process", font=(UI_CONFIG["FONT_FAMILY"], UI_CONFIG["FONT_SIZES"]["NORMAL"]))
        self.progress_label.pack(pady=5)
        button_frame = ctk.CTkFrame(tab)
        button_frame.pack(fill="x", padx=10, pady=5)
        ctk.CTkButton(button_frame, text="Run Reconciliation", command=self.run_reconciliation,
                      font=(UI_CONFIG["FONT_FAMILY"], UI_CONFIG["FONT_SIZES"]["NORMAL"])).pack(side="left", padx=5)
        ctk.CTkButton(button_frame, text="Save Results", command=self.save_results,
                      font=(UI_CONFIG["FONT_FAMILY"], UI_CONFIG["FONT_SIZES"]["NORMAL"])).pack(side="left", padx=5)

    def build_results_tab(self):
        tab = self.tab_view.tab("Results")
        self.chart_frame = ModernScrollableFrame(tab)
        self.chart_frame.pack(fill="both", expand=True, padx=10, pady=5)
        self.chart_containers = {
            'dimension': ctk.CTkFrame(self.chart_frame.scrollable_frame),
            'attribute': ctk.CTkFrame(self.chart_frame.scrollable_frame),
            'missing': ctk.CTkFrame(self.chart_frame.scrollable_frame)
        }
        for container in self.chart_containers.values():
            container.pack(fill="x", pady=10)

    def run_reconciliation(self):
        try:
            self.progress_bar.set(0.1)
            self.progress_label.configure(text="Loading ALFA data...")
            self.update()
            df_alfa = process_alfa_data(Path(self.path_entries["ALFA_PATH"].get()), self.rules_config)
            self.progress_bar.set(0.3)
            self.progress_label.configure(text="Loading GAMMA data...")
            self.update()
            df_gamma = process_gamma_data(Path(self.path_entries["GAMMA_PATH"].get()), self.rules_config)
            self.progress_bar.set(0.6)
            self.progress_label.configure(text="Comparing data...")
            self.update()
            df_diff = compare_data(df_alfa, df_gamma, self.comparison_mode.get())
            if not df_diff.empty:
                df_diff["Key"] = (df_diff["Dimension"].str.strip() + " | " +
                                  df_diff["Name"].str.strip() + " | " +
                                  df_diff["Attribute"].str.strip() + " | " +
                                  df_diff["Value"].str.strip())
            exc_path = Path(self.path_entries["EXCEPTION_PATH"].get())
            df_exceptions = read_exception_table(exc_path) if exc_path.exists() else pd.DataFrame()
            df_diff = merge_exceptions(df_diff, df_exceptions)
            if "Action Item" not in df_diff.columns:
                df_diff["Action Item"] = ""
            self.df_differences = df_diff
            self.progress_bar.set(0.8)
            self.progress_label.configure(text="Generating visualizations...")
            self.update()
            self.create_visualizations()
            self.progress_bar.set(1.0)
            self.progress_label.configure(text="Processing complete!")
            self.update()
            self.tab_view.set("Results")
        except Exception as e:
            logging.exception("Error during reconciliation")
            messagebox.showerror("Error", f"An error occurred: {str(e)}")
            self.progress_label.configure(text="Error occurred during processing")

    def create_visualizations(self):
        if self.df_differences is None or self.df_differences.empty:
            logging.warning("No differences to visualize")
            return
        for container in self.chart_containers.values():
            for widget in container.winfo_children():
                widget.destroy()
        dim_counts = self.df_differences["Dimension"].value_counts()
        self.create_bar_chart(self.chart_containers['dimension'], dim_counts, "Differences by Dimension", "Dimension", "Count")
        attr_counts = self.df_differences["Attribute"].value_counts()
        self.create_bar_chart(self.chart_containers['attribute'], attr_counts, "Differences by Attribute", "Attribute", "Count")
        missing_counts = self.df_differences["Missing In"].value_counts()
        self.create_bar_chart(self.chart_containers['missing'], missing_counts, "Differences by Source", "Source", "Count")

    def create_bar_chart(self, container, data, title, xlabel, ylabel):
        fig = Figure(figsize=(12, 6))
        ax = fig.add_subplot(111)
        bars = ax.bar(range(len(data)), data.values, color=UI_CONFIG["COLORS"]["PRIMARY"])
        ax.set_xticks(range(len(data)))
        ax.set_xticklabels(data.index, rotation=45, ha='right')
        ax.set_title(title, pad=20)
        ax.set_xlabel(xlabel)
        ax.set_ylabel(ylabel)
        for bar in bars:
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2., height, f'{int(height):,}', ha='center', va='bottom')
        canvas = FigureCanvasTkAgg(fig, master=container)
        canvas.draw()
        mplcursors.cursor(bars, hover=True)
        canvas.get_tk_widget().pack(fill="both", expand=True)

    def save_results(self):
        if self.df_differences is None or self.df_differences.empty:
            messagebox.showwarning("Warning", "No results to save")
            return
        try:
            output_path = Path(self.path_entries["OUTPUT_PATH"].get())
            output_path.parent.mkdir(parents=True, exist_ok=True)
            final_cols = ["Key", "Dimension", "Name", "Attribute", "Value", "Comments_1", "Comments_2", "Action Item", "Missing In"]
            df_out = self.df_differences.copy()
            for col in final_cols:
                if col not in df_out.columns:
                    df_out[col] = ""
            df_out = df_out[final_cols]
            df_out.to_excel(output_path, index=False)
            format_excel_output(output_path)
            messagebox.showinfo("Success", f"Results saved to {output_path}")
        except Exception as e:
            logging.exception("Error saving results")
            messagebox.showerror("Error", f"Error saving results: {str(e)}")

    def browse_file(self, key: str):
        initial_dir = os.path.dirname(self.path_entries[key].get())
        file_path = filedialog.askopenfilename(initialdir=initial_dir)
        if file_path:
            self.path_entries[key].delete(0, tk.END)
            self.path_entries[key].insert(0, file_path)

    def load_saved_config(self):
        config_path = Path(DEFAULT_PATHS["CONFIG_PATH"])
        try:
            if config_path.exists():
                with config_path.open('r', encoding="utf-8") as f:
                    config = json.load(f)
                logging.info(f"Configuration loaded from {config_path}")
                self.current_config = config
            else:
                logging.info("No configuration file found; using defaults")
        except Exception as e:
            logging.error(f"Error loading configuration: {e}")

    def create_tooltips(self):
        self.tooltip_text = {
            'keep_rules': 'Specify the rules to keep rows based on column values.',
            'exclude_rules': 'Specify the rules to exclude rows based on column values.',
            'Run Reconciliation': 'Start the reconciliation process.',
            'Save Results': 'Save the processed results to an Excel file.'
        }
        # (Implementation of tooltip display is left as an exercise.)

    def add_keyboard_shortcuts(self):
        self.bind('<Control-s>', lambda e: self.save_results())
        self.bind('<Control-r>', lambda e: self.run_reconciliation())

    def setup_logging(self):
        setup_logging()

def main():
    try:
        app = ReconciliationGUI()
        app.mainloop()
    except Exception as e:
        logging.exception("Critical error in main application")
        messagebox.showerror("Critical Error", f"Application encountered a critical error: {str(e)}")

if __name__ == "__main__":
    main()
