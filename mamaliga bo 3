#!/usr/bin/env python3
"""
Ultra-Mega Reconciliation:
 - Use param dictionary: short code => full dimension name internally
 - When generating missing_items.xlsx, rename 'Dimension' -> 'DimFull' and
   'DimCode' -> 'Dimension' so final Dimension = short code in Excel
 - End Date auto-filter: keep only blank or strictly > today's date
 - Two-sheet Excel: 'Mismatch' & 'Case_Differences' (case diffs differ only by letter case)
 - 8-chart dashboard (example for 2 charts in PDF)
 - History double-click => show JSON
 - No user date filters; meltdown does it automatically
 - Fix 'float' -> 'strip' by ensuring we convert date fields to string
"""

import os
import json
import math
import logging
import zipfile
import shutil
import io
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, List, Set, Tuple

import tkinter as tk
from tkinter import ttk, filedialog, messagebox
import customtkinter as ctk

import pandas as pd
import numpy as np

import matplotlib
matplotlib.use("TkAgg")
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg, NavigationToolbar2Tk
from matplotlib.backends.backend_pdf import PdfPages

try:
    import mplcursors
    MPLCURSORS_AVAILABLE = True
except ImportError:
    MPLCURSORS_AVAILABLE = False

from openpyxl import Workbook
from openpyxl.styles import PatternFill, Font, Alignment

logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")

# ----------------------------------------------------------------------------
# CONFIG
# ----------------------------------------------------------------------------
DEFAULT_PATHS = {
    "ERP_EXCEL_PATH": "data/ERP_Config.xlsx",
    "MASTER_ZIP_PATH": "data/Master_Config.zip",
    "EXCEPTION_PATH": "data/Exception_Table.xlsx",
    "OUTPUT_PATH": "output/missing_items.xlsx",
    "CONFIG_PATH": "config/ui_config.json",   # hidden
    "PARAMETER_PATH": "data/parameters.xlsx",
    "MASTER_CSV_OUTPUT": "temp_master_csv",   # hidden
    "PDF_EXPORT_PATH": "output/dashboard_report.pdf",
    "LOGO_PATH": "images/company_logo.png",   # hidden
    "HISTORY_PATH": "history_runs",           # hidden
    "BAND_CHART_JSON_PATH": "data/bollinger_data.json"  # hidden
}

def default_config() -> Dict:
    return {
        "paths": DEFAULT_PATHS.copy(),
        "erp_grid": {"filters": {}},
        "master_grid": {"filters": {}},
        "dashboard": {
            "selected_dims": [],
            "selected_attrs": [],
            "top_n": 10
        }
    }

def load_config(path: Path)-> Dict:
    if path.is_file():
        try:
            with open(path,"r",encoding="utf-8") as f:
                return json.load(f)
        except Exception as e:
            logging.warning(f"Cannot load config => {e}")
    return default_config()

def save_config(cfg: Dict, path: Path):
    path.parent.mkdir(parents=True, exist_ok=True)
    try:
        with open(path,"w",encoding="utf-8") as f:
            json.dump(cfg, f, indent=2)
        logging.info(f"Saved config => {path}")
    except Exception as e:
        logging.error(f"Error saving config => {e}")

# ----------------------------------------------------------------------------
# LOGGER => TEXTBOX
# ----------------------------------------------------------------------------
class TextHandler(logging.Handler):
    def __init__(self, widget: ctk.CTkTextbox):
        super().__init__()
        self.widget= widget
    def emit(self, record):
        msg= self.format(record) + "\n"
        self.widget.after(0, self._append, msg)
    def _append(self, msg):
        self.widget.configure(state="normal")
        self.widget.insert("end", msg)
        self.widget.see("end")
        self.widget.configure(state="disabled")

# ----------------------------------------------------------------------------
# PARAM
# ----------------------------------------------------------------------------
def read_param_file(path: Path)-> Dict[str,object]:
    """
    param["dim_erp_keep"]: which short codes to keep
    param["dim_erp_map"]: short code => full dimension name
    param["dim_master_map"]: filename => full dimension name
    param["attr_erp_map"]: old => new attr
    param["attr_master_map"]: old => new attr
    """
    out= {
        "dim_erp_keep": set(),
        "dim_erp_map": {},
        "dim_master_map": {},
        "attr_erp_map": {},
        "attr_master_map": {}
    }
    if not path.is_file():
        logging.warning(f"Param => not found => {path}")
        return out
    try:
        dim_df= pd.read_excel(path, sheet_name="Dimension Parameters")
        dim_df.columns= dim_df.columns.astype(str).str.strip()

        def s(x): return str(x).strip() if pd.notna(x) else ""

        for _, row in dim_df.iterrows():
            fn= s(row.get("FileName",""))
            vsc= s(row.get("V S C",""))
            dim= s(row.get("Dimension",""))
            erpval= s(row.get("ERP Values",""))
            if erpval.lower()=="x" and vsc and dim:
                out["dim_erp_keep"].add(vsc)
                out["dim_erp_map"][vsc]= dim
            if fn and dim and erpval.lower()=="x":
                out["dim_master_map"][fn]= dim

        attr_df= pd.read_excel(path, sheet_name="Attribute Parameters")
        attr_df.columns= attr_df.columns.astype(str).str.strip()
        for _, row in attr_df.iterrows():
            e_orig= s(row.get("ERP Original Attributes",""))
            m_orig= s(row.get("Master Original Attributes",""))
            final_= s(row.get("Attribute",""))
            onoff=  s(row.get("On/Off",""))
            if onoff.lower()=="x" and final_:
                if e_orig:
                    out["attr_erp_map"][e_orig]= final_
                if m_orig:
                    out["attr_master_map"][m_orig]= final_
        return out
    except Exception as e:
        logging.error(f"Param => {e}")
        return out

# ----------------------------------------------------------------------------
# END DATE FILTER
# ----------------------------------------------------------------------------
def keep_valid_end_date(attr: str, val) -> bool:
    """
    Keep row if attribute != 'End Date', or if 'End Date' => blank or strictly future
    Format => 'YYYY-MM-DD'
    """
    if attr!="End Date":
        return True
    s= str(val).strip()
    if not s:
        return True
    try:
        dt= datetime.strptime(s, "%Y-%m-%d").date()
        return dt> datetime.now().date()
    except:
        return False

def strip_t(val)-> str:
    if pd.isna(val):
        return ""
    s= str(val).strip()
    if "T" in s:
        s= s.split("T")[0]
    return s

# ----------------------------------------------------------------------------
# ERP
# ----------------------------------------------------------------------------
def read_erp_excel(path: Path)-> pd.DataFrame:
    if not path.is_file():
        logging.warning(f"ERP => not found => {path}")
        return pd.DataFrame()
    try:
        df= pd.read_excel(path, skiprows=3)
        df.columns= df.columns.str.strip()
        if "Enabled_Flag" in df.columns:
            df= df[df["Enabled_Flag"]=="Enabled"]
        return df
    except Exception as e:
        logging.error(f"read_erp_excel => {e}")
        return pd.DataFrame()

# ----------------------------------------------------------------------------
# MASTER => unify
# ----------------------------------------------------------------------------
def read_txt_2encodings(raw: bytes)-> pd.DataFrame:
    import io
    for enc in ["utf-8-sig","utf-16-le"]:
        try:
            buf= io.BytesIO(raw)
            df= pd.read_csv(buf, encoding=enc, on_bad_lines="skip", engine="python")
            df.dropna(how="all", axis=0, inplace=True)
            df.dropna(how="all", axis=1, inplace=True)
            df.columns= df.columns.astype(str).str.strip()
            logging.info(f"read_txt_2encodings => ok => {enc}, shape={df.shape}")
            return df
        except Exception as e:
            logging.debug(f"fail => {enc}: {e}")
    logging.error("Could not parse => empty.")
    return pd.DataFrame()

def convert_master_txt_to_csv(zip_path: Path, out_dir: Path)-> List[Path]:
    if not zip_path.is_file():
        logging.warning(f"Master ZIP => not found => {zip_path}")
        return []
    if out_dir.exists():
        shutil.rmtree(out_dir, ignore_errors=True)
    out_dir.mkdir(parents=True, exist_ok=True)
    csvs=[]
    with zipfile.ZipFile(zip_path,"r") as z:
        tfs= [f for f in z.namelist() if f.lower().endswith(".txt")]
        for tf in tfs:
            bname= os.path.basename(tf)
            if not bname:
                continue
            try:
                with z.open(tf) as fo:
                    raw= fo.read()
                df= read_txt_2encodings(raw)
                if df.empty:
                    continue
                df["RawFileName"]= bname
                if "Name" not in df.columns and len(df.columns)>0:
                    c0= df.columns[0]
                    df.rename(columns={c0:"Name"}, inplace=True)
                out_csv= out_dir/(bname.replace(".txt",".csv"))
                df.to_csv(out_csv, index=False, encoding="utf-8")
                csvs.append(out_csv)
            except Exception as e:
                logging.error(f"Master => {tf}: {e}")
    return csvs

def unify_master_csvs(csvs: List[Path])-> pd.DataFrame:
    frames=[]
    for c in csvs:
        if not c.is_file():
            continue
        try:
            df= pd.read_csv(c, encoding="utf-8", on_bad_lines="skip")
            df.columns= df.columns.str.strip()
            frames.append(df)
        except Exception as e:
            logging.error(f"unify_master_csvs => {c}: {e}")
    if frames:
        return pd.concat(frames, ignore_index=True)
    return pd.DataFrame()

# ----------------------------------------------------------------------------
# MELTDOWN => store DimCode=short, Dimension=full
# ----------------------------------------------------------------------------
def meltdown_erp_for_preview(df: pd.DataFrame, param: Dict[str,object])-> pd.DataFrame:
    if "V_S_C" not in df.columns:
        return pd.DataFrame()
    keep= param["dim_erp_keep"]
    dmap= param["dim_erp_map"]
    amap= param["attr_erp_map"]

    df2= df[df["V_S_C"].isin(keep)].copy()
    if df2.empty:
        return pd.DataFrame()

    df2["DimCode"]= df2["V_S_C"]
    df2["Dimension"]= df2["V_S_C"].map(dmap).fillna(df2["V_S_C"])

    skip= {"V_S_C","Enabled_Flag","DimCode","Dimension"}
    idv= ["DimCode","Dimension"]
    if "Value" in df2.columns:
        idv.append("Value")
        skip.add("Value")

    meltdown_cols= [c for c in df2.columns if c not in skip]
    melted= df2.melt(id_vars=idv, value_vars=meltdown_cols,
                     var_name="OrigAttr", value_name="ValX")

    if "Value" in idv:
        melted.rename(columns={"Value":"Name"}, inplace=True)
    else:
        melted["Name"]= ""

    # keep recognized
    melted= melted[melted["OrigAttr"].isin(amap.keys())].copy()
    melted["Attribute"]= melted["OrigAttr"].map(amap)

    # convert date
    def handle_date(a,v):
        s= strip_t(v)
        if a not in ["Start Date","End Date"]:
            return s
        if not s:
            return s
        try:
            dt= datetime.strptime(s, "%Y-%m-%d").date()
            return dt.strftime("%Y-%m-%d")
        except:
            return ""
    melted["Value"]= melted.apply(lambda r: handle_date(r["Attribute"], r["ValX"]), axis=1)

    # filter EndDate not blank/future
    keep_rows=[]
    for _, row in melted.iterrows():
        if keep_valid_end_date(row["Attribute"], row["Value"]):
            keep_rows.append(row)
    out= pd.DataFrame(keep_rows)
    return out[["DimCode","Dimension","Name","Attribute","Value"]]

def meltdown_master_for_preview(df: pd.DataFrame, param: Dict[str,object])-> pd.DataFrame:
    if df.empty or "RawFileName" not in df.columns:
        return pd.DataFrame()
    dmap= param["dim_master_map"]
    amap= param["attr_master_map"]

    df2= df[df["RawFileName"].isin(dmap.keys())].copy()
    if df2.empty:
        return pd.DataFrame()

    df2["DimCode"]= df2["RawFileName"]
    df2["Dimension"]= df2["RawFileName"].map(dmap).fillna(df2["RawFileName"])

    skip= {"RawFileName","DimCode","Dimension"}
    idv= ["DimCode","Dimension"]
    if "Name" in df2.columns:
        idv.append("Name")
        skip.add("Name")

    meltdown_cols= [c for c in df2.columns if c not in skip]
    melted= df2.melt(id_vars=idv, value_vars=meltdown_cols,
                     var_name="OrigAttr", value_name="ValX")

    melted= melted[melted["OrigAttr"].isin(amap.keys())].copy()
    melted["Attribute"]= melted["OrigAttr"].map(amap)

    def handle_date(a,v):
        s= strip_t(v)
        if a not in ["Start Date","End Date"]:
            return s
        if not s:
            return s
        try:
            dt= datetime.strptime(s, "%Y-%m-%d").date()
            return dt.strftime("%Y-%m-%d")
        except:
            return ""
    melted["Value"]= melted.apply(lambda r: handle_date(r["Attribute"], r["ValX"]), axis=1)

    keep_rows=[]
    for _, row in melted.iterrows():
        if keep_valid_end_date(row["Attribute"], row["Value"]):
            keep_rows.append(row)
    out= pd.DataFrame(keep_rows)
    if "Name" not in out.columns:
        out["Name"]= ""
    return out[["DimCode","Dimension","Name","Attribute","Value"]]

def pivot_for_preview(df: pd.DataFrame)-> pd.DataFrame:
    if not df.empty and {"DimCode","Dimension","Name","Attribute"}.issubset(df.columns):
        df= df.drop_duplicates(subset=["DimCode","Dimension","Name","Attribute"])
        try:
            df= df.pivot(index=["DimCode","Dimension","Name"], columns="Attribute", values="Value").reset_index()
        except Exception as e:
            logging.error(f"Pivot => {e}")
    return df

# ----------------------------------------------------------------------------
# COMPARE => Master vs. ERP
# ----------------------------------------------------------------------------
def compare_erp_master(erp_df: pd.DataFrame, mast_df: pd.DataFrame)-> pd.DataFrame:
    """
    erp => [DimCode, Dimension, Name, Attribute, Value=ERP]
    mast=> [DimCode, Dimension, Name, Attribute, Value=Master]
    Compare ignoring case => if differ => GapIn= MASTER or ERP or MISMATCH
    """
    e2= erp_df.copy()
    e2.rename(columns={"Value":"ERP"}, inplace=True)
    m2= mast_df.copy()
    m2.rename(columns={"Value":"Master"}, inplace=True)

    key_cols= ["DimCode","Dimension","Name","Attribute"]
    merged= e2.merge(m2, on=key_cols, how="outer")
    merged["ERP"]= merged["ERP"].fillna("")
    merged["Master"]= merged["Master"].fillna("")

    diff_mask= merged["ERP"].str.upper()!= merged["Master"].str.upper()
    out= merged[diff_mask].copy()

    def gap_func(r):
        e= r["ERP"]
        ma= r["Master"]
        if e and not ma:
            return "MASTER"
        elif ma and not e:
            return "ERP"
        else:
            return "MISMATCH"

    out["Gap In"]= out.apply(gap_func, axis=1)
    out["Comments_1"]= ""
    out["Comments_2"]= ""

    # Key => uppercase of full dimension
    out["Key"]= (
        out["Dimension"].str.upper().str.strip()+" | "+
        out["Name"].str.upper().str.strip()+" | "+
        out["Attribute"].str.upper().str.strip()
    )
    return out[["DimCode","Dimension","Name","Attribute","Master","ERP","Comments_1","Comments_2","Gap In","Key"]]

def separate_case_diffs(df: pd.DataFrame)-> Tuple[pd.DataFrame,pd.DataFrame]:
    """
    Return mismatch, case_only => differ only by letter case
    """
    same_lower= df["Master"].str.lower()== df["ERP"].str.lower()
    diff_actual= df["Master"]!= df["ERP"]
    mask= same_lower & diff_actual
    case_df= df[mask].copy()
    mismatch_df= df[~mask].copy()
    return mismatch_df, case_df

# ----------------------------------------------------------------------------
# EXCEPTIONS
# ----------------------------------------------------------------------------
def read_exception_table(path: Path)-> pd.DataFrame:
    if not path.is_file():
        logging.warning(f"Exception => not found => {path}")
        return pd.DataFrame()
    try:
        df= pd.read_excel(path)
        df.columns= df.columns.astype(str).str.strip()
        return df
    except Exception as e:
        logging.error(f"read_exception_table => {e}")
        return pd.DataFrame()

def merge_exceptions(df: pd.DataFrame, df_exc: pd.DataFrame)-> pd.DataFrame:
    if df.empty or df_exc.empty or "Key" not in df.columns:
        return df
    keep= [c for c in ["Key","Comments_1","Comments_2","hide exception"] if c in df_exc.columns]
    if not keep:
        return df
    exc= df_exc[keep].copy()
    exc["Key"]= exc["Key"].astype(str).str.strip()
    merged= df.merge(exc, on="Key", how="left", suffixes=("","_exc"))
    merged["hide exception"]= merged.get("hide exception","").fillna("").str.lower()
    final= merged[merged["hide exception"]!="yes"].copy()
    if "Comments_1_exc" in final.columns:
        final["Comments_1"]= np.where(final["Comments_1_exc"].notna(), final["Comments_1_exc"], final["Comments_1"])
        final.drop(columns=["Comments_1_exc"], inplace=True)
    if "Comments_2_exc" in final.columns:
        final["Comments_2"]= np.where(final["Comments_2_exc"].notna(), final["Comments_2_exc"], final["Comments_2"])
        final.drop(columns=["Comments_2_exc"], inplace=True)
    if "hide exception" in final.columns:
        final.drop(columns=["hide exception"], inplace=True)
    return final

# ----------------------------------------------------------------------------
# WRITE => 2 sheets => Mismatch + Case_Differences
# ----------------------------------------------------------------------------
def write_two_sheet_excel(mismatch: pd.DataFrame, case_only: pd.DataFrame, out_path: Path):
    """
    We rename 'Dimension' => 'DimFull', and 'DimCode' => 'Dimension'
    so final => short code is shown in final excel 'Dimension' column.
    The columns: Key, Dimension, Name, Attribute, Master, ERP, Comments_1, Comments_2, Gap In
    """
    out_path.parent.mkdir(parents=True, exist_ok=True)
    main_cols= ["Key","Dimension","Name","Attribute","Master","ERP","Comments_1","Comments_2","Gap In"]

    def finalize(df: pd.DataFrame)-> pd.DataFrame:
        dfc= df.copy()
        # rename dimension => short code
        if "Dimension" in dfc.columns and "DimCode" in dfc.columns:
            # store 'Dimension' in 'DimFull'
            # store 'DimCode' in 'Dimension'
            dfc.rename(columns={"Dimension":"DimFull","DimCode":"Dimension"}, inplace=True)
        # ensure columns
        for c in main_cols:
            if c not in dfc.columns:
                dfc[c]= ""
        return dfc[main_cols]

    mismatch_f= finalize(mismatch)
    case_f= finalize(case_only)

    wb= Workbook()
    ws1= wb.active
    ws1.title= "Mismatch"
    ws1.append(main_cols)
    for row in mismatch_f.itertuples(index=False):
        ws1.append(row)

    header_font= Font(bold=True)
    fill= PatternFill(start_color="DDDDDD", end_color="DDDDDD", fill_type="solid")

    for cell in ws1[1]:
        cell.font= header_font
        cell.fill= fill
        cell.alignment= Alignment(horizontal="center")

    for col in ws1.columns:
        mx= 0
        let= col[0].column_letter
        for cell in col:
            val= str(cell.value) if cell.value else ""
            mx= max(mx,len(val))
        ws1.column_dimensions[let].width= mx+2
    ws1.freeze_panes= "A2"

    ws2= wb.create_sheet("Case_Differences")
    ws2.append(main_cols)
    for row in case_f.itertuples(index=False):
        ws2.append(row)
    for cell in ws2[1]:
        cell.font= header_font
        cell.fill= fill
        cell.alignment= Alignment(horizontal="center")
    for col in ws2.columns:
        mx= 0
        let= col[0].column_letter
        for cell in col:
            val= str(cell.value) if cell.value else ""
            mx= max(mx,len(val))
        ws2.column_dimensions[let].width= mx+2
    ws2.freeze_panes= "A2"

    wb.save(out_path)
    logging.info(f"Missing => {out_path}")

# ----------------------------------------------------------------------------
# SIMPLE PREVIEW => no user date filter
# ----------------------------------------------------------------------------
class SimplePreview(ctk.CTkFrame):
    def __init__(self, parent, label: str):
        super().__init__(parent)
        self.label= label
        self.df= pd.DataFrame()
        self.build_toolbar()
        self.build_table()
        self.build_status()

    def build_toolbar(self):
        bar= ctk.CTkFrame(self, corner_radius=10, fg_color="#f0f0f0")
        bar.pack(fill="x", padx=5, pady=5)
        lb= ctk.CTkLabel(bar, text=f"{self.label} Preview",
                         fg_color="#800020", corner_radius=8,
                         text_color="white",
                         font= ctk.CTkFont(size=14, weight="bold"))
        lb.pack(side="left", padx=5)
        ctk.CTkButton(bar, text="ⓘ", width=30, command=self.show_info,
                      fg_color="#800020", hover_color="#a52a2a", text_color="white").pack(side="left", padx=5)

    def show_info(self):
        messagebox.showinfo("Info",f"{self.label} meltdown => no user date filter.\nWe keep future/blank End Date only.")

    def build_table(self):
        ctn= ctk.CTkFrame(self)
        ctn.pack(fill="both", expand=True)
        self.tree= ttk.Treeview(ctn, show="headings")
        vsb= ttk.Scrollbar(ctn, orient="vertical", command=self.tree.yview)
        hsb= ttk.Scrollbar(ctn, orient="horizontal", command=self.tree.xview)
        self.tree.configure(yscrollcommand=vsb.set, xscrollcommand=hsb.set)
        self.tree.grid(row=0, column=0, sticky="nsew")
        vsb.grid(row=0, column=1, sticky="ns")
        hsb.grid(row=1, column=0, sticky="ew")
        ctn.rowconfigure(0, weight=1)
        ctn.columnconfigure(0, weight=1)

    def build_status(self):
        self.status= ctk.CTkLabel(self, text="0 rows", fg_color="#f0f0f0", text_color="black")
        self.status.pack(fill="x")

    def set_data(self, df: pd.DataFrame):
        self.df= df.copy()
        self.refresh()

    def refresh(self):
        for i in self.tree.get_children():
            self.tree.delete(i)
        if self.df.empty:
            self.tree["columns"]=[]
            self.status.configure(text="0 rows")
            return
        cols= list(self.df.columns)
        self.tree["columns"]= cols
        for c in cols:
            self.tree.heading(c, text=c, anchor="w")
            self.tree.column(c, anchor="w", width=150)
        for _, row in self.df.iterrows():
            rowvals= [row[c] for c in cols]
            self.tree.insert("", "end", values=rowvals)
        self.status.configure(text=f"{len(self.df)} rows")

    def get_filtered_df(self)-> pd.DataFrame:
        return self.df.copy()

# ----------------------------------------------------------------------------
# PDF => minimal
# ----------------------------------------------------------------------------
def enable_hover(ax, polar=False):
    if not MPLCURSORS_AVAILABLE:
        return
    c= mplcursors.cursor(ax, hover=True)
    @c.connect("add")
    def on_add(sel):
        xy= sel.target
        if polar and len(xy)==2:
            sel.annotation.set_text(f"{xy[1]:.0f}")
        elif isinstance(xy,(tuple,list)) and len(xy)==2:
            sel.annotation.set_text(f"{xy[1]:.0f}")
        else:
            sel.annotation.set_text(str(xy))

class EnhancedPDFReport:
    def __init__(self, df_current: pd.DataFrame, df_history: pd.DataFrame, cfg: Dict):
        self.df_current= df_current
        self.df_history= df_history
        self.cfg= cfg
        self.logo_path= Path(cfg["paths"].get("LOGO_PATH","images/company_logo.png"))
        self.page_no= 0
        self.W= 11
        self.H= 8.5

    def generate(self)-> Path:
        stamp= datetime.now().strftime("%Y%m%d_%H%M%S")
        outdir= Path("Reconciliation_pdf")
        outdir.mkdir(parents=True, exist_ok=True)
        pdf_path= outdir/f"Reconciliation_{stamp}.pdf"
        with PdfPages(pdf_path) as pdf:
            # cover
            fig= plt.figure(figsize=(self.W,self.H))
            plt.axis("off")
            plt.text(0.5, 0.5, f"Reconciliation => {stamp}", ha="center", fontsize=24, transform=fig.transFigure)
            pdf.savefig(fig)
            plt.close(fig)

            # summary
            fig= plt.figure(figsize=(self.W,self.H))
            plt.axis("off")
            t= len(self.df_current)
            plt.text(0.5, 0.5, f"Mismatches => {t}", ha="center", fontsize=12, transform=fig.transFigure)
            pdf.savefig(fig)
            plt.close(fig)
        logging.info(f"PDF => {pdf_path}")
        return pdf_path

# ----------------------------------------------------------------------------
# HISTORY => double-click => popup
# ----------------------------------------------------------------------------
class HistoryTab(ctk.CTkFrame):
    def __init__(self, parent, hist_dir: Path):
        super().__init__(parent)
        self.hist_dir= hist_dir
        self.build()

    def build(self):
        lb= ctk.CTkLabel(self, text="Reconciliation History", font=("Arial",16))
        lb.pack(pady=5)
        self.tree= ttk.Treeview(self, columns=("File",), show="headings", height=15)
        self.tree.heading("File", text="History File")
        self.tree.pack(fill="both", expand=True, padx=10, pady=10)
        self.tree.bind("<Double-1>", self.on_db_click)
        ref= ctk.CTkButton(self, text="Refresh", command=self.refresh,
                           fg_color="#800020", hover_color="#a52a2a", text_color="white")
        ref.pack(pady=5)
        self.refresh()

    def refresh(self):
        for i in self.tree.get_children():
            self.tree.delete(i)
        if not self.hist_dir.is_dir():
            self.hist_dir.mkdir(parents=True, exist_ok=True)
        fs= sorted(self.hist_dir.glob("*.json"), reverse=True)
        for f in fs:
            self.tree.insert("", "end", values=(f.name,))

    def on_db_click(self, event):
        sel= self.tree.focus()
        if not sel:
            return
        fname= self.tree.item(sel,"values")[0]
        path= self.hist_dir/fname
        if not path.is_file():
            return
        try:
            with open(path,"r",encoding="utf-8") as ff:
                data= ff.read()
            pop= tk.Toplevel(self)
            pop.title(f"Viewing {fname}")
            txt= ctk.CTkTextbox(pop, width=800, height=600)
            txt.pack(fill="both", expand=True)
            txt.insert("end", data)
            txt.configure(state="disabled")
        except Exception as e:
            logging.error(f"history => {e}")

# ----------------------------------------------------------------------------
# ADV DASH => stubs
# ----------------------------------------------------------------------------
class AdvancedDashboard(ctk.CTkFrame):
    def __init__(self, parent, cfg: Dict):
        super().__init__(parent)
        dash= cfg.get("dashboard",{})
        self.selected_dims= set(dash.get("selected_dims",[]))
        self.selected_attrs= set(dash.get("selected_attrs",[]))
        self.top_n= dash.get("top_n",10)
        self.df_current= pd.DataFrame()
        self.df_history= pd.DataFrame()
        top= ctk.CTkScrollableFrame(self, orientation="horizontal", height=60)
        top.pack(fill="x", pady=5)
        self.metric= ctk.CTkLabel(top, text="Metrics: 0 mismatch, 0 dims", width=300)
        self.metric.pack(side="left", padx=5)
        ctk.CTkButton(top, text="Filter Dimension", command=lambda:None,
                      fg_color="#800020", hover_color="#a52a2a", text_color="white").pack(side="left", padx=5)
        ctk.CTkButton(top, text="Filter Attribute", command=lambda:None,
                      fg_color="#800020", hover_color="#a52a2a", text_color="white").pack(side="left", padx=5)
        ctk.CTkButton(top, text="Toggle Top10/All", command=self.toggle_top,
                      fg_color="#800020", hover_color="#a52a2a", text_color="white").pack(side="left", padx=5)

        self.nb= ttk.Notebook(self)
        self.nb.pack(fill="both", expand=True)
        for c in ["Heatmap","Lollipop","Circular","Scatter","Radar","Normal Pie","Normal Bar","Bollinger Chart"]:
            fr= ctk.CTkFrame(self.nb)
            self.nb.add(fr, text=c)

    def toggle_top(self):
        if self.top_n==10:
            self.top_n= None
        else:
            self.top_n= 10
        self.update_data_filters()

    def set_data(self, dfc: pd.DataFrame, dfh: pd.DataFrame):
        self.df_current= dfc.copy()
        self.df_history= dfh.copy()
        self.update_data_filters()

    def update_data_filters(self):
        mism= len(self.df_current)
        dims= self.df_current["Dimension"].nunique() if not self.df_current.empty else 0
        self.metric.configure(text=f"Metrics: {mism} mismatch, {dims} dims")

# ----------------------------------------------------------------------------
# MAIN
# ----------------------------------------------------------------------------
class MainApp(ctk.CTk):
    def __init__(self):
        super().__init__()
        self.title("Ultra-Mega Reconciliation => short code in final xlsx")
        self.geometry("1400x800")
        ctk.set_appearance_mode("light")

        self.protocol("WM_DELETE_WINDOW", self.on_close)
        self.config= load_config(Path(DEFAULT_PATHS["CONFIG_PATH"]))
        self.param= read_param_file(Path(self.config["paths"].get("PARAMETER_PATH", DEFAULT_PATHS["PARAMETER_PATH"])))

        self.history_df= pd.DataFrame()

        self.tabs= ttk.Notebook(self)
        self.tabs.pack(fill="both", expand=True)

        # 1) Paths
        self.tab_paths= ctk.CTkFrame(self.tabs)
        self.build_paths_tab(self.tab_paths)
        self.tabs.add(self.tab_paths, text="Paths")

        # 2) ERP
        self.tab_erp= ctk.CTkFrame(self.tabs)
        self.erp_preview= SimplePreview(self.tab_erp,"ERP")
        self.erp_preview.pack(fill="both", expand=True)
        self.tabs.add(self.tab_erp, text="ERP Preview")

        # 3) MASTER
        self.tab_master= ctk.CTkFrame(self.tabs)
        self.mast_preview= SimplePreview(self.tab_master,"Master")
        self.mast_preview.pack(fill="both", expand=True)
        self.tabs.add(self.tab_master, text="Master Preview")

        # 4) Compare
        self.tab_compare= ctk.CTkFrame(self.tabs)
        self.build_compare_tab(self.tab_compare)
        self.tabs.add(self.tab_compare, text="Compare")

        # 5) Dashboard
        self.dash_tab= AdvancedDashboard(self.tabs, self.config)
        self.tabs.add(self.dash_tab, text="Dashboard")

        # 6) History
        histp= Path(self.config["paths"].get("HISTORY_PATH","history_runs"))
        self.hist_tab= HistoryTab(self.tabs, histp)
        self.tabs.add(self.hist_tab, text="History")

        # logging
        self.log_box= ctk.CTkTextbox(self, height=120)
        self.log_box.pack(fill="both", side="bottom")
        self.log_box.configure(state="disabled")
        handler= TextHandler(self.log_box)
        handler.setLevel(logging.INFO)
        logging.getLogger().addHandler(handler)

        self.temp_dir= Path(self.config["paths"].get("MASTER_CSV_OUTPUT","temp_master_csv"))
        self.temp_dir.mkdir(parents=True, exist_ok=True)

        # load older runs
        self.load_history()

        # meltdown => preview
        self.refresh_erp()
        self.refresh_master()

        ctk.CTkButton(self, text="Close Script", command=self.on_close,
                      fg_color="#800020", hover_color="#a52a2a", text_color="white").pack(pady=5)

        # pass entire hist => dash
        self.dash_tab.set_data(pd.DataFrame(), self.history_df)

    def build_paths_tab(self, parent):
        frm= ctk.CTkFrame(parent)
        frm.pack(fill="both", expand=True, padx=10, pady=10)
        self.erp_var= tk.StringVar(value=self.config["paths"].get("ERP_EXCEL_PATH", DEFAULT_PATHS["ERP_EXCEL_PATH"]))
        self.mast_var= tk.StringVar(value=self.config["paths"].get("MASTER_ZIP_PATH", DEFAULT_PATHS["MASTER_ZIP_PATH"]))
        self.exc_var= tk.StringVar(value=self.config["paths"].get("EXCEPTION_PATH", DEFAULT_PATHS["EXCEPTION_PATH"]))
        self.out_var= tk.StringVar(value=self.config["paths"].get("OUTPUT_PATH", DEFAULT_PATHS["OUTPUT_PATH"]))
        self.par_var= tk.StringVar(value=self.config["paths"].get("PARAMETER_PATH", DEFAULT_PATHS["PARAMETER_PATH"]))
        self.pdf_var= tk.StringVar(value=self.config["paths"].get("PDF_EXPORT_PATH", DEFAULT_PATHS["PDF_EXPORT_PATH"]))

        def mkrow(lbl, var, is_dir=False):
            rowf= ctk.CTkFrame(frm)
            rowf.pack(fill="x", pady=5)
            ctk.CTkLabel(rowf, text=lbl, width=180).pack(side="left", padx=5)
            e= ctk.CTkEntry(rowf, textvariable=var, width=600)
            e.pack(side="left", padx=5)
            def br():
                if is_dir:
                    p= filedialog.askdirectory()
                else:
                    p= filedialog.askopenfilename()
                if p:
                    var.set(p)
            ctk.CTkButton(rowf, text="Browse", command=br,
                          fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)

        mkrow("ERP Excel:", self.erp_var)
        mkrow("Master ZIP:", self.mast_var)
        mkrow("Exception Path:", self.exc_var)
        mkrow("Missing Items Output:", self.out_var)
        mkrow("Parameter File:", self.par_var)
        mkrow("PDF Export Path:", self.pdf_var)

        bf= ctk.CTkFrame(frm)
        bf.pack(fill="x", pady=10)
        ctk.CTkButton(bf, text="Save Config", command=self.save_config,
                      fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)
        ctk.CTkButton(bf, text="Refresh ERP", command=self.refresh_erp,
                      fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)
        ctk.CTkButton(bf, text="Refresh Master", command=self.refresh_master,
                      fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)

    def build_compare_tab(self, parent):
        frm= ctk.CTkFrame(parent)
        frm.pack(fill="both", expand=True, padx=10, pady=10)
        ctk.CTkLabel(frm, text="Generate Missing Items", font=("Arial",16)).pack(pady=5)
        ctk.CTkButton(frm, text="Run Reconciliation", command=self.run_recon,
                      fg_color="#800020", hover_color="#a52a2a").pack(pady=10)
        ctk.CTkButton(frm, text="Export PDF", command=self.export_pdf,
                      fg_color="#800020", hover_color="#a52a2a").pack(pady=10)

    def load_history(self):
        hpath= Path(self.config["paths"].get("HISTORY_PATH","history_runs"))
        if not hpath.is_dir():
            return
        frs=[]
        for jf in hpath.glob("run_*.json"):
            try:
                dfj= pd.read_json(jf, orient="records")
                frs.append(dfj)
            except Exception as e:
                logging.error(f"history => {jf}: {e}")
        if frs:
            cat= pd.concat(frs, ignore_index=True)
            if self.history_df.empty:
                self.history_df= cat
            else:
                self.history_df= pd.concat([self.history_df,cat], ignore_index=True)
            self.history_df.drop_duplicates(inplace=True)
            logging.info(f"Loaded history => total {len(self.history_df)}")

    def refresh_erp(self):
        p= Path(self.erp_var.get().strip())
        raw= read_erp_excel(p)
        if raw.empty:
            self.erp_preview.set_data(pd.DataFrame())
            return
        meltdown= meltdown_erp_for_preview(raw, self.param)
        pivoted= pivot_for_preview(meltdown)
        self.erp_preview.set_data(pivoted)

    def refresh_master(self):
        p= Path(self.mast_var.get().strip())
        csvs= convert_master_txt_to_csv(p, self.temp_dir)
        comb= unify_master_csvs(csvs)
        if comb.empty:
            self.mast_preview.set_data(pd.DataFrame())
            return
        meltdown= meltdown_master_for_preview(comb, self.param)
        pivoted= pivot_for_preview(meltdown)
        self.mast_preview.set_data(pivoted)

    def run_recon(self):
        e_wide= self.erp_preview.get_filtered_df()
        m_wide= self.mast_preview.get_filtered_df()

        erp_long= self.unpivot(e_wide)
        mast_long= self.unpivot(m_wide)

        out= compare_erp_master(erp_long, mast_long)
        exc_path= Path(self.exc_var.get().strip())
        dfe= read_exception_table(exc_path)
        final= merge_exceptions(out, dfe)

        mismatch, case_df= separate_case_diffs(final)

        outp= Path(self.out_var.get().strip())
        write_two_sheet_excel(mismatch, case_df, outp)

        now= datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        mismatch["RunDate"]= now
        case_df["RunDate"]= now
        combo= pd.concat([mismatch, case_df], ignore_index=True)
        self.history_df= pd.concat([self.history_df, combo], ignore_index=True)

        # save
        h_dir= Path(self.config["paths"].get("HISTORY_PATH","history_runs"))
        h_dir.mkdir(parents=True, exist_ok=True)
        run_file= h_dir/f"run_{now.replace(':','-')}.json"
        combo.to_json(run_file, orient="records", indent=2)
        logging.info(f"Saved => {run_file}")

        # dash update
        self.dash_tab.set_data(combo, self.history_df)
        # refresh hist tab
        if hasattr(self.hist_tab, "refresh"):
            self.hist_tab.refresh()

        self.tabs.select(self.dash_tab)
        messagebox.showinfo("Done", f"Missing => {outp}")

    def unpivot(self, df_wide: pd.DataFrame)-> pd.DataFrame:
        if df_wide.empty:
            return pd.DataFrame(columns=["DimCode","Dimension","Name","Attribute","Value"])
        idv= ["DimCode","Dimension","Name"]
        meltdown_cols= [c for c in df_wide.columns if c not in idv]
        melted= df_wide.melt(id_vars=idv, value_vars=meltdown_cols,
                             var_name="Attribute", value_name="Value")
        for c in ["DimCode","Dimension","Name","Attribute","Value"]:
            if c not in melted.columns:
                melted[c]= ""
            melted[c]= melted[c].fillna("").astype(str).str.strip()
        return melted

    def export_pdf(self):
        if self.history_df.empty:
            messagebox.showinfo("No Data","History is empty => no PDF.")
            return
        if "RunDate" in self.history_df.columns:
            last_run= self.history_df["RunDate"].max()
            df_curr= self.history_df[self.history_df["RunDate"]== last_run].copy()
        else:
            df_curr= self.history_df.copy()
        df_hist= self.history_df.copy()
        rep= EnhancedPDFReport(df_curr, df_hist, self.config)
        pdfp= rep.generate()
        messagebox.showinfo("PDF Export", f"PDF => {pdfp}")

    def save_config(self):
        self.config["paths"]["ERP_EXCEL_PATH"]= self.erp_var.get().strip()
        self.config["paths"]["MASTER_ZIP_PATH"]= self.mast_var.get().strip()
        self.config["paths"]["EXCEPTION_PATH"]= self.exc_var.get().strip()
        self.config["paths"]["OUTPUT_PATH"]= self.out_var.get().strip()
        self.config["paths"]["PARAMETER_PATH"]= self.par_var.get().strip()
        self.config["paths"]["PDF_EXPORT_PATH"]= self.pdf_var.get().strip()

        dash= self.config.setdefault("dashboard",{})
        dash["selected_dims"]= list(self.dash_tab.selected_dims)
        dash["selected_attrs"]= list(self.dash_tab.selected_attrs)
        dash["top_n"]= self.dash_tab.top_n

        cfg_p= Path(self.config["paths"].get("CONFIG_PATH","config/ui_config.json"))
        save_config(self.config, cfg_p)
        messagebox.showinfo("Saved","Paths & config saved.")

    def on_close(self):
        self.save_config()
        band= self.config["paths"].get("BAND_CHART_JSON_PATH","")
        if band and not self.history_df.empty and "RunDate" in self.history_df.columns:
            try:
                outp= Path(band)
                date_ct= self.history_df.groupby("RunDate")["Key"].count().reset_index(name="Count")
                date_ct["dt"]= pd.to_datetime(date_ct["RunDate"], errors="coerce")
                date_ct.sort_values("dt", inplace=True)
                date_ct.reset_index(drop=True, inplace=True)
                date_ct["rolling_mean"]= date_ct["Count"].rolling(3, min_periods=1).mean()
                date_ct["rolling_std"]= date_ct["Count"].rolling(3, min_periods=1).std(ddof=0)
                date_ct["upper"]= date_ct["rolling_mean"]+2*date_ct["rolling_std"]
                date_ct["lower"]= date_ct["rolling_mean"]-2*date_ct["rolling_std"]
                date_ct["RunDate"]= date_ct["dt"].dt.strftime("%Y-%m-%d %H:%M:%S")
                date_ct.drop(columns=["dt"], inplace=True)
                date_ct.to_json(outp, orient="records", indent=2)
                logging.info(f"Bollinger => {outp}")
            except Exception as e:
                logging.error(f"Bollinger => {e}")
        self.destroy()


def main():
    app= MainApp()
    app.mainloop()

if __name__=="__main__":
    main()
