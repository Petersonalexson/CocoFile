#!/usr/bin/env python3
"""
Single-file "Ultra-Mega Reconciliation" with:
 - ERP & Master Previews (date filtering on Start/End Date)
 - Compare Tab producing missing_items.xlsx
 - AdvancedDashboard (8 mismatch charts) -> separate from PDF charts
 - EnhancedPDFReport for PDF generation (watermark only on cover)
 - HistoryTab to browse prior JSON runs in a user-editable HISTORY_PATH

Why sets vs. lists?
-------------------
We store filter values in sets for quick membership checks and guaranteed uniqueness.
But JSON doesn't natively support sets, so before saving we convert these sets to lists.
When loading config, we convert them back to sets. 
This keeps our code flexible (fast membership checks) while staying JSON-friendly.
"""

import os
import sys
import json
import math
import logging
import zipfile
import shutil
import io
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, Set, List

import tkinter as tk
from tkinter import ttk, filedialog, messagebox
import customtkinter as ctk

import pandas as pd
import numpy as np

import matplotlib
matplotlib.use("TkAgg")
import matplotlib.pyplot as plt
from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg
from matplotlib.backends.backend_pdf import PdfPages

from openpyxl import Workbook
from openpyxl.styles import PatternFill, Font, Alignment

try:
    import chardet
except ImportError:
    chardet = None

logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")

# ----------------------------------------------------------------------------
# DEFAULT CONFIG & SAVE/LOAD
# ----------------------------------------------------------------------------
DEFAULT_PATHS = {
    "ERP_EXCEL_PATH": "data/ERP_Config.xlsx",
    "MASTER_ZIP_PATH": "data/Master_Config.zip",
    "EXCEPTION_PATH": "data/Exception_Table.xlsx",
    "OUTPUT_PATH": "output/missing_items.xlsx",
    "CONFIG_PATH": "config/ui_config.json",
    "PARAMETER_PATH": "data/parameters.xlsx",
    "MASTER_CSV_OUTPUT": "temp_master_csv",
    "PDF_EXPORT_PATH": "output/pdf_reports",
    "LOGO_PATH": "images/company_logo.png",
    "HISTORY_PATH": "history_runs"
}

def default_config() -> Dict:
    return {
        "paths": DEFAULT_PATHS.copy(),
        "erp_grid": {"filters": {}},
        "master_grid": {"filters": {}},
        "date_filters": {
            "start_date": (datetime.now() - timedelta(days=30)).strftime("%Y-%m-%d"),
            "end_date": datetime.now().strftime("%Y-%m-%d")
        }
    }

def load_config(path: Path) -> Dict:
    """Load config from JSON, or return defaults if file not found/invalid."""
    if path.is_file():
        try:
            with open(path, "r", encoding="utf-8") as f:
                return json.load(f)
        except Exception as e:
            logging.warning(f"Could not load config => {e}")
    return default_config()

def save_config(cfg: Dict, path: Path):
    """
    Before saving, convert any sets -> lists for JSON compatibility.
    Then write the JSON to disk.
    """
    path.parent.mkdir(parents=True, exist_ok=True)
    try:
        # Convert sets->lists in ERP preview filters
        if "erp_grid" in cfg and "filters" in cfg["erp_grid"]:
            newf = {}
            for col, svals in cfg["erp_grid"]["filters"].items():
                newf[col] = list(svals)
            cfg["erp_grid"]["filters"] = newf

        # Convert sets->lists in Master preview filters
        if "master_grid" in cfg and "filters" in cfg["master_grid"]:
            newf = {}
            for col, svals in cfg["master_grid"]["filters"].items():
                newf[col] = list(svals)
            cfg["master_grid"]["filters"] = newf

        with open(path, "w", encoding="utf-8") as f:
            json.dump(cfg, f, indent=2)
        logging.info(f"Saved config to {path}")
    except Exception as e:
        logging.error(f"Error saving config => {e}")

# ----------------------------------------------------------------------------
# LOG HANDLER => direct Python logs to a CTkTextbox
# ----------------------------------------------------------------------------
class TextHandler(logging.Handler):
    def __init__(self, widget: ctk.CTkTextbox):
        super().__init__()
        self.widget = widget
    def emit(self, record):
        msg = self.format(record) + "\n"
        self.widget.after(0, self._append, msg)
    def _append(self, msg):
        self.widget.configure(state="normal")
        self.widget.insert("end", msg)
        self.widget.see("end")
        self.widget.configure(state="disabled")

# ----------------------------------------------------------------------------
# PARAM & MELTDOWN
# ----------------------------------------------------------------------------
def read_param_file(path: Path) -> Dict[str, object]:
    """
    Loads dimension & attribute parameters from two Excel sheets:
     1) "Dimension Parameters"
     2) "Attribute Parameters"
    Returns a dict with "dim_erp_keep", "dim_erp_map", "dim_master_map", "attr_erp_map", "attr_master_map".
    """
    param = {
        "dim_erp_keep": set(),
        "dim_erp_map": {},
        "dim_master_map": {},
        "attr_erp_map": {},
        "attr_master_map": {}
    }
    if not path.is_file():
        logging.warning(f"Param file not found => {path}")
        return param
    try:
        dim_df = pd.read_excel(path, sheet_name="Dimension Parameters")
        dim_df.columns = dim_df.columns.astype(str).str.strip()

        def s(x): return str(x).strip() if pd.notna(x) else ""

        for _, row in dim_df.iterrows():
            fn = s(row.get("FileName",""))
            vsc= s(row.get("V S C",""))
            dim= s(row.get("Dimension",""))
            ev = s(row.get("ERP Values",""))
            if ev.lower()=="x" and vsc and dim:
                param["dim_erp_keep"].add(vsc)
            if vsc and dim:
                param["dim_erp_map"][vsc] = dim
            if fn and dim and ev.lower()=="x":
                param["dim_master_map"][fn] = dim

        attr_df = pd.read_excel(path, sheet_name="Attribute Parameters")
        attr_df.columns = attr_df.columns.astype(str).str.strip()
        for _, row in attr_df.iterrows():
            eorig= s(row.get("ERP Original Attributes",""))
            morig= s(row.get("Master Original Attributes",""))
            final_= s(row.get("Attribute",""))
            onoff= s(row.get("On/Off",""))
            if onoff.lower()=="x" and final_:
                if eorig:
                    param["attr_erp_map"][eorig] = final_
                if morig:
                    param["attr_master_map"][morig] = final_
        return param
    except Exception as e:
        logging.error(f"Error reading param => {e}")
        return param

def meltdown_erp_for_preview(df: pd.DataFrame, param: Dict[str, object]) -> pd.DataFrame:
    """
    - Keep only rows where df["V_S_C"] in param["dim_erp_keep"].
    - rename dimension using param["dim_erp_map"]
    - rename attributes using param["attr_erp_map"]
    - meltdown => columns -> rows, then keep only mapped attributes
    - strip T from Start/End
    """
    keep= param.get("dim_erp_keep", set())
    dmap= param.get("dim_erp_map", {})
    amap= param.get("attr_erp_map", {})
    if "V_S_C" not in df.columns:
        return pd.DataFrame()
    df2= df[df["V_S_C"].isin(keep)].copy()
    if df2.empty:
        return df2
    skip_cols= {"V_S_C","Enabled_Flag"}
    id_vars=[]
    if "Value" in df2.columns:
        id_vars.append("Value")
        skip_cols.add("Value")
    df2["DimRaw"]= df2["V_S_C"]
    skip_cols.add("DimRaw")
    id_vars.insert(0,"DimRaw")

    meltdown_cols= [c for c in df2.columns if c not in skip_cols]
    melted= df2.melt(
        id_vars=id_vars,
        value_vars= meltdown_cols,
        var_name="OrigAttr",
        value_name="ValX"
    )
    def rename_dim(v):
        return dmap.get(v,v)
    melted["Dimension"]= melted["DimRaw"].apply(rename_dim)
    if "Value" in id_vars:
        melted.rename(columns={"Value":"Name"}, inplace=True)
    else:
        melted["Name"]=""
    # only mapped
    melted= melted[melted["OrigAttr"].isin(amap.keys())].copy()
    melted["Attribute"]= melted["OrigAttr"].map(amap)

    def strip_t(x):
        if isinstance(x,str) and "T" in x:
            return x.split("T")[0]
        return x
    melted["Value"]= np.where(
        melted["Attribute"].isin(["Start Date","End Date"]),
        melted["ValX"].apply(strip_t),
        melted["ValX"]
    )
    return melted[["Dimension","Name","Attribute","Value"]]

def meltdown_master_for_preview(df: pd.DataFrame, param: Dict[str, object]) -> pd.DataFrame:
    """
    - Keep rows where df["RawFileName"] in param["dim_master_map"]
    - rename dimension using param["dim_master_map"]
    - rename attributes using param["attr_master_map"]
    """
    keep_map= param.get("dim_master_map", {})
    amap= param.get("attr_master_map", {})
    if df.empty or "RawFileName" not in df.columns:
        return pd.DataFrame()
    df2= df[df["RawFileName"].isin(keep_map.keys())].copy()
    if df2.empty:
        return df2
    df2["DimRaw"]= df2["RawFileName"]
    skip_cols= {"RawFileName","DimRaw"}
    id_vars= ["DimRaw"]
    if "Name" in df2.columns:
        id_vars.append("Name")
        skip_cols.add("Name")
    meltdown_cols= [c for c in df2.columns if c not in skip_cols]
    melted= df2.melt(
        id_vars=id_vars,
        value_vars= meltdown_cols,
        var_name="OrigAttr",
        value_name="ValX"
    )
    def rename_dim(fn):
        return keep_map.get(fn, fn)
    melted["Dimension"]= melted["DimRaw"].apply(rename_dim)
    if "Name" not in melted.columns:
        melted["Name"]=""
    melted= melted[melted["OrigAttr"].isin(amap.keys())].copy()
    melted["Attribute"]= melted["OrigAttr"].map(amap)
    def strip_t(x):
        if isinstance(x,str) and "T" in x:
            return x.split("T")[0]
        return x
    melted["Value"]= np.where(
        melted["Attribute"].isin(["Start Date","End Date"]),
        melted["ValX"].apply(strip_t),
        melted["ValX"]
    )
    return melted[["Dimension","Name","Attribute","Value"]]

def pivot_for_preview(df: pd.DataFrame)-> pd.DataFrame:
    """Pivot meltdown => wide for user preview. Remove duplicates on (Dimension,Name,Attribute)."""
    if df.empty or {"Dimension","Name","Attribute"}.difference(df.columns):
        return df
    df2= df.drop_duplicates(subset=["Dimension","Name","Attribute"]).copy()
    try:
        df2= df2.pivot(index=["Dimension","Name"], columns="Attribute", values="Value").reset_index()
    except Exception as e:
        logging.error(f"Pivot error => {e}")
    return df2

# ----------------------------------------------------------------------------
# MASTER => read from .txt in ZIP
# ----------------------------------------------------------------------------
def read_txt_2encodings(raw: bytes) -> pd.DataFrame:
    """Tries utf-8-sig or utf-16-le to decode raw bytes. Returns DataFrame."""
    import io
    for enc in ["utf-8-sig","utf-16-le"]:
        try:
            buf= io.BytesIO(raw)
            df= pd.read_csv(buf, encoding=enc, on_bad_lines="skip", engine="python")
            df.dropna(how="all", axis=0, inplace=True)
            df.dropna(how="all", axis=1, inplace=True)
            df.columns= df.columns.astype(str).str.strip()
            logging.info(f"[read_txt_2encodings] success => {enc}, shape={df.shape}")
            return df
        except Exception as e:
            logging.debug(f"[read_txt_2encodings] fail => {enc} => {e}")
    logging.error("[read_txt_2encodings] could not parse => empty.")
    return pd.DataFrame()

def convert_master_txt_to_csv(zip_path: Path, out_dir: Path) -> List[Path]:
    """
    1) Unzip all .txt
    2) read each with read_txt_2encodings
    3) put them into .csv in out_dir
    returns list of .csv file paths
    """
    import pandas as pd
    if not zip_path.is_file():
        logging.warning(f"No ZIP => {zip_path}")
        return []
    if out_dir.exists():
        shutil.rmtree(out_dir, ignore_errors=True)
    out_dir.mkdir(parents=True, exist_ok=True)
    csvs=[]
    with zipfile.ZipFile(zip_path,"r") as z:
        txt_files= [f for f in z.namelist() if f.lower().endswith(".txt")]
        for txtf in txt_files:
            base= os.path.basename(txtf)
            if not base:
                continue
            try:
                with z.open(txtf) as fo:
                    raw= fo.read()
                df= read_txt_2encodings(raw)
                if df.empty:
                    continue
                df["RawFileName"]= base
                if "Name" not in df.columns and len(df.columns)>0:
                    firstcol= df.columns[0]
                    df.rename(columns={firstcol:"Name"}, inplace=True)
                out_csv= out_dir / (base.replace(".txt",".csv"))
                df.to_csv(out_csv, index=False, encoding="utf-8")
                csvs.append(out_csv)
            except Exception as e:
                logging.error(f"[Master] error => {txtf} => {e}")
    return csvs

def unify_master_csvs(csvs: List[Path]) -> pd.DataFrame:
    """Combine a list of CSV into one DataFrame."""
    frames=[]
    for cp in csvs:
        if not cp.is_file():
            continue
        try:
            df= pd.read_csv(cp, encoding="utf-8", on_bad_lines="skip")
            df.columns= df.columns.str.strip()
            frames.append(df)
        except Exception as e:
            logging.error(f"unify_master_csvs => {cp} => {e}")
    if frames:
        return pd.concat(frames, ignore_index=True)
    return pd.DataFrame()

# ----------------------------------------------------------------------------
# COMPARE => meltdown => produce missing items
# ----------------------------------------------------------------------------
def melt_back(df: pd.DataFrame)-> pd.DataFrame:
    """Pivoted wide => meltdown => [Dimension, Name, Attribute, Value]."""
    if df.empty or {"Dimension","Name"}.difference(df.columns):
        return pd.DataFrame()
    meltdown_cols= [c for c in df.columns if c not in ("Dimension","Name")]
    melted= df.melt(
        id_vars=["Dimension","Name"],
        value_vars= meltdown_cols,
        var_name="Attribute",
        value_name="Value"
    )
    return melted

def build_keys(df: pd.DataFrame)-> pd.DataFrame:
    """Add Key,GroupKey, plus Comments_x,Missing In columns."""
    df= df.copy()
    for c in ["Dimension","Name","Attribute","Value"]:
        if c not in df.columns:
            df[c]=""
        df[c]= df[c].fillna("").astype(str).str.strip()
    df["GroupKey"]= df["Dimension"]+" | "+df["Name"]
    df["Key"]= df["Dimension"]+" | "+df["Name"]+" | "+df["Attribute"]+" | "+df["Value"]
    df["Comments_1"]=""
    df["Comments_2"]=""
    df["Action Item"]=""
    df["Missing In"]=""
    return df

def compare_mode2(df_erp: pd.DataFrame, df_mast: pd.DataFrame)-> pd.DataFrame:
    """
    We group by GroupKey => compare attributes
    If name on both sides => compare. If mismatch => "Missing In ERP" or "Missing In MASTER"
    If name in one side not the other => missing
    """
    def to_dict(d):
        out={}
        for gk, grp in d.groupby("GroupKey"):
            rec={}
            nm= grp["Name"].iloc[0] if not grp.empty else ""
            rec["Name"]= nm
            for _, row in grp.iterrows():
                rec[row["Attribute"]]= row["Value"]
            out[gk]= rec
        return out
    e_dict= to_dict(df_erp)
    m_dict= to_dict(df_mast)
    all_gk= set(e_dict.keys())| set(m_dict.keys())
    results=[]
    for gk in all_gk:
        dim= gk.split(" | ")[0]
        a_data= e_dict.get(gk,{})
        b_data= m_dict.get(gk,{})
        name_a= a_data.get("Name","")
        name_b= b_data.get("Name","")
        if name_a and name_b and name_a==name_b:
            union_attrs= (set(a_data.keys())| set(b_data.keys()))-{"Name"}
            for at in union_attrs:
                va= a_data.get(at,"")
                vb= b_data.get(at,"")
                if va!=vb:
                    if va and not vb:
                        results.append({"Dimension":dim,"Name":name_a,"Attribute":at,"Value":va,"Missing In":"MASTER"})
                    elif vb and not va:
                        results.append({"Dimension":dim,"Name":name_a,"Attribute":at,"Value":vb,"Missing In":"ERP"})
                    else:
                        results.append({"Dimension":dim,"Name":name_a,"Attribute":at,"Value":va,"Missing In":"MASTER"})
                        results.append({"Dimension":dim,"Name":name_a,"Attribute":at,"Value":vb,"Missing In":"ERP"})
        else:
            # name mismatch => missing in one side
            if name_a and not name_b:
                results.append({"Dimension":dim,"Name":name_a,"Attribute":"Name","Value":name_a,"Missing In":"MASTER"})
            elif name_b and not name_a:
                results.append({"Dimension":dim,"Name":name_b,"Attribute":"Name","Value":name_b,"Missing In":"ERP"})
    df_res= pd.DataFrame(results)
    if not df_res.empty:
        df_res["Key"]= (df_res["Dimension"].str.strip()+" | "+
                        df_res["Name"].str.strip()+" | "+
                        df_res["Attribute"].str.strip()+" | "+
                        df_res["Value"].str.strip())
    return df_res

def read_exception_table(path: Path)-> pd.DataFrame:
    """Loads exception table from XLSX, returns DataFrame with Key, Comments_x, hide exception, etc."""
    if not path.is_file():
        logging.warning(f"Exception table not found => {path}")
        return pd.DataFrame()
    try:
        df= pd.read_excel(path)
        df.columns= df.columns.astype(str).str.strip()
        return df
    except Exception as e:
        logging.error(f"Error reading exception => {e}")
        return pd.DataFrame()

def merge_exceptions(df: pd.DataFrame, df_exc: pd.DataFrame)-> pd.DataFrame:
    """Hide or merge comments from exception table if 'hide exception'=='yes'."""
    if df.empty or df_exc.empty or "Key" not in df.columns:
        return df
    keep= [c for c in ["Key","Comments_1","Comments_2","hide exception"] if c in df_exc.columns]
    if not keep:
        return df
    exc= df_exc[keep].copy()
    exc["Key"]= exc["Key"].astype(str).str.strip()
    merged= df.merge(exc, on="Key", how="left", suffixes=("","_exc"))
    merged["hide exception"]= merged.get("hide exception","").fillna("").str.lower()
    final= merged[merged["hide exception"]!="yes"].copy()
    if "Comments_1_exc" in final.columns:
        final["Comments_1"]= np.where(final["Comments_1_exc"].notna(), final["Comments_1_exc"], final["Comments_1"])
        final.drop(columns=["Comments_1_exc"], inplace=True)
    if "Comments_2_exc" in final.columns:
        final["Comments_2"]= np.where(final["Comments_2_exc"].notna(), final["Comments_2_exc"], final["Comments_2"])
        final.drop(columns=["Comments_2_exc"], inplace=True)
    if "hide exception" in final.columns:
        final.drop(columns=["hide exception"], inplace=True)
    return final

def write_missing_items(df: pd.DataFrame, out_path: Path):
    """
    Writes mismatch data to an Excel 'Missing Items' sheet with auto-sized columns.
    """
    if df.empty:
        logging.info("No missing items => skip writing missing_items.xlsx")
        return
    out_path.parent.mkdir(parents=True, exist_ok=True)
    final_cols= ["Key","Dimension","Name","Attribute","Value","Comments_1","Comments_2","Action Item","Missing In"]
    for c in final_cols:
        if c not in df.columns:
            df[c] = ""
    df= df[final_cols].copy()
    wb= Workbook()
    ws= wb.active
    ws.title= "Missing Items"
    ws.append(final_cols)
    for rowvals in df.itertuples(index=False):
        ws.append(rowvals)
    header_font= Font(bold=True)
    fill= PatternFill(start_color="DDDDDD", end_color="DDDDDD", fill_type="solid")
    for cell in ws[1]:
        cell.font= header_font
        cell.fill= fill
        cell.alignment= Alignment(horizontal="center")
    # autosize
    for col in ws.columns:
        max_len=0
        letter= col[0].column_letter
        for cell in col:
            val= str(cell.value) if cell.value else ""
            max_len= max(max_len, len(val))
        ws.column_dimensions[letter].width= max_len+2
    ws.freeze_panes= "A2"
    wb.save(out_path)
    logging.info(f"Missing items => {out_path}")

# ----------------------------------------------------------------------------
# SIMPLE PREVIEW (with date filter on Start/End Date)
# ----------------------------------------------------------------------------
class SimplePreview(ctk.CTkFrame):
    """
    Show meltdown data for ERP or Master in a wide table. 
    Only "Start Date" / "End Date" are filterable columns.
    """
    FILTERABLE= {"Start Date","End Date"}
    def __init__(self, parent, name: str, filters_dict=None):
        super().__init__(parent)
        self.name= name
        self.df= pd.DataFrame()
        self.filters: Dict[str, Set]= {}
        if filters_dict:
            for col, val_list in filters_dict.items():
                # Convert any list->set
                if isinstance(val_list, list):
                    self.filters[col] = set(val_list)
                else:
                    self.filters[col] = val_list

        self.create_toolbar()
        self.create_table()
        self.create_statusbar()

    def create_toolbar(self):
        bar= ctk.CTkFrame(self, fg_color="#f0f0f0")
        bar.pack(fill="x", padx=5, pady=5)
        ctk.CTkLabel(
            bar, text=f"{self.name} Preview",
            fg_color="#800020", corner_radius=8,
            text_color="white",
            font=ctk.CTkFont(size=14, weight="bold")
        ).pack(side="left", padx=5)
        ctk.CTkButton(
            bar, text="ⓘ", width=30, command=self.show_info,
            fg_color="#800020", hover_color="#a52a2a", text_color="white"
        ).pack(side="left", padx=5)
        ctk.CTkButton(
            bar, text="Clear Date Filters", command=self.clear_filters,
            fg_color="#800020", hover_color="#a52a2a", text_color="white"
        ).pack(side="left", padx=5)

    def show_info(self):
        messagebox.showinfo("Info", f"{self.name} meltdown data. Only Start/End Date columns are filterable.")

    def create_table(self):
        container= ctk.CTkFrame(self)
        container.pack(fill="both", expand=True, padx=5, pady=5)
        self.tree= ttk.Treeview(container, show="headings")
        vsb= ttk.Scrollbar(container, orient="vertical", command=self.tree.yview)
        hsb= ttk.Scrollbar(container, orient="horizontal", command=self.tree.xview)
        self.tree.configure(yscrollcommand=vsb.set, xscrollcommand=hsb.set)
        self.tree.grid(row=0, column=0, sticky="nsew")
        vsb.grid(row=0, column=1, sticky="ns")
        hsb.grid(row=1, column=0, sticky="ew")
        container.rowconfigure(0,weight=1)
        container.columnconfigure(0,weight=1)

    def create_statusbar(self):
        self.status_label= ctk.CTkLabel(self, text="0 rows", fg_color="#f0f0f0", text_color="black")
        self.status_label.pack(fill="x")

    def set_data(self, df: pd.DataFrame):
        self.df= df.copy()
        self.refresh_table()

    def refresh_table(self):
        for i in self.tree.get_children():
            self.tree.delete(i)
        if self.df.empty:
            self.tree["columns"]=[]
            self.status_label.configure(text="0 rows")
            return
        cols= list(self.df.columns)
        self.tree["columns"]= cols
        for c in cols:
            self.tree.heading(c, text=c, anchor="w",
                              command=lambda col=c: self.on_heading_click(col))
            self.tree.column(c, anchor="w", width=150)
        df_f= self.apply_filters()
        for _, row in df_f.iterrows():
            rowvals= [row.get(c,"") for c in cols]
            self.tree.insert("", "end", values=rowvals)
        self.status_label.configure(text=f"{len(df_f)} rows")

    def apply_filters(self)-> pd.DataFrame:
        df_f= self.df.copy()
        for col, allowed in self.filters.items():
            if col in df_f.columns and len(allowed)>0:
                df_f= df_f[df_f[col].isin(allowed)]
        return df_f

    def on_heading_click(self, col_name: str):
        if col_name in self.FILTERABLE:
            self.show_filter_popup(col_name)

    def show_filter_popup(self, col_name: str):
        if self.df.empty or col_name not in self.df.columns:
            return
        popup= tk.Toplevel(self)
        popup.title(f"Filter: {col_name}")
        popup.geometry("300x400")

        frame= ctk.CTkFrame(popup)
        frame.pack(fill="both", expand=True, padx=5, pady=5)
        unique_vals= self.df[col_name].unique()
        display_map={}
        for v in unique_vals:
            if pd.isna(v):
                dsp= "(NaN)"
            elif isinstance(v,str) and not v.strip():
                dsp= "(blank)"
            else:
                dsp= str(v)
            display_map[v]= dsp
        sorted_vals= sorted(display_map.keys(), key=lambda x: display_map[x].lower())
        all_vals= set(sorted_vals)
        curr_filter= self.filters.get(col_name, all_vals)

        selall_var= tk.BooleanVar(value=True)
        def toggle_all():
            check= selall_var.get()
            for vb in var_dict.values():
                vb.set(check)

        ctk.CTkCheckBox(
            frame, text="Select All", variable=selall_var, command=toggle_all,
            fg_color="#800020", hover_color="#a52a2a", text_color="black"
        ).pack(anchor="w", pady=5)

        scroll= ctk.CTkScrollableFrame(frame, width=250, height=250)
        scroll.pack(fill="both", expand=True, padx=5, pady=5)
        var_dict= {}
        for rv in sorted_vals:
            in_filter= rv in curr_filter
            bvar= tk.BooleanVar(value=in_filter)
            var_dict[rv]= bvar
            ctk.CTkCheckBox(scroll, text=display_map[rv], variable=bvar,
                            fg_color="#800020", hover_color="#a52a2a", text_color="black").pack(anchor="w")

        def apply_():
            sel= {rv for rv,vb in var_dict.items() if vb.get()}
            if sel==all_vals or not sel:
                if col_name in self.filters:
                    del self.filters[col_name]
            else:
                self.filters[col_name]= sel
            popup.destroy()
            self.refresh_table()

        bf= ctk.CTkFrame(frame)
        bf.pack(fill="x", pady=5)
        ctk.CTkButton(bf, text="Apply", command=apply_,
                      fg_color="#800020", hover_color="#a52a2a", text_color="white").pack(side="left", padx=5)
        ctk.CTkButton(bf, text="Cancel", command=popup.destroy,
                      fg_color="#800020", hover_color="#a52a2a", text_color="white").pack(side="left", padx=5)

    def clear_filters(self):
        remove_keys=[]
        for k in self.filters:
            if k in self.FILTERABLE:
                remove_keys.append(k)
        for rk in remove_keys:
            del self.filters[rk]
        self.refresh_table()

    def get_filtered_df(self)-> pd.DataFrame:
        return self.apply_filters()

# ----------------------------------------------------------------------------
# ADVANCED DASHBOARD (8 charts)
# ----------------------------------------------------------------------------
class AdvancedDashboard(ctk.CTkFrame):
    """
    8 mismatch charts: Heatmap, Lollipop, Circular, Scatter, Radar, Pie, Bar, Band Chart
    (separate from PDF charts).
    """
    def __init__(self, parent):
        super().__init__(parent)
        self.df_current= pd.DataFrame()
        self.df_history= pd.DataFrame()
        self.selected_dims: Set[str] = set()
        self.selected_attrs: Set[str] = set()
        self.top_n= 10

        # top bar
        topbar= ctk.CTkFrame(self, fg_color="#DDDDDD")
        topbar.pack(fill="x", pady=5)
        self.metric_label= ctk.CTkLabel(topbar, text="Mismatches=0, Dims=0", width=300)
        self.metric_label.pack(side="left", padx=5)

        ctk.CTkButton(topbar, text="Filter Dimension", command=self.show_dimension_filter,
                      fg_color="#800020", hover_color="#a52a2a", text_color="white").pack(side="left", padx=5)
        ctk.CTkButton(topbar, text="Filter Attribute", command=self.show_attribute_filter,
                      fg_color="#800020", hover_color="#a52a2a", text_color="white").pack(side="left", padx=5)

        ctk.CTkButton(topbar, text="Last 7 Days", command=lambda: self.set_quick_range(7),
                      fg_color="#800020", hover_color="#a52a2a", text_color="white").pack(side="left", padx=5)
        ctk.CTkButton(topbar, text="Last 30 Days", command=lambda: self.set_quick_range(30),
                      fg_color="#800020", hover_color="#a52a2a", text_color="white").pack(side="left", padx=5)
        ctk.CTkButton(topbar, text="Last 90 Days", command=lambda: self.set_quick_range(90),
                      fg_color="#800020", hover_color="#a52a2a", text_color="white").pack(side="left", padx=5)
        ctk.CTkButton(topbar, text="All Time", command=lambda: self.set_quick_range(9999),
                      fg_color="#800020", hover_color="#a52a2a", text_color="white").pack(side="left", padx=5)

        self.start_date_var= tk.StringVar(value=(datetime.now()-timedelta(days=30)).strftime("%Y-%m-%d"))
        self.end_date_var= tk.StringVar(value=datetime.now().strftime("%Y-%m-%d"))
        ctk.CTkEntry(topbar, textvariable=self.start_date_var, width=100).pack(side="left", padx=5)
        ctk.CTkEntry(topbar, textvariable=self.end_date_var, width=100).pack(side="left", padx=5)
        ctk.CTkButton(topbar, text="Update Timeline", command=self.update_data_filters,
                      fg_color="#800020", hover_color="#a52a2a", text_color="white").pack(side="left", padx=5)
        ctk.CTkButton(topbar, text="Toggle Top 10 / All", command=self.toggle_top_n,
                      fg_color="#800020", hover_color="#a52a2a", text_color="white").pack(side="left", padx=5)

        self.notebook= ttk.Notebook(self)
        self.notebook.pack(fill="both", expand=True)
        self.frames= {}
        chart_names= ["Heatmap","Lollipop","Circular","Scatter","Radar","Pie","Bar","Band Chart"]
        for lbl in chart_names:
            fr= ctk.CTkFrame(self.notebook)
            fr.pack(fill="both", expand=True)
            self.notebook.add(fr, text=lbl)
            self.frames[lbl]= fr

    def show_dimension_filter(self):
        self.show_filter_popup("Dimension")

    def show_attribute_filter(self):
        self.show_filter_popup("Attribute")

    def set_quick_range(self, days: int):
        if days>9000:
            self.start_date_var.set("1900-01-01")
            self.end_date_var.set("2100-12-31")
        else:
            dt_end= datetime.now()
            dt_start= dt_end - timedelta(days=days)
            self.start_date_var.set(dt_start.strftime("%Y-%m-%d"))
            self.end_date_var.set(dt_end.strftime("%Y-%m-%d"))
        self.update_data_filters()

    def toggle_top_n(self):
        if self.top_n==10:
            self.top_n= None
        else:
            self.top_n= 10
        self.update_data_filters()

    def show_filter_popup(self, col: str):
        base_df= self.df_history if not self.df_history.empty else self.df_current
        if base_df.empty or col not in base_df.columns:
            return
        popup= tk.Toplevel(self)
        popup.title(f"Filter: {col}")
        popup.geometry("300x400")

        frame= ctk.CTkFrame(popup)
        frame.pack(fill="both", expand=True, padx=5, pady=5)

        unique_vals= base_df[col].unique()
        display_map={}
        for v in unique_vals:
            if pd.isna(v):
                dsp= "(NaN)"
            elif isinstance(v,str) and not v.strip():
                dsp= "(blank)"
            else:
                dsp= str(v)
            display_map[v]= dsp
        sorted_vals= sorted(display_map.keys(), key=lambda x: display_map[x].lower())
        if col=="Dimension":
            curr= self.selected_dims
        else:
            curr= self.selected_attrs
        if not curr:
            curr= set(unique_vals)

        selall_var= tk.BooleanVar(value=True)
        def toggle_all():
            check= selall_var.get()
            for vb in var_dict.values():
                vb.set(check)

        ctk.CTkCheckBox(frame, text="Select All", variable=selall_var, command=toggle_all,
                        fg_color="#800020", hover_color="#a52a2a", text_color="black"
        ).pack(anchor="w", pady=5)
        scroll= ctk.CTkScrollableFrame(frame, width=250, height=250)
        scroll.pack(fill="both", expand=True, padx=5, pady=5)
        var_dict={}
        for rv in sorted_vals:
            in_filter= rv in curr
            bvar= tk.BooleanVar(value=in_filter)
            var_dict[rv]= bvar
            ctk.CTkCheckBox(
                scroll, text=display_map[rv], variable=bvar,
                fg_color="#800020", hover_color="#a52a2a", text_color="black"
            ).pack(anchor="w")

        def apply_():
            sel= {rv for rv,vb in var_dict.items() if vb.get()}
            if col=="Dimension":
                self.selected_dims= sel
            else:
                self.selected_attrs= sel
            popup.destroy()
            self.update_data_filters()

        bf= ctk.CTkFrame(frame)
        bf.pack(fill="x", pady=5)
        ctk.CTkButton(
            bf, text="Apply", command=apply_,
            fg_color="#800020", hover_color="#a52a2a", text_color="white"
        ).pack(side="left", padx=5)
        ctk.CTkButton(
            bf, text="Cancel", command=popup.destroy,
            fg_color="#800020", hover_color="#a52a2a", text_color="white"
        ).pack(side="left", padx=5)

    def update_data(self, df_current: pd.DataFrame, df_history: pd.DataFrame):
        self.df_current= df_current.copy()
        self.df_history= df_history.copy()
        self.update_data_filters()

    def update_data_filters(self):
        dfc= self.df_current.copy()
        if not dfc.empty:
            # dimension/attribute filter
            if self.selected_dims:
                dfc= dfc[dfc["Dimension"].isin(self.selected_dims)]
            if self.selected_attrs:
                dfc= dfc[dfc["Attribute"].isin(self.selected_attrs)]
            # date range if "RunDate" present
            if "RunDate" in dfc.columns:
                try:
                    start= datetime.strptime(self.start_date_var.get(), "%Y-%m-%d")
                    end= datetime.strptime(self.end_date_var.get(), "%Y-%m-%d")
                    dfc["RunDate_dt"]= pd.to_datetime(dfc["RunDate"], errors="coerce")
                    dfc= dfc[(dfc["RunDate_dt"]>= start)&(dfc["RunDate_dt"]<= end)]
                except Exception as e:
                    logging.error(f"Date filter => {e}")
        mism= len(dfc)
        dims= dfc["Dimension"].nunique() if not dfc.empty and "Dimension" in dfc.columns else 0
        self.metric_label.configure(text=f"Mismatches={mism}, Dims={dims}")

        # re-plot
        self.plotHeatmap(dfc)
        self.plotLollipop(dfc)
        self.plotCircular(dfc)
        self.plotScatter(dfc)
        self.plotRadar(dfc)
        self.plotPie(dfc)
        self.plotBar(dfc)
        self.plotBandChart(dfc)

    def plot_chart(self, frame, fig):
        for w in frame.winfo_children():
            w.destroy()
        canvas= FigureCanvasTkAgg(fig, master=frame)
        canvas.draw()
        canvas.get_tk_widget().pack(fill="both", expand=True)

    def _limit_if_needed(self, series: pd.Series)-> pd.Series:
        if self.top_n==10:
            return series.head(10)
        else:
            return series

    def plotHeatmap(self, dfc: pd.DataFrame):
        fr= self.frames["Heatmap"]
        for w in fr.winfo_children():
            w.destroy()
        if dfc.empty or "Missing In" not in dfc.columns:
            return
        df_m= dfc[dfc["Missing In"]!=""]
        if df_m.empty or not {"Dimension","Attribute"}.issubset(df_m.columns):
            return
        pivot= df_m.groupby(["Dimension","Attribute"]).size().unstack(fill_value=0)
        if pivot.empty:
            return
        fig, ax= plt.subplots(figsize=(6,5))
        cax= ax.imshow(pivot, aspect="auto", cmap="Blues")
        ax.set_xticks(range(len(pivot.columns)))
        ax.set_xticklabels(pivot.columns, rotation=90)
        ax.set_yticks(range(len(pivot.index)))
        ax.set_yticklabels(pivot.index)
        fig.colorbar(cax, ax=ax)
        ax.set_title("Heatmap: Missing Items")
        self.plot_chart(fr, fig)

    def plotLollipop(self, dfc: pd.DataFrame):
        fr= self.frames["Lollipop"]
        for w in fr.winfo_children():
            w.destroy()
        if dfc.empty:
            return
        df_m= dfc[dfc["Missing In"]!=""]
        if df_m.empty:
            return
        c= df_m["Dimension"].value_counts()
        c= self._limit_if_needed(c)
        if c.empty:
            return
        fig, ax= plt.subplots(figsize=(6,5))
        ax.hlines(y=c.index, xmin=0, xmax=c.values, color="#0072B2")
        ax.plot(c.values, c.index, "o", color="#D55E00")
        ax.set_title("Lollipop: Missing Dimensions")
        ax.set_xlabel("Count")
        self.plot_chart(fr, fig)

    def plotCircular(self, dfc: pd.DataFrame):
        fr= self.frames["Circular"]
        for w in fr.winfo_children():
            w.destroy()
        if dfc.empty:
            return
        df_m= dfc[dfc["Missing In"]!=""]
        if df_m.empty:
            return
        c= df_m["Attribute"].value_counts()
        c= self._limit_if_needed(c)
        if c.empty:
            return
        fig= plt.figure(figsize=(6,6))
        ax= fig.add_subplot(111, polar=True)
        angles= np.linspace(0,2*np.pi,len(c), endpoint=False)
        ax.set_theta_offset(np.pi/2)
        ax.set_theta_direction(-1)
        ax.set_xticks(angles)
        ax.set_xticklabels(c.index, fontsize=9)
        ax.bar(angles, c.values, width=0.3, color="#009E73", alpha=0.8)
        ax.set_title("Circular: Missing Attributes")
        self.plot_chart(fr, fig)

    def plotScatter(self, dfc: pd.DataFrame):
        fr= self.frames["Scatter"]
        for w in fr.winfo_children():
            w.destroy()
        if dfc.empty:
            return
        df_m= dfc[dfc["Missing In"]!=""]
        if df_m.empty:
            return
        c= df_m.groupby("Dimension")["Key"].count().reset_index(name="Count")
        c.sort_values("Count", ascending=False, inplace=True)
        if self.top_n==10:
            c= c.head(10)
        if c.empty:
            return
        fig, ax= plt.subplots(figsize=(6,5))
        xvals= np.arange(len(c))
        yvals= c["Count"].values
        labels= c["Dimension"].values
        ax.scatter(xvals, yvals, color="#CC79A7")
        for i, txt in enumerate(labels):
            ax.text(xvals[i], yvals[i], txt, ha="center", va="bottom", rotation=60)
        ax.set_title("Scatter: Dims by Count")
        ax.set_xticks([])
        ax.set_ylabel("Count")
        self.plot_chart(fr, fig)

    def plotRadar(self, dfc: pd.DataFrame):
        fr= self.frames["Radar"]
        for w in fr.winfo_children():
            w.destroy()
        if dfc.empty:
            return
        df_m= dfc[dfc["Missing In"]!=""]
        if df_m.empty:
            return
        c= df_m["Dimension"].value_counts()
        if self.top_n==10:
            c= c.head(10)
        if c.empty or len(c)<2:
            return
        cat= c.index.tolist()
        val= c.values.tolist()
        angles= np.linspace(0,2*np.pi,len(cat), endpoint=False).tolist()
        angles+= angles[:1]
        val+= val[:1]
        fig= plt.figure(figsize=(6,6))
        ax= fig.add_subplot(111, polar=True)
        ax.set_theta_offset(np.pi/2)
        ax.set_theta_direction(-1)
        ax.set_xticks(angles[:-1])
        ax.set_xticklabels(cat, fontsize=9)
        ax.plot(angles, val, color="#F0E442", linewidth=2)
        ax.fill(angles, val, color="#F0E442", alpha=0.3)
        ax.set_title("Radar: Missing Dims", y=1.08)
        self.plot_chart(fr, fig)

    def plotPie(self, dfc: pd.DataFrame):
        fr= self.frames["Pie"]
        for w in fr.winfo_children():
            w.destroy()
        if dfc.empty:
            return
        df_m= dfc[dfc["Missing In"]!=""]
        if df_m.empty:
            return
        dist= df_m["Missing In"].value_counts()
        fig, ax= plt.subplots(figsize=(5,5))
        ax.pie(dist.values, labels=dist.index, autopct="%.1f%%", startangle=140)
        ax.set_title("Missing In distribution")
        self.plot_chart(fr, fig)

    def plotBar(self, dfc: pd.DataFrame):
        fr= self.frames["Bar"]
        for w in fr.winfo_children():
            w.destroy()
        if dfc.empty:
            return
        df_m= dfc[dfc["Missing In"]!=""]
        if df_m.empty:
            return
        c= df_m["Attribute"].value_counts()
        if self.top_n==10:
            c= c.head(10)
        if c.empty:
            return
        fig, ax= plt.subplots(figsize=(6,4))
        bars= ax.bar(range(len(c)), c.values, color="#D55E00")
        ax.set_xticks(range(len(c)))
        ax.set_xticklabels(c.index, rotation=45, ha="right")
        ax.set_ylabel("Count")
        ax.set_title("Bar: Missing Attributes")
        for bar in bars:
            h= bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2., h, str(int(h)), ha="center", va="bottom")
        plt.tight_layout()
        self.plot_chart(fr, fig)

    def plotBandChart(self, dfc: pd.DataFrame):
        fr= self.frames["Band Chart"]
        for w in fr.winfo_children():
            w.destroy()
        if self.df_history.empty or "RunDate" not in self.df_history.columns:
            return
        date_ct= self.df_history.groupby("RunDate")["Key"].count().reset_index(name="Count")
        date_ct.sort_values("RunDate", inplace=True)
        if date_ct.empty:
            return
        date_ct["Count_min"]= date_ct["Count"]*0.9
        date_ct["Count_max"]= date_ct["Count"]*1.1
        fig, ax= plt.subplots(figsize=(6,4))
        ax.plot(date_ct["RunDate"], date_ct["Count"], color="#009E73", marker="o", label="Missing Count")
        ax.fill_between(date_ct["RunDate"], date_ct["Count_min"], date_ct["Count_max"],
                        color="#009E73", alpha=0.2)
        ax.set_title("Band Chart Over Time")
        ax.set_xlabel("RunDate")
        ax.set_ylabel("Missing Count")
        plt.xticks(rotation=45)
        for i,rowv in date_ct.iterrows():
            ax.text(rowv["RunDate"], rowv["Count"], str(rowv["Count"]), ha="center", va="bottom")
        ax.legend()
        self.plot_chart(fr, fig)

# ----------------------------------------------------------------------------
# PDF REPORT (separate from Dashboard charts)
# ----------------------------------------------------------------------------
class EnhancedPDFReport:
    """
    Minimal PDF logic with watermark on cover only, plus summary & trend pages.
    """
    def __init__(self, df_current: pd.DataFrame, df_history: pd.DataFrame, config: Dict):
        self.df_current= df_current
        self.df_history= df_history
        self.config= config
        self.logo_path= self.config["paths"].get("LOGO_PATH","images/company_logo.png")

    def generate(self)-> Path:
        pdf_path= self._get_outpath()
        with PdfPages(pdf_path) as pdf:
            self._cover_page(pdf)
            self._summary_page(pdf)
            self._trend_page(pdf)
        logging.info(f"PDF => {pdf_path}")
        return pdf_path

    def _get_outpath(self)-> Path:
        base= self.config["paths"].get("PDF_EXPORT_PATH","output/pdf_reports")
        out= Path(base)
        out.mkdir(parents=True, exist_ok=True)
        stamp= datetime.now().strftime("%Y%m%d_%H%M%S")
        return out / f"recon_{stamp}.pdf"

    def _stamp_logo(self, fig):
        if not self.logo_path or not os.path.exists(self.logo_path):
            return
        try:
            import matplotlib.image as mpimg
            img= mpimg.imread(self.logo_path)
            fig.figimage(img, 72, 700, alpha=0.15)
        except Exception as e:
            logging.error(f"Logo => {e}")

    def _cover_page(self, pdf: PdfPages):
        fig= plt.figure(figsize=(8.5,11))
        plt.axis('off')
        self._stamp_logo(fig)
        plt.text(0.5, 0.6, "Ultra-Mega Reconciliation\nPDF Export",
                 ha="center", fontsize=24, transform=fig.transFigure)
        pdf.savefig(fig)
        plt.close(fig)

    def _summary_page(self, pdf: PdfPages):
        fig= plt.figure(figsize=(8.5,11))
        plt.axis('off')
        plt.text(0.5, 0.9, "Reconciliation Summary", ha="center", fontsize=16, transform=fig.transFigure)
        y= 0.75
        if self.df_current.empty:
            plt.text(0.5, y, "No mismatches in current run", ha="center", fontsize=14, transform=fig.transFigure)
        else:
            tot= len(self.df_current)
            e= (self.df_current["Missing In"]=="ERP").sum()
            m= (self.df_current["Missing In"]=="MASTER").sum()
            lines= [
                f"Total: {tot}",
                f"Missing in ERP: {e}",
                f"Missing in Master: {m}"
            ]
            bigtxt= "\n".join(lines)
            plt.text(0.5, y, bigtxt, ha="center", fontsize=14, transform=fig.transFigure)
        pdf.savefig(fig)
        plt.close(fig)

    def _trend_page(self, pdf: PdfPages):
        fig= plt.figure(figsize=(8.5,11))
        plt.axis('off')
        plt.text(0.5, 0.9, "Historical Trend", ha="center", fontsize=16, transform=fig.transFigure)
        if self.df_history.empty or "RunDate" not in self.df_history.columns:
            plt.text(0.5, 0.5, "No history to show", ha="center", fontsize=12, transform=fig.transFigure)
            pdf.savefig(fig)
            plt.close(fig)
            return
        date_ct= self.df_history.groupby("RunDate")["Key"].count().reset_index(name="Count")
        date_ct.sort_values("RunDate", inplace=True)
        ax= fig.add_axes([0.15,0.3,0.7,0.5])
        try:
            date_ct["RunDate_dt"]= pd.to_datetime(date_ct["RunDate"], errors="coerce")
            ax.plot(date_ct["RunDate_dt"], date_ct["Count"], marker="o", color="blue", label="Count")
            ax.set_title("Mismatch Over Time")
            ax.set_xlabel("RunDate")
            ax.set_ylabel("Count")
            plt.xticks(rotation=45)
            ax.legend()
            for i,rowv in date_ct.iterrows():
                ax.text(rowv["RunDate_dt"], rowv["Count"], str(rowv["Count"]), ha="center", va="bottom")
        except Exception as e:
            logging.error(f"PDF Trend => {e}")
        pdf.savefig(fig)
        plt.close(fig)

# ----------------------------------------------------------------------------
# HISTORY TAB => browse JSON
# ----------------------------------------------------------------------------
class HistoryTab(ctk.CTkFrame):
    def __init__(self, parent, hist_dir: Path):
        super().__init__(parent)
        self.hist_dir= hist_dir
        self.tree= None
        self.build_ui()

    def build_ui(self):
        ctk.CTkLabel(self, text="History Runs", font=("Arial",16)).pack(pady=5)
        self.tree= ttk.Treeview(self, columns=("filename",), show="headings", height=15)
        self.tree.heading("filename", text="History File")
        self.tree.pack(fill="both", expand=True, padx=10, pady=10)
        self.tree.bind("<Double-1>", self.on_open)
        ctk.CTkButton(self, text="Refresh", command=self.refresh_list,
                      fg_color="#800020", hover_color="#a52a2a").pack(pady=5)
        self.refresh_list()

    def refresh_list(self):
        for i in self.tree.get_children():
            self.tree.delete(i)
        if not self.hist_dir.is_dir():
            self.hist_dir.mkdir(parents=True, exist_ok=True)
        files= sorted(self.hist_dir.glob("*.json"), reverse=True)
        for f in files:
            self.tree.insert("", "end", values=(f.name,))

    def on_open(self, event):
        sel= self.tree.selection()
        if not sel:
            return
        item_id= sel[0]
        fname= self.tree.item(item_id,"values")[0]
        path= self.hist_dir / fname
        if not path.is_file():
            return
        ans= messagebox.askyesno("History", "Yes => raw JSON, No => summary?")
        with open(path,"r", encoding="utf-8") as f:
            data= json.load(f)
        if ans:
            # raw
            top= tk.Toplevel(self)
            top.title(fname)
            txt= ctk.CTkTextbox(top, width=800, height=600)
            txt.pack(fill="both", expand=True)
            txt.insert("end", json.dumps(data, indent=2))
            txt.configure(state="disabled")
        else:
            # summary
            df= pd.DataFrame(data)
            if df.empty:
                messagebox.showinfo("Summary", "Empty file.")
                return
            lines= [f"Rows: {len(df)}"]
            if "Dimension" in df.columns:
                d= df["Dimension"].value_counts().head(1)
                if not d.empty:
                    lines.append(f"Top Dimension => {d.index[0]} => {d.iloc[0]}")
            messagebox.showinfo("Summary", "\n".join(lines))

# ----------------------------------------------------------------------------
# MAIN APP
# ----------------------------------------------------------------------------
class MainApp(ctk.CTk):
    def __init__(self):
        super().__init__()
        self.title("Ultra-Mega Reconciliation: Full Dashboard")
        self.geometry("1600x900")
        ctk.set_appearance_mode("light")

        # load config & param
        self.config_dict= load_config(Path(DEFAULT_PATHS["CONFIG_PATH"]))
        self.param_dict= read_param_file(Path(self.config_dict["paths"].get("PARAMETER_PATH", DEFAULT_PATHS["PARAMETER_PATH"])))
        self.history_df= pd.DataFrame()

        self.tabs= ttk.Notebook(self)
        self.tabs.pack(fill="both", expand=True)

        # 1) Paths Tab
        self.tab_paths= ctk.CTkFrame(self.tabs)
        self.tabs.add(self.tab_paths, text="Paths")
        self.build_paths_tab(self.tab_paths)

        # 2) ERP Preview
        self.tab_erp= ctk.CTkFrame(self.tabs)
        erp_f= self.config_dict.get("erp_grid",{}).get("filters",{})
        self.erp_preview= SimplePreview(self.tab_erp, "ERP", filters_dict=erp_f)
        self.erp_preview.pack(fill="both", expand=True)
        self.tabs.add(self.tab_erp, text="ERP Preview")

        # 3) Master Preview
        self.tab_master= ctk.CTkFrame(self.tabs)
        mast_f= self.config_dict.get("master_grid",{}).get("filters",{})
        self.master_preview= SimplePreview(self.tab_master, "Master", filters_dict=mast_f)
        self.master_preview.pack(fill="both", expand=True)
        self.tabs.add(self.tab_master, text="Master Preview")

        # 4) Compare
        self.tab_compare= ctk.CTkFrame(self.tabs)
        self.build_compare_tab(self.tab_compare)
        self.tabs.add(self.tab_compare, text="Compare")

        # 5) Dashboard
        self.dashboard_tab= AdvancedDashboard(self.tabs)
        self.tabs.add(self.dashboard_tab, text="Dashboard")

        # 6) History
        hist_path= Path(self.config_dict["paths"].get("HISTORY_PATH","history_runs"))
        self.history_tab= HistoryTab(self.tabs, hist_path)
        self.tabs.add(self.history_tab, text="History")

        # Log area
        self.log_box= ctk.CTkTextbox(self, height=120)
        self.log_box.pack(fill="both")
        self.log_box.configure(state="disabled")
        handler= TextHandler(self.log_box)
        handler.setLevel(logging.INFO)
        logging.getLogger().addHandler(handler)

        # create Master CSV folder
        self.temp_csv= Path(self.config_dict["paths"].get("MASTER_CSV_OUTPUT","temp_master_csv"))
        self.temp_csv.mkdir(parents=True, exist_ok=True)

        # meltdown => previews
        self.refresh_erp()
        self.refresh_master()

        # close button
        ctk.CTkButton(self, text="Close", command=self.quit,
                      fg_color="#800020", hover_color="#a52a2a",
                      text_color="white").pack(pady=5)

    def build_paths_tab(self, parent):
        frm= ctk.CTkFrame(parent)
        frm.pack(fill="both", expand=True, padx=10, pady=10)

        self.erp_var= tk.StringVar(value=self.config_dict["paths"].get("ERP_EXCEL_PATH", DEFAULT_PATHS["ERP_EXCEL_PATH"]))
        self.mast_var= tk.StringVar(value=self.config_dict["paths"].get("MASTER_ZIP_PATH", DEFAULT_PATHS["MASTER_ZIP_PATH"]))
        self.exc_var= tk.StringVar(value=self.config_dict["paths"].get("EXCEPTION_PATH", DEFAULT_PATHS["EXCEPTION_PATH"]))
        self.out_var= tk.StringVar(value=self.config_dict["paths"].get("OUTPUT_PATH", DEFAULT_PATHS["OUTPUT_PATH"]))
        self.cfg_var= tk.StringVar(value=self.config_dict["paths"].get("CONFIG_PATH", DEFAULT_PATHS["CONFIG_PATH"]))
        self.par_var= tk.StringVar(value=self.config_dict["paths"].get("PARAMETER_PATH", DEFAULT_PATHS["PARAMETER_PATH"]))
        self.csv_var= tk.StringVar(value=self.config_dict["paths"].get("MASTER_CSV_OUTPUT", DEFAULT_PATHS["MASTER_CSV_OUTPUT"]))
        self.pdf_var= tk.StringVar(value=self.config_dict["paths"].get("PDF_EXPORT_PATH", DEFAULT_PATHS["PDF_EXPORT_PATH"]))
        self.hist_var= tk.StringVar(value=self.config_dict["paths"].get("HISTORY_PATH", DEFAULT_PATHS["HISTORY_PATH"]))

        def mkrow(lbl, var, is_dir=False):
            rowf= ctk.CTkFrame(frm)
            rowf.pack(fill="x", pady=5)
            ctk.CTkLabel(rowf, text=lbl, width=180).pack(side="left", padx=5)
            e= ctk.CTkEntry(rowf, textvariable=var, width=600)
            e.pack(side="left", padx=5)
            def br():
                if is_dir:
                    p= filedialog.askdirectory()
                else:
                    p= filedialog.askopenfilename()
                if p:
                    var.set(p)
            ctk.CTkButton(rowf, text="Browse", command=br,
                          fg_color="#800020", hover_color="#a52a2a",
                          text_color="white").pack(side="left", padx=5)

        mkrow("ERP Excel:", self.erp_var)
        mkrow("Master ZIP:", self.mast_var)
        mkrow("Exception Path:", self.exc_var)
        mkrow("Missing Items Output:", self.out_var)
        mkrow("JSON Config Path:", self.cfg_var)
        mkrow("Parameter File:", self.par_var)
        mkrow("Master CSV Folder:", self.csv_var, is_dir=True)
        mkrow("PDF Export Folder:", self.pdf_var, is_dir=True)
        mkrow("History Folder:", self.hist_var, is_dir=True)

        bf= ctk.CTkFrame(frm)
        bf.pack(fill="x", pady=10)
        ctk.CTkButton(bf, text="Save Config", command=self.save_all_config,
                      fg_color="#800020", hover_color="#a52a2a",
                      text_color="white").pack(side="left", padx=5)
        ctk.CTkButton(bf, text="Refresh ERP", command=self.refresh_erp,
                      fg_color="#800020", hover_color="#a52a2a",
                      text_color="white").pack(side="left", padx=5)
        ctk.CTkButton(bf, text="Refresh Master", command=self.refresh_master,
                      fg_color="#800020", hover_color="#a52a2a",
                      text_color="white").pack(side="left", padx=5)

    def build_compare_tab(self, parent):
        frm= ctk.CTkFrame(parent)
        frm.pack(fill="both", expand=True, padx=10, pady=10)
        ctk.CTkLabel(frm, text="Generate Missing Items", font=("Arial",16)).pack(pady=5)
        ctk.CTkButton(frm, text="Run Reconciliation", command=self.run_comparison,
                      fg_color="#800020", hover_color="#a52a2a",
                      text_color="white").pack(pady=10)
        ctk.CTkButton(frm, text="Export PDF Report",
                      command=self.export_pdf,
                      fg_color="#800020", hover_color="#a52a2a",
                      text_color="white").pack(pady=10)

    def refresh_erp(self):
        ep= Path(self.erp_var.get().strip())
        raw_erp= self.read_erp_excel(ep)
        if raw_erp.empty:
            self.erp_preview.set_data(pd.DataFrame())
            return
        param= self.param_dict
        erp_m= meltdown_erp_for_preview(raw_erp,{
            "dim_erp_keep": param.get("dim_erp_keep", set()),
            "dim_erp_map": param.get("dim_erp_map", {}),
            "attr_erp_map": param.get("attr_erp_map", {})
        })
        pivoted= pivot_for_preview(erp_m)
        self.erp_preview.set_data(pivoted)

    def read_erp_excel(self, path: Path)-> pd.DataFrame:
        """Helper to read ERP Excel skipping 3 rows, keep only Enabled."""
        if not path.is_file():
            logging.warning(f"ERP Excel not found => {path}")
            return pd.DataFrame()
        try:
            df= pd.read_excel(path, skiprows=3)
            df.columns= df.columns.str.strip()
            if "Enabled_Flag" in df.columns:
                df= df[df["Enabled_Flag"]=="Enabled"]
            return df
        except Exception as e:
            logging.error(f"ERP read => {e}")
            return pd.DataFrame()

    def refresh_master(self):
        zip_path= Path(self.mast_var.get().strip())
        out_dir= Path(self.csv_var.get().strip())
        csvs= convert_master_txt_to_csv(zip_path, out_dir)
        raw_m= unify_master_csvs(csvs)
        if raw_m.empty:
            self.master_preview.set_data(pd.DataFrame())
            return
        param= self.param_dict
        mast_m= meltdown_master_for_preview(raw_m, {
            "dim_master_map": param.get("dim_master_map", {}),
            "attr_master_map": param.get("attr_master_map", {})
        })
        pivoted= pivot_for_preview(mast_m)
        self.master_preview.set_data(pivoted)

    def run_comparison(self):
        df_erp_wide= self.erp_preview.get_filtered_df()
        df_mast_wide= self.master_preview.get_filtered_df()
        erp_long= melt_back(df_erp_wide)
        erp_long= build_keys(erp_long)
        mast_long= melt_back(df_mast_wide)
        mast_long= build_keys(mast_long)

        df_diff= compare_mode2(erp_long, mast_long)
        exc_path= Path(self.exc_var.get().strip())
        df_exc= read_exception_table(exc_path)
        final= merge_exceptions(df_diff, df_exc)

        out_path= Path(self.out_var.get().strip())
        write_missing_items(final, out_path)

        run_time= datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        final["RunDate"]= run_time
        if self.history_df.empty:
            self.history_df= final.copy()
        else:
            self.history_df= pd.concat([self.history_df, final], ignore_index=True)

        # also store in JSON
        hist_dir= Path(self.hist_var.get().strip())
        hist_dir.mkdir(parents=True, exist_ok=True)
        fname= f"run_{run_time.replace(':','-').replace(' ','_')}.json"
        try:
            final.to_json(hist_dir/fname, orient="records", indent=2)
        except Exception as e:
            logging.error(f"Error saving JSON => {e}")

        self.dashboard_tab.update_data(final, self.history_df)
        self.tabs.select(self.dashboard_tab)
        messagebox.showinfo("Done", f"Missing items => {out_path}")

    def export_pdf(self):
        if self.history_df.empty:
            messagebox.showinfo("PDF Export", "No mismatch data => cannot export.")
            return
        last_run= self.history_df["RunDate"].max()
        df_curr= self.history_df[self.history_df["RunDate"]== last_run].copy()
        df_hist= self.history_df.copy()
        rep= EnhancedPDFReport(df_curr, df_hist, self.config_dict)
        pdf_path= rep.generate()
        messagebox.showinfo("PDF Export", f"PDF => {pdf_path}")

    def save_all_config(self):
        self.config_dict["paths"]["ERP_EXCEL_PATH"]= self.erp_var.get().strip()
        self.config_dict["paths"]["MASTER_ZIP_PATH"]= self.mast_var.get().strip()
        self.config_dict["paths"]["EXCEPTION_PATH"]= self.exc_var.get().strip()
        self.config_dict["paths"]["OUTPUT_PATH"]= self.out_var.get().strip()
        self.config_dict["paths"]["CONFIG_PATH"]= self.cfg_var.get().strip()
        self.config_dict["paths"]["PARAMETER_PATH"]= self.par_var.get().strip()
        self.config_dict["paths"]["MASTER_CSV_OUTPUT"]= self.csv_var.get().strip()
        self.config_dict["paths"]["PDF_EXPORT_PATH"]= self.pdf_var.get().strip()
        self.config_dict["paths"]["HISTORY_PATH"]= self.hist_var.get().strip()

        # ERP filters
        self.config_dict.setdefault("erp_grid", {})
        self.config_dict["erp_grid"]["filters"]= self.erp_preview.filters
        # Master filters
        self.config_dict.setdefault("master_grid", {})
        self.config_dict["master_grid"]["filters"]= self.master_preview.filters

        save_config(self.config_dict, Path(self.config_dict["paths"]["CONFIG_PATH"]))
        messagebox.showinfo("Saved", "Config saved (including date filters & preview filters).")

def main():
    app= MainApp()
    app.mainloop()

if __name__=="__main__":
    main()
