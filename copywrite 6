import logging
import pandas as pd
import warnings
from openpyxl import load_workbook
from openpyxl.comments import Comment

# -----------------------------------------------------------------------------
# 1. Setup Logging
# -----------------------------------------------------------------------------
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
# Suppress openpyxl user warnings
warnings.filterwarnings("ignore", category=UserWarning, module="openpyxl")

# -----------------------------------------------------------------------------
# 2. File & Sheet Names
# -----------------------------------------------------------------------------
MAP_FILE_PATH   = r"C:\Users\alexp\OneDrive\Desktop\MAP.xlsx"
BANI_FILE_PATH  = r"C:\Users\alexp\OneDrive\Desktop\BANI.xlsx"

MAPPING_SHEET   = "Mapping Main"
XRP_SHEET       = "XRP"
COPYWRITE_SHEET = "Copywrite"

AGGREGATED_FILE = r"C:\Users\alexp\OneDrive\Desktop\Aggregated_Copywrite.xlsx"

TARGET_DESC2_VALUE = "Copywrite"  # We only keep rows in MAP where 'Description 2' == 'Copywrite'

# In the Copywrite sheet:
#   row 15 is header, data from row 16 onward
DATA_START_ROW = 16
ROW_HEADER     = 15

# Column definitions (1-based):
#   D=4 => "XO Number"
#   S=19 => "Jun Actual"
COL_XO_NUMBER  = 4
COL_JUN_ACTUAL = 19

# If your "Journal Description" is in column E=5, we read it when re-deriving aggregator below.

# -----------------------------------------------------------------------------
# 3. Load the Mapping & Keep Only Copywrite Accounts
# -----------------------------------------------------------------------------
logging.info("Loading mapping data from MAP...")
map_df = pd.read_excel(MAP_FILE_PATH, sheet_name=MAPPING_SHEET)

# Drop rows with no 'Account'
map_df = map_df.dropna(subset=["Account"])

# Convert to string
map_df["Account"]       = map_df["Account"].astype(str).str.strip()
map_df["Description 2"] = map_df["Description 2"].astype(str).str.strip()

# Filter for 'Copywrite'
copy_map = map_df[map_df["Description 2"] == TARGET_DESC2_VALUE]
if copy_map.empty:
    logging.warning(f"No rows in MAP where 'Description 2' == '{TARGET_DESC2_VALUE}'. Exiting.")
    exit()

# Build set of copywrite accounts
copywrite_accounts = set(copy_map["Account"].unique())
logging.info(f"Found {len(copywrite_accounts)} 'Copywrite' account(s).")

# -----------------------------------------------------------------------------
# 4. Load XRP Data
#    We'll keep columns: Nat Account, Journal Description, XO Number, Voice, Amount
#    with all except 'Amount' as strings
# -----------------------------------------------------------------------------
logging.info(f"Loading XRP from {BANI_FILE_PATH} (sheet '{XRP_SHEET}')...")
all_xrp = pd.read_excel(BANI_FILE_PATH, sheet_name=XRP_SHEET, dtype=str)

# If your sheet is large, you can filter columns first.
needed_cols = ["Nat Account", "Journal Description", "XO Number", "Voice", "Amount"]
xrp_df = all_xrp[needed_cols].copy()

# Fix "Amount" to numeric
xrp_df["Amount"] = pd.to_numeric(xrp_df["Amount"], errors="coerce").fillna(0.0)

# For the rest, ensure they are strings
for col in ["Nat Account", "Journal Description", "XO Number", "Voice"]:
    xrp_df[col] = xrp_df[col].fillna("").astype(str).str.strip()

logging.info(f"Loaded {len(xrp_df)} XRP rows, columns converted. First few:\n{xrp_df.head()}")

# -----------------------------------------------------------------------------
# 5. Filter to Only Copywrite Accounts
# -----------------------------------------------------------------------------
xrp_df["Nat Account"] = xrp_df["Nat Account"].astype(str).str.strip()
filtered_df = xrp_df[xrp_df["Nat Account"].isin(copywrite_accounts)].copy()
if filtered_df.empty:
    logging.info("No rows in XRP match copywrite accounts. Exiting.")
    exit()

logging.info(f"Filtered to {len(filtered_df)} row(s) for Copywrite accounts.")

# -----------------------------------------------------------------------------
# 6. Aggregator Key: If Journal Description not blank => JD
#                    else if XO not blank => XO
#                    else skip
# -----------------------------------------------------------------------------
def aggregator_key_priority(jd, xo):
    # Priority is JD if not blank
    j = jd.strip()
    if j:
        return j
    x = xo.strip()
    if x:
        return x
    return ""

filtered_df["AggregatorKey"] = filtered_df.apply(
    lambda row: aggregator_key_priority(row["Journal Description"], row["XO Number"]),
    axis=1
)

groupable = filtered_df[filtered_df["AggregatorKey"] != ""].copy()

# -----------------------------------------------------------------------------
# 7. Sum "Amount" for each aggregator key
# -----------------------------------------------------------------------------
agg_df = (
    groupable
    .groupby("AggregatorKey")["Amount"]
    .sum()
    .reset_index()
)

logging.info(f"Aggregated into {len(agg_df)} aggregator keys.")

# aggregator dict
aggregator = {}
for _, row in agg_df.iterrows():
    key = row["AggregatorKey"]
    aggregator[key] = row["Amount"]

# -----------------------------------------------------------------------------
# 8. Write aggregator to "Aggregated_Copywrite.xlsx"
# -----------------------------------------------------------------------------
logging.info(f"Creating aggregator file '{AGGREGATED_FILE}'...")
report_df = agg_df.rename(columns={
    "AggregatorKey": "Aggregator Key (JD or XO)",
    "Amount": "Sum Amount"
})
report_df.sort_values(by="Aggregator Key (JD or XO)", inplace=True)
report_df.to_excel(AGGREGATED_FILE, sheet_name="Aggregated", index=False)
logging.info("Aggregator file created successfully.")

# -----------------------------------------------------------------------------
# 9. Update the "Copywrite" Sheet
#    We'll assume col D => XO Number, col E => Journal Description,
#    col S => Jun Actual, row 16+ => data
#    aggregator key logic => if col E not blank => aggregator key = that
#                            else => col D
# -----------------------------------------------------------------------------
wb = load_workbook(BANI_FILE_PATH)
if COPYWRITE_SHEET not in wb.sheetnames:
    logging.warning(f"Sheet '{COPYWRITE_SHEET}' not found in {BANI_FILE_PATH}. Exiting update.")
    wb.close()
    exit()

ws_copy = wb[COPYWRITE_SHEET]
logging.info(f"Updating sheet '{COPYWRITE_SHEET}'...")

max_row = ws_copy.max_row
updated_count = 0

def aggregator_key_for_sheet(xo_val, jd_val):
    jd_val = jd_val.strip()
    if jd_val:
        return jd_val
    return xo_val.strip()

# We'll assume col E=5 for Journal Description
COL_JOUR_DESC = COL_XO_NUMBER + 1  # if D=4 => E=5

for r in range(DATA_START_ROW, max_row + 1):
    val_xo = ws_copy.cell(row=r, column=COL_XO_NUMBER).value
    val_jd = ws_copy.cell(row=r, column=COL_JOUR_DESC).value

    xo_str = str(val_xo).strip() if val_xo else ""
    jd_str = str(val_jd).strip() if val_jd else ""

    final_key = aggregator_key_for_sheet(xo_str, jd_str)
    if not final_key:
        continue

    if final_key in aggregator:
        sum_val = aggregator[final_key]
        cell_actual = ws_copy.cell(row=r, column=COL_JUN_ACTUAL)
        cell_actual.value = sum_val

        # remove old comment if any
        if cell_actual.comment:
            cell_actual.comment = None
        cell_actual.comment = Comment("Updated by script", "Script")

        updated_count += 1

        # If aggregator key is from JD => rename col D
        # means col E wasn't blank, but col D might have been blank
        if jd_str and not xo_str:
            ws_copy.cell(row=r, column=COL_XO_NUMBER).value = final_key

logging.info(f"Updated {updated_count} row(s) in '{COPYWRITE_SHEET}'.")

# -----------------------------------------------------------------------------
# 10. Save
# -----------------------------------------------------------------------------
logging.info("Saving updated BANI workbook...")
wb.save(BANI_FILE_PATH)
wb.close()
logging.info("Done! All updates saved.")
