# 2025-02-14 1030
"""
Ultra-Mega Reconciliation: Parameter-based with ERP & Master, only two encodings (utf-8-sig, utf-16-le).

Process:
1) ERP:
   - Read Excel (skip 3 rows).
   - Keep only rows where Enabled_Flag == 'Enabled'.
   - 'V_S_C' => dimension; 'Value' => record Name; other columns => attributes (in meltdown).
   - The param file 'Dimension Parameters' says which V_S_C to keep if 'ERP Values'=='x' and how to rename it to 'Dimension'.
   - The param file 'Attribute Parameters' says which attributes to keep/rename if 'On/Off'=='x'.
2) Master:
   - A ZIP with .txt files, each read with only 2 encodings tried: 'utf-8-sig' and 'utf-16-le'.
   - The dimension is the full .txt filename (e.g. 'alex_Master.txt').
   - The first column is Name; the rest are attributes (in meltdown).
   - The param file's 'Dimension Parameters' with 'FileName' => final 'Dimension' (if 'ERP Values'=='x'), else excluded.
   - The 'Attribute Parameters' is likewise used to filter/rename columns.
3) GUI:
   - Two preview tabs: wide format, Dimension & Name locked, only Start/End Date filterable.
   - Compare => meltdown => produce missing_items.xlsx.
   - Dashboard => placeholders for date range, dimension/attribute filtering, charts, etc.
No emojis; minimal apple-like style with burgundy accent.
"""

import os
import sys
import json
import logging
import zipfile
import shutil
import io
from pathlib import Path
from datetime import datetime
from typing import Dict, Set, List

import tkinter as tk
from tkinter import ttk, filedialog, messagebox
import customtkinter as ctk

import pandas as pd
import numpy as np
import matplotlib
matplotlib.use("TkAgg")
import matplotlib.pyplot as plt
from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg

try:
    import chardet
except ImportError:
    chardet = None

from openpyxl import Workbook
from openpyxl.styles import PatternFill, Font, Alignment

# ---------------- Logging Setup ----------------
logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")

# ---------------- DEFAULT PATHS ----------------
DEFAULT_PATHS = {
    "ERP_EXCEL_PATH": "data/ERP_Config.xlsx",
    "MASTER_ZIP_PATH": "data/Master_Config.zip",
    "EXCEPTION_PATH": "data/Exception_Table.xlsx",
    "OUTPUT_PATH": "output/missing_items.xlsx",
    "CONFIG_PATH": "config/ui_config.json",
    "PARAMETER_PATH": "data/parameters.xlsx",
    "MASTER_CSV_OUTPUT": "temp_master_csv"
}

def default_config() -> Dict:
    return {
        "paths": DEFAULT_PATHS.copy(),
        "comparison_option": 2,
        "erp_grid": {"columns": [], "filters": {}},
        "master_grid": {"columns": [], "filters": {}}
    }

def load_config(path: Path) -> Dict:
    if path.is_file():
        try:
            with open(path, "r", encoding="utf-8") as f:
                return json.load(f)
        except Exception as e:
            logging.warning(f"Could not load config {path}: {e}")
    return default_config()

def save_config(cfg: Dict, path: Path):
    path.parent.mkdir(parents=True, exist_ok=True)
    try:
        with open(path, "w", encoding="utf-8") as f:
            json.dump(cfg, f, indent=2)
        logging.info(f"Saved config to {path}")
    except Exception as e:
        logging.error(f"Error saving config: {e}")

# ---------------- TEXT LOGGER HANDLER ----------------
class TextHandler(logging.Handler):
    def __init__(self, widget: ctk.CTkTextbox):
        super().__init__()
        self.widget = widget
    def emit(self, record):
        msg = self.format(record) + "\n"
        self.widget.after(0, self._append, msg)
    def _append(self, msg):
        self.widget.configure(state="normal")
        self.widget.insert("end", msg)
        self.widget.see("end")
        self.widget.configure(state="disabled")

# ---------------- PARAM FILE (two sheets) ----------------
def read_param_file(path: Path) -> Dict[str, object]:
    """
    Expects:
     Sheet 'Dimension Parameters' => columns [FileName, V S C, Dimension, ERP Values]
       => if ERP Values == 'x', we keep it
       => param["dim_erp_keep"] = set(vsc)
       => param["dim_erp_map"][vsc] = finalDim
       => param["dim_master_map"][fileName] = finalDim
     Sheet 'Attribute Parameters' => columns [ERP Original Attributes, Master Original Attributes, Attribute, On/Off]
       => if On/Off=='x', we keep it
       => param["attr_erp_map"][origName] = finalAttr
       => param["attr_master_map"][origName] = finalAttr
    """
    param = {
        "dim_erp_keep": set(),
        "dim_erp_map": {},
        "dim_master_map": {},
        "attr_erp_map": {},
        "attr_master_map": {}
    }
    if not path.is_file():
        logging.warning(f"Param file not found => {path}")
        return param
    try:
        dim_df = pd.read_excel(path, sheet_name="Dimension Parameters")
        dim_df.columns = dim_df.columns.astype(str).str.strip()

        def s(x): return str(x).strip() if pd.notna(x) else ""
        for _, row in dim_df.iterrows():
            fn = s(row.get("FileName",""))
            vsc= s(row.get("V S C",""))
            dim= s(row.get("Dimension",""))
            ev = s(row.get("ERP Values",""))
            if ev.lower()=="x" and dim and vsc:
                param["dim_erp_keep"].add(vsc)
            if vsc and dim:
                param["dim_erp_map"][vsc] = dim
            if fn and dim:
                # if 'ERP Values'== 'x' => we keep
                if ev.lower()=="x":
                    param["dim_master_map"][fn] = dim

        attr_df = pd.read_excel(path, sheet_name="Attribute Parameters")
        attr_df.columns = attr_df.columns.astype(str).str.strip()
        for _, row in attr_df.iterrows():
            e_orig = s(row.get("ERP Original Attributes",""))
            m_orig = s(row.get("Master Original Attributes",""))
            final_ = s(row.get("Attribute",""))
            onoff = s(row.get("On/Off",""))
            if onoff.lower()=="x" and final_:
                if e_orig:
                    param["attr_erp_map"][e_orig] = final_
                if m_orig:
                    param["attr_master_map"][m_orig] = final_
        return param
    except Exception as e:
        logging.error(f"Error reading param file => {e}")
        return param

# ---------------- ERP Reading => skip 3 => keep Enabled ----------------
def read_erp_excel(path: Path) -> pd.DataFrame:
    if not path.is_file():
        logging.warning(f"ERP Excel not found => {path}")
        return pd.DataFrame()
    try:
        df = pd.read_excel(path, skiprows=3)
        df.columns = df.columns.str.strip()
        if "Enabled_Flag" in df.columns:
            df = df[df["Enabled_Flag"]=="Enabled"]
        return df
    except Exception as e:
        logging.error(f"Error reading ERP => {e}")
        return pd.DataFrame()

# ---------------- MASTER => .txt => only 2 encodings tried ----------------
def read_txt_2encodings(raw: bytes) -> pd.DataFrame:
    """
    Tries only 'utf-8-sig' & 'utf-16-le' to parse the .txt
    Returns DataFrame or empty if fails both.
    """
    import pandas as pd
    for enc in ["utf-8-sig","utf-16-le"]:
        try:
            import io
            buf = io.BytesIO(raw)
            df = pd.read_csv(buf, encoding=enc, on_bad_lines="skip", engine="python")
            df.dropna(how="all", axis=0, inplace=True)
            df.dropna(how="all", axis=1, inplace=True)
            df.columns = df.columns.astype(str).str.strip()
            logging.info(f"[read_txt_2encodings] success with '{enc}' => shape={df.shape}")
            return df
        except Exception as e:
            logging.debug(f"[read_txt_2encodings] fail with {enc} => {e}")
    logging.error("[read_txt_2encodings] cannot parse .txt with 'utf-8-sig' or 'utf-16-le'")
    return pd.DataFrame()

def convert_master_txt_to_csv(zip_path: Path, out_dir: Path) -> List[Path]:
    if not zip_path.is_file():
        logging.warning(f"[Master] ZIP not found => {zip_path}")
        return []
    if out_dir.exists():
        shutil.rmtree(out_dir, ignore_errors=True)
    out_dir.mkdir(parents=True, exist_ok=True)
    csvs = []
    with zipfile.ZipFile(zip_path,"r") as z:
        txt_files = [f for f in z.namelist() if f.lower().endswith(".txt")]
        for txt_file in txt_files:
            base_name = os.path.basename(txt_file)
            if not base_name:
                continue
            try:
                with z.open(txt_file) as fo:
                    raw = fo.read()
                df = read_txt_2encodings(raw)
                if df.empty:
                    continue
                df["RawFileName"] = base_name  # keep the .txt
                if "Name" not in df.columns and len(df.columns)>0:
                    first_col= df.columns[0]
                    df.rename(columns={first_col:"Name"}, inplace=True)
                out_csv = out_dir / (base_name.replace(".txt",".csv"))
                df.to_csv(out_csv, index=False, encoding="utf-8")
                csvs.append(out_csv)
            except Exception as e:
                logging.error(f"[Master] error reading {txt_file} => {e}")
    return csvs

def unify_master_csvs(csvs: List[Path]) -> pd.DataFrame:
    frames = []
    for cp in csvs:
        if not cp.is_file():
            continue
        try:
            df = pd.read_csv(cp, encoding="utf-8", on_bad_lines="skip")
            df.columns = df.columns.str.strip()
            frames.append(df)
        except Exception as e:
            logging.error(f"[unify_master_csvs] reading {cp} => {e}")
    if frames:
        return pd.concat(frames, ignore_index=True)
    return pd.DataFrame()

# ---------------- MELTDOWN & Filtering (Dimension & Attributes) ----------------
def meltdown_erp(df: pd.DataFrame, param: Dict[str, object]) -> pd.DataFrame:
    """
    param:
      dim_erp_keep => set of V_S_C to keep
      dim_erp_map => {vsc => finalDimension}
      attr_erp_map => {origAttr => finalAttr}
    meltdown => skip "Enabled_Flag"
    => Dimension from V_S_C
    => Name from 'Value'
    => other columns => meltdown => filter if col in attr_erp_map => rename => finalAttr
    => if attribute in [Start Date, End Date], strip T
    """
    if "V_S_C" not in df.columns:
        logging.warning("[meltdown_erp] missing V_S_C => empty.")
        return pd.DataFrame()
    keep = param["dim_erp_keep"]   # set
    dmap = param["dim_erp_map"]    # {vsc => finalDim}
    amap = param["attr_erp_map"]   # {origAttr => finalAttr}

    # filter rows by keep
    df2 = df[df["V_S_C"].isin(keep)].copy()
    if df2.empty:
        return pd.DataFrame()

    skip_cols = {"V_S_C","Enabled_Flag"}
    id_vars = []
    if "Value" in df2.columns:
        id_vars.append("Value")
        skip_cols.add("Value")

    meltdown_cols = [c for c in df2.columns if c not in skip_cols]
    df2["DimRaw"] = df2["V_S_C"]
    skip_cols.add("DimRaw")
    id_vars.insert(0, "DimRaw")

    melted = df2.melt(id_vars=id_vars, value_vars=meltdown_cols,
                      var_name="OrigAttr", value_name="ValX")

    # rename dimension
    def rename_dim(v):
        return dmap.get(v, v)
    melted["Dimension"] = melted["DimRaw"].apply(rename_dim)
    if "Value" in id_vars:
        melted.rename(columns={"Value":"Name"}, inplace=True)
    else:
        melted["Name"] = ""

    # filter columns => only those in amap
    melted = melted[melted["OrigAttr"].isin(amap.keys())].copy()
    # rename attribute
    melted["Attribute"] = melted["OrigAttr"].map(amap)

    def strip_t(val):
        if isinstance(val,str) and "T" in val:
            return val.split("T")[0]
        return val
    melted["Value"] = np.where(melted["Attribute"].isin(["Start Date","End Date"]),
                               melted["ValX"].apply(strip_t),
                               melted["ValX"])
    return melted[["Dimension","Name","Attribute","Value"]].copy()

def meltdown_master(df: pd.DataFrame, param: Dict[str, object]) -> pd.DataFrame:
    if df.empty or "RawFileName" not in df.columns:
        return pd.DataFrame()
    dmap = param["dim_master_map"]   # {filename => finalDim}
    amap = param["attr_master_map"]  # {origAttr => finalAttr}

    # filter out any row whose RawFileName is not in dmap
    df2 = df[df["RawFileName"].isin(dmap.keys())].copy()
    if df2.empty:
        return pd.DataFrame()

    skip_cols = {"RawFileName"}
    id_vars = []
    df2["DimRaw"] = df2["RawFileName"]
    skip_cols.add("DimRaw")
    id_vars.append("DimRaw")
    if "Name" in df2.columns:
        id_vars.append("Name")
        skip_cols.add("Name")

    meltdown_cols = [c for c in df2.columns if c not in skip_cols]
    melted = df2.melt(id_vars=id_vars, value_vars=meltdown_cols,
                      var_name="OrigAttr", value_name="ValX")
    def rename_dim(fn):
        return dmap.get(fn, fn)
    melted["Dimension"] = melted["DimRaw"].apply(rename_dim)
    if "Name" in id_vars:
        melted.rename(columns={"Name":"Name"}, inplace=True)
    else:
        melted["Name"] = ""

    # filter attributes => only if in amap
    melted = melted[melted["OrigAttr"].isin(amap.keys())].copy()
    melted["Attribute"] = melted["OrigAttr"].map(amap)

    def strip_t(val):
        if isinstance(val, str) and "T" in val:
            return val.split("T")[0]
        return val
    melted["Value"] = np.where(melted["Attribute"].isin(["Start Date","End Date"]),
                               melted["ValX"].apply(strip_t),
                               melted["ValX"])
    return melted[["Dimension","Name","Attribute","Value"]].copy()

def build_keys(df: pd.DataFrame)-> pd.DataFrame:
    df = df.copy()
    for c in ["Dimension","Name","Attribute","Value"]:
        if c not in df.columns:
            df[c]=""
        df[c] = df[c].fillna("").astype(str).str.strip()
    df["GroupKey"] = df["Dimension"] + " | " + df["Name"]
    df["Key"] = df["Dimension"] + " | " + df["Name"] + " | " + df["Attribute"] + " | " + df["Value"]
    df["Comments_1"]=""
    df["Comments_2"]=""
    df["Action Item"]=""
    df["Missing In"]=""
    return df

def compare_mode2(df_erp: pd.DataFrame, df_mast: pd.DataFrame) -> pd.DataFrame:
    """
    - If same dimension + name => compare attributes
    - If name missing => missing name
    - If attribute missing => missing attribute
    """
    def build_dict(d):
        out={}
        for gk, grp in d.groupby("GroupKey"):
            rec={}
            nm = grp["Name"].iloc[0] if not grp.empty else ""
            rec["Name"] = nm
            for _, row in grp.iterrows():
                rec[row["Attribute"]] = row["Value"]
            out[gk] = rec
        return out

    e_dict = build_dict(df_erp)
    m_dict = build_dict(df_mast)
    all_gk = set(e_dict.keys())| set(m_dict.keys())
    results=[]
    for gk in all_gk:
        dim = gk.split(" | ")[0]
        a_data= e_dict.get(gk,{})
        b_data= m_dict.get(gk,{})
        name_a= a_data.get("Name","")
        name_b= b_data.get("Name","")
        if name_a and name_b and (name_a==name_b):
            all_attrs= (set(a_data.keys())| set(b_data.keys())) - {"Name"}
            for at in all_attrs:
                va = a_data.get(at,"")
                vb = b_data.get(at,"")
                if va!=vb:
                    if va and not vb:
                        results.append({"Dimension":dim,"Name":name_a,"Attribute":at,"Value":va,"Missing In":"MASTER"})
                    elif vb and not va:
                        results.append({"Dimension":dim,"Name":name_a,"Attribute":at,"Value":vb,"Missing In":"ERP"})
                    else:
                        # mismatch => both
                        results.append({"Dimension":dim,"Name":name_a,"Attribute":at,"Value":va,"Missing In":"MASTER"})
                        results.append({"Dimension":dim,"Name":name_a,"Attribute":at,"Value":vb,"Missing In":"ERP"})
        else:
            if name_a and not name_b:
                # missing name in MASTER
                results.append({"Dimension":dim,"Name":name_a,"Attribute":"Name","Value":name_a,"Missing In":"MASTER"})
            elif name_b and not name_a:
                results.append({"Dimension":dim,"Name":name_b,"Attribute":"Name","Value":name_b,"Missing In":"ERP"})
    df_res= pd.DataFrame(results)
    if not df_res.empty:
        df_res["Key"] = (df_res["Dimension"].str.strip()+" | "+
                         df_res["Name"].str.strip()+" | "+
                         df_res["Attribute"].str.strip()+" | "+
                         df_res["Value"].str.strip())
    return df_res

def read_exception_table(exc_path: Path) -> pd.DataFrame:
    if not exc_path.is_file():
        logging.warning(f"Exception table not found => {exc_path}")
        return pd.DataFrame()
    try:
        df = pd.read_excel(exc_path)
        df.columns = df.columns.astype(str).str.strip()
        return df
    except Exception as e:
        logging.error(f"Error reading exception => {e}")
        return pd.DataFrame()

def merge_exceptions(df: pd.DataFrame, df_exc: pd.DataFrame) -> pd.DataFrame:
    if df.empty or df_exc.empty or "Key" not in df.columns:
        return df
    keep = [c for c in df_exc.columns if c in ["Key","Comments_1","Comments_2","hide exception"]]
    if not keep:
        return df
    exc = df_exc[keep].copy()
    exc["Key"] = exc["Key"].astype(str).str.strip()
    merged = df.merge(exc, on="Key", how="left", suffixes=("","_exc"))
    merged["hide exception"] = merged.get("hide exception","").fillna("").str.lower()
    final = merged[merged["hide exception"]!="yes"].copy()
    if "Comments_1_exc" in final.columns:
        final["Comments_1"] = np.where(final["Comments_1_exc"].notna(), final["Comments_1_exc"], final["Comments_1"])
        final.drop(columns=["Comments_1_exc"], inplace=True)
    if "Comments_2_exc" in final.columns:
        final["Comments_2"] = np.where(final["Comments_2_exc"].notna(), final["Comments_2_exc"], final["Comments_2"])
        final.drop(columns=["Comments_2_exc"], inplace=True)
    if "hide exception" in final.columns:
        final.drop(columns=["hide exception"], inplace=True)
    return final

def write_missing_items(df: pd.DataFrame, out_path: Path):
    if df.empty:
        logging.info("No missing items => skip writing.")
        return
    out_path.parent.mkdir(parents=True, exist_ok=True)
    final_cols= ["Key","Dimension","Name","Attribute","Value","Comments_1","Comments_2","Action Item","Missing In"]
    for c in final_cols:
        if c not in df.columns:
            df[c] = ""
    df = df[final_cols]
    wb = Workbook()
    ws = wb.active
    ws.title = "Missing Items"
    ws.append(final_cols)
    for rowvals in df.itertuples(index=False):
        ws.append(rowvals)

    header_font = Font(bold=True)
    fill = PatternFill(start_color="DDDDDD", end_color="DDDDDD", fill_type="solid")
    for cell in ws[1]:
        cell.font = header_font
        cell.fill = fill
        cell.alignment = Alignment(horizontal="center")

    for col in ws.columns:
        max_len= 0
        letter= col[0].column_letter
        for cell in col:
            val = str(cell.value) if cell.value else ""
            max_len = max(max_len, len(val))
        ws.column_dimensions[letter].width = max_len+2
    ws.freeze_panes = "A2"
    wb.save(out_path)
    logging.info(f"Missing items => {out_path}")

# ---------------- Basic Preview Grid => pivot => only date filter
class SimplePreview(ctk.CTkFrame):
    FILTERABLE = {"Start Date","End Date"}
    def __init__(self, parent, label: str):
        super().__init__(parent)
        self.label = label
        self.df = pd.DataFrame()
        self.filters: Dict[str, Set] = {}
        self.create_toolbar()
        self.create_table()
        self.create_statusbar()

    def create_toolbar(self):
        bar= ctk.CTkFrame(self, corner_radius=10, fg_color="#f0f0f0")
        bar.pack(fill="x", padx=5, pady=5)
        ctk.CTkLabel(bar, text=f"{self.label} Preview", fg_color="#800020", corner_radius=8).pack(side="left", padx=5)
        ctk.CTkButton(bar, text="â“˜", width=30, command=self.show_info,
                      fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)
        ctk.CTkButton(bar, text="Clear Date Filters", command=self.clear_filters,
                      fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)

    def show_info(self):
        messagebox.showinfo("Info", f"This is the {self.label} preview. Only Start/End Date columns are filterable.")

    def create_table(self):
        container= ctk.CTkFrame(self)
        container.pack(fill="both", expand=True, padx=5, pady=5)
        self.tree= ttk.Treeview(container, show="headings")
        vsb= ttk.Scrollbar(container, orient="vertical", command=self.tree.yview)
        hsb= ttk.Scrollbar(container, orient="horizontal", command=self.tree.xview)
        self.tree.configure(yscrollcommand=vsb.set, xscrollcommand=hsb.set)
        self.tree.grid(row=0, column=0, sticky="nsew")
        vsb.grid(row=0, column=1, sticky="ns")
        hsb.grid(row=1, column=0, sticky="ew")
        container.rowconfigure(0, weight=1)
        container.columnconfigure(0, weight=1)

    def create_statusbar(self):
        self.status_label= ctk.CTkLabel(self, text="0 rows")
        self.status_label.pack(fill="x")

    def set_data(self, df: pd.DataFrame):
        # remove duplicates => [Dimension,Name,Attribute]
        self.df = df.copy()
        if not self.df.empty and {"Dimension","Name","Attribute"}.issubset(self.df.columns):
            self.df.drop_duplicates(subset=["Dimension","Name","Attribute"], inplace=True)
        # pivot => wide
        if not self.df.empty and "Attribute" in self.df.columns:
            try:
                self.df = self.df.pivot(index=["Dimension","Name"], columns="Attribute", values="Value").reset_index()
            except Exception as e:
                logging.error(f"{self.label} pivot error => {e}")
        self.filters.clear()
        self.refresh_table()

    def refresh_table(self):
        for i in self.tree.get_children():
            self.tree.delete(i)
        if self.df.empty:
            self.tree["columns"] = []
            self.status_label.configure(text="0 rows")
            return
        cols = list(self.df.columns)
        self.tree["columns"] = cols
        for c in cols:
            self.tree.heading(c, text=c, anchor="w", command=lambda col=c:self.on_heading_click(col))
            self.tree.column(c, anchor="w", width=150)
        df_f = self.apply_filters()
        for _, row in df_f.iterrows():
            rowvals= [row[c] for c in cols]
            self.tree.insert("", "end", values=rowvals)
        self.status_label.configure(text=f"{len(df_f)} rows")

    def apply_filters(self)-> pd.DataFrame:
        df_f = self.df.copy()
        for col, allowed_vals in self.filters.items():
            if col in df_f.columns:
                df_f = df_f[df_f[col].isin(allowed_vals)]
        return df_f

    def on_heading_click(self, col_name: str):
        if col_name in self.FILTERABLE:
            self.show_filter_popup(col_name)

    def show_filter_popup(self, col_name: str):
        if self.df.empty or col_name not in self.df.columns:
            return
        popup= tk.Toplevel(self)
        popup.title(f"Filter: {col_name}")
        popup.geometry("300x400")
        frame= ctk.CTkFrame(popup)
        frame.pack(fill="both", expand=True, padx=5, pady=5)

        unique_vals= self.df[col_name].unique()
        curr_filter= self.filters.get(col_name,set(unique_vals))
        display_map={}
        for v in unique_vals:
            if pd.isna(v):
                dsp= "(NaN)"
            elif isinstance(v,str) and not v.strip():
                dsp= "(blank)"
            else:
                dsp= str(v)
            display_map[v]= dsp
        sorted_vals= sorted(display_map.keys(), key=lambda x: display_map[x].lower())
        select_all_var= tk.BooleanVar(value=True)
        def toggle_all():
            check= select_all_var.get()
            for vb in var_dict.values():
                vb.set(check)

        ctk.CTkCheckBox(frame, text="Select All", variable=select_all_var, command=toggle_all,
                        fg_color="#800020", hover_color="#a52a2a").pack(anchor="w", pady=5)

        scroll= ctk.CTkScrollableFrame(frame, width=250, height=250)
        scroll.pack(fill="both", expand=True, padx=5, pady=5)
        var_dict={}
        for rv in sorted_vals:
            in_filter= rv in curr_filter
            bvar= tk.BooleanVar(value=in_filter)
            var_dict[rv]= bvar
            ctk.CTkCheckBox(scroll, text=display_map[rv], variable=bvar,
                            fg_color="#800020", hover_color="#a52a2a").pack(anchor="w")
        def apply_():
            sel= {rv for rv,vb in var_dict.items() if vb.get()}
            if sel == set(sorted_vals) or not sel:
                self.filters.pop(col_name,None)
            else:
                self.filters[col_name] = sel
            popup.destroy()
            self.refresh_table()

        bf= ctk.CTkFrame(frame)
        bf.pack(fill="x", pady=5)
        ctk.CTkButton(bf, text="Apply", command=apply_,
                      fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)
        ctk.CTkButton(bf, text="Cancel", command=popup.destroy,
                      fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)

    def clear_filters(self):
        self.filters.clear()
        self.refresh_table()

    def get_filtered_df(self)-> pd.DataFrame:
        return self.apply_filters()

# ---------------- Dashboard placeholder
class Dashboard(ctk.CTkFrame):
    def __init__(self, parent):
        super().__init__(parent)
        ctk.CTkLabel(self, text="Dashboard (Placeholder)", width=200,
                     fg_color="#800020", corner_radius=10).pack(pady=5)
        self.df_current = pd.DataFrame()
        self.df_history = pd.DataFrame()
    def update_data(self, df_current: pd.DataFrame, df_history: pd.DataFrame):
        self.df_current = df_current.copy()
        self.df_history = df_history.copy()
        # expand as needed

# ---------------- MAIN APP
class MainApp(ctk.CTk):
    def __init__(self):
        super().__init__()
        self.title("Ultra-Mega Reconciliation - Light/Burgundy")
        self.geometry("1400x900")
        ctk.set_appearance_mode("light")

        self.config_dict = load_config(Path(DEFAULT_PATHS["CONFIG_PATH"]))
        self.param_dict = read_param_file(Path(self.config_dict["paths"].get("PARAMETER_PATH", DEFAULT_PATHS["PARAMETER_PATH"])))
        self.history_df = pd.DataFrame()

        # Notebook
        self.tabs = ttk.Notebook(self)
        self.tabs.pack(fill="both", expand=True)

        # 1) Paths Tab
        self.paths_tab = ctk.CTkFrame(self.tabs)
        self.tabs.add(self.paths_tab, text="Paths")
        self.build_paths_tab(self.paths_tab)

        # 2) ERP Preview
        self.erp_tab = ctk.CTkFrame(self.tabs)
        self.erp_preview = SimplePreview(self.erp_tab, "ERP")
        self.erp_preview.pack(fill="both", expand=True)
        self.tabs.add(self.erp_tab, text="ERP Preview")

        # 3) Master Preview
        self.master_tab = ctk.CTkFrame(self.tabs)
        self.master_preview = SimplePreview(self.master_tab, "Master")
        self.master_preview.pack(fill="both", expand=True)
        self.tabs.add(self.master_tab, text="Master Preview")

        # 4) Compare
        self.compare_tab = ctk.CTkFrame(self.tabs)
        self.build_compare_tab(self.compare_tab)
        self.tabs.add(self.compare_tab, text="Compare")

        # 5) Dashboard
        self.dashboard_tab = Dashboard(self.tabs)
        self.tabs.add(self.dashboard_tab, text="Dashboard")

        # Logging
        self.log_box = ctk.CTkTextbox(self, height=100)
        self.log_box.pack(fill="both")
        self.log_box.configure(state="disabled")
        handler = TextHandler(self.log_box)
        handler.setLevel(logging.INFO)
        logging.getLogger().addHandler(handler)

        # Temp CSV dir
        self.temp_csv_dir = Path(self.config_dict["paths"].get("MASTER_CSV_OUTPUT","temp_master_csv"))
        self.temp_csv_dir.mkdir(parents=True, exist_ok=True)

        # auto load
        self.refresh_erp()
        self.refresh_master()

    def build_paths_tab(self, parent):
        frm = ctk.CTkFrame(parent)
        frm.pack(fill="both", expand=True, padx=10, pady=10)
        self.erp_var = tk.StringVar(value=self.config_dict["paths"].get("ERP_EXCEL_PATH", DEFAULT_PATHS["ERP_EXCEL_PATH"]))
        self.mast_var= tk.StringVar(value=self.config_dict["paths"].get("MASTER_ZIP_PATH", DEFAULT_PATHS["MASTER_ZIP_PATH"]))
        self.exc_var = tk.StringVar(value=self.config_dict["paths"].get("EXCEPTION_PATH", DEFAULT_PATHS["EXCEPTION_PATH"]))
        self.out_var = tk.StringVar(value=self.config_dict["paths"].get("OUTPUT_PATH", DEFAULT_PATHS["OUTPUT_PATH"]))
        self.cfg_var = tk.StringVar(value=self.config_dict["paths"].get("CONFIG_PATH", DEFAULT_PATHS["CONFIG_PATH"]))
        self.par_var = tk.StringVar(value=self.config_dict["paths"].get("PARAMETER_PATH", DEFAULT_PATHS["PARAMETER_PATH"]))
        self.csv_var = tk.StringVar(value=self.config_dict["paths"].get("MASTER_CSV_OUTPUT", DEFAULT_PATHS["MASTER_CSV_OUTPUT"]))

        def mkrow(lbl,var,is_dir=False):
            rowf = ctk.CTkFrame(frm)
            rowf.pack(fill="x", pady=5)
            ctk.CTkLabel(rowf, text=lbl, width=180).pack(side="left", padx=5)
            e = ctk.CTkEntry(rowf, textvariable=var, width=600)
            e.pack(side="left", padx=5)
            def br():
                if is_dir:
                    p= filedialog.askdirectory()
                else:
                    p= filedialog.askopenfilename()
                if p:
                    var.set(p)
            ctk.CTkButton(rowf, text="Browse", command=br,
                          fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)

        mkrow("ERP Excel:", self.erp_var)
        mkrow("Master ZIP:", self.mast_var)
        mkrow("Exception XLSX:", self.exc_var)
        mkrow("Missing Items Output:", self.out_var)
        mkrow("JSON Config Path:", self.cfg_var)
        mkrow("Parameter File:", self.par_var)
        mkrow("Master CSV Dir:", self.csv_var, is_dir=True)

        bf = ctk.CTkFrame(frm)
        bf.pack(fill="x", pady=10)
        ctk.CTkButton(bf, text="Save Config", command=self.save_all_config,
                      fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)
        ctk.CTkButton(bf, text="Refresh ERP", command=self.refresh_erp,
                      fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)
        ctk.CTkButton(bf, text="Refresh Master", command=self.refresh_master,
                      fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)

    def build_compare_tab(self, parent):
        frm= ctk.CTkFrame(parent)
        frm.pack(fill="both", expand=True, padx=10, pady=10)
        ctk.CTkLabel(frm, text="Create Missing Items", font=("Arial", 16)).pack(pady=5)
        ctk.CTkButton(frm, text="Run Reconciliation", command=self.run_comparison,
                      fg_color="#800020", hover_color="#a52a2a").pack(pady=10)

    def refresh_erp(self):
        path = Path(self.erp_var.get().strip())
        df_erp = read_erp_excel(path)
        self.erp_preview.set_data(df_erp)

    def refresh_master(self):
        zip_path = Path(self.mast_var.get().strip())
        out_dir = Path(self.csv_var.get().strip())
        csvs = convert_master_txt_to_csv(zip_path, out_dir)
        df_m = unify_master_csvs(csvs)
        self.master_preview.set_data(df_m)

    def run_comparison(self):
        # meltdown ERP
        df_erp_wide = self.erp_preview.get_filtered_df()
        erp_melt = meltdown_erp(df_erp_wide, {
            "dim_erp_keep": self.param_dict.get("dim_erp_keep",set()),
            "dim_erp_map": self.param_dict.get("dim_erp_map",{}),
            "attr_erp_map": self.param_dict.get("attr_erp_map",{})
        })
        erp_final = build_keys(erp_melt)

        # meltdown Master
        df_mast_wide = self.master_preview.get_filtered_df()
        mast_melt = meltdown_master(df_mast_wide, {
            "dim_master_map": self.param_dict.get("dim_master_map",{}),
            "attr_master_map": self.param_dict.get("attr_master_map",{})
        })
        mast_final = build_keys(mast_melt)

        # Compare => mode2
        df_diff = compare_mode2(erp_final, mast_final)

        # exceptions
        exc_path = Path(self.exc_var.get().strip())
        df_exc = read_exception_table(exc_path)
        final = merge_exceptions(df_diff, df_exc)

        out_path = Path(self.out_var.get().strip())
        write_missing_items(final, out_path)

        # update dashboard
        run_date = datetime.now().strftime("%Y-%m-%d")
        final["RunDate"] = run_date
        if self.history_df.empty:
            self.history_df = final.copy()
        else:
            self.history_df = pd.concat([self.history_df, final], ignore_index=True)

        self.dashboard_tab.update_data(final, self.history_df)
        self.tabs.select(self.dashboard_tab)
        messagebox.showinfo("Done", f"Missing items => {out_path}")

    def save_all_config(self):
        self.config_dict["paths"]["ERP_EXCEL_PATH"] = self.erp_var.get().strip()
        self.config_dict["paths"]["MASTER_ZIP_PATH"] = self.mast_var.get().strip()
        self.config_dict["paths"]["EXCEPTION_PATH"] = self.exc_var.get().strip()
        self.config_dict["paths"]["OUTPUT_PATH"] = self.out_var.get().strip()
        self.config_dict["paths"]["CONFIG_PATH"] = self.cfg_var.get().strip()
        self.config_dict["paths"]["PARAMETER_PATH"] = self.par_var.get().strip()
        self.config_dict["paths"]["MASTER_CSV_OUTPUT"] = self.csv_var.get().strip()

        save_config(self.config_dict, Path(self.config_dict["paths"]["CONFIG_PATH"]))
        messagebox.showinfo("Saved", "Paths & Config saved successfully.")

def main():
    app= MainApp()
    app.mainloop()

if __name__=="__main__":
    main()
