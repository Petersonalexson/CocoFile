#!/usr/bin/env python3
"""
Ultra-Mega Reconciliation (Single File), with:
 - Automatic End Date filtering (blank or > today's date) after meltdown
 - Two-sheet missing_items.xlsx (Mismatch + Case_Differences)
 - Dimension short code in final output, but param-based full dimension internally
 - 8-chart Dashboard (incl. Bollinger)
 - History double-click => show JSON content
 - 'float' -> 'strip' error fixed by converting values to string
 - Hidden advanced paths from the user in "Paths" tab
"""

import os
import json
import math
import logging
import zipfile
import shutil
import io
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, List, Set, Tuple

import tkinter as tk
from tkinter import ttk, filedialog, messagebox
import customtkinter as ctk

import pandas as pd
import numpy as np

import matplotlib
matplotlib.use("TkAgg")
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg, NavigationToolbar2Tk
from matplotlib.backends.backend_pdf import PdfPages

try:
    import mplcursors
    MPLCURSORS_AVAILABLE = True
except ImportError:
    MPLCURSORS_AVAILABLE = False

from openpyxl import Workbook
from openpyxl.styles import PatternFill, Font, Alignment

logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")

# ----------------------------------------------------------------------------
# DEFAULT CONFIG & SAVE/LOAD
# ----------------------------------------------------------------------------
DEFAULT_PATHS = {
    "ERP_EXCEL_PATH": "data/ERP_Config.xlsx",
    "MASTER_ZIP_PATH": "data/Master_Config.zip",
    "EXCEPTION_PATH": "data/Exception_Table.xlsx",
    "OUTPUT_PATH": "output/missing_items.xlsx",
    "CONFIG_PATH": "config/ui_config.json",  # hidden
    "PARAMETER_PATH": "data/parameters.xlsx",
    "MASTER_CSV_OUTPUT": "temp_master_csv",  # hidden
    "PDF_EXPORT_PATH": "output/dashboard_report.pdf",
    "LOGO_PATH": "images/company_logo.png",  # hidden
    "HISTORY_PATH": "history_runs",          # hidden
    "BAND_CHART_JSON_PATH": "data/bollinger_data.json"  # hidden
}

def default_config() -> Dict:
    return {
        "paths": DEFAULT_PATHS.copy(),
        "erp_grid": {"filters": {}},
        "master_grid": {"filters": {}},
        "dashboard": {
            "selected_dims": [],
            "selected_attrs": [],
            "top_n": 10
        }
    }

def load_config(path: Path) -> Dict:
    if path.is_file():
        try:
            with open(path, "r", encoding="utf-8") as f:
                return json.load(f)
        except Exception as e:
            logging.warning(f"Cannot load config => {e}")
    return default_config()

def save_config(cfg: Dict, path: Path):
    path.parent.mkdir(parents=True, exist_ok=True)
    try:
        with open(path, "w", encoding="utf-8") as f:
            json.dump(cfg, f, indent=2)
        logging.info(f"Saved config => {path}")
    except Exception as e:
        logging.error(f"Error saving config => {e}")


# ----------------------------------------------------------------------------
# LOGGER HANDLER
# ----------------------------------------------------------------------------
class TextHandler(logging.Handler):
    def __init__(self, widget: ctk.CTkTextbox):
        super().__init__()
        self.widget= widget
    def emit(self, record):
        msg= self.format(record) + "\n"
        self.widget.after(0, self._append, msg)
    def _append(self, msg):
        self.widget.configure(state="normal")
        self.widget.insert("end", msg)
        self.widget.see("end")
        self.widget.configure(state="disabled")


# ----------------------------------------------------------------------------
# PARAM READING
# ----------------------------------------------------------------------------
def read_param_file(path: Path)-> Dict[str, object]:
    param= {
        "dim_erp_keep": set(),
        "dim_erp_map": {},      # short code => full dimension
        "dim_master_map": {},   # filename => full dimension
        "attr_erp_map": {},
        "attr_master_map": {}
    }
    if not path.is_file():
        logging.warning(f"Param not found => {path}")
        return param
    try:
        dim_df= pd.read_excel(path, sheet_name="Dimension Parameters")
        dim_df.columns= dim_df.columns.astype(str).str.strip()

        def s(x): return str(x).strip() if pd.notna(x) else ""

        for _, row in dim_df.iterrows():
            fn= s(row.get("FileName",""))
            vsc= s(row.get("V S C",""))
            dim= s(row.get("Dimension",""))
            ev=  s(row.get("ERP Values",""))
            if ev.lower()=="x" and vsc and dim:
                param["dim_erp_keep"].add(vsc)
                param["dim_erp_map"][vsc]= dim
            if fn and dim and ev.lower()=="x":
                param["dim_master_map"][fn]= dim

        attr_df= pd.read_excel(path, sheet_name="Attribute Parameters")
        attr_df.columns= attr_df.columns.astype(str).str.strip()
        for _, row in attr_df.iterrows():
            e_orig= s(row.get("ERP Original Attributes",""))
            m_orig= s(row.get("Master Original Attributes",""))
            final_= s(row.get("Attribute",""))
            onoff=  s(row.get("On/Off",""))
            if onoff.lower()=="x" and final_:
                if e_orig:
                    param["attr_erp_map"][e_orig]= final_
                if m_orig:
                    param["attr_master_map"][m_orig]= final_
        return param
    except Exception as e:
        logging.error(f"Error reading param => {e}")
        return param


# ----------------------------------------------------------------------------
# END DATE HELPER
# ----------------------------------------------------------------------------
def keep_valid_end_date(attr: str, val) -> bool:
    """
    If attribute == 'End Date', keep blank or strictly future.
    We convert 'val' to string to avoid float->strip errors.
    """
    if attr != "End Date":
        return True
    # convert to string:
    val_str= ""
    if pd.notna(val):
        val_str= str(val).strip()

    if not val_str:
        # blank => keep
        return True
    # parse as YYYY-MM-DD
    try:
        dt= datetime.strptime(val_str, "%Y-%m-%d").date()
        return dt> datetime.now().date()
    except:
        return False

def strip_time_if_present(x):
    """
    Convert 'x' to string, remove trailing spaces, and if 'T' present => keep only date part.
    E.g. '2023-12-15T00:00:00' => '2023-12-15'
    Floats => coerced to str first => no crash.
    """
    if pd.isna(x):
        return ""
    s= str(x).strip()
    if "T" in s:
        return s.split("T")[0]
    return s


# ----------------------------------------------------------------------------
# ERP EXCEL
# ----------------------------------------------------------------------------
def read_erp_excel(path: Path)-> pd.DataFrame:
    if not path.is_file():
        logging.warning(f"ERP => not found => {path}")
        return pd.DataFrame()
    try:
        df= pd.read_excel(path, skiprows=3)
        df.columns= df.columns.str.strip()
        if "Enabled_Flag" in df.columns:
            df= df[df["Enabled_Flag"]=="Enabled"]
        return df
    except Exception as e:
        logging.error(f"ERP read => {e}")
        return pd.DataFrame()

# ----------------------------------------------------------------------------
# MASTER => read from zip
# ----------------------------------------------------------------------------
def read_txt_2encodings(raw: bytes)-> pd.DataFrame:
    import io
    for enc in ["utf-8-sig","utf-16-le"]:
        try:
            buf= io.BytesIO(raw)
            df= pd.read_csv(buf, encoding=enc, on_bad_lines="skip", engine="python")
            df.dropna(how="all", axis=0, inplace=True)
            df.dropna(how="all", axis=1, inplace=True)
            df.columns= df.columns.astype(str).str.strip()
            logging.info(f"read_txt_2encodings => success => {enc}, shape={df.shape}")
            return df
        except Exception as e:
            logging.debug(f"read_txt_2encodings => fail => {enc}: {e}")
    logging.error("Cannot parse => returning empty.")
    return pd.DataFrame()

def convert_master_txt_to_csv(zip_path: Path, out_dir: Path)-> List[Path]:
    if not zip_path.is_file():
        logging.warning(f"Master zip not found => {zip_path}")
        return []
    if out_dir.exists():
        shutil.rmtree(out_dir, ignore_errors=True)
    out_dir.mkdir(parents=True, exist_ok=True)
    csvs=[]
    with zipfile.ZipFile(zip_path,"r") as z:
        txt_files= [f for f in z.namelist() if f.lower().endswith(".txt")]
        for txt_file in txt_files:
            bname= os.path.basename(txt_file)
            if not bname:
                continue
            try:
                with z.open(txt_file) as fo:
                    raw= fo.read()
                df= read_txt_2encodings(raw)
                if df.empty:
                    continue
                df["RawFileName"]= bname
                if "Name" not in df.columns and len(df.columns)>0:
                    first_col= df.columns[0]
                    df.rename(columns={first_col:"Name"}, inplace=True)
                out_csv= out_dir/(bname.replace(".txt",".csv"))
                df.to_csv(out_csv, index=False, encoding="utf-8")
                csvs.append(out_csv)
            except Exception as e:
                logging.error(f"Master => {txt_file}: {e}")
    return csvs

def unify_master_csvs(csvs: List[Path])-> pd.DataFrame:
    frames=[]
    for c in csvs:
        if not c.is_file():
            continue
        try:
            df= pd.read_csv(c, encoding="utf-8", on_bad_lines="skip")
            df.columns= df.columns.str.strip()
            frames.append(df)
        except Exception as e:
            logging.error(f"Unify master => {c}: {e}")
    if frames:
        return pd.concat(frames, ignore_index=True)
    return pd.DataFrame()

# ----------------------------------------------------------------------------
# MELTDOWN
# ----------------------------------------------------------------------------
def meltdown_erp_for_preview(df: pd.DataFrame, param: Dict[str,object]) -> pd.DataFrame:
    if "V_S_C" not in df.columns:
        return pd.DataFrame()
    keep= param["dim_erp_keep"]
    dmap= param["dim_erp_map"]
    amap= param["attr_erp_map"]

    df2= df[df["V_S_C"].isin(keep)].copy()
    if df2.empty:
        return pd.DataFrame()

    df2["DimCode"]= df2["V_S_C"]
    df2["Dimension"]= df2["V_S_C"].map(dmap).fillna(df2["V_S_C"])

    skip= {"V_S_C","Enabled_Flag","DimCode","Dimension"}
    id_vars= ["DimCode","Dimension"]
    if "Value" in df2.columns:
        id_vars.append("Value")
        skip.add("Value")

    meltdown_cols= [c for c in df2.columns if c not in skip]
    melted= df2.melt(id_vars=id_vars, value_vars=meltdown_cols,
                     var_name="OrigAttr", value_name="ValX")

    if "Value" in id_vars:
        melted.rename(columns={"Value":"Name"}, inplace=True)
    else:
        melted["Name"]= ""

    # keep recognized
    melted= melted[melted["OrigAttr"].isin(amap.keys())].copy()
    melted["Attribute"]= melted["OrigAttr"].map(amap)

    # strip T
    melted["Value"]= melted["ValX"].apply(strip_time_if_present)

    # keep only blank/future if End Date
    keep_rows=[]
    for _, row in melted.iterrows():
        if keep_valid_end_date(row["Attribute"], row["Value"]):
            keep_rows.append(row)
    out= pd.DataFrame(keep_rows)
    return out[["DimCode","Dimension","Name","Attribute","Value"]]

def meltdown_master_for_preview(df: pd.DataFrame, param: Dict[str,object]) -> pd.DataFrame:
    if df.empty or "RawFileName" not in df.columns:
        return pd.DataFrame()
    dmap= param["dim_master_map"]
    amap= param["attr_master_map"]

    df2= df[df["RawFileName"].isin(dmap.keys())].copy()
    if df2.empty:
        return pd.DataFrame()

    df2["DimCode"]= df2["RawFileName"]
    df2["Dimension"]= df2["RawFileName"].map(dmap).fillna(df2["RawFileName"])

    skip= {"RawFileName","DimCode","Dimension"}
    id_vars= ["DimCode","Dimension"]
    if "Name" in df2.columns:
        id_vars.append("Name")
        skip.add("Name")

    meltdown_cols= [c for c in df2.columns if c not in skip]
    melted= df2.melt(id_vars=id_vars, value_vars=meltdown_cols,
                     var_name="OrigAttr", value_name="ValX")

    melted= melted[melted["OrigAttr"].isin(amap.keys())].copy()
    melted["Attribute"]= melted["OrigAttr"].map(amap)

    melted["Value"]= melted["ValX"].apply(strip_time_if_present)

    keep_rows=[]
    for _, row in melted.iterrows():
        if keep_valid_end_date(row["Attribute"], row["Value"]):
            keep_rows.append(row)
    out= pd.DataFrame(keep_rows)
    if "Name" not in out.columns:
        out["Name"]= ""
    return out[["DimCode","Dimension","Name","Attribute","Value"]]

def pivot_for_preview(df: pd.DataFrame)-> pd.DataFrame:
    if not df.empty and {"DimCode","Dimension","Name","Attribute"}.issubset(df.columns):
        df= df.drop_duplicates(subset=["DimCode","Dimension","Name","Attribute"])
        try:
            df= df.pivot(index=["DimCode","Dimension","Name"], columns="Attribute", values="Value").reset_index()
        except Exception as e:
            logging.error(f"Pivot => {e}")
    return df

# ----------------------------------------------------------------------------
# COMPARE
# ----------------------------------------------------------------------------
def compare_erp_master(erp_df: pd.DataFrame, mast_df: pd.DataFrame)-> pd.DataFrame:
    e2= erp_df.copy()
    e2.rename(columns={"Value":"ERP"}, inplace=True)
    m2= mast_df.copy()
    m2.rename(columns={"Value":"Master"}, inplace=True)

    key_cols= ["DimCode","Dimension","Name","Attribute"]
    merged= e2.merge(m2, on=key_cols, how="outer")
    merged["ERP"]= merged["ERP"].fillna("")
    merged["Master"]= merged["Master"].fillna("")

    diff_mask= merged["ERP"].str.upper()!= merged["Master"].str.upper()
    out= merged[diff_mask].copy()

    def gap_func(r):
        e= r["ERP"]
        ms= r["Master"]
        if e and not ms:
            return "MASTER"
        elif ms and not e:
            return "ERP"
        else:
            return "MISMATCH"

    out["Gap In"]= out.apply(gap_func, axis=1)
    out["Comments_1"]= ""
    out["Comments_2"]= ""

    out["Key"]= (
        out["Dimension"].str.upper().str.strip()+" | "+
        out["Name"].str.upper().str.strip()+" | "+
        out["Attribute"].str.upper().str.strip()
    )

    final_cols= ["DimCode","Dimension","Name","Attribute","Master","ERP","Comments_1","Comments_2","Gap In","Key"]
    return out[final_cols]

def separate_case_diffs(df: pd.DataFrame)-> Tuple[pd.DataFrame,pd.DataFrame]:
    same_lower= df["Master"].str.lower()== df["ERP"].str.lower()
    diff= df["Master"]!= df["ERP"]
    mask= same_lower & diff
    case_df= df[mask].copy()
    mismatch_df= df[~mask].copy()
    return mismatch_df, case_df

# ----------------------------------------------------------------------------
# EXCEPTIONS
# ----------------------------------------------------------------------------
def read_exception_table(path: Path)-> pd.DataFrame:
    if not path.is_file():
        logging.warning(f"Exception => not found => {path}")
        return pd.DataFrame()
    try:
        df= pd.read_excel(path)
        df.columns= df.columns.astype(str).str.strip()
        return df
    except Exception as e:
        logging.error(f"Exception read => {e}")
        return pd.DataFrame()

def merge_exceptions(df: pd.DataFrame, df_exc: pd.DataFrame)-> pd.DataFrame:
    if df.empty or df_exc.empty or "Key" not in df.columns:
        return df
    keep_cols= [c for c in ["Key","Comments_1","Comments_2","hide exception"] if c in df_exc.columns]
    if not keep_cols:
        return df
    exc= df_exc[keep_cols].copy()
    exc["Key"]= exc["Key"].astype(str).str.strip()
    merged= df.merge(exc, on="Key", how="left", suffixes=("","_exc"))
    merged["hide exception"]= merged.get("hide exception","").fillna("").str.lower()
    final= merged[merged["hide exception"]!="yes"].copy()
    if "Comments_1_exc" in final.columns:
        final["Comments_1"]= np.where(final["Comments_1_exc"].notna(), final["Comments_1_exc"], final["Comments_1"])
        final.drop(columns=["Comments_1_exc"], inplace=True)
    if "Comments_2_exc" in final.columns:
        final["Comments_2"]= np.where(final["Comments_2_exc"].notna(), final["Comments_2_exc"], final["Comments_2"])
        final.drop(columns=["Comments_2_exc"], inplace=True)
    if "hide exception" in final.columns:
        final.drop(columns=["hide exception"], inplace=True)
    return final

# ----------------------------------------------------------------------------
# WRITE 2 sheets
# ----------------------------------------------------------------------------
def write_two_sheet_excel(mismatch: pd.DataFrame, case_only: pd.DataFrame, out_path: Path):
    """
    2 sheets => 'Mismatch' + 'Case_Differences'
    Columns => Key, Dimension, Name, Attribute, Master, ERP, Comments_1, Comments_2, Gap In
    We'll rename 'Dimension' => 'DimFull' + 'DimCode' => 'Dimension' so final 'Dimension' is short code.
    """
    out_path.parent.mkdir(parents=True, exist_ok=True)
    main_cols= ["Key","Dimension","Name","Attribute","Master","ERP","Comments_1","Comments_2","Gap In"]

    def finalize(df: pd.DataFrame)-> pd.DataFrame:
        dfc= df.copy()
        if "Dimension" in dfc.columns and "DimCode" in dfc.columns:
            dfc.rename(columns={"Dimension":"DimFull","DimCode":"Dimension"}, inplace=True)
        for c in main_cols:
            if c not in dfc.columns:
                dfc[c]= ""
        return dfc[main_cols]

    mismatch_f= finalize(mismatch)
    case_f= finalize(case_only)

    wb= Workbook()
    ws_m= wb.active
    ws_m.title= "Mismatch"
    ws_m.append(main_cols)
    for rowvals in mismatch_f.itertuples(index=False):
        ws_m.append(rowvals)

    header_font= Font(bold=True)
    fill= PatternFill(start_color="DDDDDD", end_color="DDDDDD", fill_type="solid")

    for cell in ws_m[1]:
        cell.font= header_font
        cell.fill= fill
        cell.alignment= Alignment(horizontal="center")

    for col in ws_m.columns:
        max_len= 0
        let= col[0].column_letter
        for cell in col:
            val= str(cell.value) if cell.value else ""
            max_len= max(max_len, len(val))
        ws_m.column_dimensions[let].width= max_len+2
    ws_m.freeze_panes= "A2"

    ws_c= wb.create_sheet("Case_Differences")
    ws_c.append(main_cols)
    for rowvals in case_f.itertuples(index=False):
        ws_c.append(rowvals)

    for cell in ws_c[1]:
        cell.font= header_font
        cell.fill= fill
        cell.alignment= Alignment(horizontal="center")

    for col in ws_c.columns:
        max_len= 0
        let= col[0].column_letter
        for cell in col:
            val= str(cell.value) if cell.value else ""
            max_len= max(max_len, len(val))
        ws_c.column_dimensions[let].width= max_len+2
    ws_c.freeze_panes= "A2"

    wb.save(out_path)
    logging.info(f"Missing items => {out_path}")


# ----------------------------------------------------------------------------
# SIMPLE PREVIEW => no user date filters
# ----------------------------------------------------------------------------
class SimplePreview(ctk.CTkFrame):
    """
    Show meltdown data for ERP or Master, no date filters in the GUI.
    """
    def __init__(self, parent, name: str):
        super().__init__(parent)
        self.name= name
        self.df= pd.DataFrame()
        self.create_toolbar()
        self.create_table()
        self.create_statusbar()

    def create_toolbar(self):
        bar= ctk.CTkFrame(self, corner_radius=10, fg_color="#f0f0f0")
        bar.pack(fill="x", padx=5, pady=5)
        lb= ctk.CTkLabel(bar, text=f"{self.name} Preview",
                         fg_color="#800020", corner_radius=8,
                         text_color="white",
                         font=ctk.CTkFont(size=14, weight="bold"))
        lb.pack(side="left", padx=5)
        ctk.CTkButton(bar, text="ⓘ", width=30, command=self.show_info,
                      fg_color="#800020", hover_color="#a52a2a", text_color="white").pack(side="left", padx=5)

    def show_info(self):
        messagebox.showinfo("Info", f"{self.name} meltdown data.\nAuto-filter End Date => blank/future.\nNo user date filters here.")

    def create_table(self):
        container= ctk.CTkFrame(self)
        container.pack(fill="both", expand=True)
        self.tree= ttk.Treeview(container, show="headings")
        vsb= ttk.Scrollbar(container, orient="vertical", command=self.tree.yview)
        hsb= ttk.Scrollbar(container, orient="horizontal", command=self.tree.xview)
        self.tree.configure(yscrollcommand=vsb.set, xscrollcommand=hsb.set)
        self.tree.grid(row=0, column=0, sticky="nsew")
        vsb.grid(row=0, column=1, sticky="ns")
        hsb.grid(row=1, column=0, sticky="ew")
        container.rowconfigure(0, weight=1)
        container.columnconfigure(0, weight=1)

    def create_statusbar(self):
        self.status_label= ctk.CTkLabel(self, text="0 rows", fg_color="#f0f0f0", text_color="black")
        self.status_label.pack(fill="x")

    def set_data(self, df: pd.DataFrame):
        self.df= df.copy()
        self.refresh_table()

    def refresh_table(self):
        for i in self.tree.get_children():
            self.tree.delete(i)
        if self.df.empty:
            self.tree["columns"]= []
            self.status_label.configure(text="0 rows")
            return
        cols= list(self.df.columns)
        self.tree["columns"]= cols
        for c in cols:
            self.tree.heading(c, text=c, anchor="w")
            self.tree.column(c, anchor="w", width=150)
        for _, row in self.df.iterrows():
            rowvals= [row[c] for c in cols]
            self.tree.insert("", "end", values=rowvals)
        self.status_label.configure(text=f"{len(self.df)} rows")

    def get_filtered_df(self)-> pd.DataFrame:
        return self.df.copy()


# ----------------------------------------------------------------------------
# PDF REPORT => 8 charts
# ----------------------------------------------------------------------------
def enable_hover_chart(ax, polar=False):
    if not MPLCURSORS_AVAILABLE:
        return
    cursor= mplcursors.cursor(ax, hover=True)
    @cursor.connect("add")
    def on_add(sel):
        coords= sel.target
        if polar and len(coords)==2:
            sel.annotation.set_text(f"{coords[1]:.0f}")
        else:
            if isinstance(coords,(tuple,list)) and len(coords)==2:
                sel.annotation.set_text(f"{coords[1]:.0f}")
            else:
                sel.annotation.set_text(str(coords))

class EnhancedPDFReport:
    def __init__(self, df_current: pd.DataFrame, df_history: pd.DataFrame, config: Dict):
        self.df_current= df_current
        self.df_history= df_history
        self.config= config
        self.logo_path= Path(config["paths"].get("LOGO_PATH","images/company_logo.png"))
        self.page_count= 0
        self.PAGE_WIDTH= 11
        self.PAGE_HEIGHT= 8.5

    def generate(self)-> Path:
        stamp= datetime.now().strftime("%Y%m%d_%H%M%S")
        out_dir= Path("Reconciliation_pdf")
        out_dir.mkdir(parents=True, exist_ok=True)
        pdf_path= out_dir / f"Reconciliation_{stamp}.pdf"
        with PdfPages(pdf_path) as pdf:
            # cover
            fig= self._new_fig()
            plt.text(0.5, 0.6, "Reconciliation Report", ha="center", fontsize=24, weight="bold", transform=fig.transFigure)
            plt.text(0.5, 0.5, f"Generated {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}", ha="center", fontsize=12, transform=fig.transFigure)
            pdf.savefig(fig)
            plt.close(fig)

            # summary
            fig= self._new_fig()
            total= len(self.df_current)
            plt.text(0.5, 0.8, "Summary", ha="center", fontsize=18, weight="bold", transform=fig.transFigure)
            plt.text(0.5, 0.6, f"Mismatches => {total}", ha="center", fontsize=12, transform=fig.transFigure)
            pdf.savefig(fig)
            plt.close(fig)

            # example => we do 2 charts: Heatmap, Bollinger
            # In your real code you'd do all 8.
            # Heatmap
            df_m= self.df_current[self.df_current["Gap In"]!=""]
            if not df_m.empty and {"Dimension","Attribute"}.issubset(df_m.columns):
                piv= df_m.groupby(["Dimension","Attribute"]).size().unstack(fill_value=0)
                if not piv.empty:
                    fig, ax= plt.subplots(figsize=(8,5))
                    im= ax.imshow(piv, aspect="auto", cmap="Reds")
                    ax.set_xticks(np.arange(len(piv.columns)))
                    ax.set_xticklabels(piv.columns, rotation=45, ha="right")
                    ax.set_yticks(np.arange(len(piv.index)))
                    ax.set_yticklabels(piv.index)
                    plt.colorbar(im, ax=ax)
                    ax.set_title("Heatmap: Dim x Attr")
                    enable_hover_chart(ax)
                    pdf.savefig(fig)
                    plt.close(fig)

            # Bollinger
            if not self.df_history.empty and "RunDate" in self.df_history.columns and "Key" in self.df_history.columns:
                date_ct= self.df_history.groupby("RunDate")["Key"].count().reset_index(name="Count")
                if not date_ct.empty:
                    date_ct["dt"]= pd.to_datetime(date_ct["RunDate"], errors="coerce")
                    date_ct.sort_values("dt", inplace=True)
                    fig, ax= plt.subplots(figsize=(8,5))
                    xvals= np.arange(len(date_ct))
                    ax.plot(xvals, date_ct["Count"], marker="o", color="purple", label="Count")
                    avg= date_ct["Count"].rolling(3, min_periods=1).mean()
                    std= date_ct["Count"].rolling(3, min_periods=1).std(ddof=0)
                    up= avg+2*std
                    lo= avg-2*std
                    ax.fill_between(xvals, lo, up, color="purple", alpha=0.2, label="±2σ")
                    for i,r in date_ct.iterrows():
                        ax.text(i, r["Count"], str(int(r["Count"])), ha="center", va="bottom")
                    ax.set_xticks(xvals)
                    xlbl= [d.strftime("%Y-%m-%d") if not pd.isna(d) else "" for d in date_ct["dt"]]
                    ax.set_xticklabels(xlbl, rotation=45, ha="right")
                    ax.set_title("Bollinger: entire history")
                    ax.legend()
                    enable_hover_chart(ax)
                    pdf.savefig(fig)
                    plt.close(fig)

        logging.info(f"PDF => {pdf_path}")
        return pdf_path

    def _new_fig(self)-> plt.Figure:
        fig= plt.figure(figsize=(self.PAGE_WIDTH,self.PAGE_HEIGHT))
        plt.axis("off")
        self.page_count+=1
        return fig


# ----------------------------------------------------------------------------
# HISTORY TAB => double click => show JSON
# ----------------------------------------------------------------------------
class HistoryTab(ctk.CTkFrame):
    def __init__(self, parent, hist_dir: Path):
        super().__init__(parent)
        self.hist_dir= hist_dir
        self.build()

    def build(self):
        lbl= ctk.CTkLabel(self, text="Reconciliation Runs History", font=("Arial",16))
        lbl.pack(pady=5)

        self.tree= ttk.Treeview(self, columns=("File",), show="headings", height=15)
        self.tree.heading("File", text="History File")
        self.tree.pack(fill="both", expand=True, padx=10, pady=10)

        self.tree.bind("<Double-1>", self.on_double_click)

        btn= ctk.CTkButton(self, text="Refresh", command=self.refresh,
                           fg_color="#800020", hover_color="#a52a2a", text_color="white")
        btn.pack(pady=5)

        self.refresh()

    def refresh(self):
        for i in self.tree.get_children():
            self.tree.delete(i)
        if not self.hist_dir.is_dir():
            self.hist_dir.mkdir(parents=True, exist_ok=True)
        files= sorted(self.hist_dir.glob("*.json"), reverse=True)
        for f in files:
            self.tree.insert("", "end", values=(f.name,))

    def on_double_click(self, event):
        sel= self.tree.focus()
        if not sel:
            return
        fname= self.tree.item(sel, "values")[0]
        path= self.hist_dir/fname
        if not path.is_file():
            return
        try:
            with open(path,"r",encoding="utf-8") as ff:
                content= ff.read()
            popup= tk.Toplevel(self)
            popup.title(f"Viewing {fname}")
            txt= ctk.CTkTextbox(popup, width=800, height=600)
            txt.pack(fill="both", expand=True)
            txt.insert("end", content)
            txt.configure(state="disabled")
        except Exception as e:
            logging.error(f"History => {e}")


# ----------------------------------------------------------------------------
# ADVANCED DASHBOARD => stubs
# ----------------------------------------------------------------------------
class AdvancedDashboard(ctk.CTkFrame):
    def __init__(self, parent, config: Dict):
        super().__init__(parent)
        self.config= config
        dash_cfg= config.get("dashboard",{})
        self.selected_dims= set(dash_cfg.get("selected_dims",[]))
        self.selected_attrs= set(dash_cfg.get("selected_attrs",[]))
        self.top_n= dash_cfg.get("top_n",10)

        self.df_current= pd.DataFrame()
        self.df_history= pd.DataFrame()

        topbar= ctk.CTkScrollableFrame(self, orientation="horizontal", height=60)
        topbar.pack(fill="x", pady=5)
        self.metric_label= ctk.CTkLabel(topbar, text="Metrics: 0 mismatch, 0 dimension", width=300)
        self.metric_label.pack(side="left", padx=5)

        ctk.CTkButton(topbar, text="Filter Dimension", command=lambda: messagebox.showinfo("Filter","Not implemented"),
                      fg_color="#800020", hover_color="#a52a2a", text_color="white").pack(side="left", padx=5)
        ctk.CTkButton(topbar, text="Filter Attribute", command=lambda: messagebox.showinfo("Filter","Not implemented"),
                      fg_color="#800020", hover_color="#a52a2a", text_color="white").pack(side="left", padx=5)
        ctk.CTkButton(topbar, text="Toggle Top 10/All", command=self.toggle_top_n,
                      fg_color="#800020", hover_color="#a52a2a", text_color="white").pack(side="left", padx=5)

        self.notebook= ttk.Notebook(self)
        self.notebook.pack(fill="both", expand=True)
        for lbl in ["Heatmap","Lollipop","Circular","Scatter","Radar","Normal Pie","Normal Bar","Bollinger Chart"]:
            fr= ctk.CTkFrame(self.notebook)
            self.notebook.add(fr, text=lbl)

    def toggle_top_n(self):
        if self.top_n==10:
            self.top_n= None
        else:
            self.top_n= 10
        self.update_data_filters()

    def set_data(self, df_current: pd.DataFrame, df_history: pd.DataFrame):
        self.df_current= df_current.copy()
        self.df_history= df_history.copy()
        self.update_data_filters()

    def update_data_filters(self):
        mism= len(self.df_current)
        dims= self.df_current["Dimension"].nunique() if not self.df_current.empty and "Dimension" in self.df_current.columns else 0
        self.metric_label.configure(text=f"Metrics: {mism} mismatch, {dims} dimension")


# ----------------------------------------------------------------------------
# MAIN APP
# ----------------------------------------------------------------------------
class MainApp(ctk.CTk):
    def __init__(self):
        super().__init__()
        self.title("Ultra-Mega Reconciliation: 2-sheet, Bollinger, dimension fix, End Date fix")
        self.geometry("1400x800")
        ctk.set_appearance_mode("light")

        self.protocol("WM_DELETE_WINDOW", self.on_close)
        self.config_dict= load_config(Path(DEFAULT_PATHS["CONFIG_PATH"]))
        self.param_dict= read_param_file(Path(self.config_dict["paths"].get("PARAMETER_PATH",DEFAULT_PATHS["PARAMETER_PATH"])))

        self.history_df= pd.DataFrame()
        self.tabs= ttk.Notebook(self)
        self.tabs.pack(fill="both", expand=True)

        # 1) Paths
        self.tab_paths= ctk.CTkFrame(self.tabs)
        self.build_paths_tab(self.tab_paths)
        self.tabs.add(self.tab_paths, text="Paths")

        # 2) ERP preview
        self.tab_erp= ctk.CTkFrame(self.tabs)
        self.erp_preview= SimplePreview(self.tab_erp,"ERP")
        self.erp_preview.pack(fill="both", expand=True)
        self.tabs.add(self.tab_erp, text="ERP Preview")

        # 3) Master preview
        self.tab_master= ctk.CTkFrame(self.tabs)
        self.master_preview= SimplePreview(self.tab_master,"Master")
        self.master_preview.pack(fill="both", expand=True)
        self.tabs.add(self.tab_master, text="Master Preview")

        # 4) Compare
        self.tab_compare= ctk.CTkFrame(self.tabs)
        self.build_compare_tab(self.tab_compare)
        self.tabs.add(self.tab_compare, text="Compare")

        # 5) Dashboard
        self.dashboard_tab= AdvancedDashboard(self.tabs, self.config_dict)
        self.tabs.add(self.dashboard_tab, text="Dashboard")

        # 6) History
        hist_dir= Path(self.config_dict["paths"].get("HISTORY_PATH","history_runs"))
        self.history_tab= HistoryTab(self.tabs, hist_dir)
        self.tabs.add(self.history_tab, text="History")

        # Logging
        self.log_box= ctk.CTkTextbox(self, height=120)
        self.log_box.pack(fill="both", side="bottom")
        self.log_box.configure(state="disabled")
        handler= TextHandler(self.log_box)
        handler.setLevel(logging.INFO)
        logging.getLogger().addHandler(handler)

        # Temp CSV
        self.temp_csv= Path(self.config_dict["paths"].get("MASTER_CSV_OUTPUT","temp_master_csv"))
        self.temp_csv.mkdir(parents=True, exist_ok=True)

        # load older runs
        self.load_history_runs()

        # meltdown => preview
        self.refresh_erp()
        self.refresh_master()

        ctk.CTkButton(self, text="Close Script", command=self.on_close,
                      fg_color="#800020", hover_color="#a52a2a", text_color="white").pack(pady=5)

        # pass entire history => band chart
        self.dashboard_tab.set_data(pd.DataFrame(), self.history_df)

    def build_paths_tab(self, parent):
        """
        Show only:
         - ERP Excel
         - Master ZIP
         - Exception Path
         - Missing Items Output
         - Parameter File
         - PDF Export Path
        """
        frm= ctk.CTkFrame(parent)
        frm.pack(fill="both", expand=True, padx=10, pady=10)

        self.erp_var= tk.StringVar(value=self.config_dict["paths"].get("ERP_EXCEL_PATH", DEFAULT_PATHS["ERP_EXCEL_PATH"]))
        self.mast_var= tk.StringVar(value=self.config_dict["paths"].get("MASTER_ZIP_PATH", DEFAULT_PATHS["MASTER_ZIP_PATH"]))
        self.exc_var= tk.StringVar(value=self.config_dict["paths"].get("EXCEPTION_PATH", DEFAULT_PATHS["EXCEPTION_PATH"]))
        self.out_var= tk.StringVar(value=self.config_dict["paths"].get("OUTPUT_PATH", DEFAULT_PATHS["OUTPUT_PATH"]))
        self.par_var= tk.StringVar(value=self.config_dict["paths"].get("PARAMETER_PATH", DEFAULT_PATHS["PARAMETER_PATH"]))
        self.pdf_var= tk.StringVar(value=self.config_dict["paths"].get("PDF_EXPORT_PATH", DEFAULT_PATHS["PDF_EXPORT_PATH"]))

        def mkrow(lbl, var, is_dir=False):
            rowf= ctk.CTkFrame(frm)
            rowf.pack(fill="x", pady=5)
            ctk.CTkLabel(rowf, text=lbl, width=180).pack(side="left", padx=5)
            e= ctk.CTkEntry(rowf, textvariable=var, width=600)
            e.pack(side="left", padx=5)
            def br():
                if is_dir:
                    p= filedialog.askdirectory()
                else:
                    p= filedialog.askopenfilename()
                if p:
                    var.set(p)
            ctk.CTkButton(rowf, text="Browse", command=br,
                          fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)

        mkrow("ERP Excel:", self.erp_var)
        mkrow("Master ZIP:", self.mast_var)
        mkrow("Exception Path:", self.exc_var)
        mkrow("Missing Items Output:", self.out_var)
        mkrow("Parameter File:", self.par_var)
        mkrow("PDF Export Path:", self.pdf_var)

        bf= ctk.CTkFrame(frm)
        bf.pack(fill="x", pady=10)
        ctk.CTkButton(bf, text="Save Config", command=self.save_all_config,
                      fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)
        ctk.CTkButton(bf, text="Refresh ERP", command=self.refresh_erp,
                      fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)
        ctk.CTkButton(bf, text="Refresh Master", command=self.refresh_master,
                      fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)

    def build_compare_tab(self, parent):
        frm= ctk.CTkFrame(parent)
        frm.pack(fill="both", expand=True, padx=10, pady=10)
        ctk.CTkLabel(frm, text="Generate Missing Items", font=("Arial",16)).pack(pady=5)
        ctk.CTkButton(frm, text="Run Reconciliation", command=self.run_comparison,
                      fg_color="#800020", hover_color="#a52a2a").pack(pady=10)
        ctk.CTkButton(frm, text="Export PDF Report",
                      command=self.export_pdf,
                      fg_color="#800020", hover_color="#a52a2a").pack(pady=10)

    def load_history_runs(self):
        hist_path= Path(self.config_dict["paths"].get("HISTORY_PATH","history_runs"))
        if not hist_path.is_dir():
            return
        frames=[]
        for jf in hist_path.glob("run_*.json"):
            try:
                df_run= pd.read_json(jf, orient="records")
                frames.append(df_run)
            except Exception as e:
                logging.error(f"History => {jf}: {e}")
        if frames:
            big= pd.concat(frames, ignore_index=True)
            self.history_df= pd.concat([self.history_df,big], ignore_index=True) if not self.history_df.empty else big
            self.history_df.drop_duplicates(inplace=True)
            logging.info(f"Loaded history => total {len(self.history_df)} items")

    def refresh_erp(self):
        erp_path= Path(self.erp_var.get().strip())
        raw_erp= read_erp_excel(erp_path)
        if raw_erp.empty:
            self.erp_preview.set_data(pd.DataFrame())
            return
        meltdown= meltdown_erp_for_preview(raw_erp, self.param_dict)
        pivoted= pivot_for_preview(meltdown)
        self.erp_preview.set_data(pivoted)

    def refresh_master(self):
        zip_path= Path(self.mast_var.get().strip())
        csvs= convert_master_txt_to_csv(zip_path, self.temp_csv)
        raw= unify_master_csvs(csvs)
        if raw.empty:
            self.master_preview.set_data(pd.DataFrame())
            return
        meltdown= meltdown_master_for_preview(raw, self.param_dict)
        pivoted= pivot_for_preview(meltdown)
        self.master_preview.set_data(pivoted)

    def run_comparison(self):
        df_erp_wide= self.erp_preview.get_filtered_df()
        df_mast_wide= self.master_preview.get_filtered_df()

        erp_long= self.unpivot(df_erp_wide)
        mast_long= self.unpivot(df_mast_wide)

        df_diff= compare_erp_master(erp_long, mast_long)
        exc_path= Path(self.exc_var.get().strip())
        df_exc= read_exception_table(exc_path)
        final= merge_exceptions(df_diff, df_exc)

        mismatch, case_df= separate_case_diffs(final)

        out_path= Path(self.out_var.get().strip())
        write_two_sheet_excel(mismatch, case_df, out_path)

        run_ts= datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        mismatch["RunDate"]= run_ts
        case_df["RunDate"]= run_ts
        appended= pd.concat([mismatch, case_df], ignore_index=True)
        self.history_df= pd.concat([self.history_df, appended], ignore_index=True)

        # Save JSON
        hist_path= Path(self.config_dict["paths"].get("HISTORY_PATH","history_runs"))
        hist_path.mkdir(parents=True, exist_ok=True)
        run_file= hist_path/f"run_{run_ts.replace(':','-')}.json"
        appended.to_json(run_file, orient="records", indent=2)
        logging.info(f"Run => {run_file}")

        # update dash
        self.dashboard_tab.set_data(appended, self.history_df)
        # refresh hist
        if hasattr(self.history_tab,"refresh"):
            self.history_tab.refresh()

        self.tabs.select(self.dashboard_tab)
        messagebox.showinfo("Done", f"Missing items => {out_path}")

    def unpivot(self, df_wide: pd.DataFrame)-> pd.DataFrame:
        if df_wide.empty:
            return pd.DataFrame(columns=["DimCode","Dimension","Name","Attribute","Value"])
        id_vars= ["DimCode","Dimension","Name"]
        meltdown_cols= [c for c in df_wide.columns if c not in id_vars]
        melted= df_wide.melt(id_vars=id_vars, value_vars=meltdown_cols,
                             var_name="Attribute", value_name="Value")
        for c in ["DimCode","Dimension","Name","Attribute","Value"]:
            if c not in melted.columns:
                melted[c]= ""
            melted[c]= melted[c].fillna("").astype(str).str.strip()
        return melted

    def export_pdf(self):
        if self.history_df.empty:
            messagebox.showinfo("PDF Export","No mismatch => history empty.")
            return
        if "RunDate" in self.history_df.columns:
            last_run= self.history_df["RunDate"].max()
            df_current= self.history_df[self.history_df["RunDate"]== last_run].copy()
        else:
            df_current= self.history_df.copy()
        df_history= self.history_df.copy()

        rep= EnhancedPDFReport(df_current, df_history, self.config_dict)
        pdf_path= rep.generate()
        messagebox.showinfo("PDF Export", f"PDF => {pdf_path}")

    def save_all_config(self):
        self.config_dict["paths"]["ERP_EXCEL_PATH"]= self.erp_var.get().strip()
        self.config_dict["paths"]["MASTER_ZIP_PATH"]= self.mast_var.get().strip()
        self.config_dict["paths"]["EXCEPTION_PATH"]= self.exc_var.get().strip()
        self.config_dict["paths"]["OUTPUT_PATH"]= self.out_var.get().strip()
        self.config_dict["paths"]["PARAMETER_PATH"]= self.par_var.get().strip()
        self.config_dict["paths"]["PDF_EXPORT_PATH"]= self.pdf_var.get().strip()

        dash_cfg= self.config_dict.setdefault("dashboard",{})
        dash_cfg["selected_dims"]= list(self.dashboard_tab.selected_dims)
        dash_cfg["selected_attrs"]= list(self.dashboard_tab.selected_attrs)
        dash_cfg["top_n"]= self.dashboard_tab.top_n

        cfg_path= Path(self.config_dict["paths"].get("CONFIG_PATH","config/ui_config.json"))
        save_config(self.config_dict, cfg_path)
        messagebox.showinfo("Saved","Paths & config saved")

    def on_close(self):
        self.save_all_config()
        # store bollinger if needed
        band_path= self.config_dict["paths"].get("BAND_CHART_JSON_PATH","")
        if band_path and not self.history_df.empty and "RunDate" in self.history_df.columns:
            try:
                outp= Path(band_path)
                date_ct= self.history_df.groupby("RunDate")["Key"].count().reset_index(name="Count")
                date_ct["dt"]= pd.to_datetime(date_ct["RunDate"], errors="coerce")
                date_ct.sort_values("dt", inplace=True)
                date_ct.reset_index(drop=True, inplace=True)
                date_ct["rolling_mean"]= date_ct["Count"].rolling(3, min_periods=1).mean()
                date_ct["rolling_std"]= date_ct["Count"].rolling(3, min_periods=1).std(ddof=0)
                date_ct["upper"]= date_ct["rolling_mean"]+2*date_ct["rolling_std"]
                date_ct["lower"]= date_ct["rolling_mean"]-2*date_ct["rolling_std"]
                date_ct["RunDate"]= date_ct["dt"].dt.strftime("%Y-%m-%d %H:%M:%S")
                date_ct.drop(columns=["dt"], inplace=True)
                date_ct.to_json(outp, orient="records", indent=2)
                logging.info(f"Bollinger => {outp}")
            except Exception as e:
                logging.error(f"Bollinger => {e}")
        self.destroy()


def main():
    app= MainApp()
    app.mainloop()

if __name__=="__main__":
    main()
