47

"""
Ultra-Mega Reconciliation (Single Master Table with Convert .txt to CSV + Dashboard)
-----------------------------------------------------------------------------------
Features:
  - Reads ERP from Excel (skipping rows).
  - Reads Master from a ZIP of .txt files:
    * Each .txt is read with robust multi-encoding attempts,
    * Converted to .csv in a temp folder,
    * Combined into a single DataFrame with a "Dimension" column.
  - Single Master grid to rename/hide/filter columns & filter row values (including NaNs).
  - "Dimension Renames" tab to rename dimension strings on meltdown.
  - Multiple compare modes (1,2,3); merges Exceptions table (hide/comments).
  - Dashboard with:
    * Discrepancy Heatmap
    * Status Distribution
    * Dimension Analysis
    * Attribute Comparison
    * Trend Over Days (each run stamped with today's date)
  - Stores UI config in JSON so next run has the same settings.

Author: X
Date: 2025
"""

import os
import json
import logging
import zipfile
import shutil
import time
from pathlib import Path
from typing import Dict, List, Set, Tuple
from datetime import datetime

import tkinter as tk
from tkinter import ttk, filedialog, messagebox, simpledialog

import customtkinter as ctk
import pandas as pd
import numpy as np

# Attempt chardet for advanced encoding detection (optional)
try:
    import chardet
except ImportError:
    chardet = None

from openpyxl import Workbook
from openpyxl.styles import PatternFill, Font, Alignment

# Matplotlib-based dashboard
import matplotlib
matplotlib.use("TkAgg")
import matplotlib.pyplot as plt
from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg

# ------------------------------------------------------------------------------
# 1) LOGGING
# ------------------------------------------------------------------------------
def setup_logger():
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s [%(levelname)s] %(message)s"
    )
setup_logger()

# ------------------------------------------------------------------------------
# 2) DEFAULT CONFIG
# ------------------------------------------------------------------------------
DEFAULT_PATHS = {
    "ERP_EXCEL_PATH": "data/ERP_Config.xlsx",
    "MASTER_ZIP_PATH": "data/Master_Config.zip",
    "EXCEPTION_PATH": "data/Exception_Table.xlsx",
    "OUTPUT_PATH": "output/Reconciliation.xlsx",
    "CONFIG_PATH": "config/ui_config.json",
    "MASTER_CSV_OUTPUT": "temp_master_csv"  # temp folder for CSV from .txt
}

def default_config() -> Dict:
    return {
        "paths": {
            "ERP_EXCEL_PATH": DEFAULT_PATHS["ERP_EXCEL_PATH"],
            "MASTER_ZIP_PATH": DEFAULT_PATHS["MASTER_ZIP_PATH"],
            "EXCEPTION_PATH": DEFAULT_PATHS["EXCEPTION_PATH"],
            "OUTPUT_PATH": DEFAULT_PATHS["OUTPUT_PATH"],
            "CONFIG_PATH": DEFAULT_PATHS["CONFIG_PATH"],
            "MASTER_CSV_OUTPUT": DEFAULT_PATHS["MASTER_CSV_OUTPUT"]
        },
        # ERP grid config
        "erp_grid": {
            "columns": [
                {"id": "Col1",           "name": "Col1",           "locked": False, "visible": True,  "renameable": True},
                {"id": "Col2",           "name": "Col2",           "locked": False, "visible": True,  "renameable": True},
                {"id": "Enabled_Flag",   "name": "Enabled_Flag",   "locked": False, "visible": True,  "renameable": True},
                {"id": "Dimension_Name", "name": "Dimension_Name", "locked": True,  "visible": True,  "renameable": False},
                {"id": "Value",          "name": "Value",          "locked": True,  "visible": True,  "renameable": False},
            ],
            "filters": {}
        },
        # Single Master grid
        "master_grid": {
            "columns": [
                {"id": "Name", "name": "Name", "locked": True,  "visible": True, "renameable": False},
                {"id": "Dimension", "name": "Dimension", "locked": True, "visible": True, "renameable": False}
            ],
            "filters": {}
        },
        # Map old dimension -> new dimension
        "dimension_renames": {},
        "comparison_option": 1
    }

def load_config(path: Path) -> Dict:
    if path.is_file():
        try:
            with open(path, "r", encoding="utf-8") as f:
                return json.load(f)
        except Exception as e:
            logging.warning(f"Could not load config from {path}: {e}")
    return default_config()

def save_config(cfg: Dict, path: Path):
    path.parent.mkdir(parents=True, exist_ok=True)
    try:
        with open(path, "w", encoding="utf-8") as f:
            json.dump(cfg, f, indent=2)
        logging.info(f"Saved config to {path}")
    except Exception as e:
        logging.error(f"Error saving config: {e}")

# ------------------------------------------------------------------------------
# 3) TEXT LOGGER HANDLER
# ------------------------------------------------------------------------------
class TextHandler(logging.Handler):
    def __init__(self, widget: ctk.CTkTextbox):
        super().__init__()
        self.widget = widget
    def emit(self, record):
        msg = self.format(record) + "\n"
        self.widget.after(0, self._append, msg)
    def _append(self, msg):
        self.widget.configure(state="normal")
        self.widget.insert("end", msg)
        self.widget.see("end")
        self.widget.configure(state="disabled")

# ------------------------------------------------------------------------------
# 4) SAFE READ ERP EXCEL
# ------------------------------------------------------------------------------
def safe_read_erp_excel(path: Path) -> pd.DataFrame:
    """
    Reads an Excel file, skipping the first 3 rows. Retries if locked, etc.
    """
    import pandas as pd
    if not path.is_file():
        logging.warning(f"ERP Excel not found: {path}")
        return pd.DataFrame()
    for attempt in range(2):
        try:
            logging.info(f"Reading Excel: {path} (attempt {attempt+1}/2)")
            df = pd.read_excel(path, skiprows=3)
            df.columns = df.columns.str.strip()
            return df
        except Exception as e:
            logging.warning(f"Failed reading Excel {path}: {e}")
            if attempt == 1:
                break
            time.sleep(1)
    return pd.DataFrame()

# ------------------------------------------------------------------------------
# 5) ROBUST CSV READING
# ------------------------------------------------------------------------------
def read_csv_robust(path: Path) -> pd.DataFrame:
    """
    Attempts to read a CSV file by trying a large list of encodings in sequence.
    Returns a DataFrame on success, else empty.
    """
    import csv

    # A broad list of encodings to try
    encoding_candidates = [
        'utf-8-sig', 'utf-8', 'utf-16', 'utf-16-le', 'utf-16-be',
        'utf-32', 'utf-32-le', 'utf-32-be',
        'cp1250', 'cp1251', 'cp1252', 'cp1254', 'cp1256', 'cp932', 'cp949',
        'latin1', 'iso-8859-1', 'iso-8859-2', 'windows-1250', 'windows-1251',
        'windows-1252', 'windows-1254', 'windows-1256', 'shift_jis',
        'euc_jp', 'euc_kr', 'big5', 'big5hkscs', 'gb2312', 'gbk', 'gb18030',
    ]

    for enc in encoding_candidates:
        try:
            df = pd.read_csv(
                path,
                encoding=enc,
                sep=",",
                on_bad_lines="skip",
                quoting=csv.QUOTE_MINIMAL,
                engine="python",
            )
            df.dropna(axis=0, how="all", inplace=True)
            df.dropna(axis=1, how="all", inplace=True)
            logging.info(f"[read_csv_robust] success '{enc}' => {path.name}, shape={df.shape}")
            return df
        except Exception as ex:
            logging.debug(f"[read_csv_robust] fail '{enc}': {ex}")

    logging.error(f"[read_csv_robust] Could not parse file with any known encoding: {path}")
    return pd.DataFrame()

# ------------------------------------------------------------------------------
# 6) MASTER TXT -> CSV
# ------------------------------------------------------------------------------
def convert_master_txt_to_csv(zip_path: Path, out_dir: Path) -> List[Path]:
    """
    Extracts all .txt from zip_path, attempts robust CSV reading, writes .csv to out_dir.
    Returns a list of created CSV paths.
    """
    if not zip_path.is_file():
        logging.warning(f"Master ZIP not found: {zip_path}")
        return []
    if out_dir.exists():
        shutil.rmtree(out_dir, ignore_errors=True)
    out_dir.mkdir(parents=True, exist_ok=True)

    created_csvs = []
    with zipfile.ZipFile(zip_path, "r") as z:
        txt_files = [f for f in z.namelist() if f.lower().endswith(".txt")]
        for txt_file in txt_files:
            base_name = os.path.basename(txt_file)
            if not base_name:
                continue
            try:
                with z.open(txt_file) as fo:
                    raw_data = fo.read()
            except Exception as e:
                logging.error(f"Error reading {txt_file} from ZIP: {e}")
                continue

            # Write to temp .txt
            temp_txt_path = out_dir / base_name
            try:
                with temp_txt_path.open("wb") as tf:
                    tf.write(raw_data)
            except Exception as e2:
                logging.error(f"Cannot write temp txt {temp_txt_path}: {e2}")
                continue

            # Now read that .txt with robust csv
            df_tmp = read_csv_robust(temp_txt_path)
            csv_name = base_name.rsplit(".",1)[0] + ".csv"
            csv_path = out_dir / csv_name
            try:
                df_tmp.to_csv(csv_path, index=False)
                created_csvs.append(csv_path)
                logging.info(f"Converted {txt_file} -> {csv_name}")
            except Exception as e3:
                logging.error(f"Error writing CSV {csv_name}: {e3}")

            # optionally remove temp txt
            try:
                temp_txt_path.unlink()
            except:
                pass

    return created_csvs

def read_all_master_csvs(csv_paths: List[Path]) -> pd.DataFrame:
    """
    Reads all CSVs in csv_paths using read_csv_robust,
    merges them, inserts Dimension from filename logic.
    """
    frames = []
    for csvf in csv_paths:
        df = read_csv_robust(csvf)
        if df.empty:
            continue
        # Derive dimension from filename
        base = csvf.stem
        if "_ceaster" in base.lower():
            base_dim = base.lower().replace("_ceaster", "")
        else:
            base_dim = base
        dimension = base_dim.replace("_", " ").title()

        # If first col is not "Name", rename
        if "Name" not in df.columns and len(df.columns)>0:
            first_col = df.columns[0]
            df.rename(columns={first_col: "Name"}, inplace=True)

        df["Dimension"] = dimension
        frames.append(df)
    if frames:
        return pd.concat(frames, ignore_index=True)
    else:
        return pd.DataFrame()

# ------------------------------------------------------------------------------
# 7) EXCEL-GRID CLASS
# ------------------------------------------------------------------------------
class ExcelGrid(ctk.CTkFrame):
    """
    Basic Excel-like grid with column manager and filters (including NaN).
    """
    LOCK_ICON = " \U0001F512"

    def __init__(self, parent, config_block: Dict, name: str):
        super().__init__(parent)
        self.name = name
        self.col_defs = config_block.get("columns", [])
        self.filters: Dict[str, Set] = {}
        for k, v in config_block.get("filters", {}).items():
            self.filters[k] = set(v)

        self.df = pd.DataFrame()

        self.create_toolbar()
        self.create_table()
        self.create_statusbar()

    def create_toolbar(self):
        tbar = ctk.CTkFrame(self)
        tbar.pack(fill="x", padx=5, pady=5)
        ctk.CTkButton(tbar, text="Manage Columns", command=self.show_column_manager).pack(side="left", padx=5)
        ctk.CTkButton(tbar, text="Clear Filters", command=self.clear_filters).pack(side="left", padx=5)

    def create_table(self):
        frame = ctk.CTkFrame(self)
        frame.pack(fill="both", expand=True, padx=5, pady=5)

        self.tree = ttk.Treeview(frame, show="headings")
        vsb = ttk.Scrollbar(frame, orient="vertical", command=self.tree.yview)
        hsb = ttk.Scrollbar(frame, orient="horizontal", command=self.tree.xview)
        self.tree.configure(yscrollcommand=vsb.set, xscrollcommand=hsb.set)

        self.tree.grid(row=0, column=0, sticky="nsew")
        vsb.grid(row=0, column=1, sticky="ns")
        hsb.grid(row=1, column=0, sticky="ew")

        frame.rowconfigure(0, weight=1)
        frame.columnconfigure(0, weight=1)

    def create_statusbar(self):
        self.status_label = ctk.CTkLabel(self, text="Ready")
        self.status_label.pack(fill="x", padx=5, pady=2)

    def set_data(self, df: pd.DataFrame):
        self.df = df.copy(deep=True)
        existing_ids = [c["id"] for c in self.col_defs]
        for col in self.df.columns:
            if col not in existing_ids:
                self.col_defs.append({
                    "id": col,
                    "name": col,
                    "locked": False,
                    "visible": True,
                    "renameable": True
                })
        self.refresh_table()

    def get_config_block(self):
        return {
            "columns": self.col_defs,
            "filters": {k: sorted(list(v)) for k,v in self.filters.items()}
        }

    def get_filtered_df(self) -> pd.DataFrame:
        if self.df.empty:
            return self.df
        df_f = self.df.copy()

        def passes_filter(x, allowed):
            if pd.isna(x):
                # pass if any allowed is also np.nan
                return any(pd.isna(a) for a in allowed)
            else:
                return x in allowed

        for col_id, allowed_vals in self.filters.items():
            if col_id in df_f.columns and allowed_vals:
                df_f = df_f[df_f[col_id].apply(lambda val: passes_filter(val, allowed_vals))]

        # keep only visible
        visible_ids = [c["id"] for c in self.col_defs if c.get("visible", True)]
        visible_ids = [c for c in visible_ids if c in df_f.columns]
        return df_f[visible_ids]

    def refresh_table(self):
        for item in self.tree.get_children():
            self.tree.delete(item)
        visible_cols = [c for c in self.col_defs if c.get("visible", True)]
        self.tree["columns"] = [c["id"] for c in visible_cols]

        for col_def in visible_cols:
            col_name = col_def["name"]
            if col_def.get("locked", False):
                col_name += self.LOCK_ICON
            self.tree.heading(
                col_def["id"],
                text=col_name,
                anchor="w",
                command=lambda c=col_def: self.show_filter_popup(c)
            )
            self.tree.column(col_def["id"], anchor="w", width=col_def.get("width", 120))

        df_f = self.get_filtered_df()
        for _, row in df_f.iterrows():
            vals = [row[c["id"]] for c in visible_cols]
            self.tree.insert("", "end", values=vals)

        self.status_label.configure(text=f"{len(df_f)} rows")

    def show_filter_popup(self, col_def: Dict):
        col_id = col_def["id"]
        if self.df.empty or col_id not in self.df.columns:
            return

        pop = tk.Toplevel(self)
        pop.title(f"Filter: {col_def['name']}")
        pop.geometry("320x500")

        frame = ctk.CTkFrame(pop)
        frame.pack(fill="both", expand=True, padx=5, pady=5)

        unique_vals = self.df[col_id].unique()
        display_map = {}
        for val in unique_vals:
            if pd.isna(val):
                disp = "(NaN)"
            elif isinstance(val, str) and not val.strip():
                disp = "(blank)"
            else:
                disp = str(val)
            display_map[val] = disp

        sorted_vals = sorted(display_map.keys(), key=lambda rv: display_map[rv].lower())
        current_filter = self.filters.get(col_id, set())
        if not current_filter:
            current_filter = set(unique_vals)

        select_all_var = tk.BooleanVar(value=True)
        def toggle_sel_all():
            cval = select_all_var.get()
            for v in var_dict.values():
                v.set(cval)

        ctk.CTkCheckBox(frame, text="Select All", variable=select_all_var, command=toggle_sel_all).pack(anchor="w", pady=5)

        scroll = ctk.CTkScrollableFrame(frame, width=280, height=350)
        scroll.pack(fill="both", expand=True, padx=5, pady=5)

        var_dict = {}
        for rv in sorted_vals:
            disp_str = display_map[rv]
            if pd.isna(rv):
                inf = any(pd.isna(a) for a in current_filter)
            else:
                inf = (rv in current_filter)
            var = tk.BooleanVar(value=inf)
            var_dict[rv] = var
            ctk.CTkCheckBox(scroll, text=disp_str, variable=var).pack(anchor="w")

        def apply_filter():
            sel = set()
            for rv, vb in var_dict.items():
                if vb.get():
                    sel.add(rv)
            self.filters[col_id] = sel
            pop.destroy()
            self.refresh_table()

        bf = ctk.CTkFrame(frame)
        bf.pack(fill="x", pady=5)
        ctk.CTkButton(bf, text="Apply", command=apply_filter).pack(side="left", padx=5)
        ctk.CTkButton(bf, text="Cancel", command=pop.destroy).pack(side="left", padx=5)

    def show_column_manager(self):
        cm = tk.Toplevel(self)
        cm.title(f"{self.name} Column Manager")
        scr = ctk.CTkScrollableFrame(cm, width=550, height=400)
        scr.pack(fill="both", expand=True)

        for i, col_def in enumerate(self.col_defs):
            rowf = ctk.CTkFrame(scr)
            rowf.pack(fill="x", pady=2)

            if col_def.get("locked", False):
                txt = col_def["name"] + self.LOCK_ICON
                ctk.CTkLabel(rowf, text=txt).pack(side="left", padx=5)
                continue

            var_vis = tk.BooleanVar(value=col_def.get("visible", True))

            def toggler(c=col_def, v=var_vis):
                c["visible"] = v.get()
                self.refresh_table()

            ctk.CTkCheckBox(rowf, text="", variable=var_vis, command=toggler).pack(side="left")

            if col_def.get("renameable", True):
                ctk.CTkButton(rowf, text=col_def["name"], command=lambda c=col_def: self.rename_column(c)).pack(side="left", padx=5)
            else:
                ctk.CTkLabel(rowf, text=col_def["name"]).pack(side="left", padx=5)

            ctk.CTkButton(rowf, text="↑", width=30,
                          command=lambda idx=i: self.move_column(idx, -1)).pack(side="right", padx=2)
            ctk.CTkButton(rowf, text="↓", width=30,
                          command=lambda idx=i: self.move_column(idx, 1)).pack(side="right", padx=2)

    def rename_column(self, col_def: Dict):
        old = col_def["name"]
        new_name = simpledialog.askstring("Rename Column", f"New name for {old}:", initialvalue=old)
        if new_name:
            col_def["name"] = new_name
            self.refresh_table()

    def move_column(self, idx: int, delta: int):
        new_idx = idx + delta
        if 0 <= new_idx < len(self.col_defs):
            self.col_defs[idx], self.col_defs[new_idx] = self.col_defs[new_idx], self.col_defs[idx]
            self.refresh_table()

    def clear_filters(self):
        self.filters.clear()
        self.refresh_table()

# ------------------------------------------------------------------------------
# 8) MELTDOWN & COMPARISON
# ------------------------------------------------------------------------------
def meltdown_erp(df: pd.DataFrame, dim_renames: Dict[str,str]) -> pd.DataFrame:
    """
    Convert ERP => (Dimension,RefName,Attribute,Value), apply dimension renames if any.
    """
    if df.empty:
        return df.copy()
    skip_cols = {"Col1","Col2","Enabled_Flag"}
    keep_cols = [c for c in df.columns if c not in skip_cols]
    id_vars = []
    if "Dimension_Name" in keep_cols:
        id_vars.append("Dimension_Name")
    if "Value" in keep_cols:
        id_vars.append("Value")
    value_vars = [c for c in keep_cols if c not in id_vars]

    if not id_vars:
        return pd.DataFrame(columns=["Dimension","RefName","Attribute","Value"])

    melted = df.melt(id_vars=id_vars, value_vars=value_vars,
                     var_name="Attribute", value_name="Value_melted")
    melted.rename(columns={"Dimension_Name":"Dimension","Value":"RefName","Value_melted":"Value"}, inplace=True)

    if dim_renames:
        melted["Dimension"] = melted["Dimension"].replace(dim_renames)
    return melted[["Dimension","RefName","Attribute","Value"]].copy()

def meltdown_master(df: pd.DataFrame, dim_renames: Dict[str,str]) -> pd.DataFrame:
    """
    Convert Master => (Dimension,RefName,Attribute,Value).
    """
    if df.empty:
        return df.copy()
    keep_cols = df.columns.tolist()
    id_vars = [c for c in ["Dimension","Name"] if c in keep_cols]
    value_vars = [c for c in keep_cols if c not in id_vars]

    if not id_vars:
        return pd.DataFrame(columns=["Dimension","RefName","Attribute","Value"])

    melted = df.melt(id_vars=id_vars, value_vars=value_vars,
                     var_name="Attribute", value_name="Value_melted")
    melted.rename(columns={"Name":"RefName","Value_melted":"Value"}, inplace=True)

    if dim_renames:
        melted["Dimension"] = melted["Dimension"].replace(dim_renames)

    return melted[["Dimension","RefName","Attribute","Value"]].copy()

def build_keys(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    for c in ["Dimension","RefName","Attribute","Value"]:
        if c not in df.columns:
            df[c] = ""
        df[c] = df[c].fillna("").astype(str).str.strip()
    df["GroupKey"] = df["Dimension"] + " | " + df["RefName"]
    df["Key"] = df["Dimension"] + " | " + df["RefName"] + " | " + df["Attribute"] + " | " + df["Value"]
    df["Comments_1"] = ""
    df["Comments_2"] = ""
    df["Action Item"] = ""
    df["Missing In"] = ""
    return df

def build_lookup_dict(df: pd.DataFrame) -> Dict[str,Dict[str,str]]:
    lookup = {}
    for gk, sub in df.groupby("GroupKey"):
        rec = {}
        if not sub.empty:
            ref = sub["RefName"].iloc[0]
        else:
            ref = ""
        rec["Name"] = ref
        for _, row in sub.iterrows():
            rec[row["Attribute"]] = row["Value"]
        lookup[gk] = rec
    return lookup

def compare_data(df_erp: pd.DataFrame, df_master: pd.DataFrame, mode: int) -> pd.DataFrame:
    erp_dict = build_lookup_dict(df_erp)
    mst_dict = build_lookup_dict(df_master)
    all_keys = set(erp_dict.keys()) | set(mst_dict.keys())
    results = []

    for gk in all_keys:
        dimension = gk.split(" | ")[0]
        a_data = erp_dict.get(gk, {})
        b_data = mst_dict.get(gk, {})
        name_a = a_data.get("Name","")
        name_b = b_data.get("Name","")

        if mode == 1:
            results.extend(compare_mode_1(dimension, name_a, name_b, a_data, b_data))
        elif mode == 2:
            results.extend(compare_mode_2(dimension, name_a, name_b, a_data, b_data))
        else:
            results.extend(compare_mode_3(dimension, name_a, name_b, a_data, b_data))

    df_diff = pd.DataFrame(results)
    if not df_diff.empty:
        df_diff["Key"] = (
            df_diff["Dimension"].str.strip() + " | " +
            df_diff["Name"].str.strip() + " | " +
            df_diff["Attribute"].str.strip() + " | " +
            df_diff["Value"].str.strip()
        )
    return df_diff

def compare_mode_1(dimension, name_a, name_b, a_data, b_data):
    """
    Show everything missing, plus mismatched values on both sides.
    """
    results = []
    all_attrs = set(a_data.keys()) | set(b_data.keys())
    for attr in all_attrs:
        va = a_data.get(attr, "")
        vb = b_data.get(attr, "")
        if va != vb:
            if va and not vb:
                results.append({
                    "Dimension": dimension, "Name": name_a,
                    "Attribute": attr, "Value": va, "Missing In": "MASTER"
                })
            elif vb and not va:
                results.append({
                    "Dimension": dimension, "Name": name_b,
                    "Attribute": attr, "Value": vb, "Missing In": "ERP"
                })
            else:
                # mismatch => both sides
                results.append({
                    "Dimension": dimension, "Name": name_a,
                    "Attribute": attr, "Value": va, "Missing In": "MASTER"
                })
                results.append({
                    "Dimension": dimension, "Name": name_b,
                    "Attribute": attr, "Value": vb, "Missing In": "ERP"
                })
    return results

def compare_mode_2(dimension, name_a, name_b, a_data, b_data):
    """
    If Name missing, skip attribute detail. Else compare attributes.
    """
    results = []
    if name_a and name_b and (name_a == name_b):
        # Name matched => compare attributes
        all_attrs = (set(a_data.keys())|set(b_data.keys())) - {"Name"}
        for attr in all_attrs:
            va = a_data.get(attr, "")
            vb = b_data.get(attr, "")
            if va != vb:
                if va and not vb:
                    results.append({
                        "Dimension": dimension, "Name": name_a,
                        "Attribute": attr, "Value": va, "Missing In": "MASTER"
                    })
                elif vb and not va:
                    results.append({
                        "Dimension": dimension, "Name": name_a,
                        "Attribute": attr, "Value": vb, "Missing In": "ERP"
                    })
                else:
                    results.append({
                        "Dimension": dimension, "Name": name_a,
                        "Attribute": attr, "Value": va, "Missing In": "MASTER"
                    })
                    results.append({
                        "Dimension": dimension, "Name": name_a,
                        "Attribute": attr, "Value": vb, "Missing In": "ERP"
                    })
    else:
        # entire record missing from one side
        if name_a and not name_b:
            results.append({
                "Dimension": dimension, "Name": name_a,
                "Attribute": "Name", "Value": name_a, "Missing In": "MASTER"
            })
        elif name_b and not name_a:
            results.append({
                "Dimension": dimension, "Name": name_b,
                "Attribute": "Name", "Value": name_b, "Missing In": "ERP"
            })
    return results

def compare_mode_3(dimension, name_a, name_b, a_data, b_data):
    """
    Show missing + matching. Mismatched attributes produce 2 rows. Matching produce 1 row with Missing In="".
    """
    results = []
    all_attrs = set(a_data.keys()) | set(b_data.keys())
    chosen_name = name_a if name_a else name_b

    for attr in all_attrs:
        va = a_data.get(attr, "")
        vb = b_data.get(attr, "")
        if va == vb:
            results.append({
                "Dimension": dimension, "Name": chosen_name, "Attribute": attr, "Value": va, "Missing In": ""
            })
        else:
            if va and not vb:
                results.append({
                    "Dimension": dimension, "Name": name_a, "Attribute": attr, "Value": va, "Missing In": "MASTER"
                })
            elif vb and not va:
                results.append({
                    "Dimension": dimension, "Name": name_b, "Attribute": attr, "Value": vb, "Missing In": "ERP"
                })
            else:
                results.append({
                    "Dimension": dimension, "Name": name_a, "Attribute": attr, "Value": va, "Missing In": "MASTER"
                })
                results.append({
                    "Dimension": dimension,
                    "Name": name_b if name_b else name_a,
                    "Attribute": attr, "Value": vb, "Missing In": "ERP"
                })
    return results

# ------------------------------------------------------------------------------
# 9) EXCEPTIONS
# ------------------------------------------------------------------------------
def read_exception_table(exc_path: Path) -> pd.DataFrame:
    if exc_path.is_file():
        try:
            df = pd.read_excel(exc_path, sheet_name=0)
            df.columns = df.columns.str.strip()
            return df
        except Exception as e:
            logging.error(f"Error reading exception table: {e}")
    return pd.DataFrame()

def merge_exceptions(df: pd.DataFrame, df_exc: pd.DataFrame) -> pd.DataFrame:
    if df.empty or df_exc.empty or "Key" not in df.columns:
        return df
    keep = [c for c in df_exc.columns if c in ["Key","Comments_1","Comments_2","hide exception"]]
    if not keep:
        return df
    exc = df_exc[keep].copy()
    exc["Key"] = exc["Key"].astype(str).str.strip()

    merged = df.merge(exc, on="Key", how="left", suffixes=("", "_exc"))
    merged["hide exception"] = merged.get("hide exception", "").fillna("").str.lower()
    final = merged[merged["hide exception"]!="yes"].copy()

    if "Comments_1_exc" in final.columns:
        final["Comments_1"] = np.where(final["Comments_1_exc"].notna(), final["Comments_1_exc"], final["Comments_1"])
        final.drop(columns=["Comments_1_exc"], inplace=True)
    if "Comments_2_exc" in final.columns:
        final["Comments_2"] = np.where(final["Comments_2_exc"].notna(), final["Comments_2_exc"], final["Comments_2"])
        final.drop(columns=["Comments_2_exc"], inplace=True)
    if "hide exception" in final.columns:
        final.drop(columns=["hide exception"], inplace=True)
    return final

# ------------------------------------------------------------------------------
# 10) WRITE RESULTS
# ------------------------------------------------------------------------------
def write_results(df: pd.DataFrame, out_path: Path, mode: int):
    if df.empty:
        logging.info("No differences to write => skipping file output.")
        return
    out_path.parent.mkdir(parents=True, exist_ok=True)
    final_cols = ["Key","Dimension","Name","Attribute","Value","Comments_1","Comments_2","Action Item","Missing In"]
    for c in final_cols:
        if c not in df.columns:
            df[c] = ""
    df = df[final_cols]

    wb = Workbook()
    max_rows_per_sheet = 30000 if mode == 3 else 999999
    sheet_count = 1
    start = 0
    while start < len(df):
        end = min(start + max_rows_per_sheet, len(df))
        chunk = df.iloc[start:end]
        if sheet_count == 1:
            ws = wb.active
            ws.title = f"Results{sheet_count}"
        else:
            ws = wb.create_sheet(title=f"Results{sheet_count}")
        ws.append(final_cols)
        for row in chunk.itertuples(index=False):
            ws.append(row)
        header_font = Font(bold=True)
        fill = PatternFill(start_color="DDDDDD", end_color="DDDDDD", fill_type="solid")
        for cell in ws[1]:
            cell.font = header_font
            cell.fill = fill
            cell.alignment = Alignment(horizontal="center")

        # Auto-col width
        for col in ws.columns:
            max_len = 0
            col_letter = col[0].column_letter
            for cell in col:
                val = str(cell.value) if cell.value else ""
                max_len = max(max_len, len(val))
            ws.column_dimensions[col_letter].width = max_len + 2
        ws.freeze_panes = "A2"

        sheet_count += 1
        start = end

    wb.save(out_path)
    logging.info(f"Results saved to {out_path}")

# ------------------------------------------------------------------------------
# 11) DASHBOARD
# ------------------------------------------------------------------------------
class Dashboard(ctk.CTkFrame):
    def __init__(self, parent):
        super().__init__(parent)
        self.df_current = pd.DataFrame()
        self.df_history = pd.DataFrame()

        self.notebook = ttk.Notebook(self)
        self.notebook.pack(fill="both", expand=True)

        self.frame_heatmap = ctk.CTkFrame(self.notebook)
        self.notebook.add(self.frame_heatmap, text="Discrepancy Heatmap")

        self.frame_status = ctk.CTkFrame(self.notebook)
        self.notebook.add(self.frame_status, text="Status Distribution")

        self.frame_dimension = ctk.CTkFrame(self.notebook)
        self.notebook.add(self.frame_dimension, text="Dimension Analysis")

        self.frame_attribute = ctk.CTkFrame(self.notebook)
        self.notebook.add(self.frame_attribute, text="Attribute Comparison")

        self.frame_linechart = ctk.CTkFrame(self.notebook)
        self.notebook.add(self.frame_linechart, text="Trend Over Days")

    def update_data(self, df_current: pd.DataFrame, df_history: pd.DataFrame):
        self.df_current = df_current.copy()
        self.df_history = df_history.copy()
        self.plot_heatmap()
        self.plot_status_distribution()
        self.plot_dimension_analysis()
        self.plot_attribute_comparison()
        self.plot_run_trend()

    def plot_heatmap(self):
        for w in self.frame_heatmap.winfo_children():
            w.destroy()
        if self.df_current.empty:
            return
        mismatch_df = self.df_current[self.df_current["Missing In"] != ""]
        if mismatch_df.empty:
            return
        pivot_df = mismatch_df.groupby(["Dimension","Attribute"]).size().unstack(fill_value=0)
        if pivot_df.empty:
            return
        fig, ax = plt.subplots(figsize=(6,5))
        cax = ax.imshow(pivot_df, cmap="Reds", aspect="auto")
        ax.set_xticks(range(len(pivot_df.columns)))
        ax.set_yticks(range(len(pivot_df.index)))
        ax.set_xticklabels(pivot_df.columns, rotation=90)
        ax.set_yticklabels(pivot_df.index)
        ax.set_title("Discrepancy Heatmap (# mismatches)")
        fig.colorbar(cax, ax=ax)
        canvas = FigureCanvasTkAgg(fig, master=self.frame_heatmap)
        canvas.draw()
        canvas.get_tk_widget().pack(fill="both", expand=True)

    def plot_status_distribution(self):
        for w in self.frame_status.winfo_children():
            w.destroy()
        if self.df_current.empty:
            return
        dist_counts = self.df_current["Missing In"].fillna("").value_counts()
        data_labels = dist_counts.index.tolist()
        data_values = dist_counts.values.tolist()
        fig, ax = plt.subplots(figsize=(5,5))
        ax.pie(data_values, labels=data_labels, autopct="%.1f%%", startangle=140)
        ax.set_title("Status Distribution (Current Run)")
        canvas = FigureCanvasTkAgg(fig, master=self.frame_status)
        canvas.draw()
        canvas.get_tk_widget().pack(fill="both", expand=True)

    def plot_dimension_analysis(self):
        for w in self.frame_dimension.winfo_children():
            w.destroy()
        if self.df_current.empty:
            return
        dim_counts = self.df_current.groupby("Dimension")["Key"].count().sort_values(ascending=False)
        fig, ax = plt.subplots(figsize=(6,4))
        dim_counts.plot(kind="bar", ax=ax, color="blue")
        ax.set_ylabel("Count of Rows")
        ax.set_title("Records per Dimension (Current Run)")
        canvas = FigureCanvasTkAgg(fig, master=self.frame_dimension)
        canvas.draw()
        canvas.get_tk_widget().pack(fill="both", expand=True)

    def plot_attribute_comparison(self):
        for w in self.frame_attribute.winfo_children():
            w.destroy()
        if self.df_current.empty:
            return
        attr_counts = self.df_current.groupby("Attribute")["Key"].count().sort_values(ascending=False).head(10)
        fig, ax = plt.subplots(figsize=(6,4))
        attr_counts.plot(kind="bar", ax=ax, color="red")
        ax.set_ylabel("# of Mismatches")
        ax.set_title("Top 10 Mismatched Attributes (Current Run)")
        canvas = FigureCanvasTkAgg(fig, master=self.frame_attribute)
        canvas.draw()
        canvas.get_tk_widget().pack(fill="both", expand=True)

    def plot_run_trend(self):
        for w in self.frame_linechart.winfo_children():
            w.destroy()
        if self.df_history.empty or "RunDate" not in self.df_history.columns:
            return
        mismatch_df = self.df_history[self.df_history["Missing In"] != ""]
        if mismatch_df.empty:
            return
        date_counts = mismatch_df.groupby("RunDate")["Key"].count().reset_index()
        fig, ax = plt.subplots(figsize=(6,4))
        ax.plot(date_counts["RunDate"], date_counts["Key"], marker="o", color="green")
        ax.set_xlabel("Date")
        ax.set_ylabel("Mismatch Count")
        ax.set_title("Mismatch Trend Over Days")
        plt.xticks(rotation=45)
        for i, row in date_counts.iterrows():
            ax.text(row["RunDate"], row["Key"], str(row["Key"]), ha="center", va="bottom")
        canvas = FigureCanvasTkAgg(fig, master=self.frame_linechart)
        canvas.draw()
        canvas.get_tk_widget().pack(fill="both", expand=True)

# ------------------------------------------------------------------------------
# 12) MAIN APP
# ------------------------------------------------------------------------------
class MainApp(ctk.CTk):
    """
    - Single Master + Single ERP
    - For Master, we do .txt->.csv robustly, unify into one DataFrame with Dimension
    - Compare in multiple modes, merges exceptions, Dashboard with run-date stamping
    - Paths tab with all paths
    - Dimension Renames
    """
    def __init__(self):
        super().__init__()
        self.title("Ultra-Mega Reconciliation (Single Master + Dashboard)")
        self.geometry("1600x900")

        self.config_dict = load_config(Path(DEFAULT_PATHS["CONFIG_PATH"]))
        self.history_df = pd.DataFrame()

        # Main Notebook
        self.notebook = ttk.Notebook(self)
        self.notebook.pack(fill="both", expand=True)

        # Tab 1: Paths
        self.tab_paths = ctk.CTkFrame(self.notebook)
        self.notebook.add(self.tab_paths, text="Paths")
        self.build_paths_tab(self.tab_paths)

        # Tab 2: ERP
        self.tab_erp = ctk.CTkFrame(self.notebook)
        self.notebook.add(self.tab_erp, text="ERP Data")
        self.erp_grid = ExcelGrid(self.tab_erp, self.config_dict["erp_grid"], "ERP")
        self.erp_grid.pack(fill="both", expand=True)

        # Tab 3: Master
        self.tab_master = ctk.CTkFrame(self.notebook)
        self.notebook.add(self.tab_master, text="Master Data")
        self.master_grid = ExcelGrid(self.tab_master, self.config_dict["master_grid"], "Master")
        self.master_grid.pack(fill="both", expand=True)

        # Tab 4: Dimension Renames
        self.tab_dim = ctk.CTkFrame(self.notebook)
        self.notebook.add(self.tab_dim, text="Dimension Renames")
        self.build_dimension_tab(self.tab_dim)

        # Tab 5: Compare & Exceptions
        self.tab_compare = ctk.CTkFrame(self.notebook)
        self.notebook.add(self.tab_compare, text="Compare & Exceptions")
        self.build_compare_tab(self.tab_compare)

        # Tab 6: Dashboard
        self.tab_dashboard = Dashboard(self.notebook)
        self.notebook.add(self.tab_dashboard, text="Dashboard")

        # Logging
        self.log_box = ctk.CTkTextbox(self, height=140)
        self.log_box.pack(fill="both", expand=False)
        self.log_box.configure(state="disabled")
        handler = TextHandler(self.log_box)
        handler.setLevel(logging.INFO)
        logging.getLogger().addHandler(handler)

        # Load data initially
        self.refresh_erp_data()
        self.refresh_master_data()

    def build_paths_tab(self, parent):
        frm = ctk.CTkFrame(parent)
        frm.pack(fill="both", expand=True, padx=10, pady=10)

        self.erp_var = tk.StringVar(value=self.config_dict["paths"].get("ERP_EXCEL_PATH", DEFAULT_PATHS["ERP_EXCEL_PATH"]))
        self.mst_var = tk.StringVar(value=self.config_dict["paths"].get("MASTER_ZIP_PATH", DEFAULT_PATHS["MASTER_ZIP_PATH"]))
        self.exc_var = tk.StringVar(value=self.config_dict["paths"].get("EXCEPTION_PATH", DEFAULT_PATHS["EXCEPTION_PATH"]))
        self.out_var = tk.StringVar(value=self.config_dict["paths"].get("OUTPUT_PATH", DEFAULT_PATHS["OUTPUT_PATH"]))
        self.cfg_var = tk.StringVar(value=self.config_dict["paths"].get("CONFIG_PATH", DEFAULT_PATHS["CONFIG_PATH"]))
        self.temp_var = tk.StringVar(value=self.config_dict["paths"].get("MASTER_CSV_OUTPUT", DEFAULT_PATHS["MASTER_CSV_OUTPUT"]))

        def mkrow(label, var, is_dir=False):
            rowf = ctk.CTkFrame(frm)
            rowf.pack(fill="x", pady=5)
            ctk.CTkLabel(rowf, text=label, width=200).pack(side="left", padx=5)
            ent = ctk.CTkEntry(rowf, textvariable=var, width=800)
            ent.pack(side="left", padx=5)
            def br():
                if is_dir:
                    p = filedialog.askdirectory()
                else:
                    p = filedialog.askopenfilename()
                if p:
                    var.set(p)
            ctk.CTkButton(rowf, text="Browse", command=br).pack(side="left", padx=5)

        mkrow("ERP Excel Path:", self.erp_var)
        mkrow("Master ZIP Path:", self.mst_var)
        mkrow("Exception Path:", self.exc_var)
        mkrow("Output Excel Path:", self.out_var)
        mkrow("JSON Config Path:", self.cfg_var)
        mkrow("Temp CSV Folder:", self.temp_var, is_dir=True)

    def build_dimension_tab(self, parent):
        frm = ctk.CTkFrame(parent)
        frm.pack(fill="both", expand=True, padx=10, pady=10)
        ctk.CTkLabel(frm, text="Old Dimension -> New Dimension").pack(pady=5)

        self.dim_list_frame = ctk.CTkScrollableFrame(frm, width=600, height=300)
        self.dim_list_frame.pack(fill="both", expand=True)
        self.rename_vars = []

        # Populate from existing
        for oldv, newv in self.dim_rename_map.items():
            self.add_dim_rename_row(oldv, newv)

        ctk.CTkButton(frm, text="Add Dimension Rename", command=lambda: self.add_dim_rename_row("", "")).pack(pady=5)
        ctk.CTkButton(frm, text="Save Dimension Renames", command=self.save_dim_renames).pack(pady=5)

    def add_dim_rename_row(self, oldval, newval):
        rowf = ctk.CTkFrame(self.dim_list_frame)
        rowf.pack(fill="x", pady=2)
        var_old = tk.StringVar(value=oldval)
        var_new = tk.StringVar(value=newval)

        ctk.CTkLabel(rowf, text="Old:").pack(side="left", padx=5)
        ctk.CTkEntry(rowf, textvariable=var_old, width=200).pack(side="left", padx=5)
        ctk.CTkLabel(rowf, text=" -> ").pack(side="left")
        ctk.CTkEntry(rowf, textvariable=var_new, width=200).pack(side="left", padx=5)

        self.rename_vars.append((var_old, var_new))

    def save_dim_renames(self):
        new_map = {}
        for (vold, vnew) in self.rename_vars:
            o = vold.get().strip()
            n = vnew.get().strip()
            if o and n and (o != n):
                new_map[o] = n
        self.dim_rename_map = new_map
        messagebox.showinfo("Saved", "Dimension renames updated in memory.")

    @property
    def dim_rename_map(self) -> Dict[str, str]:
        return self.config_dict.get("dimension_renames", {})

    @dim_rename_map.setter
    def dim_rename_map(self, value: Dict[str, str]):
        self.config_dict["dimension_renames"] = value

    def build_compare_tab(self, parent):
        frm = ctk.CTkFrame(parent)
        frm.pack(fill="both", expand=True, padx=10, pady=10)

        self.mode_var = tk.IntVar(value=self.config_dict.get("comparison_option", 1))
        for i, text in enumerate([
            "Option 1: Show everything missing in ERP or MASTER",
            "Option 2: If Name missing, skip attributes; else show missing attributes",
            "Option 3: Show missing + matching"
        ], start=1):
            ctk.CTkRadioButton(frm, text=text, variable=self.mode_var, value=i).pack(anchor="w", padx=5, pady=2)

        btnf = ctk.CTkFrame(frm)
        btnf.pack(fill="x", pady=10)
        ctk.CTkButton(btnf, text="Run Comparison", command=self.run_comparison).pack(side="left", padx=5)
        ctk.CTkButton(btnf, text="Save Config", command=self.save_all_config).pack(side="left", padx=5)

    def refresh_erp_data(self):
        p = Path(self.erp_var.get())
        df_erp = safe_read_erp_excel(p)
        self.erp_grid.set_data(df_erp)

    def refresh_master_data(self):
        """
        1) Convert all .txt in Master ZIP to CSV using robust attempts, store in MASTER_CSV_OUTPUT.
        2) Read all CSV => single DataFrame, deduce dimension from filename.
        3) Display in master_grid.
        """
        zip_path = Path(self.mst_var.get())
        out_dir = Path(self.temp_var.get())
        if not zip_path.is_file():
            logging.warning("Master ZIP not found.")
            return

        csv_paths = convert_master_txt_to_csv(zip_path, out_dir)
        if not csv_paths:
            logging.warning("No CSV generated => empty Master Data.")
            df_master = pd.DataFrame()
        else:
            df_master = read_all_master_csvs(csv_paths)

        self.master_grid.set_data(df_master)

    def run_comparison(self):
        # Update config paths
        self.config_dict["paths"]["ERP_EXCEL_PATH"] = self.erp_var.get().strip()
        self.config_dict["paths"]["MASTER_ZIP_PATH"] = self.mst_var.get().strip()
        self.config_dict["paths"]["EXCEPTION_PATH"] = self.exc_var.get().strip()
        self.config_dict["paths"]["OUTPUT_PATH"] = self.out_var.get().strip()
        self.config_dict["paths"]["CONFIG_PATH"] = self.cfg_var.get().strip()
        self.config_dict["paths"]["MASTER_CSV_OUTPUT"] = self.temp_var.get().strip()

        mode = self.mode_var.get()
        self.config_dict["comparison_option"] = mode

        # 1) meltdown ERP
        df_erp_filt = self.erp_grid.get_filtered_df()
        erp_m = meltdown_erp(df_erp_filt, self.dim_rename_map)
        erp_m = build_keys(erp_m)

        # 2) meltdown Master
        df_mst_filt = self.master_grid.get_filtered_df()
        mst_m = meltdown_master(df_mst_filt, self.dim_rename_map)
        mst_m = build_keys(mst_m)

        # 3) compare
        df_diff = compare_data(erp_m, mst_m, mode)

        # 4) exceptions
        exc_path = Path(self.exc_var.get().strip())
        df_exc = read_exception_table(exc_path)
        final = merge_exceptions(df_diff, df_exc)

        # 5) write
        out_path = Path(self.out_var.get().strip())
        write_results(final, out_path, mode)

        # 6) dashboard => timestamp run
        run_date = datetime.now().strftime("%Y-%m-%d")
        final["RunDate"] = run_date
        self.history_df = pd.concat([self.history_df, final], ignore_index=True)

        # update dashboard
        self.notebook.select(len(self.notebook.tabs()) - 1)  # jump to dashboard tab
        self.tab_dashboard.update_data(final, self.history_df)

        messagebox.showinfo("Done", f"Comparison done for date {run_date}. Output => {out_path}")

    def save_all_config(self):
        # Save grids
        self.config_dict["erp_grid"] = self.erp_grid.get_config_block()
        self.config_dict["master_grid"] = self.master_grid.get_config_block()

        # Save dimension renames
        self.config_dict["dimension_renames"] = self.dim_rename_map

        # Save paths
        self.config_dict["paths"]["ERP_EXCEL_PATH"] = self.erp_var.get().strip()
        self.config_dict["paths"]["MASTER_ZIP_PATH"] = self.mst_var.get().strip()
        self.config_dict["paths"]["EXCEPTION_PATH"] = self.exc_var.get().strip()
        self.config_dict["paths"]["OUTPUT_PATH"] = self.out_var.get().strip()
        self.config_dict["paths"]["CONFIG_PATH"] = self.cfg_var.get().strip()
        self.config_dict["paths"]["MASTER_CSV_OUTPUT"] = self.temp_var.get().strip()

        # Save compare mode
        self.config_dict["comparison_option"] = self.mode_var.get()

        # Final write
        save_config(self.config_dict, Path(self.cfg_var.get().strip()))
        messagebox.showinfo("Saved", "All config saved successfully.")

# ------------------------------------------------------------------------------
# 13) MAIN
# ------------------------------------------------------------------------------
def main():
    app = MainApp()
    app.mainloop()

if __name__ == "__main__":
    main()
