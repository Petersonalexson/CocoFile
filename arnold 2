import logging
import pandas as pd
import warnings
from openpyxl import load_workbook
from openpyxl.comments import Comment

# Suppress common openpyxl warnings
warnings.filterwarnings("ignore", category=UserWarning, module="openpyxl")

# -----------------------------------------------------------------------------
# 1. Setup Logging
# -----------------------------------------------------------------------------
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)

# -----------------------------------------------------------------------------
# 2. File Paths (Adjust to your actual paths)
# -----------------------------------------------------------------------------
MAP_FILE_PATH = r"C:\Users\alexp\OneDrive\Desktop\MAP.xlsx"
BANI_FILE_PATH = r"C:\Users\alexp\OneDrive\Desktop\BANI.xlsx"

MAPPING_SHEET = "Mapping Main"
XRP_SHEET = "XRP"

ARNOLD_DESC2 = "Arnold"  # The string in "Description 2" that indicates Arnold's accounts
SYLV_DESC2 = "Sylv"      # The string in "Description 2" that indicates Sylv's accounts

ARNOLD_SHEET_NAME = "Arnold"  # In BANI.xlsx, the sheet where Arnold's multiple tables exist
SYLV_SHEET_NAME = "Sylv"      # In BANI.xlsx, the sheet for Sylv

# -----------------------------------------------------------------------------
# 3. Read the Mapping Data
#    We'll read the "Mapping Main" sheet from MAP.xlsx
#    and filter for "Arnold" and "Sylv" accounts separately.
# -----------------------------------------------------------------------------
logging.info("Loading mapping data from MAP.xlsx...")
map_df = pd.read_excel(MAP_FILE_PATH, sheet_name=MAPPING_SHEET)

# Drop rows with no 'Account'
map_df = map_df.dropna(subset=["Account"])

# Convert 'Account' to string (since we'll do the same in BANI data)
map_df["Account"] = map_df["Account"].astype(str).str.strip()

# Also ensure 'Description 2' is string
map_df["Description 2"] = map_df["Description 2"].astype(str).str.strip()

# -----------------------------------------------------------------------------
# 4. Read the BANI (XRP) data
#    We'll keep "Nat Cont", "Centru", "Quantitate", "Num"
#    and also treat "Nat Cont" as string so it matches map_df["Account"].
# -----------------------------------------------------------------------------
logging.info("Loading BANI data from BANI.xlsx (XRP sheet)...")
bani_df = pd.read_excel(BANI_FILE_PATH, sheet_name=XRP_SHEET)

needed_cols = ["Nat Cont", "Centru", "Quantitate", "Num"]
bani_df = bani_df[needed_cols].dropna(subset=["Nat Cont", "Centru", "Quantitate"])

bani_df["Nat Cont"] = bani_df["Nat Cont"].astype(str).str.strip()
bani_df["Centru"]   = bani_df["Centru"].astype(str).str.strip()
bani_df["Num"]      = bani_df["Num"].fillna("").astype(str).str.strip()
bani_df["Quantitate"] = bani_df["Quantitate"].astype(float)

# -----------------------------------------------------------------------------
# 5. A helper function to build an aggregator for a given 'Description 2'.
#    This means:
#     - Filter map_df by 'Description 2'
#     - Grab those account strings
#     - Filter bani_df by those accounts
#     - Group by (Centru, Num), sum Quantitate
#     - Return a dict { (center, xo_number) : sum_of_quant }
# -----------------------------------------------------------------------------
def build_aggregator(desc2_value):
    submap = map_df[map_df["Description 2"] == desc2_value]
    if submap.empty:
        logging.warning(f"No mapping rows found for '{desc2_value}'. Returning empty aggregator.")
        return {}
    
    accounts = set(submap["Account"].unique())  # set of strings
    filtered_bani = bani_df[bani_df["Nat Cont"].isin(accounts)]
    if filtered_bani.empty:
        logging.info(f"No BANI rows match accounts for '{desc2_value}'; returning empty aggregator.")
        return {}
    
    grouped = filtered_bani.groupby(["Centru", "Num"], dropna=False)["Quantitate"].sum().reset_index()
    agg_dict = {}
    for _, row in grouped.iterrows():
        c  = row["Centru"]
        n  = row["Num"]
        qt = row["Quantitate"]
        agg_dict[(c, n)] = qt
    
    logging.info(f"Built aggregator for '{desc2_value}': {len(agg_dict)} items.")
    return agg_dict

# Build the two aggregators
arnold_lookup = build_aggregator(ARNOLD_DESC2)
sylv_lookup   = build_aggregator(SYLV_DESC2)

# If both empty, we can exit early
if not arnold_lookup and not sylv_lookup:
    logging.info("No aggregator data found for either Arnold or Sylv. Exiting.")
    exit()

# -----------------------------------------------------------------------------
# 6. openpyxl-based function to find "tables" in a sheet
#    A "table" is identified by the presence (in one row) of the strings:
#      - "Actual Oct" (or "oct actual", ignoring case)
#      - "XO number"
#      - "XO c" (center)
#
#    We then capture the columns. We'll parse data in the rows beneath until
#    we hit another table's header row, or reach max_row, or a big blank row.
# -----------------------------------------------------------------------------
def find_tables_with_headers(ws, max_search_rows=2000):
    """
    Scan each row for columns that have:
      - 'xo number'
      - 'xo c'
      - 'actual oct'   (case-insensitive)
    Return a list of dictionaries:
      [ 
         {
           'header_row': <row_idx>,
           'col_xo_number': X,
           'col_xo_c': Y,
           'col_actual_oct': Z
         },
         ...
      ]
    """
    tables = []
    max_row = min(ws.max_row, max_search_rows)

    for r in range(1, max_row + 1):
        # We'll see if row r has all three necessary headers
        headers_found = {
            "xo number": None,
            "xo c": None,
            "actual oct": None
        }
        row_cells = [ws.cell(row=r, column=cc).value for cc in range(1, ws.max_column + 1)]
        
        # Look across columns for the needed headers
        for c_idx, val in enumerate(row_cells, start=1):
            if val is None:
                continue
            val_str = str(val).strip().lower()
            # Check each header possibility
            if val_str == "xo number":
                headers_found["xo number"] = c_idx
            elif val_str == "xo c":
                headers_found["xo c"] = c_idx
            elif val_str in ("actual oct", "oct actual"):
                headers_found["actual oct"] = c_idx
        
        # If all three found in this row, that is a table header row
        if all(headers_found.values()):
            tables.append({
                "header_row": r,
                "col_xo_number": headers_found["xo number"],
                "col_xo_c": headers_found["xo c"],
                "col_actual_oct": headers_found["actual oct"]
            })
    
    return tables

# -----------------------------------------------------------------------------
# 7. A function to update data rows beneath a known "table header"
#    until we reach another table's header row or a blank row sequence.
# -----------------------------------------------------------------------------
def update_table_data(ws, table_info, aggregator):
    """
    For the table that begins at table_info['header_row'],
    we read from (header_row + 1) downward. For each row:
      - Read XO number from col_xo_number
      - Read XO c from col_xo_c
      - If both are blank, or we run into the next table header, we stop.
      - Otherwise, find aggregator[(xo_c, xo_number)] if present
        and put that in col_actual_oct, clearing old data.
    We'll keep going until we hit:
      - Another table's header row
      - A completely blank row (heuristic)
      - The end of the sheet
    """
    start_row = table_info["header_row"] + 1
    col_xo_number = table_info["col_xo_number"]
    col_xo_c = table_info["col_xo_c"]
    col_actual_oct = table_info["col_actual_oct"]

    max_row = ws.max_row
    
    r = start_row
    while r <= max_row:
        # If we detect that row r might be another table's header row, we break
        # The simplest approach: if we see "Actual Oct" again in col_actual_oct
        check_val = ws.cell(row=r, column=col_actual_oct).value
        if check_val and str(check_val).strip().lower() in ("actual oct", "oct actual"):
            # Means a new table header begins here
            break

        # Read XO c, XO number
        val_xo_c = ws.cell(row=r, column=col_xo_c).value
        val_xo_num = ws.cell(row=r, column=col_xo_number).value
        
        xo_c = str(val_xo_c).strip() if val_xo_c else ""
        xo_num = str(val_xo_num).strip() if val_xo_num else ""
        
        # If row is effectively blank in these fields, we consider it "done" or skip
        if not xo_c and not xo_num:
            # We can do a quick check for "completely blank row"? 
            # For now, let's just skip this row or break if it looks empty
            # We'll skip it and move on. If we see many blank rows, might as well break.
            # But let's just skip.
            r += 1
            continue
        
        # Try aggregator
        key = (xo_c, xo_num)
        if key in aggregator:
            sum_val = aggregator[key]

            target_cell = ws.cell(row=r, column=col_actual_oct)
            # Overwrite data
            target_cell.value = sum_val

            # Remove old comment if any
            if target_cell.comment:
                target_cell.comment = None

            # Add a new comment
            target_cell.comment = Comment("Updated by script", "Script")

            logging.info(
                f"Updated row {r}: XO c='{xo_c}', XO number='{xo_num}' -> {sum_val}"
            )
        else:
            logging.info(
                f"No aggregator match at row {r} for (XO c='{xo_c}', XO number='{xo_num}'); leaving as is."
            )
        
        r += 1

# -----------------------------------------------------------------------------
# 8. Main update logic for "Arnold" and "Sylv" sheets
#    Each might have multiple "tables." We find them, then update rows below each table.
# -----------------------------------------------------------------------------
wb = load_workbook(BANI_FILE_PATH)

# --- A) Arnold sheet ---
if ARNOLD_SHEET_NAME in wb.sheetnames and arnold_lookup:
    logging.info(f"Processing multiple tables in '{ARNOLD_SHEET_NAME}' for Arnold...")
    ws_arnold = wb[ARNOLD_SHEET_NAME]
    
    # Find all tables
    arnold_tables = find_tables_with_headers(ws_arnold)
    if not arnold_tables:
        logging.info(f"No 'Actual Oct' / 'XO number' / 'XO c' headers found in '{ARNOLD_SHEET_NAME}'.")
    else:
        logging.info(f"Found {len(arnold_tables)} table(s) in '{ARNOLD_SHEET_NAME}' to update.")
        # For each table in ascending order
        for i, tinfo in enumerate(arnold_tables, start=1):
            logging.info(f"Updating table #{i} at header row {tinfo['header_row']}")
            update_table_data(ws_arnold, tinfo, arnold_lookup)

# --- B) Sylv sheet ---
if SYLV_SHEET_NAME in wb.sheetnames and sylv_lookup:
    logging.info(f"Processing multiple tables in '{SYLV_SHEET_NAME}' for Sylv...")
    ws_sylv = wb[SYLV_SHEET_NAME]

    sylv_tables = find_tables_with_headers(ws_sylv)
    if not sylv_tables:
        logging.info(f"No 'Actual Oct' / 'XO number' / 'XO c' headers found in '{SYLV_SHEET_NAME}'.")
    else:
        logging.info(f"Found {len(sylv_tables)} table(s) in '{SYLV_SHEET_NAME}' to update.")
        for i, tinfo in enumerate(sylv_tables, start=1):
            logging.info(f"Updating table #{i} at header row {tinfo['header_row']}")
            update_table_data(ws_sylv, tinfo, sylv_lookup)

# -----------------------------------------------------------------------------
# 9. Save the workbook
# -----------------------------------------------------------------------------
logging.info("Saving updates to BANI workbook...")
wb.save(BANI_FILE_PATH)
wb.close()
logging.info("All done.")
