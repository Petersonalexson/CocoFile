#320 2025-02-13
"""
Ultra-Mega Reconciliation: Mode=2 (Parameter-based) using tkinter + CustomTkinter

Key Fixes Implemented:
â€¢ ERP Processing: Reads starting at row 4; uses V_S_C (or V S C) as dimension; uses Value as record name; melts attributes.
â€¢ Master Processing: Uses full filename as dimension; first column is Name; applies robust CSV conversion and parameterâ€‘based renaming.
â€¢ Parameter Handling: Reads a twoâ€‘sheet parameter file to filter and rename dimensions and attributes.
â€¢ GUI: Provides tabs for Paths, ERP Preview, Master Preview, Compare & Exceptions, and a Dashboard (with timeline filtering and eight scrollable graphs).
â€¢ New: â€œBrowseâ€ and â€œOpenâ€ buttons in the Paths tab; Excel output is written with formatting.
"""

import sys, os, json, logging, zipfile, shutil, time, io, csv, random
from pathlib import Path
from datetime import datetime, timedelta

import pandas as pd
import numpy as np

from openpyxl import Workbook
from openpyxl.styles import PatternFill, Font, Alignment

import matplotlib.pyplot as plt
from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg

from PIL import ImageGrab, ImageFilter, ImageQt

try:
    import chardet
except ImportError:
    chardet = None

# ---------------- Tkinter & CustomTkinter ----------------
import tkinter as tk
from tkinter import ttk, filedialog, messagebox
import customtkinter as ctk

# ---------------- Logging ----------------
logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")

# ---------------- DEFAULT CONFIG ----------------
DEFAULT_PATHS = {
    "ERP_EXCEL_PATH": "data/ERP_Config.xlsx",
    "MASTER_ZIP_PATH": "data/Master_Config.zip",
    "EXCEPTION_PATH": "data/Exception_Table.xlsx",
    "OUTPUT_PATH": "output/Reconciliation.xlsx",
    "CONFIG_PATH": "config/ui_config.json",
    "PARAMETER_PATH": "data/parameters.xlsx",
    "MASTER_CSV_OUTPUT": "temp_master_csv"
}

def default_config() -> dict:
    return {
        "paths": DEFAULT_PATHS.copy(),
        "comparison_option": 2,
        "dimension_renames": {}
    }

def load_config(path: Path) -> dict:
    if path.is_file():
        try:
            with open(path, "r", encoding="utf-8") as f:
                return json.load(f)
        except Exception as e:
            logging.warning(f"Could not load config: {e}")
    return default_config()

def save_config(cfg: dict, path: Path):
    path.parent.mkdir(parents=True, exist_ok=True)
    try:
        with open(path, "w", encoding="utf-8") as f:
            json.dump(cfg, f, indent=2)
        logging.info(f"Saved config to {path}")
    except Exception as e:
        logging.error(f"Error saving config: {e}")

# ---------------- PARAMETERS FILE READING ----------------
def read_parameter_file(path: Path) -> dict:
    param = {
        "dimension_params": {"erp_vsc_map": {}, "master_file_map": {}},
        "attribute_params": {"erp_attr_map": {}, "master_attr_map": {}}
    }
    if not path.is_file():
        logging.warning(f"Parameter file not found: {path}")
        return param
    try:
        df_dim = pd.read_excel(path, sheet_name="Dimension Parameters")
        df_dim.columns = df_dim.columns.astype(str).str.strip()
        for _, row in df_dim.iterrows():
            file_ = str(row.get("FileName", "")).strip()
            vsc = str(row.get("V S C", "")).strip()
            final_dim = str(row.get("Dimension", "")).strip()
            erp_val = str(row.get("ERP Values", "")).strip()
            if erp_val.lower() == "x" and final_dim:
                if vsc:
                    param["dimension_params"]["erp_vsc_map"][vsc] = final_dim
                if file_:
                    param["dimension_params"]["master_file_map"][file_] = final_dim
        df_attr = pd.read_excel(path, sheet_name="Attribute Parameters")
        df_attr.columns = df_attr.columns.astype(str).str.strip()
        for _, row in df_attr.iterrows():
            erp_orig = str(row.get("ERP Original Attributes", "")).strip()
            master_orig = str(row.get("Master Original Attributes", "")).strip()
            final_attr = str(row.get("Attribute", "")).strip()
            on_off = str(row.get("On/Off", "")).strip()
            if on_off.lower() == "x" and final_attr:
                if erp_orig:
                    param["attribute_params"]["erp_attr_map"][erp_orig] = final_attr
                if master_orig:
                    param["attribute_params"]["master_attr_map"][master_orig] = final_attr
        return param
    except Exception as e:
        logging.error(f"Error reading parameter file: {e}")
        return param

# ---------------- SAFE READ ERP EXCEL ----------------
def safe_read_erp_excel(path: Path) -> pd.DataFrame:
    if not path.is_file():
        logging.warning(f"ERP Excel not found: {path}")
        return pd.DataFrame()
    try:
        df = pd.read_excel(path, skiprows=3)
        df.columns = df.columns.str.strip()
        if "Enabled_Flag" in df.columns:
            df = df[df["Enabled_Flag"] == "Enabled"]
        return df
    except Exception as e:
        logging.error(f"Error reading ERP Excel: {e}")
        return pd.DataFrame()

# ---------------- ROBUST CSV READING ----------------
def read_csv_robust(filebytes: bytes) -> pd.DataFrame:
    if len(filebytes) == 0:
        logging.warning("[read_csv_robust] Empty file.")
        return pd.DataFrame()
    guess_enc = None
    if chardet:
        det = chardet.detect(filebytes[:4096])
        enc_ = det.get("encoding")
        conf_ = det.get("confidence", 0)
        if enc_ and conf_ >= 0.75:
            guess_enc = enc_
            logging.info(f"[read_csv_robust] chardet guess='{enc_}', conf={conf_}")
    encodings_to_try = [guess_enc] if guess_enc else []
    encodings_to_try.extend(["utf-8-sig", "utf-16", "utf-32", "cp1252", "latin1", "iso-8859-1", "ascii"])
    delimiters = [",", ";", "\t", "|", None]
    for enc in encodings_to_try:
        if enc is None:
            continue
        for delim in delimiters:
            try:
                buf = io.BytesIO(filebytes)
                df = pd.read_csv(buf, encoding=enc, delimiter=delim, on_bad_lines="skip", engine="python")
                df.dropna(how="all", inplace=True)
                df.dropna(axis=1, how="all", inplace=True)
                df.columns = df.columns.astype(str).str.strip()
                if not df.empty and len(df.columns) > 0:
                    logging.info(f"[read_csv_robust] Success with enc='{enc}', delim='{delim}', shape={df.shape}")
                    return df
            except Exception:
                continue
    logging.error("[read_csv_robust] Could not parse file.")
    return pd.DataFrame()

# ---------------- MELTDOWN FUNCTIONS ----------------
def meltdown_erp_process(df: pd.DataFrame, param: dict) -> pd.DataFrame:
    if df.empty:
        return df
    vsc_col = None
    for col in ["V_S_C", "V S C"]:
        if col in df.columns:
            vsc_col = col
            break
    if not vsc_col:
        logging.warning("ERP meltdown: V_S_C column not found.")
        return pd.DataFrame()
    allowed = set(param["dimension_params"]["erp_vsc_map"].keys())
    df = df[df[vsc_col].isin(allowed)].copy()
    id_vars = [vsc_col]
    if "Value" in df.columns:
        id_vars.append("Value")
    value_vars = [c for c in df.columns if c not in id_vars and c != "Enabled_Flag"]
    melted = df.melt(id_vars=id_vars, value_vars=value_vars, var_name="Attribute", value_name="AttributeValue")
    melted["Dimension"] = melted[vsc_col].map(param["dimension_params"]["erp_vsc_map"])
    melted["RefName"] = melted["Value"] if "Value" in melted.columns else ""
    allowed_attrs = set(param["attribute_params"]["erp_attr_map"].keys())
    melted = melted[melted["Attribute"].isin(allowed_attrs)]
    melted["Attribute"] = melted["Attribute"].map(param["attribute_params"]["erp_attr_map"])
    def strip_t(val):
        if isinstance(val, str) and "T" in val:
            return val.split("T")[0]
        return val
    melted["AttributeValue"] = melted.apply(lambda row: strip_t(row["AttributeValue"]) 
                                              if row["Attribute"] in {"Start Date", "End Date"} 
                                              else row["AttributeValue"], axis=1)
    return melted[["Dimension", "RefName", "Attribute", "AttributeValue"]].rename(columns={"AttributeValue": "Value"})

def meltdown_master_process(df: pd.DataFrame, param: dict) -> pd.DataFrame:
    if df.empty or "RawFileName" not in df.columns:
        logging.warning("Master meltdown: No RawFileName column.")
        return pd.DataFrame()
    allowed = set(param["dimension_params"]["master_file_map"].keys())
    df = df[df["RawFileName"].isin(allowed)].copy()
    df["Dimension"] = df["RawFileName"].map(param["dimension_params"]["master_file_map"])
    id_vars = ["Dimension"]
    if "Name" in df.columns:
        id_vars.append("Name")
    value_vars = [c for c in df.columns if c not in id_vars and c != "RawFileName"]
    melted = df.melt(id_vars=id_vars, value_vars=value_vars, var_name="Attribute", value_name="Value")
    if "Name" in melted.columns:
        melted.rename(columns={"Name": "RefName"}, inplace=True)
    allowed_attrs = set(param["attribute_params"]["master_attr_map"].keys())
    melted = melted[melted["Attribute"].isin(allowed_attrs)]
    melted["Attribute"] = melted["Attribute"].map(param["attribute_params"]["master_attr_map"])
    def strip_t(val):
        if isinstance(val, str) and "T" in val:
            return val.split("T")[0]
        return val
    melted["Value"] = melted.apply(lambda row: strip_t(row["Value"]) 
                                   if row["Attribute"] in {"Start Date", "End Date"} 
                                   else row["Value"], axis=1)
    return melted[["Dimension", "RefName", "Attribute", "Value"]]

def build_keys(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    for col in ["Dimension", "RefName", "Attribute", "Value"]:
        if col not in df.columns:
            df[col] = ""
        df[col] = df[col].fillna("").astype(str).str.strip()
    df["GroupKey"] = df["Dimension"] + " | " + df["RefName"]
    df["Key"] = df["Dimension"] + " | " + df["RefName"] + " | " + df["Attribute"] + " | " + df["Value"]
    df["Comments_1"] = ""
    df["Comments_2"] = ""
    df["Action Item"] = ""
    df["Missing In"] = ""
    return df

def compare_data(df_erp: pd.DataFrame, df_master: pd.DataFrame, mode: int) -> pd.DataFrame:
    erp_dict = {}
    master_dict = {}
    for gk, grp in df_erp.groupby("GroupKey"):
        rec = {}
        name_val = grp["RefName"].iloc[0] if not grp.empty else ""
        rec["Name"] = name_val
        for _, row in grp.iterrows():
            rec[row["Attribute"]] = row["Value"]
        erp_dict[gk] = rec
    for gk, grp in df_master.groupby("GroupKey"):
        rec = {}
        name_val = grp["RefName"].iloc[0] if not grp.empty else ""
        rec["Name"] = name_val
        for _, row in grp.iterrows():
            rec[row["Attribute"]] = row["Value"]
        master_dict[gk] = rec

    all_keys = set(erp_dict.keys()) | set(master_dict.keys())
    results = []
    for gk in all_keys:
        dimension = gk.split(" | ")[0] if " | " in gk else ""
        a_data = erp_dict.get(gk, {})
        b_data = master_dict.get(gk, {})
        name_a = a_data.get("Name", "")
        name_b = b_data.get("Name", "")
        if name_a and name_b and (name_a == name_b):
            all_attrs = (set(a_data.keys()) | set(b_data.keys())) - {"Name"}
            for attr in all_attrs:
                va = a_data.get(attr, "")
                vb = b_data.get(attr, "")
                if va != vb:
                    if va and not vb:
                        results.append({"Dimension": dimension, "Name": name_a, "Attribute": attr, "Value": va, "Missing In": "MASTER"})
                    elif vb and not va:
                        results.append({"Dimension": dimension, "Name": name_a, "Attribute": attr, "Value": vb, "Missing In": "ERP"})
                    else:
                        results.append({"Dimension": dimension, "Name": name_a, "Attribute": attr, "Value": va, "Missing In": "MASTER"})
                        results.append({"Dimension": dimension, "Name": name_a, "Attribute": attr, "Value": vb, "Missing In": "ERP"})
        else:
            if name_a and not name_b:
                results.append({"Dimension": dimension, "Name": name_a, "Attribute": "Name", "Value": name_a, "Missing In": "MASTER"})
            elif name_b and not name_a:
                results.append({"Dimension": dimension, "Name": name_b, "Attribute": "Name", "Value": name_b, "Missing In": "ERP"})
    df_diff = pd.DataFrame(results)
    if not df_diff.empty:
        df_diff["Key"] = (df_diff["Dimension"].str.strip() + " | " +
                          df_diff["Name"].str.strip() + " | " +
                          df_diff["Attribute"].str.strip() + " | " +
                          df_diff["Value"].str.strip())
    return df_diff

def read_exception_table(exc_path: Path) -> pd.DataFrame:
    if exc_path.is_file():
        try:
            return pd.read_excel(exc_path, sheet_name=0)
        except Exception as e:
            logging.error(f"Error reading exception table: {e}")
    return pd.DataFrame()

def merge_exceptions(df: pd.DataFrame, df_exc: pd.DataFrame) -> pd.DataFrame:
    if df.empty or df_exc.empty or "Key" not in df.columns:
        return df
    keep = [c for c in df_exc.columns if c in ["Key", "Comments_1", "Comments_2", "hide exception"]]
    if not keep:
        return df
    exc = df_exc[keep].copy()
    exc["Key"] = exc["Key"].astype(str).str.strip()
    merged = df.merge(exc, on="Key", how="left", suffixes=("", "_exc"))
    merged["hide exception"] = merged.get("hide exception", "").fillna("").str.lower()
    final = merged[merged["hide exception"] != "yes"].copy()
    if "Comments_1_exc" in final.columns:
        final["Comments_1"] = final["Comments_1_exc"].where(final["Comments_1_exc"].notna(), final["Comments_1"])
        final.drop(columns=["Comments_1_exc"], inplace=True)
    if "Comments_2_exc" in final.columns:
        final["Comments_2"] = final["Comments_2_exc"].where(final["Comments_2_exc"].notna(), final["Comments_2"])
        final.drop(columns=["Comments_2_exc"], inplace=True)
    if "hide exception" in final.columns:
        final.drop(columns=["hide exception"], inplace=True)
    return final

def write_results(df: pd.DataFrame, out_path: Path, mode: int):
    if df.empty:
        logging.info("No differences to write => skipping output.")
        return
    out_path.parent.mkdir(parents=True, exist_ok=True)
    final_cols = ["Key", "Dimension", "Name", "Attribute", "Value", "Comments_1", "Comments_2", "Action Item", "Missing In"]
    for c in final_cols:
        if c not in df.columns:
            df[c] = ""
    df = df[final_cols]
    wb = Workbook()
    ws = wb.active
    ws.title = "Results"
    ws.append(final_cols)
    for row in df.itertuples(index=False):
        ws.append(row)
    header_font = Font(bold=True)
    fill = PatternFill(start_color="DDDDDD", end_color="DDDDDD", fill_type="solid")
    for cell in ws[1]:
        cell.font = header_font
        cell.fill = fill
        cell.alignment = Alignment(horizontal="center")
    for col in ws.columns:
        max_len = 0
        col_letter = col[0].column_letter
        for cell in col:
            val = str(cell.value) if cell.value is not None else ""
            max_len = max(max_len, len(val))
        ws.column_dimensions[col_letter].width = max_len + 2
    ws.freeze_panes = "A2"
    wb.save(out_path)
    logging.info(f"Results saved to {out_path}")

# ---------------- Helper to Populate a Treeview with a DataFrame ----------------
def populate_treeview(tree, df: pd.DataFrame):
    tree.delete(*tree.get_children())
    tree["columns"] = list(df.columns)
    tree["show"] = "headings"
    for col in df.columns:
        tree.heading(col, text=col)
        tree.column(col, width=100, anchor="w")
    for _, row in df.iterrows():
        tree.insert("", "end", values=list(row))

# ---------------- A Scrollable Frame for Embedding Matplotlib Canvases ----------------
class ScrollableFrame(ctk.CTkFrame):
    def __init__(self, parent, **kwargs):
        super().__init__(parent, **kwargs)
        self.canvas = tk.Canvas(self, borderwidth=0, background="#ffffff")
        self.v_scroll = ttk.Scrollbar(self, orient="vertical", command=self.canvas.yview)
        self.h_scroll = ttk.Scrollbar(self, orient="horizontal", command=self.canvas.xview)
        self.canvas.configure(yscrollcommand=self.v_scroll.set, xscrollcommand=self.h_scroll.set)
        self.inner_frame = ctk.CTkFrame(self.canvas)
        self.inner_frame_id = self.canvas.create_window((0,0), window=self.inner_frame, anchor="nw")
        self.canvas.bind("<Configure>", self._on_canvas_configure)
        self.inner_frame.bind("<Configure>", self._on_frame_configure)
        self.canvas.grid(row=0, column=0, sticky="nsew")
        self.v_scroll.grid(row=0, column=1, sticky="ns")
        self.h_scroll.grid(row=1, column=0, sticky="ew")
        self.grid_rowconfigure(0, weight=1)
        self.grid_columnconfigure(0, weight=1)

    def _on_canvas_configure(self, event):
        self.canvas.itemconfig(self.inner_frame_id, width=event.width)

    def _on_frame_configure(self, event):
        self.canvas.configure(scrollregion=self.canvas.bbox("all"))

# ---------------- Dashboard Frame with Timeline Filtering and Charts ----------------
class DashboardFrame(ctk.CTkFrame):
    def __init__(self, parent, history_df: pd.DataFrame, **kwargs):
        super().__init__(parent, **kwargs)
        self.history_df = history_df.copy()
        try:
            self.history_df["RunDate_dt"] = pd.to_datetime(self.history_df["RunDate"], format="%d-%m-%Y")
        except Exception:
            self.history_df["RunDate_dt"] = pd.to_datetime(self.history_df["RunDate"])
        self.filtered_df = self.history_df.copy()
        # Date filter frame
        filter_frame = ctk.CTkFrame(self)
        filter_frame.pack(fill="x", padx=10, pady=5)
        ctk.CTkLabel(filter_frame, text="Timeline Filter (dd-mm-yyyy):").pack(side="left", padx=5)
        self.start_entry = ctk.CTkEntry(filter_frame, width=100)
        self.end_entry = ctk.CTkEntry(filter_frame, width=100)
        if not self.history_df.empty:
            self.start_entry.insert(0, self.history_df["RunDate_dt"].min().strftime("%d-%m-%Y"))
            self.end_entry.insert(0, self.history_df["RunDate_dt"].max().strftime("%d-%m-%Y"))
        else:
            today_str = datetime.now().strftime("%d-%m-%Y")
            self.start_entry.insert(0, today_str)
            self.end_entry.insert(0, today_str)
        self.start_entry.pack(side="left", padx=5)
        self.end_entry.pack(side="left", padx=5)
        update_btn = ctk.CTkButton(filter_frame, text="Update Timeline", command=self.updateTimeline)
        update_btn.pack(side="left", padx=5)
        # Create tabview for charts
        self.chart_tabview = ctk.CTkTabview(self)
        self.chart_tabview.pack(fill="both", expand=True, padx=10, pady=10)
        self.chart_tabs = {}
        self.figures = {}
        chart_labels = ["Heatmap", "Lollipop", "Circular", "Scatter", "Radar", "Normal Pie", "Normal Bar", "Band Chart"]
        for label in chart_labels:
            self.chart_tabview.add(label)
            frame = self.chart_tabview.tab(label)
            # Create a scrollable frame for each chart
            scroll_frame = ScrollableFrame(frame)
            scroll_frame.pack(fill="both", expand=True)
            # Create a matplotlib figure and canvas
            fig, ax = plt.subplots(figsize=(6,4))
            canvas = FigureCanvasTkAgg(fig, master=scroll_frame.inner_frame)
            canvas.get_tk_widget().pack(fill="both", expand=True)
            self.figures[label] = (fig, ax, canvas)
            self.chart_tabs[label] = scroll_frame
        self.updateCharts()

    def updateTimeline(self):
        try:
            start = datetime.strptime(self.start_entry.get(), "%d-%m-%Y")
            end = datetime.strptime(self.end_entry.get(), "%d-%m-%Y")
        except Exception as e:
            messagebox.showerror("Error", f"Invalid date format. Please use dd-mm-yyyy.\n{e}")
            return
        df = self.history_df.copy()
        self.filtered_df = df[(df["RunDate_dt"] >= start) & (df["RunDate_dt"] <= end)]
        self.updateCharts()

    def updateCharts(self):
        self.plotHeatmap()
        self.plotLollipop()
        self.plotCircular()
        self.plotScatter()
        self.plotRadar()
        self.plotNormalPie()
        self.plotNormalBar()
        self.plotBandChart()

    def plotHeatmap(self):
        fig, ax, canvas = self.figures["Heatmap"]
        fig.clear()
        ax = fig.add_subplot(111)
        if self.filtered_df.empty:
            ax.text(0.5, 0.5, "No data", ha='center', va='center')
        else:
            try:
                pivot = self.filtered_df.pivot_table(index="Dimension", columns="Attribute", values="MissingCount", aggfunc="sum", fill_value=0)
                cax = ax.imshow(pivot, aspect="auto", cmap="Reds")
                ax.set_xticks(range(len(pivot.columns)))
                ax.set_xticklabels(pivot.columns, rotation=45, fontsize=8)
                ax.set_yticks(range(len(pivot.index)))
                ax.set_yticklabels(pivot.index, fontsize=8)
                fig.colorbar(cax, ax=ax)
                ax.set_title("Heatmap: Missing Counts")
            except Exception as e:
                ax.text(0.5, 0.5, f"Error: {e}", ha='center', va='center')
        fig.tight_layout()
        canvas.draw()

    def plotLollipop(self):
        fig, ax, canvas = self.figures["Lollipop"]
        fig.clear()
        ax = fig.add_subplot(111)
        if self.filtered_df.empty:
            ax.text(0.5, 0.5, "No data", ha='center', va='center')
        else:
            try:
                grouped = self.filtered_df.groupby("Dimension")["MissingCount"].sum().reset_index()
                grouped = grouped.sort_values("Dimension")
                ax.hlines(y=grouped["Dimension"], xmin=0, xmax=grouped["MissingCount"], color="skyblue")
                ax.plot(grouped["MissingCount"], grouped["Dimension"], "o", color="skyblue")
                ax.set_title("Lollipop: Missing Count by Dimension")
                ax.set_xlabel("Missing Count")
            except Exception as e:
                ax.text(0.5, 0.5, f"Error: {e}", ha='center', va='center')
        fig.tight_layout()
        canvas.draw()

    def plotCircular(self):
        fig, ax, canvas = self.figures["Circular"]
        fig.clear()
        ax = fig.add_subplot(111, polar=True)
        if self.filtered_df.empty:
            ax.text(0.5, 0.5, "No data", ha='center', va='center')
        else:
            try:
                grouped = self.filtered_df.groupby("Attribute")["MissingCount"].sum().reset_index()
                categories = grouped["Attribute"].tolist()
                values = grouped["MissingCount"].tolist()
                N = len(categories)
                if N > 0:
                    angles = np.linspace(0, 2*np.pi, N, endpoint=False).tolist()
                    angles += angles[:1]
                    values += values[:1]
                    ax.set_theta_offset(np.pi/2)
                    ax.set_theta_direction(-1)
                    ax.set_xticks(angles[:-1])
                    ax.set_xticklabels(categories, fontsize=8)
                    ax.plot(angles, values, color="orange", linewidth=2)
                    ax.fill(angles, values, color="orange", alpha=0.3)
                    ax.set_title("Circular: Missing Counts")
            except Exception as e:
                ax.text(0.5, 0.5, f"Error: {e}", ha='center', va='center')
        fig.tight_layout()
        canvas.draw()

    def plotScatter(self):
        fig, ax, canvas = self.figures["Scatter"]
        fig.clear()
        ax = fig.add_subplot(111)
        if self.filtered_df.empty:
            ax.text(0.5, 0.5, "No data", ha='center', va='center')
        else:
            try:
                dims = self.filtered_df["Dimension"].unique()
                for d in dims:
                    df_d = self.filtered_df[self.filtered_df["Dimension"] == d].sort_values("RunDate_dt")
                    if not df_d.empty:
                        run_counts = df_d.groupby("RunDate")["MissingCount"].sum().reset_index()
                        run_counts["RunDate_dt"] = pd.to_datetime(run_counts["RunDate"], format="%d-%m-%Y")
                        x = range(len(run_counts))
                        y = run_counts["MissingCount"].values
                        ax.plot(x, y, marker="o", linestyle="-", label=d)
                runDates = sorted(self.filtered_df["RunDate"].unique(), key=lambda d: datetime.strptime(d, "%d-%m-%Y"))
                ax.set_xticks(range(len(runDates)))
                ax.set_xticklabels(runDates, rotation=45, fontsize=8)
                ax.set_title("Scatter: Missing Count over Runs")
                ax.set_xlabel("Run Date")
                ax.set_ylabel("Missing Count")
                ax.legend(fontsize=8)
            except Exception as e:
                ax.text(0.5, 0.5, f"Error: {e}", ha='center', va='center')
        fig.tight_layout()
        canvas.draw()

    def plotRadar(self):
        fig, ax, canvas = self.figures["Radar"]
        fig.clear()
        ax = fig.add_subplot(111, polar=True)
        if self.filtered_df.empty:
            ax.text(0.5, 0.5, "No data", ha='center', va='center')
        else:
            try:
                grouped = self.filtered_df.groupby("Attribute")["MissingCount"].sum().reset_index()
                categories = grouped["Attribute"].tolist()
                values = grouped["MissingCount"].tolist()
                N = len(categories)
                if N > 0:
                    angles = np.linspace(0, 2*np.pi, N, endpoint=False).tolist()
                    angles += angles[:1]
                    values += values[:1]
                    ax.set_theta_offset(np.pi/2)
                    ax.set_theta_direction(-1)
                    ax.set_xticks(angles[:-1])
                    ax.set_xticklabels(categories, fontsize=8)
                    ax.plot(angles, values, color="red", linewidth=2)
                    ax.fill(angles, values, color="red", alpha=0.3)
                    ax.set_title("Radar: Missing Counts")
            except Exception as e:
                ax.text(0.5, 0.5, f"Error: {e}", ha='center', va='center')
        fig.tight_layout()
        canvas.draw()

    def plotNormalPie(self):
        fig, ax, canvas = self.figures["Normal Pie"]
        fig.clear()
        ax = fig.add_subplot(111)
        if self.filtered_df.empty:
            ax.text(0.5, 0.5, "No data", ha='center', va='center')
        else:
            try:
                grouped = self.filtered_df.groupby("Dimension")["MissingCount"].sum()
                ax.pie(grouped.values, labels=grouped.index, autopct="%.1f%%", startangle=140)
                ax.set_title("Pie: Missing Distribution by Dimension")
            except Exception as e:
                ax.text(0.5, 0.5, f"Error: {e}", ha='center', va='center')
        fig.tight_layout()
        canvas.draw()

    def plotNormalBar(self):
        fig, ax, canvas = self.figures["Normal Bar"]
        fig.clear()
        ax = fig.add_subplot(111)
        if self.filtered_df.empty:
            ax.text(0.5, 0.5, "No data", ha='center', va='center')
        else:
            try:
                grouped = self.filtered_df.groupby("Attribute")["MissingCount"].sum()
                ax.bar(grouped.index, grouped.values, color="blue")
                ax.set_title("Bar: Missing Count by Attribute")
                ax.set_xlabel("Attribute")
                ax.set_ylabel("Missing Count")
            except Exception as e:
                ax.text(0.5, 0.5, f"Error: {e}", ha='center', va='center')
        fig.tight_layout()
        canvas.draw()

    def plotBandChart(self):
        fig, ax, canvas = self.figures["Band Chart"]
        fig.clear()
        ax = fig.add_subplot(111)
        if self.filtered_df.empty or "RunDate" not in self.filtered_df.columns:
            ax.text(0.5, 0.5, "No data", ha='center', va='center')
        else:
            try:
                overall = self.filtered_df.groupby("RunDate")["MissingCount"].sum().reset_index()
                overall["RunDate_dt"] = pd.to_datetime(overall["RunDate"], format="%d-%m-%Y")
                overall = overall.sort_values("RunDate_dt")
                x = overall["RunDate_dt"]
                y = overall["MissingCount"]
                ax.plot(x, y, color="purple", marker="o", label="Missing Count")
                ax.fill_between(x, y*0.9, y*1.1, color="purple", alpha=0.2, label="Â±10% band")
                ax.set_title("Band Chart: Overall Missing Count")
                ax.set_xlabel("Run Date")
                ax.set_ylabel("Missing Count")
                ax.legend(fontsize=8)
            except Exception as e:
                ax.text(0.5, 0.5, f"Error: {e}", ha='center', va='center')
        fig.tight_layout()
        canvas.draw()

# ---------------- Main Application Window ----------------
class MainWindow(ctk.CTk):
    def __init__(self):
        super().__init__()
        self.title("Ultra-Mega Reconciliation ðŸŽ")
        self.geometry("1300x900")
        self.configure(fg_color="#800020")  # Maroon background

        # Load configuration and parameters
        self.config_dict = load_config(Path(DEFAULT_PATHS["CONFIG_PATH"]))
        self.history_df = pd.DataFrame()
        self.param_dict = read_parameter_file(Path(self.config_dict["paths"].get("PARAMETER_PATH", DEFAULT_PATHS["PARAMETER_PATH"])))
        self.temp_csv_dir = Path(self.config_dict["paths"].get("MASTER_CSV_OUTPUT", DEFAULT_PATHS["MASTER_CSV_OUTPUT"]))
        self.temp_csv_dir.mkdir(exist_ok=True)

        # Create a Tabview
        self.tabview = ctk.CTkTabview(self)
        self.tabview.pack(fill="both", expand=True, padx=10, pady=10)
        self.tabview.add("Paths")
        self.tabview.add("ERP Preview")
        self.tabview.add("Master Preview")
        self.tabview.add("Compare & Exceptions")
        self.dashboard_tab_created = False

        # Build each tab
        self.buildPathsTab()
        self.buildERPTab()
        self.buildMasterTab()
        self.buildCompareTab()

        # Refresh initial data
        self.refreshERPData()
        self.refreshMasterData()

    def buildPathsTab(self):
        frame = self.tabview.tab("Paths")
        self.path_entries = {}
        labels_info = [
            ("ERP Excel Path:", "ERP_EXCEL_PATH", False),
            ("Master ZIP Path:", "MASTER_ZIP_PATH", False),
            ("Exception Path:", "EXCEPTION_PATH", False),
            ("Output Excel Path:", "OUTPUT_PATH", False),
            ("JSON Config Path:", "CONFIG_PATH", False),
            ("Parameter File Path:", "PARAMETER_PATH", False),
            ("Master CSV Folder:", "MASTER_CSV_OUTPUT", True)
        ]
        for i, (label_text, key, is_dir) in enumerate(labels_info):
            lbl = ctk.CTkLabel(frame, text=label_text, width=180, anchor="w")
            lbl.grid(row=i, column=0, padx=5, pady=5, sticky="w")
            entry = ctk.CTkEntry(frame, width=400)
            entry.grid(row=i, column=1, padx=5, pady=5, sticky="w")
            entry.insert(0, self.config_dict["paths"].get(key, DEFAULT_PATHS[key]))
            self.path_entries[key] = entry
            browse_btn = ctk.CTkButton(frame, text="Browse", command=lambda k=key, ent=entry, d=is_dir: self.browsePath(k, ent, d))
            browse_btn.grid(row=i, column=2, padx=5, pady=5)
            if not is_dir:
                open_btn = ctk.CTkButton(frame, text="Open", command=lambda ent=entry: self.openFile(ent.get()))
                open_btn.grid(row=i, column=3, padx=5, pady=5)
        save_btn = ctk.CTkButton(frame, text="Save Config", command=self.saveAllConfig)
        save_btn.grid(row=len(labels_info), column=0, columnspan=4, padx=5, pady=10)

    def browsePath(self, key, entry, is_dir):
        if is_dir:
            path = filedialog.askdirectory(title="Select Directory")
        else:
            path = filedialog.askopenfilename(title="Select File")
        if path:
            entry.delete(0, tk.END)
            entry.insert(0, path)

    def openFile(self, path_str):
        path = Path(path_str)
        if path.is_file():
            try:
                if sys.platform.startswith("win"):
                    os.startfile(str(path))
                elif sys.platform.startswith("darwin"):
                    os.system(f"open '{str(path)}'")
                else:
                    os.system(f"xdg-open '{str(path)}'")
            except Exception as e:
                messagebox.showwarning("Open File", f"Error opening file: {e}")
        else:
            messagebox.showwarning("Open File", "File not found.")

    def buildERPTab(self):
        frame = self.tabview.tab("ERP Preview")
        self.erp_tree = ttk.Treeview(frame)
        self.erp_tree.pack(fill="both", expand=True, padx=5, pady=5)
        refresh_btn = ctk.CTkButton(frame, text="Refresh ERP Data", command=self.refreshERPData)
        refresh_btn.pack(pady=5)

    def buildMasterTab(self):
        frame = self.tabview.tab("Master Preview")
        self.master_tree = ttk.Treeview(frame)
        self.master_tree.pack(fill="both", expand=True, padx=5, pady=5)
        refresh_btn = ctk.CTkButton(frame, text="Refresh Master Data", command=self.refreshMasterData)
        refresh_btn.pack(pady=5)

    def buildCompareTab(self):
        frame = self.tabview.tab("Compare & Exceptions")
        mode_label = ctk.CTkLabel(frame, text="Mode 2 Comparison (default)")
        mode_label.pack(pady=10)
        run_btn = ctk.CTkButton(frame, text="Run Comparison", command=self.runComparison)
        run_btn.pack(pady=10)

    def refreshERPData(self):
        path = Path(self.path_entries["ERP_EXCEL_PATH"].get().strip())
        df = safe_read_erp_excel(path)
        df_melt = meltdown_erp_process(df, self.param_dict)
        self.erp_df = df_melt.copy()
        populate_treeview(self.erp_tree, df_melt)

    def refreshMasterData(self):
        zip_path = Path(self.path_entries["MASTER_ZIP_PATH"].get().strip())
        if not zip_path.is_file():
            logging.warning("Master ZIP not found.")
            return
        partial_dfs = []
        try:
            with zipfile.ZipFile(zip_path, "r") as z:
                txt_files = [f for f in z.namelist() if f.lower().endswith(".txt")]
                if not txt_files:
                    logging.warning("No .txt files in ZIP.")
                    return
                for txt_file in txt_files:
                    base_name = os.path.basename(txt_file)
                    if not base_name:
                        continue
                    try:
                        with z.open(txt_file) as fo:
                            file_bytes = fo.read()
                        if not file_bytes:
                            continue
                        df_raw = read_csv_robust(file_bytes)
                        if df_raw.empty:
                            continue
                        df_raw.columns = df_raw.columns.str.strip()
                        df_raw["RawFileName"] = base_name
                        if "Name" not in df_raw.columns and len(df_raw.columns) > 0:
                            first_col = df_raw.columns[0]
                            df_raw.rename(columns={first_col: "Name"}, inplace=True)
                        out_csv = self.temp_csv_dir / f"{base_name.replace('.txt','')}.csv"
                        df_raw.to_csv(out_csv, index=False, encoding="utf-8")
                        df_re = pd.read_csv(out_csv, encoding="utf-8", on_bad_lines="skip")
                        df_re.columns = df_re.columns.str.strip()
                        df_re["RawFileName"] = base_name
                        partial_dfs.append(df_re)
                    except Exception as e:
                        logging.error(f"Error processing {txt_file}: {e}")
        except Exception as e:
            logging.error(f"Error opening ZIP file: {e}")
            return
        if partial_dfs:
            df_master = pd.concat(partial_dfs, ignore_index=True)
        else:
            df_master = pd.DataFrame()
        df_melt = meltdown_master_process(df_master, self.param_dict)
        self.master_df = df_melt.copy()
        populate_treeview(self.master_tree, df_melt)

    def runComparison(self):
        # Update config paths
        for key in self.path_entries:
            self.config_dict["paths"][key] = self.path_entries[key].get().strip()
        self.config_dict["comparison_option"] = 2
        mode = self.config_dict["comparison_option"]
        df_erp = self.erp_df.copy() if hasattr(self, "erp_df") else pd.DataFrame()
        df_master = self.master_df.copy() if hasattr(self, "master_df") else pd.DataFrame()
        erp_ready = build_keys(df_erp)
        master_ready = build_keys(df_master)
        df_diff = compare_data(erp_ready, master_ready, mode)
        exc_path = Path(self.path_entries["EXCEPTION_PATH"].get().strip())
        df_exc = read_exception_table(exc_path)
        final = merge_exceptions(df_diff, df_exc)
        out_path = Path(self.path_entries["OUTPUT_PATH"].get().strip())
        write_results(final, out_path, mode)
        run_date = datetime.now().strftime("%d-%m-%Y")
        final["RunDate"] = run_date
        if self.history_df.empty:
            self.history_df = final.copy()
        else:
            self.history_df = pd.concat([self.history_df, final], ignore_index=True)
        messagebox.showinfo("Done", f"Comparison for {run_date} complete!\nResults saved to:\n{out_path}")
        if not self.dashboard_tab_created:
            self.tabview.add("Dashboard")
            dashboard_frame = self.tabview.tab("Dashboard")
            self.dashboard = DashboardFrame(dashboard_frame, self.history_df)
            self.dashboard.pack(fill="both", expand=True)
            self.dashboard_tab_created = True
        else:
            self.dashboard.history_df = self.history_df.copy()
            self.dashboard.updateTimeline()

    def saveAllConfig(self):
        for key in self.path_entries:
            self.config_dict["paths"][key] = self.path_entries[key].get().strip()
        save_config(self.config_dict, Path(self.path_entries["CONFIG_PATH"].get().strip()))
        messagebox.showinfo("Saved", "Configuration saved successfully.")

def main():
    ctk.set_appearance_mode("dark")  # Options: "dark", "light", "system"
    app = MainWindow()
    app.mainloop()

if __name__ == "__main__":
    main()
