

import logging
import math
import pandas as pd
from openpyxl import load_workbook, Workbook
from openpyxl.styles import PatternFill, Font, Alignment, Border, Side
from openpyxl.utils import get_column_letter
from openpyxl.utils.dataframe import dataframe_to_rows

# ----------------------------------------------------------------------------
# Configuration and Logging Setup
# ----------------------------------------------------------------------------

FILE_PATHS = {

}

# Sheet names used in the files
SHEET_NAMES = {
    'master': 'Main',          # Alfa sheet; header row is row 6 (so data starts at row 7)
    'e13_sheets': [
        'E13_Atlanta_1',
        'E13_Libra',
        'E13_Australia',
        'E13_Canary',       # Canary sheet
        'E13_Toby',
        'E13_Submariner',
        'E13_PolandSlovak'
    ],
    'exceptions': 'Treispe',
    'output_sheet': 'TREISPE OUTPUT'
}

# Mapping for E13: which sheetâ€™s data belongs to which dimension name.
SHEET_DIMENSION_MAPPING = {
    'E13_Atlanta_1': 'Atlanta 1',
    'E13_Libra': 'Libra',
    'E13_Australia': 'Australia',
    'E13_Canary': 'Canary',
    'E13_Toby': 'Toby',
    'E13_Submariner': 'Submariner',
    'E13_PolandSlovak': 'Poland Slovak'
}

# manually replacing certain Canary power-of-10 values.
CANARY_REPLACEMENTS = {
    # "1E02": "Custom_100",
    # "1E03": "Custom_1000"  
}

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# ----------------------------------------------------------------------------
# Helper Functions
# ----------------------------------------------------------------------------

def auto_fit_columns(ws, min_width=12, max_width=50):
    for col_cells in ws.columns:
        max_len = 0
        col_letter = get_column_letter(col_cells[0].column)
        for cell in col_cells:
            if cell.value is not None:
                try:
                    length = len(str(cell.value))
                    if length > max_len:
                        max_len = length
                except Exception as e:
                    logging.debug(f"Error measuring cell length: {e}")
        adjusted_width = max(max_len + 2, min_width)
        if adjusted_width > max_width:
            adjusted_width = max_width
        ws.column_dimensions[col_letter].width = adjusted_width

def handle_canary_power_of_ten(value: str) -> str:
    """
    For Alfa's Canary dimension: if value is a power of 10, convert to scientific notation,
    then check if it requires manual replacement using CANARY_REPLACEMENTS.
    """
    try:
        float_val = float(value)
        if float_val <= 0:
            return value
        log_val = math.log10(float_val)
        if abs(log_val - round(log_val)) < 1e-9:
            sci_str = f"{float_val:.0E}"
            sci_str = sci_str.replace("E+", "E")
            if sci_str in CANARY_REPLACEMENTS:
                return CANARY_REPLACEMENTS[sci_str]
            return sci_str
        else:
            return value
    except ValueError:
        return value

def read_master_file(file_path: str, sheet_name: str, valid_dimensions: list) -> pd.DataFrame:
    """
    Reads Alfa (master) file using specific columns.
    - Columns: E:F,I,K (corresponding to DIM, V Master, Desc, End Date)
    - Data starts at row 7 (header at row 6)
    - Uses dtype=str so that raw values (like "00000") are preserved.
    - Filters rows so that only dimensions that appear in E13 (valid_dimensions) are kept.
    - Applies manual replacement for Canary 
    """
    logging.info(f"Reading master file from {file_path}, sheet: {sheet_name}")
    df = pd.read_excel(file_path, sheet_name=sheet_name, usecols="E:F,I,K", header=5, dtype=str)
    df.columns = ['DIM', 'V Master', 'Desc', 'End Date']
    df.dropna(how='all', inplace=True)
    
    # For 'Canary', apply manual replacement on the value.
    mask_canary = df['DIM'] == 'Canary'
    df.loc[mask_canary, 'V Master'] = df.loc[mask_canary, 'V Master'].apply(handle_canary_power_of_ten)
    
    try:
        df["End Date"] = pd.to_datetime(df["End Date"], errors='coerce')
    except Exception as e:
        logging.error(f"Error converting 'End Date': {e}")
    
    filtered_df = df[df['DIM'].isin(valid_dimensions)]
    logging.info(f"Master file contains {len(filtered_df)} relevant records after filtering.")
    return filtered_df

def read_e13_file(file_path: str, sheet_names: list, sheet_mapping: dict) -> pd.DataFrame:
    """
    Reads multiple E13 sheets.
    - For each sheet, reads column A starting from row 3 (skipping first 2 rows)
    - Uses dtype=str so raw strings (like "00000") are preserved.
    - Trims leading/trailing spaces from the values in "V E13".
    - Adds a column 'DIM E13' from the provided mapping.
    Returns the concatenated data.
    """
    logging.info(f"Reading E13 file from {file_path}")
    xls = pd.ExcelFile(file_path)
    data_list = []
    
    for sheet in sheet_names:
        if sheet in xls.sheet_names:
            logging.info(f"Processing sheet: {sheet}")
            df = pd.read_excel(xls, sheet_name=sheet, usecols="A", skiprows=2, header=None, dtype=str)
            df.columns = ['V E13']
            # Trim spaces in E13 data
            df['V E13'] = df['V E13'].astype(str).str.strip()
            df['DIM E13'] = sheet_mapping[sheet]
            data_list.append(df)
        else:
            logging.warning(f"Sheet {sheet} not found in E13 file.")
    
    if data_list:
        combined_df = pd.concat(data_list, ignore_index=True)
        logging.info(f"E13 file contains {len(combined_df)} total records after processing.")
        return combined_df
    else:
        logging.error("No valid sheets found in E13 file.")
        return pd.DataFrame(columns=['DIM E13', 'V E13'])

def compare_data(df_master: pd.DataFrame, df_e13: pd.DataFrame) -> pd.DataFrame:
    """
    Compares Alfa and E13 data by creating keys from:
      - Alfa key: DIM + "|" + V Master
      - E13 key: DIM E13 + "|" + V E13
    Merges using an outer join and adds a Status column.
    Also creates an empty Flag column.
    """
    logging.info("Comparing Alfa and E13 data.")
    df_master['Key_Alfa'] = df_master['DIM'].astype(str) + '|' + df_master['V Master'].astype(str)
    df_e13['Key_E13'] = df_e13['DIM E13'].astype(str) + '|' + df_e13['V E13'].astype(str)
    
    merged = pd.merge(df_master, df_e13, left_on='Key_Alfa', right_on='Key_E13', how='outer', indicator=True)
    merged['Status'] = merged['_merge'].map({
        "both": "Match",
        "left_only": "Missing in E13",
        "right_only": "Missing in Alfa"
    })
    merged['Flag'] = ""  # You can calculate a flag as needed
    merged.drop(columns=['_merge', 'Key_Alfa', 'Key_E13'], inplace=True)
    logging.info(f"Comparison completed with {len(merged)} records.")
    return merged

def read_exceptions(file_path: str, sheet_name: str) -> pd.DataFrame:
    """
    Reads the Exceptions file.
    Expects columns D, V, ER (after spaces are removed), and creates a key = DIM + V.
    """
    logging.info(f"Reading exceptions from {file_path}, sheet: {sheet_name}")
    df_exc = pd.read_excel(file_path, sheet_name=sheet_name)
    df_exc.columns = [col.replace(" ", "") for col in df_exc.columns]
    df_exc = df_exc[['D', 'V', 'ER']].copy()
    df_exc.columns = ['DIM', 'V', 'Comment']
    df_exc.dropna(subset=['DIM', 'V'], inplace=True)
    df_exc['DIM'] = df_exc['DIM'].astype(str).str.strip()
    df_exc['V'] = df_exc['V'].astype(str).str.strip()
    df_exc['Key'] = df_exc['DIM'] + df_exc['V']
    logging.info(f"Exceptions file contains {len(df_exc)} records after cleaning.")
    return df_exc

def apply_exceptions(df: pd.DataFrame, df_exc: pd.DataFrame) -> pd.DataFrame:
    """
    Populates the 'Comment' column based on keys from exceptions.
    Uses:
      - Alfa key: DIM + V Master
      - E13 key: DIM E13 + V E13
    """
    logging.info("Populating comments based on exceptions.")
    if 'Comment' not in df.columns:
        df['Comment'] = ""
    
    df['Key_Alfa'] = df['DIM'].astype(str) + df['V Master'].astype(str)
    df['Key_E13'] = df['DIM E13'].astype(str) + df['V E13'].astype(str)
    
    exc_dict = df_exc.set_index('Key')['Comment'].to_dict()
    df['Comment'] = df['Key_Alfa'].map(exc_dict).fillna(df['Key_E13'].map(exc_dict)).fillna(df['Comment'])
    
    df.drop(['Key_Alfa', 'Key_E13'], axis=1, inplace=True)
    logging.info("Comments populated successfully.")
    return df

def write_to_excel(df: pd.DataFrame, output_path: str, sheet_name: str) -> None:
    """
    Writes the DataFrame to an Excel
    Applies custom formatting (colors, header borders, auto fit).
    """
    logging.info(f"Writing data to Excel file at {output_path}, sheet: {sheet_name}")
    try:
        wb = load_workbook(output_path)
        if sheet_name in wb.sheetnames:
            ws_to_remove = wb[sheet_name]
            wb.remove(ws_to_remove)
            logging.info(f"Removed existing sheet '{sheet_name}'.")
        ws = wb.create_sheet(sheet_name)
    except FileNotFoundError:
        logging.warning(f"Output file '{output_path}' does not exist. Creating a new file.")
        wb = Workbook()
        ws = wb.active
        ws.title = sheet_name

    # Arrange columns as needed:
    # Alfa Dimension, Alfa Name, E13 Dimension, E13 Name, End Date Alfa, Status, Comment, Flag
    desired_columns = ['DIM', 'V Master', 'DIM E13', 'V E13', 'End Date', 'Status', 'Comment', 'Flag']
    df_out = df.copy()
    df_out = df_out[desired_columns]
    df_out.rename(columns={
        'DIM': 'Alfa Dimension',
        'V Master': 'Alfa Name',
        'DIM E13': 'E13 Dimension',
        'V E13': 'E13 Name',
        'End Date': 'End Date Alfa'
    }, inplace=True)
    
    rows = dataframe_to_rows(df_out, index=False, header=True)
    for r_idx, row_data in enumerate(rows, start=1):
        for c_idx, val in enumerate(row_data, start=1):
            ws.cell(row=r_idx, column=c_idx, value=val)
    
    # Define color fills and header border.
    header_fill = PatternFill(start_color="D9D9D9", end_color="D9D9D9", fill_type="solid")
    green_fill = PatternFill(start_color="C6EFCE", end_color="C6EFCE", fill_type="solid")  # Alfa columns
    blue_fill = PatternFill(start_color="DDEBF7", end_color="DDEBF7", fill_type="solid")   # E13 columns
    yellow_fill = PatternFill(start_color="FFF2CC", end_color="FFF2CC", fill_type="solid")  # End Date
    red_fill = PatternFill(start_color="FFC7CE", end_color="FFC7CE", fill_type="solid")     # Status if missing
    white_fill = PatternFill(start_color="FFFFFF", end_color="FFFFFF", fill_type="solid")
    
    thin_side = Side(border_style="thin", color="000000")
    thin_border = Border(left=thin_side, right=thin_side, top=thin_side, bottom=thin_side)
    
    # Format header row.
    header_row = ws[1]
    for cell in header_row:
        cell.fill = header_fill
        cell.font = Font(bold=True)
        cell.alignment = Alignment(horizontal='center')
        cell.border = thin_border

    # Column positions:
    # 1: Alfa Dimension (green)
    # 2: Alfa Name (green)
    # 3: E13 Dimension (blue)
    # 4: E13 Name (blue)
    # 5: End Date Alfa (yellow)
    # 6: Status (green if Match, red otherwise)
    # 7: Comment (white)
    # 8: Flag (white)
    status_colors = {
        'Match': green_fill,
        'Missing in E13': red_fill,
        'Missing in Alfa': red_fill
    }
    for row in ws.iter_rows(min_row=2):
        row[0].fill = green_fill
        row[1].fill = green_fill
        row[2].fill = blue_fill
        row[3].fill = blue_fill
        row[4].fill = yellow_fill
        status_cell = row[5]
        cell_color = status_colors.get(status_cell.value, white_fill)
        status_cell.fill = cell_color
        row[6].fill = white_fill
        row[7].fill = white_fill

    auto_fit_columns(ws, min_width=12, max_width=50)
    
    try:
        wb.save(output_path)
        logging.info("Excel file updated successfully with custom formatting.")
    except Exception as e:
        logging.error(f"Error saving workbook '{output_path}': {e}")

# ----------------------------------------------------------------------------
# Main Code Execution
# ----------------------------------------------------------------------------

if __name__ == "__main__":
    try:
        # Read E13 file first to get the dimensions available.
        df_e13 = read_e13_file(FILE_PATHS['e13'], SHEET_NAMES['e13_sheets'], SHEET_DIMENSION_MAPPING)
        unique_e13_dims = df_e13['DIM E13'].unique().tolist()
        logging.info(f"Unique dimensions in E13: {unique_e13_dims}")
        
        # Read Alfa (master) file and filter to keep only those with dimensions in E13.
        df_master = read_master_file(FILE_PATHS['master'], SHEET_NAMES['master'], unique_e13_dims)
        
        # Compare Alfa and E13 data.
        df_comparison = compare_data(df_master, df_e13)
        
        # Process exceptions if needed.
        df_exceptions = read_exceptions(FILE_PATHS['exceptions'], SHEET_NAMES['exceptions'])
        df_comparison = apply_exceptions(df_comparison, df_exceptions)
        
        # Write to OUTPUT.
        write_to_excel(df_comparison, FILE_PATHS['output'], SHEET_NAMES['output_sheet'])
        
        logging.info("Process completed successfully.")
    except Exception as e:
        logging.error(f"Process terminated with error: {e}")
