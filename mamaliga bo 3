#!/usr/bin/env python3
"""
Ultra-Mega Reconciliation with:
 - Automatic loading of all history JSON runs on startup
 - ERP & Master Previews (no user date filters; End Date automatically filtered)
 - Compare => missing_items.xlsx with 2 sheets (Mismatch & Case_Differences)
 - Key is trimmed & uppercase, columns: Master, ERP, Gap In
 - 8-chart Dashboard with Bollinger band (all charts use mplcursors hover)
 - Bollinger data saved on close
 - History double-click => "Show Summary" or "Load Data for Charts"
 - NO UI fields for JSON CONFIG PATH, MASTER CSV FOLDER, LOGO PATH, HISTORY PATH, BOLLINGER JSON PATH
"""

import os
import sys
import json
import math
import logging
import zipfile
import shutil
import io
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, Set, List

import tkinter as tk
from tkinter import ttk, filedialog, messagebox
import customtkinter as ctk

import pandas as pd
import numpy as np

import matplotlib
matplotlib.use("TkAgg")
import matplotlib.pyplot as plt
from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg, NavigationToolbar2Tk
from matplotlib.backends.backend_pdf import PdfPages

try:
    import mplcursors
    MPLCURSORS_AVAILABLE = True
except ImportError:
    MPLCURSORS_AVAILABLE = False

from openpyxl import Workbook
from openpyxl.styles import PatternFill, Font, Alignment

logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")

# ----------------------------------------------------------------------------
# DEFAULT CONFIG & SAVE/LOAD
# ----------------------------------------------------------------------------
DEFAULT_PATHS = {
    "ERP_EXCEL_PATH": "data/ERP_Config.xlsx",
    "MASTER_ZIP_PATH": "data/Master_Config.zip",
    "EXCEPTION_PATH": "data/Exception_Table.xlsx",
    "OUTPUT_PATH": "output/missing_items.xlsx",
    "CONFIG_PATH": "config/ui_config.json",        # (not shown in GUI)
    "PARAMETER_PATH": "data/parameters.xlsx",
    "MASTER_CSV_OUTPUT": "temp_master_csv",        # (not shown in GUI)
    "PDF_EXPORT_PATH": "output/dashboard_report.pdf",
    "LOGO_PATH": "images/company_logo.png",        # (not shown in GUI)
    "HISTORY_PATH": "history_runs",                # (not shown in GUI)
    "BAND_CHART_JSON_PATH": "data/bollinger_data.json"  # (not shown in GUI)
}

def default_config() -> Dict:
    return {
        "paths": DEFAULT_PATHS.copy(),
        "erp_grid": {"filters": {}},
        "master_grid": {"filters": {}},
        "dashboard": {
            "selected_dims": [],
            "selected_attrs": [],
            "top_n": 10
        }
    }

def load_config(path: Path) -> Dict:
    if path.is_file():
        try:
            with open(path, "r", encoding="utf-8") as f:
                return json.load(f)
        except Exception as e:
            logging.warning(f"Could not load config => {e}")
    return default_config()

def save_config(cfg: Dict, path: Path):
    path.parent.mkdir(parents=True, exist_ok=True)
    try:
        # Convert sets->lists in erp_grid
        if "erp_grid" in cfg and "filters" in cfg["erp_grid"]:
            newf = {}
            for col, svals in cfg["erp_grid"]["filters"].items():
                newf[col] = list(svals)
            cfg["erp_grid"]["filters"] = newf

        # Convert sets->lists in master_grid
        if "master_grid" in cfg and "filters" in cfg["master_grid"]:
            newf = {}
            for col, svals in cfg["master_grid"]["filters"].items():
                newf[col] = list(svals)
            cfg["master_grid"]["filters"] = newf

        with open(path, "w", encoding="utf-8") as f:
            json.dump(cfg, f, indent=2)
        logging.info(f"Saved config to {path}")
    except Exception as e:
        logging.error(f"Error saving config => {e}")


# ----------------------------------------------------------------------------
# TEXT LOGGER HANDLER
# ----------------------------------------------------------------------------
class TextHandler(logging.Handler):
    def __init__(self, widget: ctk.CTkTextbox):
        super().__init__()
        self.widget = widget
    def emit(self, record):
        msg = self.format(record) + "\n"
        self.widget.after(0, self._append, msg)
    def _append(self, msg):
        self.widget.configure(state="normal")
        self.widget.insert("end", msg)
        self.widget.see("end")
        self.widget.configure(state="disabled")


# ----------------------------------------------------------------------------
# HELPER: MPLCURSORS
# ----------------------------------------------------------------------------
def enable_hover(ax):
    """Enable interactive hover (if mplcursors installed)."""
    if not MPLCURSORS_AVAILABLE:
        return
    cursor = mplcursors.cursor(ax, hover=True)
    @cursor.connect("add")
    def on_add(sel):
        # sel.target is (x, y) or something
        coords = sel.target
        # If it's a line or scatter, coords is (x, y)
        if isinstance(coords, (tuple, list)) and len(coords)==2:
            xval, yval = coords
            sel.annotation.set_text(f"{yval:.0f}")
        else:
            sel.annotation.set_text(str(coords))


# ----------------------------------------------------------------------------
# PARAM READ
# ----------------------------------------------------------------------------
def read_param_file(path: Path) -> Dict[str, object]:
    param = {
        "dim_erp_keep": set(),
        "dim_erp_map": {},
        "dim_master_map": {},
        "attr_erp_map": {},
        "attr_master_map": {}
    }
    if not path.is_file():
        logging.warning(f"Param file not found => {path}")
        return param
    try:
        dim_df = pd.read_excel(path, sheet_name="Dimension Parameters")
        dim_df.columns = dim_df.columns.astype(str).str.strip()

        def s(x): return str(x).strip() if pd.notna(x) else ""

        for _, row in dim_df.iterrows():
            fn  = s(row.get("FileName", ""))
            vsc = s(row.get("V S C", ""))
            dim = s(row.get("Dimension", ""))
            ev  = s(row.get("ERP Values", ""))
            if ev.lower() == "x" and vsc and dim:
                param["dim_erp_keep"].add(vsc)
            if vsc and dim:
                param["dim_erp_map"][vsc] = dim
            if fn and ev.lower()=="x":
                param["dim_master_map"][fn] = vsc  # store short code for Master

        attr_df = pd.read_excel(path, sheet_name="Attribute Parameters")
        attr_df.columns = attr_df.columns.astype(str).str.strip()
        for _, row in attr_df.iterrows():
            e_orig = s(row.get("ERP Original Attributes", ""))
            m_orig = s(row.get("Master Original Attributes", ""))
            final_ = s(row.get("Attribute", ""))
            onoff  = s(row.get("On/Off", ""))
            if onoff.lower() == "x" and final_:
                if e_orig:
                    param["attr_erp_map"][e_orig] = final_
                if m_orig:
                    param["attr_master_map"][m_orig] = final_
        return param
    except Exception as e:
        logging.error(f"Error reading param file => {e}")
        return param


# ----------------------------------------------------------------------------
# ERP READING
# ----------------------------------------------------------------------------
def read_erp_excel(path: Path) -> pd.DataFrame:
    if not path.is_file():
        logging.warning(f"ERP Excel not found => {path}")
        return pd.DataFrame()
    try:
        df = pd.read_excel(path, skiprows=3)
        df.columns = df.columns.str.strip()
        if "Enabled_Flag" in df.columns:
            df = df[df["Enabled_Flag"] == "Enabled"]
        return df
    except Exception as e:
        logging.error(f"Error reading ERP => {e}")
        return pd.DataFrame()


# ----------------------------------------------------------------------------
# MASTER
# ----------------------------------------------------------------------------
def read_txt_2encodings(raw: bytes) -> pd.DataFrame:
    import io
    for enc in ["utf-8-sig","utf-16-le"]:
        try:
            buf = io.BytesIO(raw)
            df = pd.read_csv(buf, encoding=enc, on_bad_lines="skip", engine="python")
            df.dropna(how="all", axis=0, inplace=True)
            df.dropna(how="all", axis=1, inplace=True)
            df.columns = df.columns.astype(str).str.strip()
            logging.info(f"[read_txt_2encodings] success with {enc}, shape={df.shape}")
            return df
        except Exception as e:
            logging.debug(f"[read_txt_2encodings] fail with {enc} => {e}")
    logging.error("[read_txt_2encodings] cannot parse .txt => empty.")
    return pd.DataFrame()

def convert_master_txt_to_csv(zip_path: Path, out_dir: Path):
    if not zip_path.is_file():
        logging.warning(f"[Master] ZIP not found => {zip_path}")
        return []
    if out_dir.exists():
        shutil.rmtree(out_dir, ignore_errors=True)
    out_dir.mkdir(parents=True, exist_ok=True)
    csvs = []
    with zipfile.ZipFile(zip_path, "r") as z:
        txt_files = [f for f in z.namelist() if f.lower().endswith(".txt")]
        for txt_file in txt_files:
            base_name = os.path.basename(txt_file)
            if not base_name:
                continue
            try:
                with z.open(txt_file) as fo:
                    raw = fo.read()
                df = read_txt_2encodings(raw)
                if df.empty:
                    continue
                df["RawFileName"] = base_name
                if "Name" not in df.columns and len(df.columns) > 0:
                    first_col = df.columns[0]
                    df.rename(columns={first_col: "Name"}, inplace=True)
                out_csv = out_dir / (base_name.replace(".txt", ".csv"))
                df.to_csv(out_csv, index=False, encoding="utf-8")
                csvs.append(out_csv)
            except Exception as e:
                logging.error(f"[Master] error reading {txt_file} => {e}")
    return csvs

def unify_master_csvs(csvs: List[Path]) -> pd.DataFrame:
    frames = []
    for cp in csvs:
        if not cp.is_file():
            continue
        try:
            df = pd.read_csv(cp, encoding="utf-8", on_bad_lines="skip")
            df.columns = df.columns.str.strip()
            frames.append(df)
        except Exception as e:
            logging.error(f"[unify_master_csvs] reading {cp} => {e}")
    if frames:
        return pd.concat(frames, ignore_index=True)
    return pd.DataFrame()


# ----------------------------------------------------------------------------
# MELTDOWN with End Date filter (blank or future)
# ----------------------------------------------------------------------------
def keep_valid_end_date(attr: str, val: str) -> bool:
    """
    If attribute == 'End Date', keep only if blank or strictly > today
    Otherwise keep row
    """
    if attr != "End Date":
        return True
    v = str(val).strip()
    if not v:
        # blank => keep
        return True
    # parse date
    try:
        dt = datetime.strptime(v, "%Y-%m-%d").date()
        # keep if dt > today
        return dt > datetime.now().date()
    except:
        return False

def meltdown_erp_for_preview(df: pd.DataFrame, param: Dict[str, object]) -> pd.DataFrame:
    """
    Convert wide -> long => filter End Date => pivot is done by caller.
    We do NOT show date filters in GUI. We'll automatically skip rows
    if 'End Date' is <= today.
    """
    keep = param.get("dim_erp_keep", set())
    if "V_S_C" not in df.columns:
        return pd.DataFrame()
    df2 = df[df["V_S_C"].isin(keep)].copy()
    if df2.empty:
        return pd.DataFrame()

    dmap = param.get("dim_erp_map", {})
    amap = param.get("attr_erp_map", {})

    skip_cols = {"V_S_C", "Enabled_Flag"}
    id_vars = []
    if "Value" in df2.columns:
        id_vars.append("Value")
        skip_cols.add("Value")

    df2["DimRaw"] = df2["V_S_C"]
    skip_cols.add("DimRaw")
    id_vars.insert(0, "DimRaw")

    meltdown_cols = [c for c in df2.columns if c not in skip_cols]
    melted = df2.melt(
        id_vars=id_vars,
        value_vars=meltdown_cols,
        var_name="OrigAttr",
        value_name="ValX"
    )

    def rename_dim(v):
        return dmap.get(v, v)
    melted["Dimension"] = melted["DimRaw"].apply(rename_dim)

    if "Value" in id_vars:
        melted.rename(columns={"Value":"Name"}, inplace=True)
    else:
        melted["Name"] = ""

    melted = melted[melted["OrigAttr"].isin(amap.keys())].copy()
    melted["Attribute"] = melted["OrigAttr"].map(amap)

    # strip stuff after T if it's a date
    def strip_t(val):
        if isinstance(val,str) and "T" in val:
            return val.split("T")[0]
        return val
    melted["Value"] = melted["ValX"].apply(strip_t)

    # now filter End Date
    keep_rows = []
    for idx, row in melted.iterrows():
        if keep_valid_end_date(row["Attribute"], row["Value"]):
            keep_rows.append(row)
    melted2 = pd.DataFrame(keep_rows)

    return melted2[["Dimension","Name","Attribute","Value"]]

def meltdown_master_for_preview(df: pd.DataFrame, param: Dict[str, object]) -> pd.DataFrame:
    """
    Similar meltdown for Master, with automatic End Date filter
    """
    amap = param.get("attr_master_map", {})
    keep_map = param.get("dim_master_map", {})

    if df.empty or "RawFileName" not in df.columns:
        return pd.DataFrame()

    df2 = df[df["RawFileName"].isin(keep_map.keys())].copy()
    if df2.empty:
        return pd.DataFrame()

    df2["DimRaw"] = df2["RawFileName"]
    skip_cols = {"RawFileName","DimRaw"}
    id_vars = ["DimRaw"]
    if "Name" in df2.columns:
        id_vars.append("Name")
        skip_cols.add("Name")

    meltdown_cols = [c for c in df2.columns if c not in skip_cols]
    melted = df2.melt(
        id_vars=id_vars,
        value_vars=meltdown_cols,
        var_name="OrigAttr",
        value_name="ValX"
    )

    def rename_dim(fn):
        return keep_map.get(fn, fn)
    melted["Dimension"] = melted["DimRaw"].apply(rename_dim)
    if "Name" not in melted.columns:
        melted["Name"] = ""
    melted = melted[melted["OrigAttr"].isin(amap.keys())].copy()
    melted["Attribute"] = melted["OrigAttr"].map(amap)

    # strip T
    def strip_t(val):
        if isinstance(val,str) and "T" in val:
            return val.split("T")[0]
        return val
    melted["Value"] = melted["ValX"].apply(strip_t)

    keep_rows = []
    for idx, row in melted.iterrows():
        if keep_valid_end_date(row["Attribute"], row["Value"]):
            keep_rows.append(row)
    melted2 = pd.DataFrame(keep_rows)

    return melted2[["Dimension","Name","Attribute","Value"]]


def pivot_for_preview(df: pd.DataFrame) -> pd.DataFrame:
    if not df.empty and {"Dimension","Name","Attribute"}.issubset(df.columns):
        df = df.drop_duplicates(subset=["Dimension","Name","Attribute"])
        try:
            df = df.pivot(
                index=["Dimension","Name"],
                columns="Attribute",
                values="Value"
            ).reset_index()
        except Exception as e:
            logging.error(f"Pivot error => {e}")
    return df


# ----------------------------------------------------------------------------
# COMPARE => produce Master/ERP + Gap In
# ----------------------------------------------------------------------------
def compare_erp_master(erp_df: pd.DataFrame, mast_df: pd.DataFrame) -> pd.DataFrame:
    """
    Return rows that differ ignoring case, with columns:
      Key, Dimension, Name, Attribute, Master, ERP, Comments_1, Comments_2, Gap In
    Gap In => MASTER | ERP | MISMATCH
    Also ensure Key is UPPERCASED fully.
    """
    erp2 = erp_df.copy()
    erp2.rename(columns={"Value":"ERP"}, inplace=True)
    mast2 = mast_df.copy()
    mast2.rename(columns={"Value":"Master"}, inplace=True)

    key_cols = ["Dimension","Name","Attribute"]
    merged = erp2.merge(mast2, on=key_cols, how="outer")
    merged["ERP"] = merged["ERP"].fillna("")
    merged["Master"] = merged["Master"].fillna("")

    diff_mask = merged["ERP"].str.upper() != merged["Master"].str.upper()
    out = merged[diff_mask].copy()

    def gap_logic(row):
        e = row["ERP"]
        m = row["Master"]
        if e and not m:
            return "MASTER"
        elif m and not e:
            return "ERP"
        else:
            return "MISMATCH"

    out["Gap In"] = out.apply(gap_logic, axis=1)

    # build Key uppercase
    out["Key"] = (
        out["Dimension"].str.strip().str.upper() + " | " +
        out["Name"].str.strip().str.upper() + " | " +
        out["Attribute"].str.strip().str.upper()
    )
    out["Comments_1"] = ""
    out["Comments_2"] = ""

    return out[["Key","Dimension","Name","Attribute","Master","ERP","Comments_1","Comments_2","Gap In"]]


def separate_case_diffs(df: pd.DataFrame) -> (pd.DataFrame, pd.DataFrame):
    same_lower = df["Master"].str.lower() == df["ERP"].str.lower()
    different_actual = df["Master"] != df["ERP"]
    mask = same_lower & different_actual
    df_case = df[mask].copy()
    df_mismatch = df[~mask].copy()
    return df_mismatch, df_case


# ----------------------------------------------------------------------------
# Exceptions & Write Excel (two sheets)
# ----------------------------------------------------------------------------
def read_exception_table(path: Path) -> pd.DataFrame:
    if not path.is_file():
        logging.warning(f"Exception table not found => {path}")
        return pd.DataFrame()
    try:
        df = pd.read_excel(path)
        df.columns = df.columns.astype(str).str.strip()
        return df
    except Exception as e:
        logging.error(f"Error reading exception => {e}")
        return pd.DataFrame()

def merge_exceptions(df: pd.DataFrame, df_exc: pd.DataFrame) -> pd.DataFrame:
    if df.empty or df_exc.empty or "Key" not in df.columns:
        return df
    keep_cols = [c for c in ["Key","Comments_1","Comments_2","hide exception"] if c in df_exc.columns]
    if not keep_cols:
        return df
    exc = df_exc[keep_cols].copy()
    exc["Key"] = exc["Key"].astype(str).str.strip()

    merged = df.merge(exc, on="Key", how="left", suffixes=("","_exc"))
    merged["hide exception"] = merged.get("hide exception","").fillna("").str.lower()
    final = merged[merged["hide exception"]!="yes"].copy()

    if "Comments_1_exc" in final.columns:
        final["Comments_1"] = np.where(final["Comments_1_exc"].notna(), final["Comments_1_exc"], final["Comments_1"])
        final.drop(columns=["Comments_1_exc"], inplace=True)
    if "Comments_2_exc" in final.columns:
        final["Comments_2"] = np.where(final["Comments_2_exc"].notna(), final["Comments_2_exc"], final["Comments_2"])
        final.drop(columns=["Comments_2_exc"], inplace=True)
    if "hide exception" in final.columns:
        final.drop(columns=["hide exception"], inplace=True)
    return final

def write_to_excel(mismatch: pd.DataFrame, case_only: pd.DataFrame, out_path: Path):
    """
    Write 2 sheets => Mismatch, Case_Differences
    Columns: Key, Dimension, Name, Attribute, Master, ERP, Comments_1, Comments_2, Gap In
    """
    out_path.parent.mkdir(parents=True, exist_ok=True)
    wb = Workbook()

    main_cols = ["Key","Dimension","Name","Attribute","Master","ERP","Comments_1","Comments_2","Gap In"]

    ws_m = wb.active
    ws_m.title = "Mismatch"
    ws_m.append(main_cols)
    for rowvals in mismatch[main_cols].itertuples(index=False):
        ws_m.append(rowvals)

    header_font = Font(bold=True)
    fill = PatternFill(start_color="DDDDDD", end_color="DDDDDD", fill_type="solid")
    for cell in ws_m[1]:
        cell.font = header_font
        cell.fill = fill
        cell.alignment = Alignment(horizontal="center")

    for col in ws_m.columns:
        max_len = 0
        letter = col[0].column_letter
        for cell in col:
            val = str(cell.value) if cell.value else ""
            max_len= max(max_len, len(val))
        ws_m.column_dimensions[letter].width= max_len+2
    ws_m.freeze_panes= "A2"

    # Second sheet
    ws_c = wb.create_sheet("Case_Differences")
    ws_c.append(main_cols)
    for rowvals in case_only[main_cols].itertuples(index=False):
        ws_c.append(rowvals)
    for cell in ws_c[1]:
        cell.font = header_font
        cell.fill = fill
        cell.alignment = Alignment(horizontal="center")

    for col in ws_c.columns:
        max_len = 0
        letter = col[0].column_letter
        for cell in col:
            val = str(cell.value) if cell.value else ""
            max_len= max(max_len, len(val))
        ws_c.column_dimensions[letter].width= max_len+2
    ws_c.freeze_panes= "A2"

    wb.save(out_path)
    logging.info(f"Missing items => {out_path}")


# ----------------------------------------------------------------------------
# SIMPLE PREVIEW (no user date filter, no date buttons)
# ----------------------------------------------------------------------------
class SimplePreview(ctk.CTkFrame):
    """Lightweight table preview for ERP or Master meltdown. No date filters."""
    def __init__(self, parent, name: str, filters_dict=None):
        super().__init__(parent)
        self.name= name
        self.df= pd.DataFrame()
        self.filters= {}  # not used now (no date filters), but kept for config synergy
        self.create_toolbar()
        self.create_table()
        self.create_statusbar()

    def create_toolbar(self):
        bar= ctk.CTkFrame(self, corner_radius=10, fg_color="#f0f0f0")
        bar.pack(fill="x", padx=5, pady=5)
        title_label= ctk.CTkLabel(
            bar, text=f"{self.name} Preview",
            fg_color="#800020", corner_radius=8,
            text_color="white",
            font=ctk.CTkFont(size=14, weight="bold")
        )
        title_label.pack(side="left", padx=5)
        # Just an info button
        ctk.CTkButton(
            bar, text="ⓘ", width=30, command=self.show_info,
            fg_color="#800020", hover_color="#a52a2a", text_color="white"
        ).pack(side="left", padx=5)

    def show_info(self):
        messagebox.showinfo("Info", f"{self.name} meltdown data.\nEnd Date automatically filtered (blank or future).")

    def create_table(self):
        container= ctk.CTkFrame(self)
        container.pack(fill="both", expand=True, padx=5, pady=5)
        self.tree= ttk.Treeview(container, show="headings")
        vsb= ttk.Scrollbar(container, orient="vertical", command=self.tree.yview)
        hsb= ttk.Scrollbar(container, orient="horizontal", command=self.tree.xview)
        self.tree.configure(yscrollcommand=vsb.set, xscrollcommand=hsb.set)
        self.tree.grid(row=0, column=0, sticky="nsew")
        vsb.grid(row=0, column=1, sticky="ns")
        hsb.grid(row=1, column=0, sticky="ew")
        container.rowconfigure(0,weight=1)
        container.columnconfigure(0,weight=1)

    def create_statusbar(self):
        self.status_label= ctk.CTkLabel(self, text="0 rows", fg_color="#f0f0f0", text_color="black")
        self.status_label.pack(fill="x")

    def set_data(self, df: pd.DataFrame):
        self.df= df.copy()
        self.refresh_table()

    def refresh_table(self):
        for i in self.tree.get_children():
            self.tree.delete(i)
        if self.df.empty:
            self.tree["columns"]=[]
            self.status_label.configure(text="0 rows")
            return
        cols= list(self.df.columns)
        self.tree["columns"]= cols
        for c in cols:
            self.tree.heading(c, text=c, anchor="w")
            self.tree.column(c, anchor="w", width=150)
        for _, row in self.df.iterrows():
            rowvals= [row[c] for c in cols]
            self.tree.insert("", "end", values=rowvals)
        self.status_label.configure(text=f"{len(self.df)} rows")

    def get_filtered_df(self)-> pd.DataFrame:
        """Return df as-is, no date filter from user."""
        return self.df.copy()


# ----------------------------------------------------------------------------
# PDF REPORT (with some charts)
# ----------------------------------------------------------------------------
class EnhancedPDFReport:
    def __init__(self, df_current: pd.DataFrame, df_history: pd.DataFrame, config: Dict):
        self.df_current = df_current
        self.df_history = df_history
        self.config = config
        self.page_count = 0

    def generate(self) -> Path:
        stamp= datetime.now().strftime("%Y%m%d_%H%M%S")
        out_dir= Path("Reconciliation_pdf")
        out_dir.mkdir(parents=True, exist_ok=True)
        pdf_name= f"Reconciliationpdf_{stamp}.pdf"
        pdf_path= out_dir / pdf_name

        with PdfPages(pdf_path) as pdf:
            self._cover_page(pdf)
            self._summary_page(pdf)
            self._all_charts(pdf)
        logging.info(f"PDF => {pdf_path}")
        return pdf_path

    def _cover_page(self, pdf):
        fig= plt.figure(figsize=(8.5,11))
        plt.axis("off")
        plt.text(0.5,0.6,"Reconciliation Report",ha="center",fontsize=24,weight="bold")
        plt.text(0.5,0.5,f"Generated on {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",ha="center",fontsize=12)
        pdf.savefig(fig)
        plt.close(fig)

    def _summary_page(self, pdf):
        fig= plt.figure(figsize=(8.5,11))
        plt.axis("off")
        total= len(self.df_current)
        txt= [
            "Summary",
            "-------",
            f"Total Items => {total}"
        ]
        plt.text(0.1,0.9,"\n".join(txt),fontsize=12,va="top")
        pdf.savefig(fig)
        plt.close(fig)

    def _all_charts(self, pdf):
        """
        We'll add 2 additional charts: missing by dimension, missing by attribute,
        plus Bollinger if we have df_history.
        We'll add mplcursors hover.
        """
        dfc= self.df_current.copy()
        if dfc.empty:
            return

        # 1) Missing by dimension
        if "Dimension" in dfc.columns and "Gap In" in dfc.columns:
            dcount= dfc.groupby("Dimension")["Key"].count().sort_values(ascending=False).head(10)
            if not dcount.empty:
                fig, ax= plt.subplots(figsize=(8,5))
                bars= ax.bar(dcount.index, dcount.values, color="steelblue")
                for bar in bars:
                    height= bar.get_height()
                    ax.text(bar.get_x()+bar.get_width()/2., height, f"{int(height)}",ha="center",va="bottom")
                ax.set_title("Missing by Dimension (top 10)")
                ax.tick_params(axis='x', rotation=45)
                enable_hover(ax)
                pdf.savefig(fig)
                plt.close(fig)

        # 2) Missing by attribute
        if "Attribute" in dfc.columns and "Gap In" in dfc.columns:
            acount= dfc.groupby("Attribute")["Key"].count().sort_values(ascending=False).head(10)
            if not acount.empty:
                fig, ax= plt.subplots(figsize=(8,5))
                bars= ax.bar(acount.index, acount.values, color="orange")
                for bar in bars:
                    height= bar.get_height()
                    ax.text(bar.get_x()+bar.get_width()/2., height, f"{int(height)}",ha="center",va="bottom")
                ax.set_title("Missing by Attribute (top 10)")
                ax.tick_params(axis='x', rotation=45)
                enable_hover(ax)
                pdf.savefig(fig)
                plt.close(fig)

        # Bollinger
        if not self.df_history.empty and "RunDate" in self.df_history.columns:
            date_ct= self.df_history.groupby("RunDate")["Key"].count().reset_index(name="Count")
            date_ct.sort_values("RunDate", inplace=True)
            if not date_ct.empty:
                date_ct["RunDate_dt"]= pd.to_datetime(date_ct["RunDate"], errors="coerce")
                date_ct.sort_values("RunDate_dt", inplace=True)
                date_ct.reset_index(drop=True, inplace=True)

                date_ct["rolling_mean"]= date_ct["Count"].rolling(3, min_periods=1).mean()
                date_ct["rolling_std"] = date_ct["Count"].rolling(3, min_periods=1).std(ddof=0)
                date_ct["upper_band"]  = date_ct["rolling_mean"] + 2*date_ct["rolling_std"]
                date_ct["lower_band"]  = date_ct["rolling_mean"] - 2*date_ct["rolling_std"]

                fig, ax= plt.subplots(figsize=(8,5))
                xvals= np.arange(len(date_ct))
                ax.plot(xvals, date_ct["rolling_mean"], color="blue", label="Rolling Mean")
                ax.fill_between(xvals, date_ct["lower_band"], date_ct["upper_band"],
                                color="blue", alpha=0.2, label="±2σ Band")
                sc= ax.scatter(xvals, date_ct["Count"], color="red", label="Actual Count")
                ax.set_xticks(xvals)
                xlabels= [d.strftime("%Y-%m-%d") for d in date_ct["RunDate_dt"]]
                ax.set_xticklabels(xlabels, rotation=45, ha="right")
                ax.set_title("Bollinger Band Over Time")
                ax.legend()
                enable_hover(ax)
                pdf.savefig(fig)
                plt.close(fig)


# ----------------------------------------------------------------------------
# HISTORY: Double-click => "Show Summary" or "Load Data for Charts"
# ----------------------------------------------------------------------------
class HistoryTab(ctk.CTkFrame):
    def __init__(self, parent, hist_dir: Path, run_selected_callback=None):
        super().__init__(parent)
        self.history_dir= hist_dir
        self.run_selected_callback = run_selected_callback
        self.build_ui()

    def build_ui(self):
        lbl= ctk.CTkLabel(self, text="Reconciliation Runs History", font=("Arial",16))
        lbl.pack(pady=5)

        self.tree= ttk.Treeview(self, columns=("Filename",), show="headings", height=15)
        self.tree.heading("Filename", text="History File")
        self.tree.pack(fill="both", expand=True, padx=10, pady=10)

        self.tree.bind("<Double-1>", self.on_double_click)

        refresh_btn= ctk.CTkButton(self, text="Refresh", command=self.refresh_history,
                                   fg_color="#800020", hover_color="#a52a2a", text_color="white")
        refresh_btn.pack(pady=5)

        self.refresh_history()

    def refresh_history(self):
        for i in self.tree.get_children():
            self.tree.delete(i)
        if not self.history_dir.is_dir():
            self.history_dir.mkdir(parents=True, exist_ok=True)
        files= sorted(self.history_dir.glob("run_*.json"), reverse=True)
        for f in files:
            self.tree.insert("", "end", values=(f.name,))

    def on_double_click(self, event):
        item_id= self.tree.focus()
        if not item_id:
            return
        filename= self.tree.item(item_id,"values")[0]
        file_path= self.history_dir / filename
        if not file_path.is_file():
            return
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                data= json.load(f)

            # new popup with two buttons => "Show Summary" or "Load Data for Charts"
            popup= tk.Toplevel(self)
            popup.title("History Run Options")
            popup.geometry("400x200")

            lbl= ctk.CTkLabel(popup, text=f"Found {len(data)} items in {filename}")
            lbl.pack(pady=10)

            def show_summary():
                # We'll compute a quick summary
                if not data:
                    messagebox.showinfo("Summary","No items.")
                    return
                df_run= pd.DataFrame(data)
                summary_txt= f"Timestamp: ??? (not stored)\nCount: {len(df_run)}"
                # You might store timestamp in data, or not
                messagebox.showinfo("Run Summary", summary_txt)
                popup.destroy()

            def load_charts():
                # Send the entire data => callback
                if self.run_selected_callback:
                    self.run_selected_callback(file_path, data)
                popup.destroy()

            bf= ctk.CTkFrame(popup)
            bf.pack(pady=10)

            ctk.CTkButton(bf, text="Show Summary", command=show_summary,
                          fg_color="#800020", hover_color="#a52a2a", text_color="white").pack(side="left", padx=10)
            ctk.CTkButton(bf, text="Load Data for Charts", command=load_charts,
                          fg_color="#800020", hover_color="#a52a2a", text_color="white").pack(side="left", padx=10)

        except Exception as e:
            logging.error(f"Error reading run => {e}")


# ----------------------------------------------------------------------------
# ADVANCED DASHBOARD
# ----------------------------------------------------------------------------
class AdvancedDashboard(ctk.CTkFrame):
    """
    Basic skeleton from the original code, but minimal usage. 
    We can update data with .update_data(df_current, df_history)
    """
    def __init__(self, parent, config: Dict):
        super().__init__(parent)
        dash_cfg= config.get("dashboard", {})
        self.selected_dims = set(dash_cfg.get("selected_dims", []))
        self.selected_attrs= set(dash_cfg.get("selected_attrs", []))
        self.top_n= dash_cfg.get("top_n", 10)

        self.df_current= pd.DataFrame()
        self.df_history= pd.DataFrame()

        # top bar
        bar= ctk.CTkScrollableFrame(self, orientation="horizontal", height=60)
        bar.pack(fill="x", pady=5)
        self.metric_label= ctk.CTkLabel(bar, text="Metrics: 0 mismatch, 0 dimension", width=300)
        self.metric_label.pack(side="left", padx=5)

        # no dimension/attribute filter for brevity, or add if needed
        ctk.CTkButton(bar, text="Filter Dimension", command=self.filter_dim,
                      fg_color="#800020", hover_color="#a52a2a", text_color="white").pack(side="left", padx=5)
        ctk.CTkButton(bar, text="Filter Attribute", command=self.filter_attr,
                      fg_color="#800020", hover_color="#a52a2a", text_color="white").pack(side="left", padx=5)

        self.notebook= ttk.Notebook(self)
        self.notebook.pack(fill="both", expand=True)

        # one tab with "some chart"? We'll skip actual chart code for brevity
        dummy_tab= ctk.CTkFrame(self.notebook)
        self.notebook.add(dummy_tab, text="Charts (Demo)")

    def filter_dim(self):
        # placeholder
        messagebox.showinfo("Info","Dimension filter not implemented here")

    def filter_attr(self):
        # placeholder
        messagebox.showinfo("Info","Attribute filter not implemented here")

    def update_data(self, df_current: pd.DataFrame, df_history: pd.DataFrame):
        self.df_current = df_current.copy()
        self.df_history = df_history.copy()
        mism = len(self.df_current)
        dims = self.df_current["Dimension"].nunique() if not self.df_current.empty and "Dimension" in self.df_current.columns else 0
        self.metric_label.configure(text=f"Metrics: {mism} mismatch, {dims} dimension")


# ----------------------------------------------------------------------------
# MAIN APP
# ----------------------------------------------------------------------------
class MainApp(ctk.CTk):
    def __init__(self):
        super().__init__()
        self.title("Ultra-Mega Reconciliation: Updated Script")
        self.geometry("1400x800")  # user can resize
        ctk.set_appearance_mode("light")
        self.protocol("WM_DELETE_WINDOW", self.on_close)

        self.config_dict= load_config(Path(DEFAULT_PATHS["CONFIG_PATH"]))
        self.param_dict= read_param_file(Path(self.config_dict["paths"].get("PARAMETER_PATH", DEFAULT_PATHS["PARAMETER_PATH"])))
        self.history_df= pd.DataFrame()

        self.tabs= ttk.Notebook(self)
        self.tabs.pack(fill="both", expand=True)

        # PATHS tab
        self.tab_paths= ctk.CTkFrame(self.tabs)
        self.build_paths_tab(self.tab_paths)
        self.tabs.add(self.tab_paths, text="Paths")

        # ERP preview
        self.tab_erp= ctk.CTkFrame(self.tabs)
        self.erp_preview= SimplePreview(self.tab_erp,"ERP")
        self.erp_preview.pack(fill="both", expand=True)
        self.tabs.add(self.tab_erp, text="ERP Preview")

        # Master preview
        self.tab_master= ctk.CTkFrame(self.tabs)
        self.master_preview= SimplePreview(self.tab_master,"Master")
        self.master_preview.pack(fill="both", expand=True)
        self.tabs.add(self.tab_master, text="Master Preview")

        # Compare
        self.tab_compare= ctk.CTkFrame(self.tabs)
        self.build_compare_tab(self.tab_compare)
        self.tabs.add(self.tab_compare, text="Compare")

        # Dashboard
        self.dashboard_tab= AdvancedDashboard(self.tabs, self.config_dict)
        self.tabs.add(self.dashboard_tab, text="Dashboard")

        # History
        hist_dir= Path(self.config_dict["paths"].get("HISTORY_PATH","history_runs"))
        self.history_tab= HistoryTab(self.tabs, hist_dir, run_selected_callback=self.on_history_file_selected)
        self.tabs.add(self.history_tab, text="History")

        # log box
        self.log_box= ctk.CTkTextbox(self, height=120)
        self.log_box.pack(fill="both", side="bottom")
        self.log_box.configure(state="disabled")
        handler= TextHandler(self.log_box)
        handler.setLevel(logging.INFO)
        logging.getLogger().addHandler(handler)

        # hidden paths (won't show in GUI)
        self.temp_csv_dir= Path(self.config_dict["paths"].get("MASTER_CSV_OUTPUT","temp_master_csv"))
        self.temp_csv_dir.mkdir(parents=True, exist_ok=True)

        # load older runs
        self.load_all_runs()

        # meltdown => preview
        self.refresh_erp()
        self.refresh_master()

        ctk.CTkButton(self, text="Close Script", command=self.on_close,
                      fg_color="#800020", hover_color="#a52a2a", text_color="white").pack(pady=5)

        # pass entire history to dashboard
        self.dashboard_tab.update_data(pd.DataFrame(), self.history_df)

    def build_paths_tab(self, parent):
        """Show only the user-requested path fields:
          - ERP Excel
          - Master ZIP
          - Exception Path
          - Missing Items Output
          - Parameter File
          - PDF Export Path
        (Hide config path, CSV folder, logo, history, bollinger, etc.)
        """
        frm= ctk.CTkFrame(parent)
        frm.pack(fill="both", expand=True, padx=10, pady=10)

        self.erp_var= tk.StringVar(value=self.config_dict["paths"].get("ERP_EXCEL_PATH", DEFAULT_PATHS["ERP_EXCEL_PATH"]))
        self.mast_var= tk.StringVar(value=self.config_dict["paths"].get("MASTER_ZIP_PATH", DEFAULT_PATHS["MASTER_ZIP_PATH"]))
        self.exc_var= tk.StringVar(value=self.config_dict["paths"].get("EXCEPTION_PATH", DEFAULT_PATHS["EXCEPTION_PATH"]))
        self.out_var= tk.StringVar(value=self.config_dict["paths"].get("OUTPUT_PATH", DEFAULT_PATHS["OUTPUT_PATH"]))
        self.par_var= tk.StringVar(value=self.config_dict["paths"].get("PARAMETER_PATH", DEFAULT_PATHS["PARAMETER_PATH"]))
        self.pdf_var= tk.StringVar(value=self.config_dict["paths"].get("PDF_EXPORT_PATH", DEFAULT_PATHS["PDF_EXPORT_PATH"]))

        def mkrow(lbl, var, is_dir=False):
            rowf= ctk.CTkFrame(frm)
            rowf.pack(fill="x", pady=5)
            ctk.CTkLabel(rowf, text=lbl, width=180).pack(side="left", padx=5)
            e= ctk.CTkEntry(rowf, textvariable=var, width=600)
            e.pack(side="left", padx=5)
            def br():
                if is_dir:
                    p= filedialog.askdirectory()
                else:
                    p= filedialog.askopenfilename()
                if p:
                    var.set(p)
            ctk.CTkButton(rowf, text="Browse", command=br,
                          fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)

        mkrow("ERP Excel:", self.erp_var)
        mkrow("Master ZIP:", self.mast_var)
        mkrow("Exception Path:", self.exc_var)
        mkrow("Missing Items Output:", self.out_var)
        mkrow("Parameter File:", self.par_var)
        mkrow("PDF Export Path:", self.pdf_var)

        bf= ctk.CTkFrame(frm)
        bf.pack(fill="x", pady=10)
        ctk.CTkButton(bf, text="Save Config", command=self.save_all_config,
                      fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)
        ctk.CTkButton(bf, text="Refresh ERP", command=self.refresh_erp,
                      fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)
        ctk.CTkButton(bf, text="Refresh Master", command=self.refresh_master,
                      fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)

    def build_compare_tab(self, parent):
        frm= ctk.CTkFrame(parent)
        frm.pack(fill="both", expand=True, padx=10, pady=10)
        ctk.CTkLabel(frm, text="Generate Missing Items", font=("Arial",16)).pack(pady=5)
        ctk.CTkButton(frm, text="Run Reconciliation", command=self.run_comparison,
                      fg_color="#800020", hover_color="#a52a2a").pack(pady=10)
        ctk.CTkButton(frm, text="Export PDF Report", command=self.export_pdf,
                      fg_color="#800020", hover_color="#a52a2a").pack(pady=10)

    def load_all_runs(self):
        hist_path= Path(self.config_dict["paths"].get("HISTORY_PATH","history_runs"))
        if not hist_path.is_dir():
            return
        frames=[]
        for jf in hist_path.glob("run_*.json"):
            try:
                jdata= pd.read_json(jf, orient="records")
                frames.append(jdata)
            except Exception as e:
                logging.error(f"Error reading {jf} => {e}")
        if frames:
            big= pd.concat(frames, ignore_index=True)
            self.history_df= pd.concat([self.history_df, big], ignore_index=True) if not self.history_df.empty else big
            self.history_df.drop_duplicates(inplace=True)
            logging.info(f"Loaded all runs => {len(self.history_df)} from {hist_path}")

    def refresh_erp(self):
        erp_path= Path(self.erp_var.get().strip())
        raw_erp= read_erp_excel(erp_path)
        if raw_erp.empty:
            self.erp_preview.set_data(pd.DataFrame())
            return
        melted= meltdown_erp_for_preview(raw_erp, self.param_dict)
        pivoted= pivot_for_preview(melted)
        self.erp_preview.set_data(pivoted)

    def refresh_master(self):
        zip_path= Path(self.mast_var.get().strip())
        csvs= convert_master_txt_to_csv(zip_path, self.temp_csv_dir)
        raw_mast= unify_master_csvs(csvs)
        if raw_mast.empty:
            self.master_preview.set_data(pd.DataFrame())
            return
        melted= meltdown_master_for_preview(raw_mast, self.param_dict)
        pivoted= pivot_for_preview(melted)
        self.master_preview.set_data(pivoted)

    def run_comparison(self):
        df_erp_wide= self.erp_preview.get_filtered_df()
        df_mast_wide= self.master_preview.get_filtered_df()

        erp_long= self._unpivot(df_erp_wide)
        mast_long= self._unpivot(df_mast_wide)

        # compare => returns Master, ERP, Gap In
        df_diff= compare_erp_master(erp_long, mast_long)

        # exceptions
        exc_path= Path(self.exc_var.get().strip())
        df_exc= read_exception_table(exc_path)
        final= merge_exceptions(df_diff, df_exc)

        # separate case diffs
        mismatch, case_only= separate_case_diffs(final)

        # write to excel
        out_path= Path(self.out_var.get().strip())
        write_to_excel(mismatch, case_only, out_path)

        run_stamp= datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        mismatch["RunDate"]= run_stamp
        case_only["RunDate"]= run_stamp
        appended= pd.concat([mismatch, case_only], ignore_index=True)

        # store in self.history_df
        self.history_df= pd.concat([self.history_df, appended], ignore_index=True)

        # save JSON
        hist_path= Path(self.config_dict["paths"].get("HISTORY_PATH","history_runs"))
        hist_path.mkdir(parents=True, exist_ok=True)
        run_file= hist_path / f"run_{run_stamp.replace(':','-').replace(' ','_')}.json"
        appended.to_json(run_file, orient="records", indent=2)
        logging.info(f"Saved run => {run_file}")

        # update dashboard
        self.dashboard_tab.update_data(appended, self.history_df)

        # refresh history tab
        if hasattr(self.history_tab,"refresh_history"):
            self.history_tab.refresh_history()

        self.tabs.select(self.dashboard_tab)
        messagebox.showinfo("Done", f"Missing items => {out_path}")

    def _unpivot(self, df_wide: pd.DataFrame) -> pd.DataFrame:
        """Pivoted => unpivot => (Dimension, Name, Attribute, Value)."""
        if df_wide.empty:
            return pd.DataFrame(columns=["Dimension","Name","Attribute","Value"])
        id_vars= ["Dimension","Name"]
        meltdown_cols= [c for c in df_wide.columns if c not in id_vars]
        melted= df_wide.melt(id_vars=id_vars, value_vars=meltdown_cols,
                             var_name="Attribute", value_name="Value")
        for c in ["Dimension","Name","Attribute","Value"]:
            melted[c]= melted[c].fillna("").astype(str).str.strip()
        return melted

    def export_pdf(self):
        if self.history_df.empty:
            messagebox.showinfo("PDF Export","No mismatch data => history is empty.")
            return
        if "RunDate" in self.history_df.columns:
            last_run= self.history_df["RunDate"].max()
            df_current= self.history_df[self.history_df["RunDate"]== last_run].copy()
        else:
            df_current= self.history_df.copy()
        df_history= self.history_df.copy()

        rep= EnhancedPDFReport(df_current, df_history, self.config_dict)
        pdf_path= rep.generate()
        messagebox.showinfo("PDF Export", f"PDF exported => {pdf_path}")

    def save_all_config(self):
        self.config_dict["paths"]["ERP_EXCEL_PATH"]= self.erp_var.get().strip()
        self.config_dict["paths"]["MASTER_ZIP_PATH"]= self.mast_var.get().strip()
        self.config_dict["paths"]["EXCEPTION_PATH"]= self.exc_var.get().strip()
        self.config_dict["paths"]["OUTPUT_PATH"]= self.out_var.get().strip()
        self.config_dict["paths"]["PARAMETER_PATH"]= self.par_var.get().strip()
        self.config_dict["paths"]["PDF_EXPORT_PATH"]= self.pdf_var.get().strip()

        # erp_grid filters => store
        self.config_dict.setdefault("erp_grid", {})
        self.config_dict["erp_grid"]["filters"]= self.erp_preview.filters
        self.config_dict.setdefault("master_grid", {})
        self.config_dict["master_grid"]["filters"]= self.master_preview.filters

        # dashboard
        dash_cfg= self.config_dict.setdefault("dashboard", {})
        dash_cfg["selected_dims"]= list(self.dashboard_tab.selected_dims)
        dash_cfg["selected_attrs"]= list(self.dashboard_tab.selected_attrs)
        dash_cfg["top_n"]= self.dashboard_tab.top_n

        save_config(self.config_dict, Path(self.config_dict["paths"].get("CONFIG_PATH","config/ui_config.json")))
        messagebox.showinfo("Saved","Config saved.")

    def on_history_file_selected(self, file_path, data):
        """Load data for charts except bollinger => sets df_current to data, preserves full self.history_df for bollinger."""
        df_run= pd.DataFrame(data)
        if not df_run.empty and "RunDate" in df_run.columns:
            run_date = df_run["RunDate"].iloc[0]
            # remove old run with same date
            self.history_df= self.history_df[self.history_df["RunDate"]!= run_date]
        self.history_df= pd.concat([self.history_df, df_run], ignore_index=True)
        self.dashboard_tab.update_data(df_run, self.history_df)
        self.tabs.select(self.dashboard_tab)

    def on_close(self):
        # save config
        self.save_all_config()

        # optionally write bollinger data
        band_path= self.config_dict["paths"].get("BAND_CHART_JSON_PATH","")
        if band_path and not self.history_df.empty and "RunDate" in self.history_df.columns:
            try:
                outp= Path(band_path)
                date_ct= self.history_df.groupby("RunDate")["Key"].count().reset_index(name="Count")
                date_ct["RunDate_dt"]= pd.to_datetime(date_ct["RunDate"], errors="coerce")
                date_ct.sort_values("RunDate_dt", inplace=True)
                date_ct.reset_index(drop=True, inplace=True)

                date_ct["rolling_mean"]= date_ct["Count"].rolling(3, min_periods=1).mean()
                date_ct["rolling_std"] = date_ct["Count"].rolling(3, min_periods=1).std(ddof=0)
                date_ct["upper_band"]  = date_ct["rolling_mean"] + 2*date_ct["rolling_std"]
                date_ct["lower_band"]  = date_ct["rolling_mean"] - 2*date_ct["rolling_std"]

                date_ct["RunDate"]= date_ct["RunDate_dt"].dt.strftime("%Y-%m-%d %H:%M:%S")
                date_ct.drop(columns=["RunDate_dt"], inplace=True)

                date_ct.to_json(outp, orient="records", indent=2)
                logging.info(f"Bollinger data saved => {outp}")
            except Exception as e:
                logging.error(f"Bollinger => {e}")

        self.destroy()


def main():
    app= MainApp()
    app.mainloop()

if __name__=="__main__":
    main()
