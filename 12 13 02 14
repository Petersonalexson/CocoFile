# 12 13 02 14
"""
Ultra-Mega Reconciliation: Mode=2, Parameter-based (Using Dimension & Attribute Parameters)

Key features:
  • Reads ERP Excel (skipping first 3 rows) and filters only rows with Enabled_Flag == "Enabled".
  • Uses column "V_S_C" (or "V S C") as the raw ERP dimension, then melts and renames attributes.
  • Reads Master .txt files from a ZIP archive (using the full file name as raw dimension) and
    assumes the first column is "Name" with the rest as attributes.
  • Loads a two-sheet parameter Excel file (for Dimension and Attribute mappings) – only rows marked with "x" are kept.
  • In previews, the processed (melted) data is pivoted wide (so that Dimension, Name and the renamed attributes appear as columns).
  • The Compare tab takes the filtered wide preview data (converted back to long) to run Mode=2 reconciliation,
    then writes an output Excel file.
  • The Dashboard tab shows eight charts (each in a scrollable area) based on the latest run plus historical runs.
    In addition to timeline filtering (“Show Today’s Run”), two extra controls allow filtering by Dimension and Attribute.
    The Band Chart displays gaps in time with percentage increase/decrease annotated.
  • All CTkButtons use a burgundy style (#800020) with a “hand2” cursor.
  • The interface is in light mode and includes help icons (ⓘ) in the preview toolbars.
"""

import os, sys, json, logging, zipfile, shutil, io
from pathlib import Path
from datetime import datetime
from typing import Dict, Set, List

import pandas as pd
import numpy as np
import matplotlib
matplotlib.use("TkAgg")
import matplotlib.pyplot as plt
from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg
try:
    import chardet
except ImportError:
    chardet = None

from openpyxl import Workbook
from openpyxl.styles import PatternFill, Font, Alignment

import tkinter as tk
from tkinter import ttk, filedialog, messagebox
import customtkinter as ctk

# ---------------- Logging Setup ----------------
logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")

# ---------------- DEFAULT CONFIG ----------------
DEFAULT_PATHS = {
    "ERP_EXCEL_PATH": "data/ERP_Config.xlsx",
    "MASTER_ZIP_PATH": "data/Master_Config.zip",
    "EXCEPTION_PATH": "data/Exception_Table.xlsx",
    "OUTPUT_PATH": "output/Reconciliation.xlsx",
    "CONFIG_PATH": "config/ui_config.json",
    "PARAMETER_PATH": "data/parameters.xlsx",
    "MASTER_CSV_OUTPUT": "temp_master_csv"
}

def default_config() -> Dict:
    return {
        "paths": DEFAULT_PATHS.copy(),
        "comparison_option": 2
    }

def load_config(path: Path) -> Dict:
    if path.is_file():
        try:
            with open(path, "r", encoding="utf-8") as f:
                return json.load(f)
        except Exception as e:
            logging.warning(f"Could not load config: {e}")
    return default_config()

def save_config(cfg: Dict, path: Path):
    path.parent.mkdir(parents=True, exist_ok=True)
    try:
        with open(path, "w", encoding="utf-8") as f:
            json.dump(cfg, f, indent=2)
        logging.info(f"Saved config to {path}")
    except Exception as e:
        logging.error(f"Error saving config: {e}")

# ---------------- TEXT LOGGER HANDLER ----------------
class TextHandler(logging.Handler):
    def __init__(self, widget: ctk.CTkTextbox):
        super().__init__()
        self.widget = widget
    def emit(self, record):
        msg = self.format(record) + "\n"
        self.widget.after(0, self._append, msg)
    def _append(self, msg):
        self.widget.configure(state="normal")
        self.widget.insert("end", msg)
        self.widget.see("end")
        self.widget.configure(state="disabled")

# ---------------- Helper Functions ----------------
def get_vsc_column(df: pd.DataFrame) -> str:
    for col in ["V_S_C", "V S C"]:
        if col in df.columns:
            return col
    return ""

# ---------------- PARAMETERS FILE READING ----------------
def read_parameter_file(path: Path) -> Dict[str,object]:
    param = {
        "dimension_params": {
            "erp_vsc_map": {},
            "master_file_map": {}
        },
        "attribute_params": {
            "erp_attr_map": {},
            "master_attr_map": {}
        }
    }
    if not path.is_file():
        logging.warning(f"Parameter file not found: {path}")
        return param

    try:
        df_dim = pd.read_excel(path, sheet_name="Dimension Parameters")
        df_dim.columns = df_dim.columns.astype(str).str.strip()
        def s(x):
            return str(x).strip() if pd.notna(x) else ""
        for _, row in df_dim.iterrows():
            file_ = s(row.get("FileName", ""))
            vsc = s(row.get("V S C", ""))
            final_dim = s(row.get("Dimension", ""))
            erp_val = s(row.get("ERP Values", ""))
            if erp_val.lower() == "x" and final_dim:
                if vsc:
                    param["dimension_params"]["erp_vsc_map"][vsc] = final_dim
                if file_:
                    param["dimension_params"]["master_file_map"][file_] = final_dim

        df_attr = pd.read_excel(path, sheet_name="Attribute Parameters")
        df_attr.columns = df_attr.columns.astype(str).str.strip()
        for _, row in df_attr.iterrows():
            erp_orig = s(row.get("ERP Original Attributes", ""))
            master_orig = s(row.get("Master Original Attributes", ""))
            final_attr = s(row.get("Attribute", ""))
            on_off = s(row.get("On/Off", ""))
            if on_off.lower() == "x" and final_attr:
                if erp_orig:
                    param["attribute_params"]["erp_attr_map"][erp_orig] = final_attr
                if master_orig:
                    param["attribute_params"]["master_attr_map"][master_orig] = final_attr
        return param
    except Exception as e:
        logging.error(f"Error reading parameter file: {e}")
        return param

# ---------------- ERP Reading ----------------
def read_erp_enabled(path: Path) -> pd.DataFrame:
    if not path.is_file():
        logging.warning(f"ERP file not found: {path}")
        return pd.DataFrame()
    try:
        df = pd.read_excel(path, skiprows=3)
        df.columns = df.columns.str.strip()
        if "Enabled_Flag" in df.columns:
            df = df[df["Enabled_Flag"] == "Enabled"]
        return df
    except Exception as e:
        logging.error(f"Error reading ERP: {e}")
        return pd.DataFrame()

# ---------------- MASTER Reading ----------------
def read_txt_robust_in_memory(raw: bytes) -> pd.DataFrame:
    import csv
    encs = [
        'utf-8-sig','utf-8','utf-16','utf-16-le','utf-16-be','utf-32','utf-32-le','utf-32-be',
        'cp1250','cp1251','cp1252','latin1','iso-8859-1','iso-8859-2'
    ]
    for enc in encs:
        try:
            buf = io.BytesIO(raw)
            df = pd.read_csv(buf, encoding=enc, sep=",", on_bad_lines="skip", engine="python")
            df.dropna(how="all", axis=0, inplace=True)
            df.dropna(how="all", axis=1, inplace=True)
            return df
        except Exception:
            continue
    logging.error("[Master] Could not parse .txt with known encodings.")
    return pd.DataFrame()

def convert_master_txt_to_csv(zip_path: Path, out_dir: Path) -> List[Path]:
    if out_dir.exists():
        shutil.rmtree(out_dir, ignore_errors=True)
    out_dir.mkdir(parents=True, exist_ok=True)
    csvs = []
    if not zip_path.is_file():
        logging.warning(f"[Master] ZIP not found: {zip_path}")
        return csvs
    with zipfile.ZipFile(zip_path, "r") as z:
        txt_files = [f for f in z.namelist() if f.lower().endswith(".txt")]
        for txt_file in txt_files:
            base_name = os.path.basename(txt_file)
            if not base_name:
                continue
            try:
                with z.open(txt_file) as fo:
                    raw = fo.read()
                if not raw:
                    continue
                df = read_txt_robust_in_memory(raw)
                df.columns = df.columns.str.strip()
                df["RawFileName"] = base_name
                if "Name" not in df.columns and len(df.columns) > 0:
                    firstcol = df.columns[0]
                    df.rename(columns={firstcol: "Name"}, inplace=True)
                out_csv = out_dir / base_name.replace(".txt", ".csv")
                df.to_csv(out_csv, index=False, encoding="utf-8")
                csvs.append(out_csv)
            except Exception as e:
                logging.error(f"[Master] Error reading {txt_file}: {e}")
    return csvs

def unify_master_csvs(csvs: List[Path]) -> pd.DataFrame:
    frames = []
    for cp in csvs:
        if not cp.is_file():
            continue
        try:
            df = pd.read_csv(cp, encoding="utf-8", on_bad_lines="skip")
            df.columns = df.columns.str.strip()
            frames.append(df)
        except Exception as e:
            logging.error(f"[Master unify] Error reading {cp}: {e}")
    if frames:
        return pd.concat(frames, ignore_index=True)
    return pd.DataFrame()

# ---------------- MELTDOWN FUNCTIONS ----------------
def meltdown_erp(df: pd.DataFrame, param: Dict[str,object]) -> pd.DataFrame:
    vsc_col = get_vsc_column(df)
    if not vsc_col:
        logging.warning("[ERP meltdown] ERP dimension column not found.")
        return pd.DataFrame()
    allowed_erp = set(param["dimension_params"]["erp_vsc_map"].keys())
    df2 = df[df[vsc_col].isin(allowed_erp)].copy()
    if df2.empty:
        logging.warning("[ERP meltdown] No rows left after filtering ERP dimensions.")
        return pd.DataFrame()
    id_vars = [vsc_col]
    if "Value" in df2.columns:
        id_vars.append("Value")
    value_vars = [c for c in df2.columns if c not in id_vars and c != "Enabled_Flag"]
    melted = df2.melt(id_vars=id_vars, value_vars=value_vars, var_name="Attribute", value_name="Value")
    melted.rename(columns={vsc_col: "DimRaw"}, inplace=True)
    if "Value" in melted.columns:
        melted.rename(columns={"Value": "RefName"}, inplace=True)
    melted["Dimension"] = melted["DimRaw"].apply(lambda orig: param["dimension_params"]["erp_vsc_map"].get(orig, orig))
    allowed_attrs = set(param["attribute_params"]["erp_attr_map"].keys())
    melted = melted[melted["Attribute"].isin(allowed_attrs)]
    melted["Attribute"] = melted["Attribute"].map(param["attribute_params"]["erp_attr_map"])
    def strip_t(val):
        if isinstance(val, str) and "T" in val:
            return val.split("T")[0]
        return val
    melted["Value"] = melted.apply(lambda row: strip_t(row["Value"]) if row["Attribute"] in {"Start Date", "End Date"} else row["Value"], axis=1)
    return melted[["Dimension", "RefName", "Attribute", "Value"]].copy()

def meltdown_master(df: pd.DataFrame, param: Dict[str,object]) -> pd.DataFrame:
    if df.empty:
        return df
    allowed_master = set(param["dimension_params"]["master_file_map"].keys())
    if "RawFileName" not in df.columns:
        logging.warning("[Master meltdown] 'RawFileName' not found; cannot apply dimension mapping.")
        df["Dimension"] = ""
        id_vars = [c for c in ["Dimension", "Name"] if c in df.columns]
        value_vars = [c for c in df.columns if c not in id_vars]
        melted = df.melt(id_vars=id_vars, value_vars=value_vars, var_name="Attribute", value_name="Value")
        if "Name" in melted.columns:
            melted.rename(columns={"Name": "RefName"}, inplace=True)
        allowed_attrs = set(param["attribute_params"]["master_attr_map"].keys())
        melted = melted[melted["Attribute"].isin(allowed_attrs)]
        melted["Attribute"] = melted["Attribute"].map(param["attribute_params"]["master_attr_map"])
        def strip_t(val):
            if isinstance(val, str) and "T" in val:
                return val.split("T")[0]
            return val
        melted["Value"] = melted.apply(lambda row: strip_t(row["Value"]) if row["Attribute"] in {"Start Date", "End Date"} else row["Value"], axis=1)
        return melted[["Dimension", "RefName", "Attribute", "Value"]].copy()
    else:
        df2 = df[df["RawFileName"].isin(allowed_master)].copy()
        if df2.empty:
            return pd.DataFrame()
        df2["Dimension"] = df2["RawFileName"].apply(lambda rawfile: param["dimension_params"]["master_file_map"].get(rawfile, rawfile))
        id_vars = ["RawFileName"]
        if "Name" in df2.columns:
            id_vars.append("Name")
        value_vars = [c for c in df2.columns if c not in id_vars]
        melted = df2.melt(id_vars=id_vars, value_vars=value_vars, var_name="Attribute", value_name="Value")
        if "Name" in melted.columns:
            melted.rename(columns={"Name": "RefName"}, inplace=True)
        allowed_attrs = set(param["attribute_params"]["master_attr_map"].keys())
        melted = melted[melted["Attribute"].isin(allowed_attrs)]
        melted["Attribute"] = melted["Attribute"].map(param["attribute_params"]["master_attr_map"])
        def strip_t(val):
            if isinstance(val, str) and "T" in val:
                return val.split("T")[0]
            return val
        melted["Value"] = melted.apply(lambda row: strip_t(row["Value"]) if row["Attribute"] in {"Start Date", "End Date"} else row["Value"], axis=1)
        return melted[["Dimension", "RefName", "Attribute", "Value"]].copy()

def build_keys(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    for c in ["Dimension", "RefName", "Attribute", "Value"]:
        if c not in df.columns:
            df[c] = ""
        df[c] = df[c].fillna("").astype(str).str.strip()
    df["GroupKey"] = df["Dimension"] + " | " + df["RefName"]
    df["Key"] = df["Dimension"] + " | " + df["RefName"] + " | " + df["Attribute"] + " | " + df["Value"]
    df["Comments_1"] = ""
    df["Comments_2"] = ""
    df["Action Item"] = ""
    df["Missing In"] = ""
    return df

def build_lookup_dict(df: pd.DataFrame) -> Dict[str, Dict[str, str]]:
    lookup = {}
    for gk, grp in df.groupby("GroupKey"):
        rec = {}
        name_ = grp["RefName"].iloc[0] if not grp.empty else ""
        rec["Name"] = name_
        for _, row in grp.iterrows():
            rec[row["Attribute"]] = row["Value"]
        lookup[gk] = rec
    return lookup

def compare_mode2(df_erp: pd.DataFrame, df_mst: pd.DataFrame) -> pd.DataFrame:
    erp_dict = build_lookup_dict(df_erp)
    mst_dict = build_lookup_dict(df_mst)
    all_keys = set(erp_dict.keys()) | set(mst_dict.keys())
    results = []
    for gk in all_keys:
        dim = gk.split(" | ")[0]
        a_data = erp_dict.get(gk, {})
        b_data = mst_dict.get(gk, {})
        name_a = a_data.get("Name", "")
        name_b = b_data.get("Name", "")
        if name_a and name_b and (name_a == name_b):
            all_attrs = (set(a_data.keys()) | set(b_data.keys())) - {"Name"}
            for attr in all_attrs:
                va = a_data.get(attr, "")
                vb = b_data.get(attr, "")
                if va != vb:
                    if va and not vb:
                        results.append({"Dimension": dim, "Name": name_a, "Attribute": attr, "Value": va, "Missing In": "MASTER"})
                    elif vb and not va:
                        results.append({"Dimension": dim, "Name": name_a, "Attribute": attr, "Value": vb, "Missing In": "ERP"})
                    else:
                        results.append({"Dimension": dim, "Name": name_a, "Attribute": attr, "Value": va, "Missing In": "MASTER"})
                        results.append({"Dimension": dim, "Name": name_a, "Attribute": attr, "Value": vb, "Missing In": "ERP"})
        else:
            if name_a and not name_b:
                results.append({"Dimension": dim, "Name": name_a, "Attribute": "Name", "Value": name_a, "Missing In": "MASTER"})
            elif name_b and not name_a:
                results.append({"Dimension": dim, "Name": name_b, "Attribute": "Name", "Value": name_b, "Missing In": "ERP"})
    df_diff = pd.DataFrame(results)
    if not df_diff.empty:
        df_diff["Key"] = (df_diff["Dimension"].str.strip() + " | " +
                          df_diff["Name"].str.strip() + " | " +
                          df_diff["Attribute"].str.strip() + " | " +
                          df_diff["Value"].str.strip())
    return df_diff

def read_exception_table(path: Path) -> pd.DataFrame:
    if not path.is_file():
        logging.warning(f"Exception table not found: {path}")
        return pd.DataFrame()
    try:
        df = pd.read_excel(path)
        df.columns = df.columns.astype(str).str.strip()
        return df
    except Exception as e:
        logging.error(f"Error reading exception table: {e}")
        return pd.DataFrame()

def merge_exceptions(df: pd.DataFrame, df_exc: pd.DataFrame) -> pd.DataFrame:
    if df.empty or df_exc.empty or "Key" not in df.columns:
        return df
    keep = [c for c in df_exc.columns if c in ["Key", "Comments_1", "Comments_2", "hide exception"]]
    if not keep:
        return df
    exc = df_exc[keep].copy()
    exc["Key"] = exc["Key"].astype(str).str.strip()
    merged = df.merge(exc, on="Key", how="left", suffixes=("", "_exc"))
    merged["hide exception"] = merged.get("hide exception", "").fillna("").str.lower()
    final = merged[merged["hide exception"] != "yes"].copy()
    if "Comments_1_exc" in final.columns:
        final["Comments_1"] = final["Comments_1_exc"].where(final["Comments_1_exc"].notna(), final["Comments_1"])
        final.drop(columns=["Comments_1_exc"], inplace=True)
    if "Comments_2_exc" in final.columns:
        final["Comments_2"] = final["Comments_2_exc"].where(final["Comments_2_exc"].notna(), final["Comments_2"])
        final.drop(columns=["Comments_2_exc"], inplace=True)
    if "hide exception" in final.columns:
        final.drop(columns=["hide exception"], inplace=True)
    return final

def write_results(df: pd.DataFrame, out_path: Path):
    if df.empty:
        logging.info("No differences found; skipping write.")
        return
    out_path.parent.mkdir(parents=True, exist_ok=True)
    final_cols = ["Key", "Dimension", "Name", "Attribute", "Value", "Comments_1", "Comments_2", "Action Item", "Missing In"]
    for c in final_cols:
        if c not in df.columns:
            df[c] = ""
    df = df[final_cols]
    wb = Workbook()
    ws = wb.active
    ws.title = "Results"
    ws.append(final_cols)
    for rowvals in df.itertuples(index=False):
        ws.append(rowvals)
    header_font = Font(bold=True)
    fill = PatternFill(start_color="DDDDDD", end_color="DDDDDD", fill_type="solid")
    for cell in ws[1]:
        cell.font = header_font
        cell.fill = fill
        cell.alignment = Alignment(horizontal="center")
    for col in ws.columns:
        max_len = 0
        col_letter = col[0].column_letter
        for cell in col:
            val = str(cell.value) if cell.value else ""
            max_len = max(max_len, len(val))
        ws.column_dimensions[col_letter].width = max_len + 2
    ws.freeze_panes = "A2"
    wb.save(out_path)
    logging.info(f"Results saved to {out_path}")

# ---------------- ExcelGrid (Wide Preview with Scrollbars & Help Icon) ----------------
class ExcelGrid(ctk.CTkFrame):
    FILTERABLE_COLS = {"Start Date", "End Date"}
    def __init__(self, parent, config_block: Dict, name: str):
        super().__init__(parent)
        self.name = name
        self.df = pd.DataFrame()
        self.filters: Dict[str, Set] = {}
        self.create_toolbar()
        self.create_table()
        self.create_statusbar()
    def create_toolbar(self):
        tb = ctk.CTkFrame(self)
        tb.pack(fill="x", padx=5, pady=5)
        ctk.CTkButton(tb, text="Clear Filters", command=self.clear_filters,
                      fg_color="#800020", hover_color="#a52a2a", cursor="hand2").pack(side="left", padx=5)
        ctk.CTkButton(tb, text="ⓘ", width=30, command=self.show_help,
                      fg_color="#800020", hover_color="#a52a2a", cursor="hand2").pack(side="left", padx=5)
    def create_table(self):
        container = ctk.CTkFrame(self)
        container.pack(fill="both", expand=True, padx=5, pady=5)
        self.tree = ttk.Treeview(container, show="headings")
        vsb = ttk.Scrollbar(container, orient="vertical", command=self.tree.yview)
        hsb = ttk.Scrollbar(container, orient="horizontal", command=self.tree.xview)
        self.tree.configure(yscrollcommand=vsb.set, xscrollcommand=hsb.set)
        self.tree.grid(row=0, column=0, sticky="nsew")
        vsb.grid(row=0, column=1, sticky="ns")
        hsb.grid(row=1, column=0, sticky="ew")
        container.rowconfigure(0, weight=1)
        container.columnconfigure(0, weight=1)
    def create_statusbar(self):
        self.status_label = ctk.CTkLabel(self, text="Ready")
        self.status_label.pack(fill="x")
    def show_help(self):
        messagebox.showinfo("Help", f"This preview shows the processed {self.name} data in wide format.\n"
                                     "Columns include Dimension, Name and the selected attributes.\n\n"
                                     "You may filter on 'Start Date' and 'End Date' by clicking the column header.")
    def set_data(self, df: pd.DataFrame):
        if not df.empty and "Attribute" in df.columns:
            try:
                df = df.pivot(index=["Dimension", "RefName"], columns="Attribute", values="Value").reset_index()
            except Exception as e:
                logging.error(f"Error pivoting data: {e}")
        self.df = df.copy()
        self.refresh_table()
    def get_filtered_df(self) -> pd.DataFrame:
        if self.df.empty:
            return self.df
        df_f = self.df.copy()
        def passes(x, allowed):
            if pd.isna(x):
                return any(pd.isna(a) for a in allowed)
            else:
                return x in allowed
        for col, allowed_vals in self.filters.items():
            if col in df_f.columns and allowed_vals:
                df_f = df_f[df_f[col].apply(lambda z: passes(z, allowed_vals))]
        return df_f
    def refresh_table(self):
        for item in self.tree.get_children():
            self.tree.delete(item)
        cols = list(self.df.columns)
        self.tree["columns"] = cols
        for col in cols:
            self.tree.heading(col, text=col, anchor="w", command=lambda c=col: self.on_heading_click(c))
            self.tree.column(col, anchor="w", width=150)
        df_f = self.get_filtered_df()
        for _, row in df_f.iterrows():
            rowvals = [row[c] if c in df_f.columns else "" for c in cols]
            self.tree.insert("", "end", values=rowvals)
        self.status_label.configure(text=f"{len(df_f)} rows")
    def on_heading_click(self, col_name: str):
        if col_name in self.FILTERABLE_COLS:
            self.show_filter_popup(col_name)
    def show_filter_popup(self, col_name: str):
        if self.df.empty or col_name not in self.df.columns:
            return
        popup = tk.Toplevel(self)
        popup.title(f"Filter: {col_name}")
        popup.geometry("300x400")
        frame = ctk.CTkFrame(popup)
        frame.pack(fill="both", expand=True, padx=5, pady=5)
        unique_vals = self.df[col_name].unique()
        display_map = {}
        for v in unique_vals:
            if pd.isna(v):
                dsp = "(NaN)"
            elif isinstance(v, str) and not v.strip():
                dsp = "(blank)"
            else:
                dsp = str(v)
            display_map[v] = dsp
        sorted_vals = sorted(display_map.keys(), key=lambda x: display_map[x].lower())
        curr_filter = self.filters.get(col_name, set(unique_vals))
        select_all_var = tk.BooleanVar(value=True)
        def toggle_all():
            check = select_all_var.get()
            for vb in var_dict.values():
                vb.set(check)
        ctk.CTkCheckBox(frame, text="Select All", variable=select_all_var, command=toggle_all,
                        fg_color="#800020", hover_color="#a52a2a", cursor="hand2").pack(anchor="w", pady=5)
        scroll = ctk.CTkScrollableFrame(frame, width=250, height=250)
        scroll.pack(fill="both", expand=True, padx=5, pady=5)
        var_dict = {}
        for rv in sorted_vals:
            in_filter = (rv in curr_filter) if not pd.isna(rv) else any(pd.isna(a) for a in curr_filter)
            bvar = tk.BooleanVar(value=in_filter)
            var_dict[rv] = bvar
            ctk.CTkCheckBox(scroll, text=display_map[rv], variable=bvar,
                            fg_color="#800020", hover_color="#a52a2a", cursor="hand2").pack(anchor="w")
        def apply_():
            sel = set(rv for rv, vb in var_dict.items() if vb.get())
            self.filters[col_name] = sel
            popup.destroy()
            self.refresh_table()
        bf = ctk.CTkFrame(frame)
        bf.pack(fill="x", pady=5)
        ctk.CTkButton(bf, text="Apply", command=apply_,
                      fg_color="#800020", hover_color="#a52a2a", cursor="hand2").pack(side="left", padx=5)
        ctk.CTkButton(bf, text="Cancel", command=popup.destroy,
                      fg_color="#800020", hover_color="#a52a2a", cursor="hand2").pack(side="left", padx=5)
    def clear_filters(self):
        self.filters.clear()
        self.refresh_table()

# ---------------- Dashboard with Extra Filter Controls ----------------
class Dashboard(ctk.CTkFrame):
    def __init__(self, parent):
        super().__init__(parent)
        self.df_current = pd.DataFrame()
        self.df_history = pd.DataFrame()
        # Extra filter controls for dimension and attribute
        self.selected_dimensions: Set[str] = set()
        self.selected_attributes: Set[str] = set()
        topbar = ctk.CTkFrame(self)
        topbar.pack(fill="x", padx=5, pady=5)
        ctk.CTkButton(topbar, text="Show Today's Run", command=self.show_today,
                      fg_color="#800020", hover_color="#a52a2a", cursor="hand2").pack(side="left", padx=5)
        ctk.CTkButton(topbar, text="Filter Dimension", command=self.show_dimension_filter_popup,
                      fg_color="#800020", hover_color="#a52a2a", cursor="hand2").pack(side="left", padx=5)
        ctk.CTkButton(topbar, text="Filter Attribute", command=self.show_attribute_filter_popup,
                      fg_color="#800020", hover_color="#a52a2a", cursor="hand2").pack(side="left", padx=5)
        self.notebook = ttk.Notebook(self)
        self.notebook.pack(fill="both", expand=True)
        self.frames = {}
        chart_labels = ["Heatmap", "Lollipop", "Circular", "Scatter", "Radar", "Normal Pie", "Normal Bar", "Band Chart"]
        for label in chart_labels:
            frame = ctk.CTkFrame(self.notebook)
            self.notebook.add(frame, text=label)
            self.frames[label] = frame

    def apply_filters(self, df: pd.DataFrame) -> pd.DataFrame:
        if df.empty:
            return df
        df_filtered = df.copy()
        if self.selected_dimensions:
            df_filtered = df_filtered[df_filtered["Dimension"].isin(self.selected_dimensions)]
        if self.selected_attributes:
            df_filtered = df_filtered[df_filtered["Attribute"].isin(self.selected_attributes)]
        return df_filtered

    def update_data(self, df_current: pd.DataFrame, df_history: pd.DataFrame):
        self.df_current = df_current.copy()
        self.df_history = df_history.copy()
        self.plot_heatmap()
        self.plot_lollipop()
        self.plot_circular()
        self.plot_scatter()
        self.plot_radar()
        self.plot_normal_pie()
        self.plot_normal_bar()
        self.plot_band_chart()

    def show_today(self):
        today_str = datetime.now().strftime("%Y-%m-%d")
        if "RunDate" not in self.df_history.columns:
            messagebox.showinfo("Info", "No run data available. Please run reconciliation first.")
            return
        df_today = self.df_history[self.df_history["RunDate"] == today_str]
        if df_today.empty:
            messagebox.showinfo("Info", "No run for today. Please run reconciliation to display today's data.")
        else:
            self.update_data(df_today, self.df_history)

    def show_dimension_filter_popup(self):
        self._show_filter_popup("Dimension")

    def show_attribute_filter_popup(self):
        self._show_filter_popup("Attribute")

    def _show_filter_popup(self, col: str):
        # Use df_history if available, else df_current
        base_df = self.df_history if not self.df_history.empty else self.df_current
        if base_df.empty or col not in base_df.columns:
            return
        popup = tk.Toplevel(self)
        popup.title(f"Filter: {col}")
        popup.geometry("300x400")
        frame = ctk.CTkFrame(popup)
        frame.pack(fill="both", expand=True, padx=5, pady=5)
        unique_vals = base_df[col].unique()
        display_map = {v: (str(v) if pd.notna(v) and str(v).strip() else "(blank)") for v in unique_vals}
        sorted_vals = sorted(display_map.keys(), key=lambda x: display_map[x].lower())
        current_filter = self.selected_dimensions if col=="Dimension" else self.selected_attributes
        if not current_filter:
            current_filter = set(unique_vals)
        select_all_var = tk.BooleanVar(value=True)
        def toggle_all():
            check = select_all_var.get()
            for vb in var_dict.values():
                vb.set(check)
        ctk.CTkCheckBox(frame, text="Select All", variable=select_all_var, command=toggle_all,
                        fg_color="#800020", hover_color="#a52a2a", cursor="hand2").pack(anchor="w", pady=5)
        scroll = ctk.CTkScrollableFrame(frame, width=250, height=250)
        scroll.pack(fill="both", expand=True, padx=5, pady=5)
        var_dict = {}
        for rv in sorted_vals:
            in_filter = (rv in current_filter) if not pd.isna(rv) else any(pd.isna(a) for a in current_filter)
            bvar = tk.BooleanVar(value=in_filter)
            var_dict[rv] = bvar
            ctk.CTkCheckBox(scroll, text=display_map[rv], variable=bvar,
                            fg_color="#800020", hover_color="#a52a2a", cursor="hand2").pack(anchor="w")
        def apply_():
            sel = set(rv for rv, vb in var_dict.items() if vb.get())
            if col=="Dimension":
                self.selected_dimensions = sel
            else:
                self.selected_attributes = sel
            popup.destroy()
            self.update_data(self.df_current, self.df_history)
        bf = ctk.CTkFrame(frame)
        bf.pack(fill="x", pady=5)
        ctk.CTkButton(bf, text="Apply", command=apply_,
                      fg_color="#800020", hover_color="#a52a2a", cursor="hand2").pack(side="left", padx=5)
        ctk.CTkButton(bf, text="Cancel", command=popup.destroy,
                      fg_color="#800020", hover_color="#a52a2a", cursor="hand2").pack(side="left", padx=5)

    def plot_chart(self, frame, fig):
        for widget in frame.winfo_children():
            widget.destroy()
        canvas = FigureCanvasTkAgg(fig, master=frame)
        canvas.draw()
        canvas.get_tk_widget().pack(fill="both", expand=True)

    def plot_heatmap(self):
        frame = self.frames["Heatmap"]
        data = self.apply_filters(self.df_current)
        df_m = data[data["Missing In"] != ""]
        if df_m.empty:
            return
        try:
            pivoted = df_m.groupby(["Dimension", "Attribute"]).size().unstack(fill_value=0)
        except Exception as e:
            logging.error(f"Heatmap grouping error: {e}")
            return
        fig, ax = plt.subplots(figsize=(6,5))
        cax = ax.imshow(pivoted, aspect="auto", cmap="Reds")
        ax.set_xticks(range(len(pivoted.columns)))
        ax.set_xticklabels(pivoted.columns, rotation=90)
        ax.set_yticks(range(len(pivoted.index)))
        ax.set_yticklabels(pivoted.index)
        fig.colorbar(cax, ax=ax)
        ax.set_title("Heatmap: Missing Items")
        self.plot_chart(frame, fig)

    def plot_lollipop(self):
        frame = self.frames["Lollipop"]
        data = self.apply_filters(self.df_current)
        df_m = data[data["Missing In"] != ""]
        if df_m.empty:
            return
        count_dim = df_m.groupby("Dimension")["Key"].count().sort_values(ascending=False).head(10)
        if count_dim.empty:
            return
        fig, ax = plt.subplots(figsize=(6,5))
        ax.hlines(y=count_dim.index, xmin=0, xmax=count_dim.values, color="skyblue")
        ax.plot(count_dim.values, count_dim.index, "o", color="skyblue")
        ax.set_title("Lollipop: Missing Dimensions")
        ax.set_xlabel("Missing Count")
        self.plot_chart(frame, fig)

    def plot_circular(self):
        frame = self.frames["Circular"]
        data = self.apply_filters(self.df_current)
        df_m = data[data["Missing In"] != ""]
        if df_m.empty:
            return
        count_attr = df_m.groupby("Attribute")["Key"].count().sort_values(ascending=False).head(10)
        if count_attr.empty:
            return
        categories = count_attr.index.tolist()
        values = count_attr.values
        angles = np.linspace(0, 2*np.pi, len(categories), endpoint=False)
        fig = plt.figure(figsize=(6,6))
        ax = fig.add_subplot(111, polar=True)
        ax.set_theta_offset(np.pi/2)
        ax.set_theta_direction(-1)
        ax.set_xticks(angles)
        ax.set_xticklabels(categories, fontsize=9)
        ax.bar(angles, values, width=0.4, color="orange", alpha=0.6)
        ax.set_title("Circular Barplot: Missing Attributes", y=1.05)
        self.plot_chart(frame, fig)

    def plot_scatter(self):
        frame = self.frames["Scatter"]
        data = self.apply_filters(self.df_current)
        df_m = data[data["Missing In"] != ""]
        if df_m.empty:
            return
        count_dim = df_m.groupby("Dimension")["Key"].count().reset_index(name="Count")
        count_dim.sort_values("Count", ascending=False, inplace=True)
        if count_dim.empty:
            return
        xvals = np.arange(len(count_dim))
        yvals = count_dim["Count"].values
        labels = count_dim["Dimension"].values
        fig, ax = plt.subplots(figsize=(6,5))
        ax.scatter(xvals, yvals, color="green")
        for i, txt in enumerate(labels):
            ax.text(xvals[i], yvals[i], txt, ha="center", va="bottom", rotation=60)
        ax.set_xticks([])
        ax.set_ylabel("Missing Count")
        ax.set_title("Scatter: Missing by Dimension")
        self.plot_chart(frame, fig)

    def plot_radar(self):
        frame = self.frames["Radar"]
        data = self.apply_filters(self.df_current)
        df_m = data[data["Missing In"] != ""]
        if df_m.empty:
            return
        count_dim = df_m.groupby("Dimension")["Key"].count().sort_values(ascending=False).head(5)
        if count_dim.empty:
            return
        categories = count_dim.index.tolist()
        values = count_dim.values.tolist()
        N = len(categories)
        angles = np.linspace(0, 2*np.pi, N, endpoint=False).tolist()
        angles += angles[:1]
        values += values[:1]
        fig = plt.figure(figsize=(6,6))
        ax = fig.add_subplot(111, polar=True)
        ax.set_theta_offset(np.pi/2)
        ax.set_theta_direction(-1)
        ax.set_xticks(angles[:-1])
        ax.set_xticklabels(categories, fontsize=9)
        ax.plot(angles, values, color="red", linewidth=2)
        ax.fill(angles, values, color="red", alpha=0.3)
        ax.set_title("Radar: Top 5 Missing Dimensions", y=1.08)
        self.plot_chart(frame, fig)

    def plot_normal_pie(self):
        frame = self.frames["Normal Pie"]
        data = self.apply_filters(self.df_current)
        df_m = data[data["Missing In"] != ""]
        if df_m.empty:
            return
        dist = df_m["Missing In"].value_counts()
        fig, ax = plt.subplots(figsize=(5,5))
        ax.pie(dist.values, labels=dist.index, autopct="%.1f%%", startangle=140)
        ax.set_title("Normal Pie: Missing In Distribution")
        self.plot_chart(frame, fig)

    def plot_normal_bar(self):
        frame = self.frames["Normal Bar"]
        data = self.apply_filters(self.df_current)
        df_m = data[data["Missing In"] != ""]
        if df_m.empty:
            return
        count_attr = df_m.groupby("Attribute")["Key"].count().sort_values(ascending=False).head(10)
        fig, ax = plt.subplots(figsize=(6,4))
        count_attr.plot(kind="bar", ax=ax, color="blue")
        ax.set_ylabel("Missing Count")
        ax.set_title("Normal Bar: Top 10 Missing Attributes")
        self.plot_chart(frame, fig)

    def plot_band_chart(self):
        frame = self.frames["Band Chart"]
        data = self.apply_filters(self.df_history)
        if data.empty or "RunDate" not in data.columns:
            return
        # Convert RunDate to datetime
        try:
            data["RunDate_dt"] = pd.to_datetime(data["RunDate"], format="%Y-%m-%d")
        except Exception:
            data["RunDate_dt"] = pd.to_datetime(data["RunDate"])
        date_counts = data.groupby("RunDate_dt")["Key"].count().reset_index(name="Count")
        date_counts.sort_values("RunDate_dt", inplace=True)
        date_counts["PctChange"] = date_counts["Count"].pct_change()*100
        fig, ax = plt.subplots(figsize=(6,4))
        ax.plot(date_counts["RunDate_dt"], date_counts["Count"], color="purple", marker="o", label="Missing Count")
        # Fill band ±10%
        ax.fill_between(date_counts["RunDate_dt"], date_counts["Count"]*0.9, date_counts["Count"]*1.1,
                        color="purple", alpha=0.2, label="±10% band")
        ax.set_title("Band Chart: Missing Count Over Runs\n(Gaps & % Change Annotated)")
        ax.set_xlabel("Run Date")
        ax.set_ylabel("Missing Count")
        plt.xticks(rotation=45)
        ax.legend(fontsize=8)
        # Annotate percentage change
        for i in range(1, len(date_counts)):
            pct = date_counts["PctChange"].iloc[i]
            txt = f"{pct:+.1f}%"
            ax.annotate(txt, (date_counts["RunDate_dt"].iloc[i], date_counts["Count"].iloc[i]),
                        textcoords="offset points", xytext=(0,10), ha="center", fontsize=8, color="red")
        self.plot_chart(frame, fig)

# ---------------- Main Application ----------------
class MainApp(ctk.CTk):
    def __init__(self):
        super().__init__()
        self.title("Ultra-Mega Reconciliation: Mode=2")
        self.geometry("1600x900")
        ctk.set_appearance_mode("light")
        self.config_dict = load_config(Path(DEFAULT_PATHS["CONFIG_PATH"]))
        self.param_dict = read_parameter_file(Path(self.config_dict["paths"].get("PARAMETER_PATH", DEFAULT_PATHS["PARAMETER_PATH"])))
        self.history_df = pd.DataFrame()
        self.notebook = ttk.Notebook(self)
        self.notebook.pack(fill="both", expand=True)
        self.tab_paths = ctk.CTkFrame(self.notebook)
        self.notebook.add(self.tab_paths, text="Paths")
        self.build_paths_tab(self.tab_paths)
        self.tab_erp = ctk.CTkFrame(self.notebook)
        self.notebook.add(self.tab_erp, text="ERP")
        self.erp_grid = ExcelGrid(self.tab_erp, {}, "ERP")
        self.erp_grid.pack(fill="both", expand=True)
        self.tab_master = ctk.CTkFrame(self.notebook)
        self.notebook.add(self.tab_master, text="Master")
        self.master_grid = ExcelGrid(self.tab_master, {}, "Master")
        self.master_grid.pack(fill="both", expand=True)
        self.tab_compare = ctk.CTkFrame(self.notebook)
        self.notebook.add(self.tab_compare, text="Compare")
        self.build_compare_tab(self.tab_compare)
        self.tab_dashboard = Dashboard(self.notebook)
        self.notebook.add(self.tab_dashboard, text="Dashboard")
        self.log_box = ctk.CTkTextbox(self, height=120)
        self.log_box.pack(fill="both")
        self.log_box.configure(state="disabled")
        handler = TextHandler(self.log_box)
        handler.setLevel(logging.INFO)
        logging.getLogger().addHandler(handler)
        self.temp_csv_dir = Path(self.config_dict["paths"].get("MASTER_CSV_OUTPUT", DEFAULT_PATHS["MASTER_CSV_OUTPUT"]))
        self.temp_csv_dir.mkdir(exist_ok=True)
        self.refresh_erp_data()
        self.refresh_master_data()
    def build_paths_tab(self, parent):
        frm = ctk.CTkFrame(parent)
        frm.pack(fill="both", expand=True, padx=10, pady=10)
        self.erp_var = tk.StringVar(value=self.config_dict["paths"].get("ERP_EXCEL_PATH", DEFAULT_PATHS["ERP_EXCEL_PATH"]))
        self.mst_var = tk.StringVar(value=self.config_dict["paths"].get("MASTER_ZIP_PATH", DEFAULT_PATHS["MASTER_ZIP_PATH"]))
        self.exc_var = tk.StringVar(value=self.config_dict["paths"].get("EXCEPTION_PATH", DEFAULT_PATHS["EXCEPTION_PATH"]))
        self.out_var = tk.StringVar(value=self.config_dict["paths"].get("OUTPUT_PATH", DEFAULT_PATHS["OUTPUT_PATH"]))
        self.cfg_var = tk.StringVar(value=self.config_dict["paths"].get("CONFIG_PATH", DEFAULT_PATHS["CONFIG_PATH"]))
        self.par_var = tk.StringVar(value=self.config_dict["paths"].get("PARAMETER_PATH", DEFAULT_PATHS["PARAMETER_PATH"]))
        self.csv_var = tk.StringVar(value=self.config_dict["paths"].get("MASTER_CSV_OUTPUT", DEFAULT_PATHS["MASTER_CSV_OUTPUT"]))
        def mkrow(lbl, var, is_dir=False):
            rowf = ctk.CTkFrame(frm)
            rowf.pack(fill="x", pady=5)
            ctk.CTkLabel(rowf, text=lbl, width=180).pack(side="left", padx=5)
            e = ctk.CTkEntry(rowf, textvariable=var, width=600)
            e.pack(side="left", padx=5)
            def br():
                if is_dir:
                    p = filedialog.askdirectory()
                else:
                    p = filedialog.askopenfilename()
                if p:
                    var.set(p)
            ctk.CTkButton(rowf, text="Browse", command=br,
                          fg_color="#800020", hover_color="#a52a2a", cursor="hand2").pack(side="left", padx=5)
        mkrow("ERP Excel Path:", self.erp_var)
        mkrow("Master ZIP Path:", self.mst_var)
        mkrow("Exception Path:", self.exc_var)
        mkrow("Output Excel Path:", self.out_var)
        mkrow("JSON Config Path:", self.cfg_var)
        mkrow("Parameter File Path:", self.par_var)
        mkrow("Master CSV Folder:", self.csv_var, is_dir=True)
    def build_compare_tab(self, parent):
        frm = ctk.CTkFrame(parent)
        frm.pack(fill="both", expand=True, padx=10, pady=10)
        ctk.CTkLabel(frm, text="Mode=2 Comparison", font=("Arial", 16)).pack(pady=5)
        btnf = ctk.CTkFrame(frm)
        btnf.pack(fill="x", pady=5)
        ctk.CTkButton(btnf, text="Run Comparison", command=self.run_comparison,
                      fg_color="#800020", hover_color="#a52a2a", cursor="hand2").pack(side="left", padx=5)
        ctk.CTkButton(btnf, text="Save Config", command=self.save_all_config,
                      fg_color="#800020", hover_color="#a52a2a", cursor="hand2").pack(side="left", padx=5)
    def refresh_erp_data(self):
        df_raw = read_erp_enabled(Path(self.erp_var.get().strip()))
        df_melt = meltdown_erp(df_raw, self.param_dict)
        if not df_melt.empty:
            try:
                df_wide = df_melt.pivot(index=["Dimension", "RefName"], columns="Attribute", values="Value").reset_index()
            except Exception as e:
                logging.error(f"Error pivoting ERP data: {e}")
                df_wide = df_melt.copy()
        else:
            df_wide = pd.DataFrame()
        self.erp_grid.set_data(df_wide)
    def refresh_master_data(self):
        zip_path = Path(self.mst_var.get().strip())
        out_dir = Path(self.csv_var.get().strip())
        csvs = convert_master_txt_to_csv(zip_path, out_dir)
        df_raw = unify_master_csvs(csvs)
        df_melt = meltdown_master(df_raw, self.param_dict)
        if not df_melt.empty:
            try:
                df_wide = df_melt.pivot(index=["Dimension", "RefName"], columns="Attribute", values="Value").reset_index()
            except Exception as e:
                logging.error(f"Error pivoting Master data: {e}")
                df_wide = df_melt.copy()
        else:
            df_wide = pd.DataFrame()
        self.master_grid.set_data(df_wide)
    def run_comparison(self):
        self.config_dict["paths"]["ERP_EXCEL_PATH"] = self.erp_var.get().strip()
        self.config_dict["paths"]["MASTER_ZIP_PATH"] = self.mst_var.get().strip()
        self.config_dict["paths"]["EXCEPTION_PATH"] = self.exc_var.get().strip()
        self.config_dict["paths"]["OUTPUT_PATH"] = self.out_var.get().strip()
        self.config_dict["paths"]["CONFIG_PATH"] = self.cfg_var.get().strip()
        self.config_dict["paths"]["PARAMETER_PATH"] = self.par_var.get().strip()
        self.config_dict["paths"]["MASTER_CSV_OUTPUT"] = self.csv_var.get().strip()
        self.config_dict["comparison_option"] = 2
        newparam = read_parameter_file(Path(self.par_var.get().strip()))
        df_erp_wide = self.erp_grid.get_filtered_df()
        if not df_erp_wide.empty and {"Dimension", "RefName"}.issubset(df_erp_wide.columns):
            df_erp_long = pd.melt(df_erp_wide, id_vars=["Dimension", "RefName"], var_name="Attribute", value_name="Value")
        else:
            df_erp_long = pd.DataFrame()
        df_mst_wide = self.master_grid.get_filtered_df()
        if not df_mst_wide.empty and {"Dimension", "RefName"}.issubset(df_mst_wide.columns):
            df_mst_long = pd.melt(df_mst_wide, id_vars=["Dimension", "RefName"], var_name="Attribute", value_name="Value")
        else:
            df_mst_long = pd.DataFrame()
        erp_ready = build_keys(df_erp_long)
        mst_ready = build_keys(df_mst_long)
        df_diff = compare_mode2(erp_ready, mst_ready)
        exc_path = Path(self.exc_var.get().strip())
        df_exc = read_exception_table(exc_path)
        final = merge_exceptions(df_diff, df_exc)
        out_path = Path(self.out_var.get().strip())
        write_results(final, out_path)
        run_date = datetime.now().strftime("%Y-%m-%d")
        final["RunDate"] = run_date
        if self.history_df.empty:
            self.history_df = final.copy()
        else:
            self.history_df = pd.concat([self.history_df, final], ignore_index=True)
        self.notebook.select(self.tab_dashboard)
        self.tab_dashboard.update_data(final, self.history_df)
        messagebox.showinfo("Done", f"Comparison done. Output saved to:\n{out_path}")
    def save_all_config(self):
        self.config_dict["paths"]["ERP_EXCEL_PATH"] = self.erp_var.get().strip()
        self.config_dict["paths"]["MASTER_ZIP_PATH"] = self.mst_var.get().strip()
        self.config_dict["paths"]["EXCEPTION_PATH"] = self.exc_var.get().strip()
        self.config_dict["paths"]["OUTPUT_PATH"] = self.out_var.get().strip()
        self.config_dict["paths"]["CONFIG_PATH"] = self.cfg_var.get().strip()
        self.config_dict["paths"]["PARAMETER_PATH"] = self.par_var.get().strip()
        self.config_dict["paths"]["MASTER_CSV_OUTPUT"] = self.csv_var.get().strip()
        self.config_dict["comparison_option"] = 2
        save_config(self.config_dict, Path(self.cfg_var.get()))
        messagebox.showinfo("Saved", "Config saved successfully.")

def main():
    app = MainApp()
    app.mainloop()

if __name__ == "__main__":
    main()
