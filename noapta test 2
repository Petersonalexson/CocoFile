

"""
Ultra-Mega Reconciliation (Single Master Table + Convert .txt to UTF-8 CSV)
---------------------------------------------------------------------------
- Each .txt in the Master ZIP -> read robustly, saved to a temp CSV in UTF-8,
  then combined into ONE DataFrame with a 'Dimension' column.
- We display a SINGLE Master grid, so you can filter/rename columns in one place.
- The meltdown then occurs on that single Master DataFrame when running comparison.
- Multiple comparison modes (1, 2, 3), merges exception table, plus a dashboard.

Author: X
Date: 2025
"""

import os
import json
import logging
import time
import csv
import zipfile
from pathlib import Path
from typing import Dict, List, Set, Tuple
from datetime import datetime

import tkinter as tk
from tkinter import ttk, filedialog, messagebox, simpledialog

import customtkinter as ctk
import pandas as pd
import numpy as np

# Attempt chardet for advanced encoding detection
try:
    import chardet
except ImportError:
    chardet = None

from openpyxl import Workbook
from openpyxl.styles import PatternFill, Font, Alignment

import matplotlib
matplotlib.use("TkAgg")
import matplotlib.pyplot as plt
from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg

# ------------------------------------------------------------------------------
# 1) LOGGING
# ------------------------------------------------------------------------------
def setup_logger():
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s [%(levelname)s] %(message)s"
    )
setup_logger()

# ------------------------------------------------------------------------------
# 2) DEFAULT CONFIG
# ------------------------------------------------------------------------------
DEFAULT_PATHS = {
    "ERP_EXCEL_PATH": "data/ERP_Config.xlsx",
    "MASTER_ZIP_PATH": "data/Master_Config.zip",
    "EXCEPTION_PATH": "data/Exception_Table.xlsx",
    "OUTPUT_PATH": "output/Reconciliation.xlsx",
    "CONFIG_PATH": "config/ui_config.json"
}

def default_config() -> Dict:
    return {
        "paths": {
            "ERP_EXCEL_PATH": DEFAULT_PATHS["ERP_EXCEL_PATH"],
            "MASTER_ZIP_PATH": DEFAULT_PATHS["MASTER_ZIP_PATH"],
            "EXCEPTION_PATH": DEFAULT_PATHS["EXCEPTION_PATH"],
            "OUTPUT_PATH": DEFAULT_PATHS["OUTPUT_PATH"],
            "CONFIG_PATH": DEFAULT_PATHS["CONFIG_PATH"]
        },
        "erp_grid": {
            "columns": [
                {"id": "Col1",           "name": "Col1",           "locked": False, "visible": True,  "renameable": True},
                {"id": "Col2",           "name": "Col2",           "locked": False, "visible": True,  "renameable": True},
                {"id": "Enabled_Flag",   "name": "Enabled_Flag",   "locked": False, "visible": True,  "renameable": True},
                {"id": "Dimension_Name", "name": "Dimension_Name", "locked": True,  "visible": True,  "renameable": False},
                {"id": "Value",          "name": "Value",          "locked": True,  "visible": True,  "renameable": False},
            ],
            "filters": {}
        },
        # Single Master Grid, not multiple sub-tabs
        "master_grid": {
            "columns": [],
            "filters": {}
        },
        "dimension_renames": {},
        "comparison_option": 1
    }

def load_config(path: Path) -> Dict:
    if path.is_file():
        try:
            with open(path, "r", encoding="utf-8") as f:
                return json.load(f)
        except Exception as e:
            logging.warning(f"Could not load config from {path}: {e}")
    return default_config()

def save_config(cfg: Dict, path: Path):
    path.parent.mkdir(parents=True, exist_ok=True)
    try:
        with open(path, "w", encoding="utf-8") as f:
            json.dump(cfg, f, indent=2)
        logging.info(f"Saved config to {path}")
    except Exception as e:
        logging.error(f"Error saving config: {e}")

# ------------------------------------------------------------------------------
# 3) TEXT LOGGER HANDLER
# ------------------------------------------------------------------------------
class TextHandler(logging.Handler):
    def __init__(self, widget: ctk.CTkTextbox):
        super().__init__()
        self.widget = widget
    def emit(self, record):
        msg = self.format(record) + "\n"
        self.widget.after(0, self._append, msg)
    def _append(self, msg):
        self.widget.configure(state="normal")
        self.widget.insert("end", msg)
        self.widget.see("end")
        self.widget.configure(state="disabled")

# ------------------------------------------------------------------------------
# 4) SAFE READ ERP EXCEL
# ------------------------------------------------------------------------------
class FileHandler:
    @staticmethod
    def safe_read_excel(path: Path, skiprows: int = 0, retries: int = 2) -> pd.DataFrame:
        import pandas as pd
        for attempt in range(retries):
            try:
                logging.info(f"Reading Excel: {path} (attempt {attempt+1}/{retries})")
                df = pd.read_excel(path, skiprows=skiprows)
                df.columns = df.columns.str.strip()
                return df
            except Exception as e:
                logging.warning(f"Failed reading Excel {path}: {e}")
                if attempt == retries - 1:
                    raise
                time.sleep(1)
        return pd.DataFrame()

def safe_read_erp_excel(path: Path) -> pd.DataFrame:
    if not path.is_file():
        logging.warning(f"ERP Excel not found at {path}")
        return pd.DataFrame()
    try:
        return FileHandler.safe_read_excel(path, skiprows=3)
    except Exception as e:
        logging.error(f"Error reading ERP Excel: {e}")
        return pd.DataFrame()

# ------------------------------------------------------------------------------
# 5) ROBUST CSV READING
# ------------------------------------------------------------------------------
def read_csv_robust(filebytes: bytes) -> pd.DataFrame:
    """
    Attempts multiple encodings: chardet guess, utf-8-sig, utf-16, ...
    Multiple delimiters: ',', ';', '\\t', '|', plus None for inference.
    Skips bad lines, fallback for older Pandas, etc.
    """
    import io
    import pandas as pd

    if len(filebytes) == 0:
        logging.warning("[read_csv_robust] Empty file => returning empty DataFrame.")
        return pd.DataFrame()

    guess_enc = None
    if chardet:
        det = chardet.detect(filebytes[:4096])
        enc_ = det.get("encoding")
        conf_ = det.get("confidence", 0)
        if enc_ and conf_ >= 0.75:
            guess_enc = enc_
            logging.info(f"[read_csv_robust] chardet guess='{enc_}', conf={conf_}")

    encodings_to_try = []
    if guess_enc:
        encodings_to_try.append(guess_enc)
    encodings_to_try.extend(["utf-8-sig","utf-16","utf-32","cp1252","latin1","iso-8859-1","ascii"])

    delimiters = [",",";","\t","|",None]

    def try_read(data, enc, delim):
        import csv
        try:
            return pd.read_csv(
                io.BytesIO(data),
                encoding=enc,
                delimiter=delim,
                on_bad_lines="skip",
                quoting=csv.QUOTE_MINIMAL,
                error_bad_lines=False,
                engine="python"
            )
        except TypeError:
            text_decoded = data.decode(enc, errors="replace")
            buf = io.StringIO(text_decoded)
            return pd.read_csv(
                buf,
                delimiter=delim,
                error_bad_lines=False,
                warn_bad_lines=True,
                quoting=csv.QUOTE_MINIMAL,
                engine="python"
            )

    for enc in encodings_to_try:
        for delim in delimiters:
            try:
                df_tmp = try_read(filebytes, enc, delim)
                df_tmp.dropna(how="all", inplace=True)
                df_tmp.dropna(axis=1, how="all", inplace=True)
                df_tmp.columns = df_tmp.columns.astype(str).str.strip()
                if not df_tmp.empty and len(df_tmp.columns) > 0:
                    logging.info(f"[read_csv_robust] success enc='{enc}', delim='{delim}' => shape={df_tmp.shape}")
                    return df_tmp
                else:
                    logging.warning(f"[read_csv_robust] empty/no-cols with enc='{enc}', delim='{delim}'")
            except Exception as ex_:
                logging.debug(f"[read_csv_robust] fail enc='{enc}', delim='{delim}': {ex_}")
    logging.error("[read_csv_robust] Could not parse file with any combo.")
    return pd.DataFrame()

# ------------------------------------------------------------------------------
# 6) EXCELGRID
# ------------------------------------------------------------------------------
class ExcelGrid(ctk.CTkFrame):
    """
    Single Master or ERP Grid. You can rename/hide columns, filter values, etc.
    """
    LOCK_ICON = " \U0001F512"

    def __init__(self, parent, config_block: Dict, name: str):
        super().__init__(parent)
        self.name = name
        self.col_defs = config_block.get("columns", [])
        self.filters: Dict[str, Set] = {}
        for col_id, val_list in config_block.get("filters", {}).items():
            self.filters[col_id] = set(val_list) if isinstance(val_list, list) else set()

        self.df = pd.DataFrame()

        self.create_toolbar()
        self.create_table()
        self.create_statusbar()

    def create_toolbar(self):
        bar = ctk.CTkFrame(self)
        bar.pack(fill="x", padx=5, pady=5)
        ctk.CTkButton(bar, text="Manage Columns", command=self.show_column_manager).pack(side="left", padx=5)
        ctk.CTkButton(bar, text="Clear Filters", command=self.clear_filters).pack(side="left", padx=5)

    def create_table(self):
        container = ctk.CTkFrame(self)
        container.pack(fill="both", expand=True, padx=5, pady=5)

        self.tree = ttk.Treeview(container, show="headings")
        vsb = ttk.Scrollbar(container, orient="vertical", command=self.tree.yview)
        hsb = ttk.Scrollbar(container, orient="horizontal", command=self.tree.xview)
        self.tree.configure(yscrollcommand=vsb.set, xscrollcommand=hsb.set)

        self.tree.grid(row=0, column=0, sticky="nsew")
        vsb.grid(row=0, column=1, sticky="ns")
        hsb.grid(row=1, column=0, sticky="ew")

        container.rowconfigure(0, weight=1)
        container.columnconfigure(0, weight=1)

    def create_statusbar(self):
        self.status_label = ctk.CTkLabel(self, text="Ready")
        self.status_label.pack(fill="x", padx=5, pady=2)

    def set_data(self, df: pd.DataFrame):
        self.df = df.copy(deep=True)
        existing_ids = [c["id"] for c in self.col_defs]
        for col in self.df.columns:
            if col not in existing_ids:
                self.col_defs.append({
                    "id": col,
                    "name": col,
                    "locked": False,
                    "visible": True,
                    "renameable": True
                })
        self.refresh_table()

    def get_config_block(self):
        return {
            "columns": self.col_defs,
            "filters": {col_id: sorted(list(vals)) for col_id, vals in self.filters.items()}
        }

    def get_filtered_df(self) -> pd.DataFrame:
        if self.df.empty:
            return self.df
        df_f = self.df.copy()

        def passes_filter(x, allowed_vals):
            if pd.isna(x):
                return any(pd.isna(a) for a in allowed_vals)
            else:
                return x in allowed_vals

        for col_id, allowed_vals in self.filters.items():
            if col_id in df_f.columns and allowed_vals:
                mask = df_f[col_id].apply(lambda v: passes_filter(v, allowed_vals))
                df_f = df_f[mask]

        visible_ids = [c["id"] for c in self.col_defs if c.get("visible", True)]
        visible_ids = [c for c in visible_ids if c in df_f.columns]
        return df_f[visible_ids]

    def refresh_table(self):
        for item in self.tree.get_children():
            self.tree.delete(item)

        visible_cols = [c for c in self.col_defs if c.get("visible", True)]
        self.tree["columns"] = [c["id"] for c in visible_cols]

        for col_def in visible_cols:
            col_name = col_def["name"]
            if col_def.get("locked", False):
                col_name += self.LOCK_ICON
            self.tree.heading(
                col_def["id"],
                text=col_name,
                anchor="w",
                command=lambda c=col_def: self.show_filter_popup(c)
            )
            self.tree.column(col_def["id"], anchor="w", width=col_def.get("width", 150))

        df_f = self.get_filtered_df()
        for _, row in df_f.iterrows():
            vals = [row[c["id"]] for c in visible_cols]
            self.tree.insert("", "end", values=vals)

        self.status_label.configure(text=f"{len(df_f)} rows")

    def show_filter_popup(self, col_def: Dict):
        col_id = col_def["id"]
        if self.df.empty or col_id not in self.df.columns:
            return

        popup = tk.Toplevel(self)
        popup.title(f"Filter: {col_def['name']}")
        popup.geometry("320x500")

        frame = ctk.CTkFrame(popup)
        frame.pack(fill="both", expand=True, padx=5, pady=5)

        series = self.df[col_id].unique()
        display_map = {}
        for val in series:
            if pd.isna(val):
                display_str = "(NaN)"
            elif isinstance(val, str) and not val.strip():
                display_str = "(blank)"
            else:
                display_str = str(val)
            display_map[val] = display_str

        sorted_vals = sorted(display_map.keys(), key=lambda rv: display_map[rv].lower())
        current_filter = self.filters.get(col_id, set())
        if not current_filter:
            current_filter = set(series)

        select_all_var = tk.BooleanVar(value=True)
        def toggle_select_all():
            new_val = select_all_var.get()
            for vb in var_dict.values():
                vb.set(new_val)

        ctk.CTkCheckBox(frame, text="Select All", variable=select_all_var,
                        command=toggle_select_all).pack(anchor="w", pady=5)

        scroll = ctk.CTkScrollableFrame(frame, width=280, height=320)
        scroll.pack(fill="both", expand=True, padx=5, pady=5)

        var_dict = {}
        for real_val in sorted_vals:
            disp_str = display_map[real_val]
            if pd.isna(real_val):
                in_filter = any(pd.isna(fv) for fv in current_filter)
            else:
                in_filter = (real_val in current_filter)
            var = tk.BooleanVar(value=in_filter)
            var_dict[real_val] = var
            ctk.CTkCheckBox(scroll, text=disp_str, variable=var).pack(anchor="w")

        def apply_filter():
            selected = set()
            for rv, vb in var_dict.items():
                if vb.get():
                    selected.add(rv)
            self.filters[col_id] = selected
            popup.destroy()
            self.refresh_table()

        btn_frame = ctk.CTkFrame(frame)
        btn_frame.pack(fill="x", pady=5)
        ctk.CTkButton(btn_frame, text="Apply", command=apply_filter).pack(side="left", padx=5)
        ctk.CTkButton(btn_frame, text="Cancel", command=popup.destroy).pack(side="left", padx=5)

    def show_column_manager(self):
        cm = tk.Toplevel(self)
        cm.title(f"{self.name} Column Manager")
        scrolled = ctk.CTkScrollableFrame(cm, width=600, height=500)
        scrolled.pack(fill="both", expand=True)

        for i, col_def in enumerate(self.col_defs):
            rowf = ctk.CTkFrame(scrolled)
            rowf.pack(fill="x", pady=2)

            if col_def.get("locked", False):
                txt = col_def["name"] + self.LOCK_ICON
                ctk.CTkLabel(rowf, text=txt).pack(side="left", padx=5)
                continue

            var_vis = tk.BooleanVar(value=col_def.get("visible", True))
            def toggler(c=col_def, v=var_vis):
                c["visible"] = v.get()
                self.refresh_table()

            ctk.CTkCheckBox(rowf, text="", variable=var_vis, command=toggler).pack(side="left")

            if col_def.get("renameable", True):
                ctk.CTkButton(rowf, text=col_def["name"], command=lambda c=col_def: self.rename_column(c)).pack(side="left", padx=5)
            else:
                ctk.CTkLabel(rowf, text=col_def["name"]).pack(side="left", padx=5)

            ctk.CTkButton(rowf, text="↑", width=30, command=lambda idx=i: self.move_column(idx, -1)).pack(side="right", padx=2)
            ctk.CTkButton(rowf, text="↓", width=30, command=lambda idx=i: self.move_column(idx, 1)).pack(side="right", padx=2)

    def rename_column(self, col_def: Dict):
        old_name = col_def["name"]
        new_name = simpledialog.askstring("Rename Column", f"New name for {old_name}:", initialvalue=old_name)
        if new_name:
            col_def["name"] = new_name
            self.refresh_table()

    def move_column(self, idx: int, delta: int):
        new_idx = idx + delta
        if 0 <= new_idx < len(self.col_defs):
            self.col_defs[idx], self.col_defs[new_idx] = self.col_defs[new_idx], self.col_defs[idx]
            self.refresh_table()

    def clear_filters(self):
        self.filters.clear()
        self.refresh_table()

# ------------------------------------------------------------------------------
# 7) MELTDOWN & COMPARISON
# ------------------------------------------------------------------------------
def meltdown_erp(df: pd.DataFrame, dim_renames: Dict[str,str]) -> pd.DataFrame:
    if df.empty:
        return df
    skip_cols = {"Col1","Col2","Enabled_Flag"}
    keep_cols = [c for c in df.columns if c not in skip_cols]
    id_vars = []
    if "Dimension_Name" in keep_cols:
        id_vars.append("Dimension_Name")
    if "Value" in keep_cols:
        id_vars.append("Value")
    value_vars = [c for c in keep_cols if c not in id_vars]

    melted = df.melt(
        id_vars=id_vars,
        value_vars=value_vars,
        var_name="Attribute",
        value_name="Value"
    )
    melted.rename(columns={"Dimension_Name":"Dimension","Value":"RefName"}, inplace=True)
    if dim_renames:
        melted["Dimension"] = melted["Dimension"].replace(dim_renames)
    return melted[["Dimension","RefName","Attribute","Value"]].copy()

def meltdown_master(df: pd.DataFrame, dim_renames: Dict[str,str]) -> pd.DataFrame:
    if df.empty:
        return df
    keep_cols = df.columns.tolist()
    id_vars = [c for c in ["Dimension","Name"] if c in keep_cols]
    value_vars = [c for c in keep_cols if c not in id_vars]
    melted = df.melt(
        id_vars=id_vars,
        value_vars=value_vars,
        var_name="Attribute",
        value_name="Value"
    )
    melted.rename(columns={"Name":"RefName"}, inplace=True)
    if dim_renames:
        melted["Dimension"] = melted["Dimension"].replace(dim_renames)
    return melted[["Dimension","RefName","Attribute","Value"]].copy()

def build_keys(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    for col in ["Dimension","RefName","Attribute","Value"]:
        if col not in df.columns:
            df[col] = ""
        df[col] = df[col].fillna("").astype(str).str.strip()
    df["GroupKey"] = df["Dimension"] + " | " + df["RefName"]
    df["Key"] = df["Dimension"] + " | " + df["RefName"] + " | " + df["Attribute"] + " | " + df["Value"]
    df["Comments_1"] = ""
    df["Comments_2"] = ""
    df["Action Item"] = ""
    df["Missing In"] = ""
    return df

def build_lookup_dict(df: pd.DataFrame) -> Dict[str,Dict[str,str]]:
    lookup = {}
    for gk, grp in df.groupby("GroupKey"):
        rec = {}
        if not grp.empty:
            ref = grp["RefName"].iloc[0]
        else:
            ref = ""
        rec["Name"] = ref
        for _, row in grp.iterrows():
            rec[row["Attribute"]] = row["Value"]
        lookup[gk] = rec
    return lookup

def compare_data(df_erp: pd.DataFrame, df_master: pd.DataFrame, mode: int) -> pd.DataFrame:
    erp_dict = build_lookup_dict(df_erp)
    mst_dict = build_lookup_dict(df_master)
    all_keys = set(erp_dict.keys()) | set(mst_dict.keys())
    results = []
    for gk in all_keys:
        dimension = gk.split(" | ")[0] if " | " in gk else ""
        a_data = erp_dict.get(gk, {})
        b_data = mst_dict.get(gk, {})
        name_a = a_data.get("Name", a_data.get("RefName", ""))
        name_b = b_data.get("Name", b_data.get("RefName", ""))

        if mode == 1:
            results.extend(compare_mode_1(dimension, name_a, name_b, a_data, b_data))
        elif mode == 2:
            results.extend(compare_mode_2(dimension, name_a, name_b, a_data, b_data))
        else:
            results.extend(compare_mode_3(dimension, name_a, name_b, a_data, b_data))

    df_diff = pd.DataFrame(results)
    if not df_diff.empty:
        df_diff["Key"] = (
            df_diff["Dimension"].str.strip() + " | " +
            df_diff["Name"].str.strip() + " | " +
            df_diff["Attribute"].str.strip() + " | " +
            df_diff["Value"].str.strip()
        )
    return df_diff

def compare_mode_1(dimension, name_a, name_b, a_data, b_data):
    results = []
    all_attrs = set(a_data.keys()) | set(b_data.keys())
    for attr in all_attrs:
        va = a_data.get(attr, "")
        vb = b_data.get(attr, "")
        if va != vb:
            if va and not vb:
                results.append({"Dimension": dimension, "Name": name_a, "Attribute": attr, "Value": va, "Missing In": "MASTER"})
            elif vb and not va:
                results.append({"Dimension": dimension, "Name": name_b, "Attribute": attr, "Value": vb, "Missing In": "ERP"})
            else:
                results.append({"Dimension": dimension, "Name": name_a, "Attribute": attr, "Value": va, "Missing In": "MASTER"})
                results.append({"Dimension": dimension, "Name": name_b, "Attribute": attr, "Value": vb, "Missing In": "ERP"})
    return results

def compare_mode_2(dimension, name_a, name_b, a_data, b_data):
    results = []
    if name_a and name_b and (name_a == name_b):
        all_attrs = (set(a_data.keys()) | set(b_data.keys())) - {"Name"}
        for attr in all_attrs:
            va = a_data.get(attr, "")
            vb = b_data.get(attr, "")
            if va != vb:
                if va and not vb:
                    results.append({"Dimension": dimension, "Name": name_a, "Attribute": attr, "Value": va, "Missing In": "MASTER"})
                elif vb and not va:
                    results.append({"Dimension": dimension, "Name": name_a, "Attribute": attr, "Value": vb, "Missing In": "ERP"})
                else:
                    results.append({"Dimension": dimension, "Name": name_a, "Attribute": attr, "Value": va, "Missing In": "MASTER"})
                    results.append({"Dimension": dimension, "Name": name_a, "Attribute": attr, "Value": vb, "Missing In": "ERP"})
    else:
        if name_a and not name_b:
            results.append({"Dimension": dimension, "Name": name_a, "Attribute": "Name", "Value": name_a, "Missing In": "MASTER"})
        elif name_b and not name_a:
            results.append({"Dimension": dimension, "Name": name_b, "Attribute": "Name", "Value": name_b, "Missing In": "ERP"})
    return results

def compare_mode_3(dimension, name_a, name_b, a_data, b_data):
    results = []
    all_attrs = set(a_data.keys()) | set(b_data.keys())
    for attr in all_attrs:
        va = a_data.get(attr, "")
        vb = b_data.get(attr, "")
        if va == vb:
            results.append({"Dimension": dimension, "Name": name_a if name_a else name_b, "Attribute": attr, "Value": va, "Missing In": ""})
        else:
            if va and not vb:
                results.append({"Dimension": dimension, "Name": name_a, "Attribute": attr, "Value": va, "Missing In": "MASTER"})
            elif vb and not va:
                results.append({"Dimension": dimension, "Name": name_b, "Attribute": attr, "Value": vb, "Missing In": "ERP"})
            else:
                results.append({"Dimension": dimension, "Name": name_a, "Attribute": attr, "Value": va, "Missing In": "MASTER"})
                results.append({"Dimension": dimension, "Name": name_a if name_a else name_b, "Attribute": attr, "Value": vb, "Missing In": "ERP"})
    return results

# ------------------------------------------------------------------------------
# 8) EXCEPTIONS
# ------------------------------------------------------------------------------
def read_exception_table(exc_path: Path) -> pd.DataFrame:
    if exc_path.is_file():
        try:
            return pd.read_excel(exc_path, sheet_name=0)
        except Exception as e:
            logging.error(f"Error reading exception table: {e}")
    return pd.DataFrame()

def merge_exceptions(df: pd.DataFrame, df_exc: pd.DataFrame) -> pd.DataFrame:
    if df.empty or df_exc.empty or "Key" not in df.columns:
        return df
    keep = [c for c in df_exc.columns if c in ["Key","Comments_1","Comments_2","hide exception"]]
    if not keep:
        return df
    exc = df_exc[keep].copy()
    exc["Key"] = exc["Key"].astype(str).str.strip()

    merged = df.merge(exc, on="Key", how="left", suffixes=("", "_exc"))
    merged["hide exception"] = merged.get("hide exception", "").fillna("").str.lower()
    final = merged[merged["hide exception"]!="yes"].copy()

    if "Comments_1_exc" in final.columns:
        final["Comments_1"] = final["Comments_1_exc"].where(final["Comments_1_exc"].notna(), final["Comments_1"])
        final.drop(columns=["Comments_1_exc"], inplace=True)
    if "Comments_2_exc" in final.columns:
        final["Comments_2"] = final["Comments_2_exc"].where(final["Comments_2_exc"].notna(), final["Comments_2"])
        final.drop(columns=["Comments_2_exc"], inplace=True)
    if "hide exception" in final.columns:
        final.drop(columns=["hide exception"], inplace=True)
    return final

# ------------------------------------------------------------------------------
# 9) WRITE RESULTS
# ------------------------------------------------------------------------------
def write_results(df: pd.DataFrame, out_path: Path, mode: int):
    if df.empty:
        logging.info("No differences to write => skipping file output.")
        return
    out_path.parent.mkdir(parents=True, exist_ok=True)
    final_cols = ["Key","Dimension","Name","Attribute","Value","Comments_1","Comments_2","Action Item","Missing In"]
    for c in final_cols:
        if c not in df.columns:
            df[c] = ""
    df = df[final_cols]

    wb = Workbook()
    max_rows_per_sheet = 30000 if mode == 3 else 999999
    sheet_count = 1
    start = 0
    while start < len(df):
        end = min(start + max_rows_per_sheet, len(df))
        chunk = df.iloc[start:end]
        if sheet_count == 1:
            ws = wb.active
            ws.title = f"Results{sheet_count}"
        else:
            ws = wb.create_sheet(title=f"Results{sheet_count}")
        ws.append(final_cols)
        for row in chunk.itertuples(index=False):
            ws.append(row)
        header_font = Font(bold=True)
        fill = PatternFill(start_color="DDDDDD", end_color="DDDDDD", fill_type="solid")
        for cell in ws[1]:
            cell.font = header_font
            cell.fill = fill
            cell.alignment = Alignment(horizontal="center")

        # Auto-col width
        for col in ws.columns:
            max_len = 0
            col_letter = col[0].column_letter
            for cell in col:
                val = str(cell.value) if cell.value is not None else ""
                max_len = max(max_len, len(val))
            ws.column_dimensions[col_letter].width = max_len + 2

        ws.freeze_panes = "A2"
        sheet_count += 1
        start = end
    wb.save(out_path)
    logging.info(f"Results saved to {out_path}")

# ------------------------------------------------------------------------------
# 10) DASHBOARD
# ------------------------------------------------------------------------------
class Dashboard(ctk.CTkFrame):
    def __init__(self, parent):
        super().__init__(parent)
        self.df_current = pd.DataFrame()
        self.df_history = pd.DataFrame()

        self.notebook = ttk.Notebook(self)
        self.notebook.pack(fill="both", expand=True)

        self.frame_heatmap = ctk.CTkFrame(self.notebook)
        self.notebook.add(self.frame_heatmap, text="Discrepancy Heatmap")

        self.frame_status = ctk.CTkFrame(self.notebook)
        self.notebook.add(self.frame_status, text="Status Distribution")

        self.frame_dimension = ctk.CTkFrame(self.notebook)
        self.notebook.add(self.frame_dimension, text="Dimension Analysis")

        self.frame_attribute = ctk.CTkFrame(self.notebook)
        self.notebook.add(self.frame_attribute, text="Attribute Comparison")

        self.frame_linechart = ctk.CTkFrame(self.notebook)
        self.notebook.add(self.frame_linechart, text="Trend Over Days")

    def update_data(self, df_current: pd.DataFrame, df_history: pd.DataFrame):
        self.df_current = df_current.copy()
        self.df_history = df_history.copy()
        self.plot_heatmap()
        self.plot_status_distribution()
        self.plot_dimension_analysis()
        self.plot_attribute_comparison()
        self.plot_run_trend()

    def plot_heatmap(self):
        for w in self.frame_heatmap.winfo_children():
            w.destroy()
        if self.df_current.empty:
            return
        mismatch_df = self.df_current[self.df_current["Missing In"] != ""]
        pivot_df = mismatch_df.groupby(["Dimension","Attribute"]).size().unstack(fill_value=0)
        if pivot_df.empty:
            return
        fig, ax = plt.subplots(figsize=(6,5))
        cax = ax.imshow(pivot_df, cmap="Reds", aspect="auto")
        ax.set_xticks(range(len(pivot_df.columns)))
        ax.set_yticks(range(len(pivot_df.index)))
        ax.set_xticklabels(pivot_df.columns, rotation=90)
        ax.set_yticklabels(pivot_df.index)
        ax.set_title("Discrepancy Heatmap (# mismatches)")
        fig.colorbar(cax, ax=ax)
        canvas = FigureCanvasTkAgg(fig, master=self.frame_heatmap)
        canvas.draw()
        canvas.get_tk_widget().pack(fill="both", expand=True)

    def plot_status_distribution(self):
        for w in self.frame_status.winfo_children():
            w.destroy()
        if self.df_current.empty:
            return
        dist_counts = self.df_current["Missing In"].fillna("").value_counts()
        data_labels = dist_counts.index.tolist()
        data_values = dist_counts.values.tolist()
        fig, ax = plt.subplots(figsize=(5,5))
        ax.pie(data_values, labels=data_labels, autopct="%.1f%%", startangle=140)
        ax.set_title("Status Distribution (Current Run)")
        canvas = FigureCanvasTkAgg(fig, master=self.frame_status)
        canvas.draw()
        canvas.get_tk_widget().pack(fill="both", expand=True)

    def plot_dimension_analysis(self):
        for w in self.frame_dimension.winfo_children():
            w.destroy()
        if self.df_current.empty:
            return
        dim_counts = self.df_current.groupby("Dimension")["Key"].count().sort_values(ascending=False)
        fig, ax = plt.subplots(figsize=(6,4))
        dim_counts.plot(kind="bar", ax=ax, color="blue")
        ax.set_ylabel("Count of Rows")
        ax.set_title("Records per Dimension (Current Run)")
        canvas = FigureCanvasTkAgg(fig, master=self.frame_dimension)
        canvas.draw()
        canvas.get_tk_widget().pack(fill="both", expand=True)

    def plot_attribute_comparison(self):
        for w in self.frame_attribute.winfo_children():
            w.destroy()
        if self.df_current.empty:
            return
        attr_counts = self.df_current.groupby("Attribute")["Key"].count().sort_values(ascending=False).head(10)
        fig, ax = plt.subplots(figsize=(6,4))
        attr_counts.plot(kind="bar", ax=ax, color="red")
        ax.set_ylabel("# of Mismatches")
        ax.set_title("Top 10 Mismatched Attributes (Current Run)")
        canvas = FigureCanvasTkAgg(fig, master=self.frame_attribute)
        canvas.draw()
        canvas.get_tk_widget().pack(fill="both", expand=True)

    def plot_run_trend(self):
        for w in self.frame_linechart.winfo_children():
            w.destroy()
        if self.df_history.empty or "RunDate" not in self.df_history.columns:
            return
        mismatch_df = self.df_history[self.df_history["Missing In"] != ""]
        if mismatch_df.empty:
            return
        date_counts = mismatch_df.groupby("RunDate")["Key"].count().reset_index()
        fig, ax = plt.subplots(figsize=(6,4))
        ax.plot(date_counts["RunDate"], date_counts["Key"], marker="o", color="green")
        ax.set_xlabel("Date")
        ax.set_ylabel("Mismatch Count")
        ax.set_title("Mismatch Trend Over Days")
        plt.xticks(rotation=45)
        for i, row in date_counts.iterrows():
            ax.text(row["RunDate"], row["Key"], str(row["Key"]), ha="center", va="bottom")
        canvas = FigureCanvasTkAgg(fig, master=self.frame_linechart)
        canvas.draw()
        canvas.get_tk_widget().pack(fill="both", expand=True)

# ------------------------------------------------------------------------------
# 11) MAIN APP
# ------------------------------------------------------------------------------
class MainApp(ctk.CTk):
    """
    - Single ERP Grid + Single Master Grid
    - Master Data => For each .txt, robust parse -> temp CSV -> re-read => unify into one DF w/Dimension col
    - meltdown, compare, exceptions, dashboard
    """
    def __init__(self):
        super().__init__()
        self.title("Ultra-Mega Reconciliation: Single Master Table (UTF-8 CSV Conversion)")
        self.geometry("1600x900")

        self.config_dict = load_config(Path(DEFAULT_PATHS["CONFIG_PATH"]))
        self.history_df = pd.DataFrame()

        # main notebook
        self.notebook = ttk.Notebook(self)
        self.notebook.pack(fill="both", expand=True)

        # 1) Paths
        self.tab_paths = ctk.CTkFrame(self.notebook)
        self.notebook.add(self.tab_paths, text="Paths")
        self.build_paths_tab(self.tab_paths)

        # 2) ERP
        self.tab_erp = ctk.CTkFrame(self.notebook)
        self.notebook.add(self.tab_erp, text="ERP Data")
        self.erp_grid = ExcelGrid(self.tab_erp, self.config_dict.get("erp_grid", {}), "ERP")
        self.erp_grid.pack(fill="both", expand=True)

        # 3) Master
        self.tab_master = ctk.CTkFrame(self.notebook)
        self.notebook.add(self.tab_master, text="Master Data (All .txt Merged)")
        self.master_grid = ExcelGrid(self.tab_master, self.config_dict.get("master_grid", {}), "Master")
        self.master_grid.pack(fill="both", expand=True)

        # 4) Dimension Renames
        self.tab_dim = ctk.CTkFrame(self.notebook)
        self.notebook.add(self.tab_dim, text="Dimension Renames")
        self.build_dimension_tab(self.tab_dim)

        # 5) Compare & Exceptions
        self.tab_compare = ctk.CTkFrame(self.notebook)
        self.notebook.add(self.tab_compare, text="Compare & Exceptions")
        self.build_compare_tab(self.tab_compare)

        # 6) Dashboard
        self.tab_dashboard = Dashboard(self.notebook)
        self.notebook.add(self.tab_dashboard, text="Dashboard")

        # Logging box
        self.log_box = ctk.CTkTextbox(self, height=100)
        self.log_box.pack(fill="both", expand=False)
        self.log_box.configure(state="disabled")
        handler = TextHandler(self.log_box)
        handler.setLevel(logging.INFO)
        logging.getLogger().addHandler(handler)

        # Folder for temp CSV
        self.temp_csv_dir = Path("temp_master_csv")
        self.temp_csv_dir.mkdir(exist_ok=True)

        # single DataFrame that merges all Master .txt
        self.df_master_merged = pd.DataFrame()

        # initial load
        self.refresh_erp_data()
        self.refresh_master_data()

    def build_paths_tab(self, parent):
        frm = ctk.CTkFrame(parent)
        frm.pack(fill="both", expand=True, padx=10, pady=10)

        self.erp_path_var = tk.StringVar(value=self.config_dict["paths"].get("ERP_EXCEL_PATH", DEFAULT_PATHS["ERP_EXCEL_PATH"]))
        self.master_path_var = tk.StringVar(value=self.config_dict["paths"].get("MASTER_ZIP_PATH", DEFAULT_PATHS["MASTER_ZIP_PATH"]))
        self.exc_path_var = tk.StringVar(value=self.config_dict["paths"].get("EXCEPTION_PATH", DEFAULT_PATHS["EXCEPTION_PATH"]))
        self.out_path_var = tk.StringVar(value=self.config_dict["paths"].get("OUTPUT_PATH", DEFAULT_PATHS["OUTPUT_PATH"]))
        self.cfg_path_var = tk.StringVar(value=self.config_dict["paths"].get("CONFIG_PATH", DEFAULT_PATHS["CONFIG_PATH"]))

        def mkrow(lbl, var):
            rowf = ctk.CTkFrame(frm)
            rowf.pack(fill="x", pady=5)
            ctk.CTkLabel(rowf, text=lbl, width=200).pack(side="left", padx=5)
            ent = ctk.CTkEntry(rowf, textvariable=var, width=800)
            ent.pack(side="left", padx=5)
            def br():
                path = filedialog.askopenfilename()
                if path:
                    var.set(path)
            ctk.CTkButton(rowf, text="Browse", command=br).pack(side="left", padx=5)

        mkrow("ERP Excel Path:", self.erp_path_var)
        mkrow("Master ZIP Path:", self.master_path_var)
        mkrow("Exception Path:", self.exc_path_var)
        mkrow("Output Excel Path:", self.out_path_var)
        mkrow("JSON Config Path:", self.cfg_path_var)

    def refresh_erp_data(self):
        p = Path(self.erp_path_var.get())
        df_erp = safe_read_erp_excel(p)
        self.erp_grid.set_data(df_erp)

    def refresh_master_data(self):
        """
        1) For each .txt in ZIP, robust parse, store 'Dimension' col from filename
        2) Save to temp CSV in UTF-8
        3) Re-read that CSV (UTF-8)
        4) Accumulate into a single df_master_merged
        5) display in self.master_grid
        """
        zip_path = Path(self.master_path_var.get())
        if not zip_path.is_file():
            logging.warning("[Master] ZIP not found.")
            return

        # Clear old data
        self.df_master_merged = pd.DataFrame()

        with zipfile.ZipFile(zip_path, "r") as z:
            txt_files = [f for f in z.namelist() if f.lower().endswith(".txt")]
            if not txt_files:
                logging.warning("[Master] No .txt found in ZIP.")
                return

            partial_dfs = []

            for txt_file in txt_files:
                base_name = os.path.basename(txt_file)
                if "_ceaster.txt" in base_name.lower():
                    base_dim = base_name.lower().replace("_ceaster.txt", "")
                else:
                    base_dim, _ = os.path.splitext(base_name)
                dimension_name = base_dim.replace("_", " ").title()

                try:
                    with z.open(txt_file) as fo:
                        file_bytes = fo.read()
                        if not file_bytes:
                            logging.warning(f"[Master] '{txt_file}' is empty.")
                            continue
                        df_raw = read_csv_robust(file_bytes)
                        if df_raw.empty:
                            continue
                        df_raw.columns = df_raw.columns.str.strip()

                        # Insert a 'Dimension' column
                        df_raw["Dimension"] = dimension_name

                        # If no "Name" col, rename the first col
                        if "Name" not in df_raw.columns and len(df_raw.columns) > 0:
                            first_col = df_raw.columns[0]
                            df_raw.rename(columns={first_col: "Name"}, inplace=True)

                        # Save to temp CSV
                        out_csv = self.temp_csv_dir / f"{dimension_name}.csv"
                        df_raw.to_csv(out_csv, index=False, encoding="utf-8")

                        # Re-read the CSV
                        df_reutf = pd.read_csv(out_csv, encoding="utf-8", on_bad_lines="skip")
                        df_reutf.columns = df_reutf.columns.str.strip()
                        # Ensure 'Dimension' remains
                        df_reutf["Dimension"] = dimension_name
                        partial_dfs.append(df_reutf)

                except Exception as e:
                    logging.error(f"[Master] Error reading '{txt_file}': {e}")
                    continue

            if partial_dfs:
                self.df_master_merged = pd.concat(partial_dfs, ignore_index=True)
            else:
                self.df_master_merged = pd.DataFrame()

        # Now set to the Master grid
        self.master_grid.set_data(self.df_master_merged)

    def build_dimension_tab(self, parent):
        frm = ctk.CTkFrame(parent)
        frm.pack(fill="both", expand=True, padx=10, pady=10)

        ctk.CTkLabel(frm, text="Old Dimension -> New Dimension").pack(pady=5)
        self.rename_rows = []
        self.list_frame = ctk.CTkScrollableFrame(frm, width=600, height=300)
        self.list_frame.pack(fill="both", expand=True)

        for old_dim, new_dim in self.dim_rename_map.items():
            self.add_dim_rename_row(old_dim, new_dim)

        ctk.CTkButton(frm, text="Add New Mapping", command=lambda: self.add_dim_rename_row("", "")).pack(pady=5)
        ctk.CTkButton(frm, text="Save Dimension Renames", command=self.save_dim_renames).pack(pady=5)

    def add_dim_rename_row(self, old_val: str, new_val: str):
        row = ctk.CTkFrame(self.list_frame)
        row.pack(fill="x", pady=2)
        tk_old = tk.StringVar(value=old_val)
        tk_new = tk.StringVar(value=new_val)
        ctk.CTkLabel(row, text="Old:").pack(side="left", padx=5)
        ctk.CTkEntry(row, textvariable=tk_old, width=200).pack(side="left", padx=5)
        ctk.CTkLabel(row, text=" -> ").pack(side="left")
        ctk.CTkEntry(row, textvariable=tk_new, width=200).pack(side="left", padx=5)
        self.rename_rows.append((tk_old, tk_new))

    def save_dim_renames(self):
        new_map = {}
        for (tk_old, tk_new) in self.rename_rows:
            oldv = tk_old.get().strip()
            newv = tk_new.get().strip()
            if oldv and newv and oldv != newv:
                new_map[oldv] = newv
        self.dim_rename_map = new_map
        messagebox.showinfo("Saved", "Dimension renames saved in memory.")

    @property
    def dim_rename_map(self) -> Dict[str,str]:
        return self.config_dict.get("dimension_renames", {})

    @dim_rename_map.setter
    def dim_rename_map(self, new_map: Dict[str,str]):
        self.config_dict["dimension_renames"] = new_map

    def build_compare_tab(self, parent):
        frm = ctk.CTkFrame(parent)
        frm.pack(fill="both", expand=True, padx=10, pady=10)

        self.mode_var = tk.IntVar(value=self.config_dict.get("comparison_option", 1))
        for i, label in enumerate([
            "Option 1 - Show everything missing in ERP or Master",
            "Option 2 - If Name missing, do not show attributes; else show missing attributes",
            "Option 3 - Show missing + matching (can be large)"
        ], start=1):
            ctk.CTkRadioButton(frm, text=label, variable=self.mode_var, value=i).pack(anchor="w", padx=5, pady=2)

        btnf = ctk.CTkFrame(frm)
        btnf.pack(fill="x", pady=10)
        ctk.CTkButton(btnf, text="Run Comparison", command=self.run_reconciliation).pack(side="left", padx=5)
        ctk.CTkButton(btnf, text="Save Config", command=self.save_all_config).pack(side="left", padx=5)

    def run_reconciliation(self):
        # update config paths
        self.config_dict["paths"]["ERP_EXCEL_PATH"] = self.erp_path_var.get().strip()
        self.config_dict["paths"]["MASTER_ZIP_PATH"] = self.master_path_var.get().strip()
        self.config_dict["paths"]["EXCEPTION_PATH"] = self.exc_path_var.get().strip()
        self.config_dict["paths"]["OUTPUT_PATH"] = self.out_path_var.get().strip()
        self.config_dict["paths"]["CONFIG_PATH"] = self.cfg_path_var.get().strip()

        self.config_dict["comparison_option"] = self.mode_var.get()
        mode = self.config_dict["comparison_option"]

        # meltdown ERP
        df_erp = self.erp_grid.get_filtered_df()
        erp_melt = meltdown_erp(df_erp, self.dim_rename_map)
        erp_ready = build_keys(erp_melt)

        # meltdown Master
        df_master_filtered = self.master_grid.get_filtered_df().copy()
        master_melt = meltdown_master(df_master_filtered, self.dim_rename_map)
        master_ready = build_keys(master_melt)

        # compare
        df_diff = compare_data(erp_ready, master_ready, mode)

        # exceptions
        exc_path = Path(self.exc_path_var.get().strip())
        df_exc = read_exception_table(exc_path)
        final = merge_exceptions(df_diff, df_exc)

        # write
        out_path = Path(self.out_path_var.get().strip())
        write_results(final, out_path, mode)

        # dashboard
        run_date = datetime.now().strftime("%Y-%m-%d")
        final["RunDate"] = run_date
        self.history_df = pd.concat([self.history_df, final], ignore_index=True)

        self.notebook.select(self.tab_dashboard)
        self.tab_dashboard.update_data(final, self.history_df)

        messagebox.showinfo("Done", f"Comparison for {run_date} complete! Results => {out_path}")

    def save_all_config(self):
        # ERP config
        self.config_dict["erp_grid"] = self.erp_grid.get_config_block()

        # Master config
        self.config_dict["master_grid"] = self.master_grid.get_config_block()

        # dimension renames
        self.config_dict["dimension_renames"] = self.dim_rename_map

        # paths
        self.config_dict["paths"]["ERP_EXCEL_PATH"] = self.erp_path_var.get().strip()
        self.config_dict["paths"]["MASTER_ZIP_PATH"] = self.master_path_var.get().strip()
        self.config_dict["paths"]["EXCEPTION_PATH"] = self.exc_path_var.get().strip()
        self.config_dict["paths"]["OUTPUT_PATH"] = self.out_path_var.get().strip()
        self.config_dict["paths"]["CONFIG_PATH"] = self.cfg_path_var.get().strip()

        self.config_dict["comparison_option"] = self.mode_var.get()
        save_config(self.config_dict, Path(self.cfg_path_var.get().strip()))
        messagebox.showinfo("Saved", "All config saved successfully.")

# ------------------------------------------------------------------------------
# 12) MAIN
# ------------------------------------------------------------------------------
def main():
    app = MainApp()
    app.mainloop()

if __name__ == "__main__":
    main()
