#!/usr/bin/env python3
"""
Ultra-Mega Reconciliation: Single-file with:
 - ERP & Master Previews (date filters on Start/End)
 - Compare Tab => missing_items.xlsx
 - AdvancedDashboard (8 mismatch charts) in the GUI
 - EnhancedPDFReport with professional styling
 - HistoryTab to browse JSON run files
 - On close, saves config + keeps JSON runs in HISTORY_PATH

Changes requested:
 - Keep the snippet logic for filtering Start/End Date columns in ERP/Master previews.
 - Remove date-range buttons/fields in the Dashboard (always "All Time" now).
 - Use the PDF's band-chart logic in the Dashboard chart (no scanning entire folder).
 - Auto-save config on close, preserving everything for next session.
"""

import os
import sys
import json
import math
import logging
import zipfile
import shutil
import io
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, Set, List

import tkinter as tk
from tkinter import ttk, filedialog, messagebox
import customtkinter as ctk

import pandas as pd
import numpy as np

import matplotlib
matplotlib.use("TkAgg")
import matplotlib.pyplot as plt
from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg, NavigationToolbar2Tk
from matplotlib.backends.backend_pdf import PdfPages

from openpyxl import Workbook
from openpyxl.styles import PatternFill, Font, Alignment

try:
    import chardet
except ImportError:
    chardet = None

logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")


# ----------------------------------------------------------------------------
# DEFAULT CONFIG & SAVE/LOAD
# ----------------------------------------------------------------------------
DEFAULT_PATHS = {
    "ERP_EXCEL_PATH": "data/ERP_Config.xlsx",
    "MASTER_ZIP_PATH": "data/Master_Config.zip",
    "EXCEPTION_PATH": "data/Exception_Table.xlsx",
    "OUTPUT_PATH": "output/missing_items.xlsx",
    "CONFIG_PATH": "config/ui_config.json",
    "PARAMETER_PATH": "data/parameters.xlsx",
    "MASTER_CSV_OUTPUT": "temp_master_csv",
    "PDF_EXPORT_PATH": "output/dashboard_report.pdf",
    "LOGO_PATH": "images/company_logo.png",
    "HISTORY_PATH": "history_runs"
}

def default_config() -> Dict:
    return {
        "paths": DEFAULT_PATHS.copy(),
        "erp_grid": {"filters": {}},
        "master_grid": {"filters": {}},
        "date_filters": {
            "start_date": (datetime.now()-timedelta(days=30)).strftime("%Y-%m-%d"),
            "end_date": datetime.now().strftime("%Y-%m-%d")
        },
        "dashboard": {
            "selected_dims": [],
            "selected_attrs": [],
            "top_n": 10,
            # We won't actually use these start_date/end_date in the Dashboard
            # because we removed date-range usage, but we'll keep them here
            # just to avoid breaking existing JSON config structures:
            "start_date": (datetime.now()-timedelta(days=30)).strftime("%Y-%m-%d"),
            "end_date": datetime.now().strftime("%Y-%m-%d")
        }
    }

def load_config(path: Path) -> Dict:
    if path.is_file():
        try:
            with open(path, "r", encoding="utf-8") as f:
                return json.load(f)
        except Exception as e:
            logging.warning(f"Could not load config => {e}")
    return default_config()

def save_config(cfg: Dict, path: Path):
    path.parent.mkdir(parents=True, exist_ok=True)
    try:
        # Convert any sets->lists in erp_grid
        if "erp_grid" in cfg and "filters" in cfg["erp_grid"]:
            newf = {}
            for col, svals in cfg["erp_grid"]["filters"].items():
                newf[col] = list(svals)
            cfg["erp_grid"]["filters"] = newf
        # Convert sets->lists in master_grid
        if "master_grid" in cfg and "filters" in cfg["master_grid"]:
            newf = {}
            for col, svals in cfg["master_grid"]["filters"].items():
                newf[col] = list(svals)
            cfg["master_grid"]["filters"] = newf

        with open(path, "w", encoding="utf-8") as f:
            json.dump(cfg, f, indent=2)
        logging.info(f"Saved config to {path}")
    except Exception as e:
        logging.error(f"Error saving config => {e}")


# ----------------------------------------------------------------------------
# TEXT LOGGER HANDLER
# ----------------------------------------------------------------------------
class TextHandler(logging.Handler):
    def __init__(self, widget: ctk.CTkTextbox):
        super().__init__()
        self.widget = widget
    def emit(self, record):
        msg = self.format(record) + "\n"
        self.widget.after(0, self._append, msg)
    def _append(self, msg):
        self.widget.configure(state="normal")
        self.widget.insert("end", msg)
        self.widget.see("end")
        self.widget.configure(state="disabled")


# ----------------------------------------------------------------------------
# READ PARAM (Excel with dimension & attribute mapping)
# ----------------------------------------------------------------------------
def read_param_file(path: Path) -> Dict[str, object]:
    param = {
        "dim_erp_keep": set(),
        "dim_erp_map": {},
        "dim_master_map": {},
        "attr_erp_map": {},
        "attr_master_map": {}
    }
    if not path.is_file():
        logging.warning(f"Param file not found => {path}")
        return param
    try:
        dim_df = pd.read_excel(path, sheet_name="Dimension Parameters")
        dim_df.columns = dim_df.columns.astype(str).str.strip()

        def s(x): return str(x).strip() if pd.notna(x) else ""

        for _, row in dim_df.iterrows():
            fn  = s(row.get("FileName", ""))
            vsc = s(row.get("V S C", ""))
            dim = s(row.get("Dimension", ""))
            ev  = s(row.get("ERP Values", ""))
            if ev.lower() == "x" and vsc and dim:
                param["dim_erp_keep"].add(vsc)
            if vsc and dim:
                param["dim_erp_map"][vsc] = dim
            if fn and dim and ev.lower() == "x":
                param["dim_master_map"][fn] = dim

        attr_df = pd.read_excel(path, sheet_name="Attribute Parameters")
        attr_df.columns = attr_df.columns.astype(str).str.strip()
        for _, row in attr_df.iterrows():
            e_orig = s(row.get("ERP Original Attributes", ""))
            m_orig = s(row.get("Master Original Attributes", ""))
            final_ = s(row.get("Attribute", ""))
            onoff  = s(row.get("On/Off", ""))
            if onoff.lower() == "x" and final_:
                if e_orig:
                    param["attr_erp_map"][e_orig] = final_
                if m_orig:
                    param["attr_master_map"][m_orig] = final_
        return param
    except Exception as e:
        logging.error(f"Error reading param file => {e}")
        return param


# ----------------------------------------------------------------------------
# ERP
# ----------------------------------------------------------------------------
def read_erp_excel(path: Path) -> pd.DataFrame:
    if not path.is_file():
        logging.warning(f"ERP Excel not found => {path}")
        return pd.DataFrame()
    try:
        df = pd.read_excel(path, skiprows=3)
        df.columns = df.columns.str.strip()
        if "Enabled_Flag" in df.columns:
            df = df[df["Enabled_Flag"] == "Enabled"]
        return df
    except Exception as e:
        logging.error(f"Error reading ERP => {e}")
        return pd.DataFrame()


# ----------------------------------------------------------------------------
# MASTER
# ----------------------------------------------------------------------------
def read_txt_2encodings(raw: bytes) -> pd.DataFrame:
    import io
    for enc in ["utf-8-sig","utf-16-le"]:
        try:
            buf = io.BytesIO(raw)
            df = pd.read_csv(buf, encoding=enc, on_bad_lines="skip", engine="python")
            df.dropna(how="all", axis=0, inplace=True)
            df.dropna(how="all", axis=1, inplace=True)
            df.columns = df.columns.astype(str).str.strip()
            logging.info(f"[read_txt_2encodings] success with {enc}, shape={df.shape}")
            return df
        except Exception as e:
            logging.debug(f"[read_txt_2encodings] fail with {enc} => {e}")
    logging.error("[read_txt_2encodings] cannot parse .txt => empty.")
    return pd.DataFrame()

def convert_master_txt_to_csv(zip_path: Path, out_dir: Path) -> List[Path]:
    if not zip_path.is_file():
        logging.warning(f"[Master] ZIP not found => {zip_path}")
        return []
    if out_dir.exists():
        shutil.rmtree(out_dir, ignore_errors=True)
    out_dir.mkdir(parents=True, exist_ok=True)
    csvs = []
    with zipfile.ZipFile(zip_path, "r") as z:
        txt_files = [f for f in z.namelist() if f.lower().endswith(".txt")]
        for txt_file in txt_files:
            base_name = os.path.basename(txt_file)
            if not base_name:
                continue
            try:
                with z.open(txt_file) as fo:
                    raw = fo.read()
                df = read_txt_2encodings(raw)
                if df.empty:
                    continue
                df["RawFileName"] = base_name
                if "Name" not in df.columns and len(df.columns) > 0:
                    first_col = df.columns[0]
                    df.rename(columns={first_col: "Name"}, inplace=True)
                out_csv = out_dir / (base_name.replace(".txt", ".csv"))
                df.to_csv(out_csv, index=False, encoding="utf-8")
                csvs.append(out_csv)
            except Exception as e:
                logging.error(f"[Master] error reading {txt_file} => {e}")
    return csvs

def unify_master_csvs(csvs: List[Path]) -> pd.DataFrame:
    frames = []
    for cp in csvs:
        if not cp.is_file():
            continue
        try:
            df = pd.read_csv(cp, encoding="utf-8", on_bad_lines="skip")
            df.columns = df.columns.str.strip()
            frames.append(df)
        except Exception as e:
            logging.error(f"[unify_master_csvs] reading {cp} => {e}")
    if frames:
        return pd.concat(frames, ignore_index=True)
    return pd.DataFrame()


# ----------------------------------------------------------------------------
# MELTDOWN
# ----------------------------------------------------------------------------
def meltdown_erp_for_preview(df: pd.DataFrame, param: Dict[str, object]) -> pd.DataFrame:
    if "V_S_C" not in df.columns:
        return pd.DataFrame()
    keep = param.get("dim_erp_keep", set())
    dmap = param.get("dim_erp_map", {})
    amap = param.get("attr_erp_map", {})

    df2 = df[df["V_S_C"].isin(keep)].copy()
    if df2.empty:
        return pd.DataFrame()

    skip_cols = {"V_S_C", "Enabled_Flag"}
    id_vars = []
    if "Value" in df2.columns:
        id_vars.append("Value")
        skip_cols.add("Value")
    df2["DimRaw"] = df2["V_S_C"]
    skip_cols.add("DimRaw")
    id_vars.insert(0, "DimRaw")

    meltdown_cols = [c for c in df2.columns if c not in skip_cols]
    melted = df2.melt(
        id_vars=id_vars,
        value_vars=meltdown_cols,
        var_name="OrigAttr",
        value_name="ValX"
    )

    def rename_dim(v):
        return dmap.get(v, v)
    melted["Dimension"] = melted["DimRaw"].apply(rename_dim)
    if "Value" in id_vars:
        melted.rename(columns={"Value": "Name"}, inplace=True)
    else:
        melted["Name"] = ""

    melted = melted[melted["OrigAttr"].isin(amap.keys())].copy()
    melted["Attribute"] = melted["OrigAttr"].map(amap)

    def strip_t(val):
        if isinstance(val, str) and "T" in val:
            return val.split("T")[0]
        return val
    melted["Value"] = np.where(
        melted["Attribute"].isin(["Start Date","End Date"]),
        melted["ValX"].apply(strip_t),
        melted["ValX"]
    )
    return melted[["Dimension","Name","Attribute","Value"]]

def meltdown_master_for_preview(df: pd.DataFrame, param: Dict[str, object]) -> pd.DataFrame:
    if df.empty or "RawFileName" not in df.columns:
        return pd.DataFrame()
    keep_map = param.get("dim_master_map", {})
    amap = param.get("attr_master_map", {})

    df2 = df[df["RawFileName"].isin(keep_map.keys())].copy()
    if df2.empty:
        return pd.DataFrame()

    df2["DimRaw"] = df2["RawFileName"]
    skip_cols = {"RawFileName", "DimRaw"}
    id_vars = ["DimRaw"]
    if "Name" in df2.columns:
        id_vars.append("Name")
        skip_cols.add("Name")

    meltdown_cols = [c for c in df2.columns if c not in skip_cols]
    melted = df2.melt(
        id_vars=id_vars,
        value_vars=meltdown_cols,
        var_name="OrigAttr",
        value_name="ValX"
    )

    def rename_dim(fn):
        return keep_map.get(fn, fn)
    melted["Dimension"] = melted["DimRaw"].apply(rename_dim)
    if "Name" in id_vars:
        melted.rename(columns={"Name": "Name"}, inplace=True)
    else:
        melted["Name"] = ""

    melted = melted[melted["OrigAttr"].isin(amap.keys())].copy()
    melted["Attribute"] = melted["OrigAttr"].map(amap)

    def strip_t(val):
        if isinstance(val,str) and "T" in val:
            return val.split("T")[0]
        return val
    melted["Value"] = np.where(
        melted["Attribute"].isin(["Start Date","End Date"]),
        melted["ValX"].apply(strip_t),
        melted["ValX"]
    )
    return melted[["Dimension","Name","Attribute","Value"]]

def pivot_for_preview(df: pd.DataFrame) -> pd.DataFrame:
    if not df.empty and {"Dimension","Name","Attribute"}.issubset(df.columns):
        df = df.drop_duplicates(subset=["Dimension","Name","Attribute"])
        try:
            df = df.pivot(
                index=["Dimension","Name"],
                columns="Attribute",
                values="Value"
            ).reset_index()
        except Exception as e:
            logging.error(f"Pivot error => {e}")
    return df


# ----------------------------------------------------------------------------
# COMPARE => meltdown => produce missing items
# ----------------------------------------------------------------------------
def melt_back(df: pd.DataFrame) -> pd.DataFrame:
    if df.empty or {"Dimension","Name"}.difference(df.columns):
        return pd.DataFrame()
    meltdown_cols = [c for c in df.columns if c not in ("Dimension","Name")]
    melted = df.melt(
        id_vars=["Dimension","Name"],
        value_vars=meltdown_cols,
        var_name="Attribute",
        value_name="Value"
    )
    return melted[["Dimension","Name","Attribute","Value"]]

def build_keys(df: pd.DataFrame)-> pd.DataFrame:
    df = df.copy()
    for c in ["Dimension","Name","Attribute","Value"]:
        if c not in df.columns:
            df[c] = ""
        df[c] = df[c].fillna("").astype(str).str.strip()
    df["GroupKey"] = df["Dimension"] + " | " + df["Name"]
    df["Key"] = df["Dimension"] + " | " + df["Name"] + " | " + df["Attribute"] + " | " + df["Value"]
    df["Comments_1"] = ""
    df["Comments_2"] = ""
    df["Action Item"] = ""
    df["Missing In"] = ""
    return df

def compare_mode2(df_erp: pd.DataFrame, df_mst: pd.DataFrame)-> pd.DataFrame:
    def to_dict(d):
        out={}
        for gk, grp in d.groupby("GroupKey"):
            rec={}
            nm= grp["Name"].iloc[0] if not grp.empty else ""
            rec["Name"] = nm
            for _, row in grp.iterrows():
                rec[row["Attribute"]] = row["Value"]
            out[gk] = rec
        return out

    e_dict = to_dict(df_erp)
    m_dict = to_dict(df_mst)
    all_gk = set(e_dict.keys()) | set(m_dict.keys())
    results=[]
    for gk in all_gk:
        dim = gk.split(" | ")[0]
        a_data= e_dict.get(gk,{})
        b_data= m_dict.get(gk,{})
        name_a= a_data.get("Name","")
        name_b= b_data.get("Name","")
        if name_a and name_b and name_a==name_b:
            union_attrs= (set(a_data.keys()) | set(b_data.keys())) - {"Name"}
            for at in union_attrs:
                va= a_data.get(at,"")
                vb= b_data.get(at,"")
                if va!=vb:
                    if va and not vb:
                        results.append({"Dimension": dim, "Name": name_a,"Attribute": at,"Value": va,"Missing In":"MASTER"})
                    elif vb and not va:
                        results.append({"Dimension": dim,"Name": name_a,"Attribute": at,"Value": vb,"Missing In":"ERP"})
                    else:
                        results.append({"Dimension": dim,"Name": name_a,"Attribute": at,"Value": va,"Missing In":"MASTER"})
                        results.append({"Dimension": dim,"Name": name_a,"Attribute": at,"Value": vb,"Missing In":"ERP"})
        else:
            if name_a and not name_b:
                results.append({"Dimension": dim,"Name": name_a,"Attribute":"Name","Value":name_a,"Missing In":"MASTER"})
            elif name_b and not name_a:
                results.append({"Dimension": dim,"Name": name_b,"Attribute":"Name","Value":name_b,"Missing In":"ERP"})
    df_res= pd.DataFrame(results)
    if not df_res.empty:
        df_res["Key"] = (df_res["Dimension"].str.strip()+" | "+
                         df_res["Name"].str.strip()+" | "+
                         df_res["Attribute"].str.strip()+" | "+
                         df_res["Value"].str.strip())
    return df_res

def read_exception_table(path: Path)-> pd.DataFrame:
    if not path.is_file():
        logging.warning(f"Exception table not found => {path}")
        return pd.DataFrame()
    try:
        df = pd.read_excel(path)
        df.columns = df.columns.astype(str).str.strip()
        return df
    except Exception as e:
        logging.error(f"Error reading exception => {e}")
        return pd.DataFrame()

def merge_exceptions(df: pd.DataFrame, df_exc: pd.DataFrame)-> pd.DataFrame:
    if df.empty or df_exc.empty or "Key" not in df.columns:
        return df
    keep = [c for c in ["Key","Comments_1","Comments_2","hide exception"] if c in df_exc.columns]
    if not keep:
        return df
    exc= df_exc[keep].copy()
    exc["Key"]= exc["Key"].astype(str).str.strip()
    merged= df.merge(exc, on="Key", how="left", suffixes=("","_exc"))
    merged["hide exception"] = merged.get("hide exception","").fillna("").str.lower()
    final= merged[merged["hide exception"]!="yes"].copy()
    if "Comments_1_exc" in final.columns:
        final["Comments_1"]= np.where(final["Comments_1_exc"].notna(), final["Comments_1_exc"], final["Comments_1"])
        final.drop(columns=["Comments_1_exc"], inplace=True)
    if "Comments_2_exc" in final.columns:
        final["Comments_2"]= np.where(final["Comments_2_exc"].notna(), final["Comments_2_exc"], final["Comments_2"])
        final.drop(columns=["Comments_2_exc"], inplace=True)
    if "hide exception" in final.columns:
        final.drop(columns=["hide exception"], inplace=True)
    return final

def write_missing_items(df: pd.DataFrame, out_path: Path):
    if df.empty:
        logging.info("No missing items => skip writing.")
        return
    out_path.parent.mkdir(parents=True, exist_ok=True)
    final_cols= ["Key","Dimension","Name","Attribute","Value","Comments_1","Comments_2","Action Item","Missing In"]
    for c in final_cols:
        if c not in df.columns:
            df[c] = ""
    df = df[final_cols]
    wb = Workbook()
    ws = wb.active
    ws.title = "Missing Items"
    ws.append(final_cols)
    for rowvals in df.itertuples(index=False):
        ws.append(rowvals)
    header_font = Font(bold=True)
    fill = PatternFill(start_color="DDDDDD", end_color="DDDDDD", fill_type="solid")
    for cell in ws[1]:
        cell.font = header_font
        cell.fill = fill
        cell.alignment= Alignment(horizontal="center")

    for col in ws.columns:
        max_len= 0
        letter= col[0].column_letter
        for cell in col:
            val= str(cell.value) if cell.value else ""
            max_len= max(max_len, len(val))
        ws.column_dimensions[letter].width= max_len+2
    ws.freeze_panes= "A2"
    wb.save(out_path)
    logging.info(f"Missing items => {out_path}")


# ----------------------------------------------------------------------------
# SIMPLE PREVIEW (for ERP & Master) w/ Start/End Date filters
# ----------------------------------------------------------------------------
class SimplePreview(ctk.CTkFrame):
    FILTERABLE= {"Start Date","End Date"}

    def __init__(self, parent, name: str, filters_dict=None):
        super().__init__(parent)
        self.name= name
        self.df= pd.DataFrame()
        self.filters: Dict[str, Set]= {}
        if filters_dict:
            for col, val_list in filters_dict.items():
                if isinstance(val_list, list):
                    self.filters[col] = set(val_list)
                else:
                    self.filters[col] = val_list

        self.create_toolbar()
        self.create_table()
        self.create_statusbar()

    def create_toolbar(self):
        bar= ctk.CTkFrame(self, corner_radius=10, fg_color="#f0f0f0")
        bar.pack(fill="x", padx=5, pady=5)
        ctk.CTkLabel(
            bar, text=f"{self.name} Preview",
            fg_color="#800020", corner_radius=8,
            text_color="white",
            font=ctk.CTkFont(size=14, weight="bold")
        ).pack(side="left", padx=5)

        ctk.CTkButton(
            bar, text="ⓘ", width=30, command=self.show_info,
            fg_color="#800020", hover_color="#a52a2a", text_color="white"
        ).pack(side="left", padx=5)

        ctk.CTkButton(
            bar, text="Clear Date Filters", command=self.clear_filters,
            fg_color="#800020", hover_color="#a52a2a", text_color="white"
        ).pack(side="left", padx=5)

    def show_info(self):
        messagebox.showinfo(
            "Info",
            f"{self.name} meltdown data.\nOnly Start/End Date columns are filterable."
        )

    def create_table(self):
        container= ctk.CTkFrame(self)
        container.pack(fill="both", expand=True, padx=5, pady=5)
        self.tree= ttk.Treeview(container, show="headings")
        vsb= ttk.Scrollbar(container, orient="vertical", command=self.tree.yview)
        hsb= ttk.Scrollbar(container, orient="horizontal", command=self.tree.xview)
        self.tree.configure(yscrollcommand=vsb.set, xscrollcommand=hsb.set)
        self.tree.grid(row=0, column=0, sticky="nsew")
        vsb.grid(row=0, column=1, sticky="ns")
        hsb.grid(row=1, column=0, sticky="ew")
        container.rowconfigure(0,weight=1)
        container.columnconfigure(0,weight=1)

    def create_statusbar(self):
        self.status_label= ctk.CTkLabel(self, text="0 rows", fg_color="#f0f0f0", text_color="black")
        self.status_label.pack(fill="x")

    def set_data(self, df: pd.DataFrame):
        self.df= df.copy()
        self.refresh_table()

    def refresh_table(self):
        for i in self.tree.get_children():
            self.tree.delete(i)
        if self.df.empty:
            self.tree["columns"]=[]
            self.status_label.configure(text="0 rows")
            return

        cols= list(self.df.columns)
        self.tree["columns"]= cols
        for c in cols:
            self.tree.heading(
                c, text=c, anchor="w",
                command=lambda col=c: self.on_heading_click(col)
            )
            self.tree.column(c, anchor="w", width=150)

        df_f= self.apply_filters()
        for _, row in df_f.iterrows():
            rowvals= [row[c] for c in cols]
            self.tree.insert("", "end", values=rowvals)
        self.status_label.configure(text=f"{len(df_f)} rows")

    def apply_filters(self)-> pd.DataFrame:
        df_f= self.df.copy()
        # For Start/End date columns, we only filter on exact matches
        for col, allowed in self.filters.items():
            if col in df_f.columns and len(allowed)>0:
                # allow blanks/NaN if user didn't unselect them
                df_f= df_f[df_f[col].isin(allowed) | df_f[col].isna()]
        return df_f

    def on_heading_click(self, col_name: str):
        if col_name in self.FILTERABLE:
            self.show_filter_popup(col_name)

    def show_filter_popup(self, col_name: str):
        if self.df.empty or col_name not in self.df.columns:
            return
        popup= tk.Toplevel(self)
        popup.title(f"Filter: {col_name}")
        popup.geometry("300x400")

        frame= ctk.CTkFrame(popup)
        frame.pack(fill="both", expand=True, padx=5, pady=5)

        unique_vals= self.df[col_name].unique()
        display_map={}
        for v in unique_vals:
            if pd.isna(v):
                dsp= "(NaN)"
            elif isinstance(v,str) and not v.strip():
                dsp= "(blank)"
            else:
                dsp= str(v)
            display_map[v]= dsp

        sorted_vals= sorted(display_map.keys(), key=lambda x: display_map[x].lower())
        all_vals= set(sorted_vals)
        curr_filter= self.filters.get(col_name, all_vals)

        selall_var= tk.BooleanVar(value=True)
        def toggle_all():
            check= selall_var.get()
            for vb in var_dict.values():
                vb.set(check)

        ctk.CTkCheckBox(
            frame, text="Select All", variable=selall_var, command=toggle_all,
            fg_color="#800020", hover_color="#a52a2a", text_color="black"
        ).pack(anchor="w", pady=5)

        scroll= ctk.CTkScrollableFrame(frame, width=250, height=250)
        scroll.pack(fill="both", expand=True, padx=5, pady=5)
        var_dict= {}
        for rv in sorted_vals:
            in_filter= rv in curr_filter
            bvar= tk.BooleanVar(value=in_filter)
            var_dict[rv]= bvar
            ctk.CTkCheckBox(
                scroll, text=display_map[rv], variable=bvar,
                fg_color="#800020", hover_color="#a52a2a", text_color="black"
            ).pack(anchor="w")

        def apply_():
            sel= {rv for rv,vb in var_dict.items() if vb.get()}
            if sel==all_vals or not sel:
                if col_name in self.filters:
                    del self.filters[col_name]
            else:
                self.filters[col_name]= sel
            popup.destroy()
            self.refresh_table()

        bf= ctk.CTkFrame(frame)
        bf.pack(fill="x", pady=5)
        ctk.CTkButton(
            bf, text="Apply", command=apply_,
            fg_color="#800020", hover_color="#a52a2a", text_color="white"
        ).pack(side="left", padx=5)
        ctk.CTkButton(
            bf, text="Cancel", command=popup.destroy,
            fg_color="#800020", hover_color="#a52a2a", text_color="white"
        ).pack(side="left", padx=5)

    def clear_filters(self):
        remove_keys=[]
        for k in self.filters:
            if k in self.FILTERABLE:
                remove_keys.append(k)
        for rk in remove_keys:
            del self.filters[rk]
        self.refresh_table()

    def get_filtered_df(self)-> pd.DataFrame:
        return self.apply_filters()


# ----------------------------------------------------------------------------
# PDF REPORT
# ----------------------------------------------------------------------------
class EnhancedPDFReport:
    """
    PDF: separate from GUI charts; uses LOGO_PATH from config for the logo.
    """
    def __init__(self, df_current: pd.DataFrame, df_history: pd.DataFrame, config: Dict):
        self.df_current = df_current
        self.df_history = df_history
        self.config = config

        self.page_count = 0
        self.colors = {
            'primary': '#800020',
            'text': '#2C1810',
            'background': '#FFFFFF'
        }
        self.logo_path = self.config["paths"].get("LOGO_PATH","images/company_logo.png")

        self.PAGE_WIDTH = 8.5
        self.PAGE_HEIGHT= 11
        self.CHART_SCALE = 0.7

    def generate(self) -> Path:
        pdf_path= self._get_output_path()
        with PdfPages(pdf_path) as pdf:
            self._cover_page(pdf)
            self._summary_page(pdf)
            self._topdimsattrs_page(pdf)
            self._all_charts(pdf)
        logging.info(f"PDF => {pdf_path}")
        return pdf_path

    def _get_output_path(self)-> Path:
        stamp= datetime.now().strftime("%Y%m%d_%H%M%S")
        pdf_dir= Path("Reconciliation_pdf")
        pdf_dir.mkdir(parents=True, exist_ok=True)
        pdf_name= f"Reconciliationpdf_{stamp}.pdf"
        pdf_path= pdf_dir / pdf_name
        return pdf_path

    def _new_page(self)-> plt.Figure:
        self.page_count += 1
        fig= plt.figure(figsize=(self.PAGE_WIDTH,self.PAGE_HEIGHT))
        fig.patch.set_facecolor(self.colors['background'])
        plt.axis('off')
        # Light "watermark" logo
        if self.logo_path and os.path.exists(self.logo_path):
            try:
                import matplotlib.image as mpimg
                img= mpimg.imread(self.logo_path)
                ax_img= fig.add_axes([0.65,0.65, 0.25, 0.25], anchor='NE', zorder=10)
                ax_img.imshow(img, alpha=0.2)
                ax_img.axis('off')
            except Exception as e:
                logging.error(f"Logo => {e}")

        fig.text(0.5, 0.97, "Reconciliation Report", ha='center', fontsize=10, color='gray')
        fig.text(0.9, 0.03, f"Page {self.page_count}", ha='right', fontsize=8, color='gray')
        fig.text(0.5, 0.02, "© Ultra-Mega Reconciliation", ha='center', fontsize=8, color='gray')
        return fig

    def _cover_page(self, pdf: PdfPages):
        fig= self._new_page()
        plt.text(0.5, 0.7, "Reconciliation Analysis Report",
                 ha='center', fontsize=24, fontweight='bold', color=self.colors['primary'],
                 transform=fig.transFigure)
        plt.text(0.5, 0.6, f"Generated on {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
                 ha='center', fontsize=12, color=self.colors['text'], transform=fig.transFigure)
        plt.text(0.5, 0.1, "CONFIDENTIAL", ha='center', fontsize=9, color=self.colors['text'],
                 transform=fig.transFigure)
        pdf.savefig(fig)
        plt.close(fig)

    def _summary_page(self, pdf: PdfPages):
        fig= self._new_page()
        plt.text(0.5, 0.92, "Reconciliation Summary", ha='center', fontsize=18, fontweight='bold',
                 color=self.colors['primary'], transform=fig.transFigure)
        y= 0.75
        if self.df_current.empty:
            plt.text(0.5, y, "No mismatches found this run.",
                     ha='center', fontsize=14, color=self.colors['text'], transform=fig.transFigure)
        else:
            total= len(self.df_current)
            e= (self.df_current["Missing In"]=="ERP").sum()
            m= (self.df_current["Missing In"]=="MASTER").sum()
            summary= (
                f"Total Mismatches: {total}\n"
                f"Missing in ERP: {e}\n"
                f"Missing in Master: {m}"
            )
            plt.text(0.5, y, summary, ha='center', fontsize=14, color=self.colors['text'],
                     transform=fig.transFigure)
        pdf.savefig(fig)
        plt.close(fig)

    def _topdimsattrs_page(self, pdf: PdfPages):
        fig= self._new_page()
        plt.text(0.5, 0.92, "Top Dimensions & Attributes", ha='center', fontsize=18, fontweight='bold',
                 color=self.colors['primary'], transform=fig.transFigure)
        if self.df_current.empty:
            plt.text(0.5, 0.7, "No data available.", ha='center', fontsize=12, color=self.colors['text'],
                     transform=fig.transFigure)
        else:
            if "Dimension" in self.df_current.columns:
                dims= self.df_current["Dimension"].value_counts().head(5)
                lines= [f"- {k} ({v})" for k,v in dims.items()]
                dim_txt= "Top Dimensions:\n" + "\n".join(lines)
                plt.text(0.2, 0.7, dim_txt, fontsize=12, color=self.colors['text'],
                         transform=fig.transFigure)
            if "Attribute" in self.df_current.columns:
                attrs= self.df_current["Attribute"].value_counts().head(5)
                lines= [f"- {k} ({v})" for k,v in attrs.items()]
                attr_txt= "Top Attributes:\n" + "\n".join(lines)
                plt.text(0.6, 0.7, attr_txt, fontsize=12, color=self.colors['text'],
                         transform=fig.transFigure)
        pdf.savefig(fig)
        plt.close(fig)

    def _chart_page(self, pdf: PdfPages, title: str, plot_func, **kwargs):
        fig= self._new_page()
        fig.suptitle(title, fontsize=14, fontweight='bold', color=self.colors['primary'], y=0.93)

        w_inch= self.PAGE_WIDTH * self.CHART_SCALE
        if "Heatmap" in title:
            h_inch= w_inch * 1.4
            left_margin= (self.PAGE_WIDTH - w_inch)*0.5 + 0.4
        else:
            h_inch= w_inch * (9.0/16.0)
            left_margin= (self.PAGE_WIDTH - w_inch)*0.5 + 0.2

        bottom_margin= (self.PAGE_HEIGHT - h_inch)*0.5
        left_rel= left_margin / self.PAGE_WIDTH
        bottom_rel= bottom_margin / self.PAGE_HEIGHT
        width_rel= w_inch / self.PAGE_WIDTH
        height_rel= h_inch / self.PAGE_HEIGHT

        ax_rect= [left_rel, bottom_rel, width_rel, height_rel]
        ax= fig.add_axes(ax_rect)

        try:
            plot_func(ax, **kwargs)
            pdf.savefig(fig)
        except Exception as e:
            logging.error(f"{title} => {e}")
        finally:
            plt.close(fig)

    def _all_charts(self, pdf: PdfPages):
        dfc= self.df_current.copy()
        if dfc.empty:
            return
        df_m= dfc[dfc["Missing In"]!=""]

        # Heatmap
        if not df_m.empty and {"Dimension","Attribute"}.issubset(df_m.columns):
            pivot= df_m.groupby(["Dimension","Attribute"]).size().unstack(fill_value=0)
            if not pivot.empty:
                self._chart_page(pdf, "Heatmap", self._plot_heatmap, pivot=pivot)

        # Lollipop
        cdim= df_m.groupby("Dimension")["Key"].count().sort_values(ascending=False).head(10)
        if not cdim.empty:
            self._chart_page(pdf, "Lollipop", self._plot_lollipop, cdim=cdim)

        # Circular
        cattr= df_m.groupby("Attribute")["Key"].count().sort_values(ascending=False).head(10)
        if not cattr.empty:
            self._chart_page(pdf, "Circular", self._plot_circular, cattr=cattr)

        # Scatter
        cdim_sc= df_m.groupby("Dimension")["Key"].count().reset_index(name="Count")
        cdim_sc.sort_values("Count", ascending=False, inplace=True)
        cdim_sc= cdim_sc.head(10)
        if not cdim_sc.empty:
            self._chart_page(pdf, "Scatter", self._plot_scatter, cdim=cdim_sc)

        # Radar
        cdim_ra= df_m.groupby("Dimension")["Key"].count().sort_values(ascending=False).head(10)
        if not cdim_ra.empty and len(cdim_ra)>1:
            self._chart_page(pdf, "Radar", self._plot_radar, cdim=cdim_ra)

        # Pie
        dist= df_m["Missing In"].value_counts()
        if not dist.empty:
            self._chart_page(pdf, "Pie: Missing In distribution", self._plot_pie, dist=dist)

        # Bar
        cattr_b= df_m.groupby("Attribute")["Key"].count().sort_values(ascending=False).head(10)
        if not cattr_b.empty:
            self._chart_page(pdf, "Bar: Missing attributes", self._plot_bar, cattr=cattr_b)

        # Band Chart (using the PDF's logic on self.df_history)
        if not self.df_history.empty and "RunDate" in self.df_history.columns:
            date_ct= self.df_history.groupby("RunDate")["Key"].count().reset_index(name="Count")
            date_ct.sort_values("RunDate", inplace=True)
            if not date_ct.empty:
                self._chart_page(pdf, "Band Chart Over Time", self._plot_bandchart, date_ct=date_ct)

    # PDF chart helper methods
    def _plot_heatmap(self, ax, pivot):
        im= ax.imshow(pivot, aspect="auto", cmap="Reds")
        ax.set_xticks(range(len(pivot.columns)))
        ax.set_xticklabels(pivot.columns, rotation=45, ha="right")
        ax.set_yticks(range(len(pivot.index)))
        ax.set_yticklabels(pivot.index)
        plt.colorbar(im, ax=ax)

    def _plot_lollipop(self, ax, cdim):
        ax.hlines(y=cdim.index, xmin=0, xmax=cdim.values, color="skyblue")
        ax.plot(cdim.values, cdim.index, "o", color="skyblue")
        ax.set_xlabel("Missing Count")

    def _plot_circular(self, ax, cattr):
        angles= np.linspace(0, 2*np.pi, len(cattr), endpoint=False)
        ax.set_theta_offset(np.pi/2)
        ax.set_theta_direction(-1)
        ax.set_xticks(angles)
        ax.set_xticklabels(cattr.index, fontsize=9)
        ax.bar(angles, cattr.values, width=0.4, color="orange", alpha=0.6)

    def _plot_scatter(self, ax, cdim):
        xvals= np.arange(len(cdim))
        yvals= cdim["Count"].values
        ax.scatter(xvals, yvals, color="green")
        for i, row in cdim.iterrows():
            ax.text(xvals[i], yvals[i], row["Dimension"], ha="center", va="bottom", rotation=60, fontsize=8)
        ax.set_xticks([])
        ax.set_ylabel("Missing Count")

    def _plot_radar(self, ax, cdim):
        cat= cdim.index.tolist()
        val= cdim.values.tolist()
        angles= np.linspace(0, 2*np.pi, len(cat), endpoint=False).tolist()
        angles+= angles[:1]
        val+= val[:1]
        ax.set_theta_offset(np.pi/2)
        ax.set_theta_direction(-1)
        ax.set_xticks(angles[:-1])
        ax.set_xticklabels(cat, fontsize=9)
        ax.plot(angles, val, color="red", linewidth=2)
        ax.fill(angles, val, color="red", alpha=0.3)

    def _plot_pie(self, ax, dist):
        ax.pie(dist.values, labels=dist.index, autopct="%.1f%%", startangle=140)

    def _plot_bar(self, ax, cattr):
        bars= ax.bar(range(len(cattr)), cattr.values, color="blue")
        ax.set_xticks(range(len(cattr)))
        ax.set_xticklabels(cattr.index, rotation=45, ha="right", fontsize=8)
        ax.set_ylabel("Missing Count")
        for bar in bars:
            h= bar.get_height()
            ax.text(bar.get_x()+ bar.get_width()/2., h, f"{int(h)}", ha="center", va="bottom")

    def _plot_bandchart(self, ax, date_ct):
        date_ct["Count_min"]= date_ct["Count"]*0.9
        date_ct["Count_max"]= date_ct["Count"]*1.1
        ax.plot(date_ct["RunDate"], date_ct["Count"], color="purple", marker="o", label="Missing Count")
        ax.fill_between(date_ct["RunDate"], date_ct["Count_min"], date_ct["Count_max"],
                        color="purple", alpha=0.2, label="±10% band")
        ax.set_xlabel("RunDate")
        ax.set_ylabel("Missing Count")
        plt.xticks(rotation=45)
        ax.legend()
        for i,rowv in date_ct.iterrows():
            ax.text(rowv["RunDate"], rowv["Count"], str(rowv["Count"]), ha="center", va="bottom", fontsize=8)


# ----------------------------------------------------------------------------
# ADVANCED DASHBOARD (GUI CHARTS) 
# ----------------------------------------------------------------------------
class AdvancedDashboard(ctk.CTkFrame):
    """
    8 mismatch charts for the GUI, simplified to remove date-range
    filtering. We default to "All Time."
    Band Chart logic now uses self.df_history directly (PDF style).
    """
    def __init__(self, parent, dashboard_cfg: Dict):
        super().__init__(parent)
        # We still store dimension/attribute filter sets,
        # but we remove the date-based stuff from the GUI.
        self.selected_dims: Set[str] = set(dashboard_cfg.get("selected_dims", []))
        self.selected_attrs: Set[str] = set(dashboard_cfg.get("selected_attrs", []))
        self.top_n= dashboard_cfg.get("top_n", 10)

        self.df_current= pd.DataFrame()
        self.df_history= pd.DataFrame()

        # Top bar for dimension/attribute filter & toggle
        self.topbar= ctk.CTkScrollableFrame(self, orientation="horizontal", height=60)
        self.topbar.pack(fill="x", pady=5)
        self.metric_label= ctk.CTkLabel(self.topbar, text="Metrics: 0 missing, 0 dimension", width=300)
        self.metric_label.pack(side="left", padx=5)

        ctk.CTkButton(
            self.topbar, text="Filter Dimension", command=self.show_dimension_filter,
            fg_color="#800020", hover_color="#a52a2a", text_color="white"
        ).pack(side="left", padx=5)

        ctk.CTkButton(
            self.topbar, text="Filter Attribute", command=self.show_attribute_filter,
            fg_color="#800020", hover_color="#a52a2a", text_color="white"
        ).pack(side="left", padx=5)

        # Removed last 7/30/90 days buttons and timeline entry. # <-- REMOVED
        # Always "All Time."

        ctk.CTkButton(
            self.topbar, text="Toggle Top 10 / All", command=self.toggle_top_n,
            fg_color="#800020", hover_color="#a52a2a", text_color="white"
        ).pack(side="left", padx=5)

        # Notebook with 8 chart tabs
        self.notebook= ttk.Notebook(self)
        self.notebook.pack(fill="both", expand=True)
        self.frames= {}
        chart_names= ["Heatmap","Lollipop","Circular","Scatter","Radar","Normal Pie","Normal Bar","Band Chart"]
        for lbl in chart_names:
            fr= ctk.CTkFrame(self.notebook)
            fr.pack(fill="both", expand=True)
            self.notebook.add(fr, text=lbl)
            self.frames[lbl]= fr

    def toggle_top_n(self):
        if self.top_n==10:
            self.top_n= None
        else:
            self.top_n= 10
        self.update_data_filters()

    def show_dimension_filter(self):
        self.show_filter_popup("Dimension")

    def show_attribute_filter(self):
        self.show_filter_popup("Attribute")

    def show_filter_popup(self, col: str):
        base_df= self.df_history if not self.df_history.empty else self.df_current
        if base_df.empty or col not in base_df.columns:
            return
        popup= tk.Toplevel(self)
        popup.title(f"Filter: {col}")
        popup.geometry("300x400")
        frame= ctk.CTkFrame(popup)
        frame.pack(fill="both", expand=True, padx=5, pady=5)

        unique_vals= base_df[col].unique()
        display_map={}
        for v in unique_vals:
            if pd.isna(v):
                dsp= "(NaN)"
            elif isinstance(v,str) and not v.strip():
                dsp= "(blank)"
            else:
                dsp= str(v)
            display_map[v]= dsp
        sorted_vals= sorted(display_map.keys(), key=lambda x: display_map[x].lower())

        if col=="Dimension":
            curr= self.selected_dims
        else:
            curr= self.selected_attrs
        if not curr:
            curr= set(unique_vals)

        selall_var= tk.BooleanVar(value=True)
        def toggle_all():
            check= selall_var.get()
            for vb in var_dict.values():
                vb.set(check)

        ctk.CTkCheckBox(
            frame, text="Select All", variable=selall_var, command=toggle_all,
            fg_color="#800020", hover_color="#a52a2a", text_color="black"
        ).pack(anchor="w", pady=5)

        scroll= ctk.CTkScrollableFrame(frame, width=250, height=250)
        scroll.pack(fill="both", expand=True, padx=5, pady=5)
        var_dict={}
        for rv in sorted_vals:
            in_filter= rv in curr
            bvar= tk.BooleanVar(value=in_filter)
            var_dict[rv]= bvar
            ctk.CTkCheckBox(
                scroll, text=display_map[rv], variable=bvar,
                fg_color="#800020", hover_color="#a52a2a", text_color="black"
            ).pack(anchor="w")

        def apply_():
            sel= {rv for rv,vb in var_dict.items() if vb.get()}
            if col=="Dimension":
                self.selected_dims= sel
            else:
                self.selected_attrs= sel
            popup.destroy()
            self.update_data_filters()

        bf= ctk.CTkFrame(frame)
        bf.pack(fill="x", pady=5)
        ctk.CTkButton(
            bf, text="Apply", command=apply_,
            fg_color="#800020", hover_color="#a52a2a", text_color="white"
        ).pack(side="left", padx=5)
        ctk.CTkButton(
            bf, text="Cancel", command=popup.destroy,
            fg_color="#800020", hover_color="#a52a2a", text_color="white"
        ).pack(side="left", padx=5)

    def update_data(self, df_current: pd.DataFrame, df_history: pd.DataFrame):
        """
        Called when new mismatch data is generated (the 'final' from run_comparison).
        Also receives self.history_df with everything appended
        so we can do dimension filters on it.
        """
        self.df_current= df_current.copy()
        self.df_history= df_history.copy()
        self.update_data_filters()

    def update_data_filters(self):
        # We do dimension/attribute filtering only
        dfc= self.df_current.copy()
        if not dfc.empty:
            if self.selected_dims:
                dfc= dfc[dfc["Dimension"].isin(self.selected_dims)]
            if self.selected_attrs:
                dfc= dfc[dfc["Attribute"].isin(self.selected_attrs)]

        # Display some basic metrics in top bar
        mism= len(dfc)
        dims= dfc["Dimension"].nunique() if not dfc.empty and "Dimension" in dfc.columns else 0
        self.metric_label.configure(text=f"Mismatches: {mism}, Dims: {dims}")

        # Re-plot all 8 GUI charts
        self.plotHeatmap(dfc)
        self.plotLollipop(dfc)
        self.plotCircular(dfc)
        self.plotScatter(dfc)
        self.plotRadar(dfc)
        self.plotNormalPie(dfc)
        self.plotNormalBar(dfc)
        self.plotBandChart()

    def plot_chart(self, frame, fig):
        for w in frame.winfo_children():
            w.destroy()

        canvas= FigureCanvasTkAgg(fig, master=frame)
        canvas.draw()

        toolbar_frame= ctk.CTkFrame(frame)
        toolbar_frame.pack(side="top", fill="x")
        toolbar= NavigationToolbar2Tk(canvas, toolbar_frame)
        toolbar.update()

        canvas.get_tk_widget().pack(fill="both", expand=True)
        plt.close(fig)

    def _limit_if_needed(self, series: pd.Series)-> pd.Series:
        if self.top_n==10:
            return series.head(10)
        else:
            return series

    def plotHeatmap(self, dfc: pd.DataFrame):
        fr= self.frames["Heatmap"]
        for w in fr.winfo_children():
            w.destroy()
        if dfc.empty or "Missing In" not in dfc.columns:
            return
        df_m= dfc[dfc["Missing In"]!=""]
        if df_m.empty or not {"Dimension","Attribute"}.issubset(df_m.columns):
            return
        pivot= df_m.groupby(["Dimension","Attribute"]).size().unstack(fill_value=0)
        if pivot.empty:
            return
        fig, ax= plt.subplots(figsize=(6,5))
        try:
            cax= ax.imshow(pivot, aspect="auto", cmap="Reds")
            ax.set_xticks(range(len(pivot.columns)))
            ax.set_xticklabels(pivot.columns, rotation=90)
            ax.set_yticks(range(len(pivot.index)))
            ax.set_yticklabels(pivot.index)
            fig.colorbar(cax, ax=ax)
            ax.set_title("Heatmap: Missing Items")
            self.plot_chart(fr, fig)
        except IndexError as e:
            logging.error(f"Heatmap => IndexError => {e}")

    def plotLollipop(self, dfc: pd.DataFrame):
        fr= self.frames["Lollipop"]
        for w in fr.winfo_children():
            w.destroy()
        if dfc.empty or "Missing In" not in dfc.columns:
            return
        df_m= dfc[dfc["Missing In"]!=""]
        if df_m.empty:
            return
        cdim= df_m.groupby("Dimension")["Key"].count().sort_values(ascending=False)
        cdim= self._limit_if_needed(cdim)
        if cdim.empty:
            return
        fig, ax= plt.subplots(figsize=(6,5))
        try:
            ax.hlines(y= cdim.index, xmin=0, xmax=cdim.values, color="skyblue")
            ax.plot(cdim.values, cdim.index, "o", color="skyblue")
            ax.set_title("Lollipop: Missing by Dimension")
            ax.set_xlabel("Count")
            self.plot_chart(fr, fig)
        except IndexError as e:
            logging.error(f"Lollipop => IndexError => {e}")

    def plotCircular(self, dfc: pd.DataFrame):
        fr= self.frames["Circular"]
        for w in fr.winfo_children():
            w.destroy()
        if dfc.empty or "Missing In" not in dfc.columns:
            return
        df_m= dfc[dfc["Missing In"]!=""]
        if df_m.empty:
            return
        cattr= df_m.groupby("Attribute")["Key"].count().sort_values(ascending=False)
        cattr= self._limit_if_needed(cattr)
        if cattr.empty:
            return
        cat= cattr.index.tolist()
        val= cattr.values
        fig= plt.figure(figsize=(6,6))
        try:
            ax= fig.add_subplot(111, polar=True)
            angles= np.linspace(0, 2*np.pi, len(cat), endpoint=False)
            ax.set_theta_offset(np.pi/2)
            ax.set_theta_direction(-1)
            ax.set_xticks(angles)
            ax.set_xticklabels(cat, fontsize=9)
            ax.bar(angles, val, width=0.4, color="orange", alpha=0.6)
            ax.set_title("Circular: Missing Attributes")
            self.plot_chart(fr, fig)
        except IndexError as e:
            logging.error(f"Circular => IndexError => {e}")

    def plotScatter(self, dfc: pd.DataFrame):
        fr= self.frames["Scatter"]
        for w in fr.winfo_children():
            w.destroy()
        if dfc.empty or "Missing In" not in dfc.columns:
            return
        df_m= dfc[dfc["Missing In"]!=""]
        if df_m.empty:
            return
        cdim= df_m.groupby("Dimension")["Key"].count().reset_index(name="Count")
        cdim.sort_values("Count", ascending=False, inplace=True)
        if self.top_n==10:
            cdim= cdim.head(10)
        if cdim.empty:
            return
        fig, ax= plt.subplots(figsize=(6,5))
        try:
            xvals= np.arange(len(cdim))
            yvals= cdim["Count"].values
            labels= cdim["Dimension"].values
            ax.scatter(xvals,yvals,color="green")
            for i, txt in enumerate(labels):
                ax.text(xvals[i], yvals[i], txt, ha="center", va="bottom", rotation=60)
            ax.set_xticks([])
            ax.set_ylabel("Missing Count")
            ax.set_title("Scatter: Missing by Dimension")
            self.plot_chart(fr, fig)
        except IndexError as e:
            logging.error(f"Scatter => {e}")

    def plotRadar(self, dfc: pd.DataFrame):
        fr= self.frames["Radar"]
        for w in fr.winfo_children():
            w.destroy()
        if dfc.empty or "Missing In" not in dfc.columns:
            return
        df_m= dfc[dfc["Missing In"]!=""]
        if df_m.empty:
            return
        cdim= df_m.groupby("Dimension")["Key"].count().sort_values(ascending=False)
        if self.top_n==10:
            cdim= cdim.head(10)
        if cdim.empty or len(cdim)<2:
            return
        cat= cdim.index.tolist()
        val= cdim.values.tolist()
        fig= plt.figure(figsize=(6,6))
        try:
            angles= np.linspace(0,2*np.pi,len(cat), endpoint=False).tolist()
            angles+= angles[:1]
            val+= val[:1]
            ax= fig.add_subplot(111, polar=True)
            ax.set_theta_offset(np.pi/2)
            ax.set_theta_direction(-1)
            ax.set_xticks(angles[:-1])
            ax.set_xticklabels(cat, fontsize=9)
            ax.plot(angles, val, color="red", linewidth=2)
            ax.fill(angles, val, color="red", alpha=0.3)
            ax.set_title("Radar: Missing Dims", y=1.08)
            self.plot_chart(fr, fig)
        except IndexError as e:
            logging.error(f"Radar => {e}")

    def plotNormalPie(self, dfc: pd.DataFrame):
        fr= self.frames["Normal Pie"]
        for w in fr.winfo_children():
            w.destroy()
        if dfc.empty or "Missing In" not in dfc.columns:
            return
        df_m= dfc[dfc["Missing In"]!=""]
        if df_m.empty:
            return
        dist= df_m["Missing In"].value_counts()
        fig, ax= plt.subplots(figsize=(5,5))
        try:
            ax.pie(dist.values, labels=dist.index, autopct="%.1f%%", startangle=140)
            ax.set_title("Pie: Missing In distribution")
            self.plot_chart(fr, fig)
        except IndexError as e:
            logging.error(f"Pie => {e}")

    def plotNormalBar(self, dfc: pd.DataFrame):
        fr= self.frames["Normal Bar"]
        for w in fr.winfo_children():
            w.destroy()
        if dfc.empty or "Missing In" not in dfc.columns:
            return
        df_m= dfc[dfc["Missing In"]!=""]
        if df_m.empty:
            return
        cattr= df_m["Attribute"].value_counts().sort_values(ascending=False)
        if self.top_n==10:
            cattr= cattr.head(10)
        if cattr.empty:
            return
        fig, ax= plt.subplots(figsize=(6,4))
        try:
            bars= ax.bar(range(len(cattr)), cattr.values, color="blue")
            ax.set_xticks(range(len(cattr)))
            ax.set_xticklabels(cattr.index, rotation=45, ha="right")
            ax.set_ylabel("Missing Count")
            ax.set_title("Bar: Missing attributes")
            for bar in bars:
                h= bar.get_height()
                ax.text(bar.get_x() + bar.get_width()/2., h, str(int(h)), ha="center", va="bottom")
            plt.tight_layout()
            self.plot_chart(fr, fig)
        except IndexError as e:
            logging.error(f"Bar => {e}")

    def plotBandChart(self):
        """
        Now uses PDF-style logic (self.df_history) rather than scanning entire folder.
        """
        fr= self.frames["Band Chart"]
        for w in fr.winfo_children():
            w.destroy()

        df_hist= self.df_history.copy()
        if df_hist.empty or "RunDate" not in df_hist.columns:
            return

        date_ct= df_hist.groupby("RunDate")["Key"].count().reset_index(name="Count")
        date_ct.sort_values("RunDate", inplace=True)
        if date_ct.empty:
            return

        fig, ax= plt.subplots(figsize=(6,4))
        try:
            date_ct["Count_min"]= date_ct["Count"]*0.9
            date_ct["Count_max"]= date_ct["Count"]*1.1
            ax.plot(date_ct["RunDate"], date_ct["Count"], color="purple", marker="o", label="Missing Count")
            ax.fill_between(date_ct["RunDate"], date_ct["Count_min"], date_ct["Count_max"],
                            color="purple", alpha=0.2, label="±10% band")
            ax.set_title("Band Chart Over Time")
            ax.set_xlabel("RunDate")
            ax.set_ylabel("Missing Count")
            plt.xticks(rotation=45)
            ax.legend()
            for i, rowv in date_ct.iterrows():
                ax.text(rowv["RunDate"], rowv["Count"], str(int(rowv["Count"])), ha="center", va="bottom")
            plt.tight_layout()
            self.plot_chart(fr, fig)
        except IndexError as e:
            logging.error(f"Band chart => {e}")


# ----------------------------------------------------------------------------
# HISTORY TAB
# ----------------------------------------------------------------------------
class HistoryTab(ctk.CTkFrame):
    def __init__(self, parent, hist_dir: Path):
        super().__init__(parent)
        self.history_dir= hist_dir
        self.tree= None
        self.build_ui()

    def build_ui(self):
        lbl= ctk.CTkLabel(self, text="Reconciliation Runs History", font=("Arial",16))
        lbl.pack(pady=5)

        self.tree= ttk.Treeview(self, columns=("Filename",), show="headings", height=15)
        self.tree.heading("Filename", text="History File")
        self.tree.pack(fill="both", expand=True, padx=10, pady=10)

        self.tree.bind("<Double-1>", self.on_double_click)

        refresh_btn= ctk.CTkButton(self, text="Refresh", command=self.refresh_history,
                                   fg_color="#800020", hover_color="#a52a2a", text_color="white")
        refresh_btn.pack(pady=5)

        self.refresh_history()

    def refresh_history(self):
        for i in self.tree.get_children():
            self.tree.delete(i)
        if not self.history_dir.is_dir():
            self.history_dir.mkdir(parents=True, exist_ok=True)
        files= sorted(self.history_dir.glob("*.json"), reverse=True)
        for f in files:
            self.tree.insert("", "end", values=(f.name,))

    def on_double_click(self, event):
        item_id= self.tree.focus()
        if not item_id:
            return
        filename= self.tree.item(item_id,"values")[0]
        path= self.history_dir / filename
        if not path.is_file():
            return
        try:
            with open(path, "r", encoding="utf-8") as f:
                content= f.read()
            popup= tk.Toplevel(self)
            popup.title(f"Viewing {filename}")
            txt= ctk.CTkTextbox(popup, width=800, height=600)
            txt.pack(fill="both", expand=True)
            txt.insert("end", content)
            txt.configure(state="disabled")
        except Exception as e:
            logging.error(f"Error opening {path} => {e}")


# ----------------------------------------------------------------------------
# MAIN APP
# ----------------------------------------------------------------------------
class MainApp(ctk.CTk):
    def __init__(self):
        super().__init__()
        self.title("Ultra-Mega Reconciliation: Param-based, Full Dashboard")
        self.geometry("1600x900")
        ctk.set_appearance_mode("light")

        # On close => auto-save config
        self.protocol("WM_DELETE_WINDOW", self.on_close)  # <-- ADDED

        # Load config
        self.config_dict= load_config(Path(DEFAULT_PATHS["CONFIG_PATH"]))
        self.param_dict= read_param_file(Path(self.config_dict["paths"].get("PARAMETER_PATH",DEFAULT_PATHS["PARAMETER_PATH"])))
        self.history_df= pd.DataFrame()

        self.tabs= ttk.Notebook(self)
        self.tabs.pack(fill="both", expand=True)

        # 1) Paths tab
        self.tab_paths= ctk.CTkFrame(self.tabs)
        self.tabs.add(self.tab_paths, text="Paths")
        self.build_paths_tab(self.tab_paths)

        # 2) ERP preview
        self.tab_erp= ctk.CTkFrame(self.tabs)
        erp_filters= self.config_dict.get("erp_grid",{}).get("filters",{})
        self.erp_preview= SimplePreview(self.tab_erp,"ERP",filters_dict=erp_filters)
        self.erp_preview.pack(fill="both", expand=True)
        self.tabs.add(self.tab_erp, text="ERP Preview")

        # 3) Master preview
        self.tab_master= ctk.CTkFrame(self.tabs)
        mast_filters= self.config_dict.get("master_grid",{}).get("filters",{})
        self.master_preview= SimplePreview(self.tab_master,"Master",filters_dict=mast_filters)
        self.master_preview.pack(fill="both", expand=True)
        self.tabs.add(self.tab_master, text="Master Preview")

        # 4) Compare tab
        self.tab_compare= ctk.CTkFrame(self.tabs)
        self.build_compare_tab(self.tab_compare)
        self.tabs.add(self.tab_compare, text="Compare")

        # 5) Dashboard
        dash_cfg= self.config_dict.get("dashboard", {})
        self.dashboard_tab= AdvancedDashboard(self.tabs, dash_cfg)
        self.tabs.add(self.dashboard_tab, text="Dashboard")

        # 6) History
        hist_path= Path(self.config_dict["paths"].get("HISTORY_PATH","history_runs"))
        self.history_tab= HistoryTab(self.tabs, hist_path)
        self.tabs.add(self.history_tab, text="History")

        # log box
        self.log_box= ctk.CTkTextbox(self, height=120)
        self.log_box.pack(fill="both", side="bottom")
        self.log_box.configure(state="disabled")
        handler= TextHandler(self.log_box)
        handler.setLevel(logging.INFO)
        logging.getLogger().addHandler(handler)

        # meltdown => preview
        self.temp_csv_dir= Path(self.config_dict["paths"].get("MASTER_CSV_OUTPUT","temp_master_csv"))
        self.temp_csv_dir.mkdir(parents=True, exist_ok=True)

        # Initial data load
        self.refresh_erp()
        self.refresh_master()

        ctk.CTkButton(self, text="Close Script", command=self.on_close,
                      fg_color="#800020", hover_color="#a52a2a", text_color="white").pack(pady=5)

    def build_paths_tab(self, parent):
        """
        We add fields for ERP, Master ZIP, Exception Path, Output XLSX, Config,
        Parameter, CSV folder, PDF path, LOGO_PATH, and HISTORY_PATH.
        """
        frm= ctk.CTkFrame(parent)
        frm.pack(fill="both", expand=True, padx=10, pady=10)

        self.erp_var= tk.StringVar(value=self.config_dict["paths"].get("ERP_EXCEL_PATH", DEFAULT_PATHS["ERP_EXCEL_PATH"]))
        self.mast_var= tk.StringVar(value=self.config_dict["paths"].get("MASTER_ZIP_PATH", DEFAULT_PATHS["MASTER_ZIP_PATH"]))
        self.exc_var= tk.StringVar(value=self.config_dict["paths"].get("EXCEPTION_PATH", DEFAULT_PATHS["EXCEPTION_PATH"]))
        self.out_var= tk.StringVar(value=self.config_dict["paths"].get("OUTPUT_PATH", DEFAULT_PATHS["OUTPUT_PATH"]))
        self.cfg_var= tk.StringVar(value=self.config_dict["paths"].get("CONFIG_PATH", DEFAULT_PATHS["CONFIG_PATH"]))
        self.par_var= tk.StringVar(value=self.config_dict["paths"].get("PARAMETER_PATH", DEFAULT_PATHS["PARAMETER_PATH"]))
        self.csv_var= tk.StringVar(value=self.config_dict["paths"].get("MASTER_CSV_OUTPUT", DEFAULT_PATHS["MASTER_CSV_OUTPUT"]))
        self.pdf_var= tk.StringVar(value=self.config_dict["paths"].get("PDF_EXPORT_PATH", DEFAULT_PATHS["PDF_EXPORT_PATH"]))
        self.logo_var= tk.StringVar(value=self.config_dict["paths"].get("LOGO_PATH", DEFAULT_PATHS["LOGO_PATH"]))
        self.hist_var= tk.StringVar(value=self.config_dict["paths"].get("HISTORY_PATH", DEFAULT_PATHS["HISTORY_PATH"]))

        def mkrow(lbl, var, is_dir=False):
            rowf= ctk.CTkFrame(frm)
            rowf.pack(fill="x", pady=5)
            ctk.CTkLabel(rowf, text=lbl, width=180).pack(side="left", padx=5)
            e= ctk.CTkEntry(rowf, textvariable=var, width=600)
            e.pack(side="left", padx=5)
            def br():
                if is_dir:
                    p= filedialog.askdirectory()
                else:
                    p= filedialog.askopenfilename()
                if p:
                    var.set(p)
            ctk.CTkButton(rowf, text="Browse", command=br,
                          fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)

        mkrow("ERP Excel:", self.erp_var)
        mkrow("Master ZIP:", self.mast_var)
        mkrow("Exception Path:", self.exc_var)
        mkrow("Missing Items Output:", self.out_var)
        mkrow("JSON Config Path:", self.cfg_var)
        mkrow("Parameter File:", self.par_var)
        mkrow("Master CSV Folder:", self.csv_var, is_dir=True)
        mkrow("PDF Export Path:", self.pdf_var, is_dir=False)
        mkrow("Logo Path:", self.logo_var, is_dir=False)
        mkrow("History Path:", self.hist_var, is_dir=True)

        bf= ctk.CTkFrame(frm)
        bf.pack(fill="x", pady=10)
        ctk.CTkButton(bf, text="Save Config", command=self.save_all_config,
                      fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)
        ctk.CTkButton(bf, text="Refresh ERP", command=self.refresh_erp,
                      fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)
        ctk.CTkButton(bf, text="Refresh Master", command=self.refresh_master,
                      fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)

    def build_compare_tab(self, parent):
        frm= ctk.CTkFrame(parent)
        frm.pack(fill="both", expand=True, padx=10, pady=10)
        ctk.CTkLabel(frm, text="Generate Missing Items", font=("Arial",16)).pack(pady=5)
        ctk.CTkButton(frm, text="Run Reconciliation", command=self.run_comparison,
                      fg_color="#800020", hover_color="#a52a2a").pack(pady=10)
        ctk.CTkButton(frm, text="Export PDF Report",
                      command=self.export_pdf,
                      fg_color="#800020", hover_color="#a52a2a").pack(pady=10)

    def refresh_erp(self):
        erp_path= Path(self.erp_var.get().strip())
        raw_erp= read_erp_excel(erp_path)
        if raw_erp.empty:
            self.erp_preview.set_data(pd.DataFrame())
            return
        param= read_param_file(Path(self.config_dict["paths"].get("PARAMETER_PATH", DEFAULT_PATHS["PARAMETER_PATH"])))
        melted= meltdown_erp_for_preview(raw_erp, param)
        pivoted= pivot_for_preview(melted)
        self.erp_preview.set_data(pivoted)

    def refresh_master(self):
        zip_path= Path(self.mast_var.get().strip())
        out_dir= Path(self.csv_var.get().strip())
        csvs= convert_master_txt_to_csv(zip_path, out_dir)
        raw_mast= unify_master_csvs(csvs)
        if raw_mast.empty:
            self.master_preview.set_data(pd.DataFrame())
            return
        param= read_param_file(Path(self.config_dict["paths"].get("PARAMETER_PATH", DEFAULT_PATHS["PARAMETER_PATH"])))
        melted= meltdown_master_for_preview(raw_mast, param)
        pivoted= pivot_for_preview(melted)
        self.master_preview.set_data(pivoted)

    def run_comparison(self):
        df_erp_wide= self.erp_preview.get_filtered_df()
        df_mast_wide= self.master_preview.get_filtered_df()

        erp_long= melt_back(df_erp_wide)
        erp_long= build_keys(erp_long)
        mast_long= melt_back(df_mast_wide)
        mast_long= build_keys(mast_long)

        df_diff= compare_mode2(erp_long, mast_long)
        exc_path= Path(self.exc_var.get().strip())
        df_exc= read_exception_table(exc_path)
        final= merge_exceptions(df_diff, df_exc)

        out_path= Path(self.out_var.get().strip())
        write_missing_items(final, out_path)

        # add timestamp
        run_timestamp= datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        final["RunDate"]= run_timestamp
        if self.history_df.empty:
            self.history_df= final.copy()
        else:
            self.history_df= pd.concat([self.history_df, final], ignore_index=True)

        # save JSON in user-chosen HISTORY_PATH
        hist_path= self.config_dict["paths"].get("HISTORY_PATH","history_runs")
        hist_dir= Path(hist_path)
        hist_dir.mkdir(parents=True, exist_ok=True)
        run_file= hist_dir / f"run_{run_timestamp.replace(':','-').replace(' ','_')}.json"
        try:
            final.to_json(run_file, orient="records", indent=2)
            logging.info(f"Saved run => {run_file}")
        except Exception as e:
            logging.error(f"Error writing JSON => {e}")

        # update dashboard with new data
        self.dashboard_tab.update_data(final, self.history_df)
        # also refresh the HistoryTab UI
        self.history_tab.refresh_history()

        self.tabs.select(self.dashboard_tab)
        messagebox.showinfo("Done", f"Missing items => {out_path}")

    def export_pdf(self):
        if self.history_df.empty:
            messagebox.showinfo("PDF Export", "No mismatch data to export (history is empty).")
            return
        if "RunDate" in self.history_df.columns:
            last_run= self.history_df["RunDate"].max()
            df_current= self.history_df[self.history_df["RunDate"]== last_run].copy()
        else:
            df_current= self.history_df.copy()
        df_history= self.history_df.copy()
        rep= EnhancedPDFReport(df_current, df_history, self.config_dict)
        pdf_path= rep.generate()
        messagebox.showinfo("PDF Export", f"PDF exported => {pdf_path}")

    def save_all_config(self):
        self.config_dict["paths"]["ERP_EXCEL_PATH"]= self.erp_var.get().strip()
        self.config_dict["paths"]["MASTER_ZIP_PATH"]= self.mast_var.get().strip()
        self.config_dict["paths"]["EXCEPTION_PATH"]= self.exc_var.get().strip()
        self.config_dict["paths"]["OUTPUT_PATH"]= self.out_var.get().strip()
        self.config_dict["paths"]["CONFIG_PATH"]= self.cfg_var.get().strip()
        self.config_dict["paths"]["PARAMETER_PATH"]= self.par_var.get().strip()
        self.config_dict["paths"]["MASTER_CSV_OUTPUT"]= self.csv_var.get().strip()
        self.config_dict["paths"]["PDF_EXPORT_PATH"]= self.pdf_var.get().strip()
        self.config_dict["paths"]["LOGO_PATH"] = self.logo_var.get().strip()
        self.config_dict["paths"]["HISTORY_PATH"] = self.hist_var.get().strip()

        self.config_dict.setdefault("erp_grid", {})
        self.config_dict["erp_grid"]["filters"]= self.erp_preview.filters

        self.config_dict.setdefault("master_grid", {})
        self.config_dict["master_grid"]["filters"]= self.master_preview.filters

        # We'll still store date_filters if needed, though the Dashboard doesn't use them now
        self.config_dict["date_filters"]= {
            "start_date": (datetime.now()-timedelta(days=30)).strftime("%Y-%m-%d"),
            "end_date": datetime.now().strftime("%Y-%m-%d")
        }

        # advanced dashboard config
        dash_cfg= self.config_dict.setdefault("dashboard", {})
        dash_cfg["selected_dims"]= list(self.dashboard_tab.selected_dims)
        dash_cfg["selected_attrs"]= list(self.dashboard_tab.selected_attrs)
        dash_cfg["top_n"]= self.dashboard_tab.top_n
        # we won't store start_date/end_date for the dashboard since we removed them, but let's just keep them blank
        dash_cfg["start_date"]= ""
        dash_cfg["end_date"]= ""

        save_config(self.config_dict, Path(self.config_dict["paths"]["CONFIG_PATH"]))
        messagebox.showinfo("Saved", "Paths & Config (including preview filters & dashboard) saved successfully.")

    def on_close(self):
        """Auto-save config and close the app."""
        self.save_all_config()
        self.destroy()


def main():
    app= MainApp()
    app.mainloop()

if __name__=="__main__":
    main()
