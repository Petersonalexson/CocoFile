# 2025-02-14 1142
"""
Ultra-Mega Reconciliation: Parameter-based with advanced Dashboard (8 charts),
showing final dimension/attribute names in the preview, only date columns filterable.

1) ERP:
   - Reads Excel (skip 3 rows). Keep only rows with Enabled_Flag=="Enabled".
   - "V_S_C" => dimension, "Value" => Name, others => attributes.
   - Parameter file:
       Dimension sheet => which V_S_C to keep (ERP Values=='x') => rename dimension
       Attribute sheet => which attributes to keep => rename
   - After meltdown => final dimension & attribute => pivot wide => user preview.

2) Master:
   - ZIP of .txt. For each file, only try encodings "utf-8-sig" and "utf-16-le".
   - Dimension = full ".txt" filename. The first column => Name, others => attributes.
   - Parameter file => same dimension sheet => only keep if ERP Values=='x' for that FileName => rename dimension
                       attribute sheet => rename & keep only "On/Off=='x'"
   - meltdown => final dimension/attribute => pivot wide => user preview.

3) Previews:
   - Only "Start Date"/"End Date" columns have filter popups. 
   - We pivot to wide with "Dimension","Name" locked. 
   - The user sees final param-based columns, e.g. "Active_Start_Date" renamed => "Start Date".

4) Compare:
   - We take the user-filtered wide data, melt it back to long => compare using Mode=2 logic => produce missing_items.xlsx.

5) Dashboard:
   - 8 charts (Heatmap, Lollipop, Circular, Scatter, Radar, Normal Pie, Normal Bar, Band Chart).
   - Dimension/Attribute/time filters, date range quick filters (last7/30/90), PDF export, metric cards, placeholders, etc.

No emojis, minimal Apple-like style in light mode with burgundy accents.
"""

import os
import sys
import json
import logging
import zipfile
import shutil
import io
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, Set, List

import tkinter as tk
from tkinter import ttk, filedialog, messagebox, simpledialog
import customtkinter as ctk

import pandas as pd
import numpy as np

import matplotlib
matplotlib.use("TkAgg")
import matplotlib.pyplot as plt
from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg

try:
    import chardet
except ImportError:
    chardet = None

from openpyxl import Workbook
from openpyxl.styles import PatternFill, Font, Alignment

# ---------------------------------------------------------------------------
# LOGGING
# ---------------------------------------------------------------------------
logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")

# ---------------------------------------------------------------------------
# DEFAULT PATHS & CONFIG
# ---------------------------------------------------------------------------
DEFAULT_PATHS = {
    "ERP_EXCEL_PATH": "data/ERP_Config.xlsx",
    "MASTER_ZIP_PATH": "data/Master_Config.zip",
    "EXCEPTION_PATH": "data/Exception_Table.xlsx",
    "OUTPUT_PATH": "output/missing_items.xlsx",
    "CONFIG_PATH": "config/ui_config.json",
    "PARAMETER_PATH": "data/parameters.xlsx",
    "MASTER_CSV_OUTPUT": "temp_master_csv"
}

def default_config() -> Dict:
    return {
        "paths": DEFAULT_PATHS.copy(),
        "comparison_option": 2,
        "erp_grid": {"columns": [], "filters": {}},
        "master_grid": {"columns": [], "filters": {}}
    }

def load_config(path: Path) -> Dict:
    if path.is_file():
        try:
            with open(path, "r", encoding="utf-8") as f:
                return json.load(f)
        except Exception as e:
            logging.warning(f"Could not load config: {e}")
    return default_config()

def save_config(cfg: Dict, path: Path):
    path.parent.mkdir(parents=True, exist_ok=True)
    try:
        with open(path, "w", encoding="utf-8") as f:
            json.dump(cfg, f, indent=2)
        logging.info(f"Saved config to {path}")
    except Exception as e:
        logging.error(f"Error saving config: {e}")

# ---------------------------------------------------------------------------
# TEXT LOGGER HANDLER
# ---------------------------------------------------------------------------
class TextHandler(logging.Handler):
    def __init__(self, widget: ctk.CTkTextbox):
        super().__init__()
        self.widget = widget
    def emit(self, record):
        msg = self.format(record) + "\n"
        self.widget.after(0, self._append, msg)
    def _append(self, msg):
        self.widget.configure(state="normal")
        self.widget.insert("end", msg)
        self.widget.see("end")
        self.widget.configure(state="disabled")

# ---------------------------------------------------------------------------
# PARAM FILE (two sheets)
# ---------------------------------------------------------------------------
def read_param_file(path: Path) -> Dict[str, object]:
    """
    Expecting:
      Sheet "Dimension Parameters": [FileName, V S C, Dimension, ERP Values]
         => if ERP Values=='x', keep dimension
         => param["dim_erp_keep"] = set(vsc)
         => param["dim_erp_map"][vsc] = finalDimension
         => param["dim_master_map"][filename] = finalDimension
      Sheet "Attribute Parameters": [ERP Original Attributes, Master Original Attributes, Attribute, On/Off]
         => if On/Off=='x', keep
         => param["attr_erp_map"][origName] = finalAttr
         => param["attr_master_map"][origName] = finalAttr
    """
    param = {
        "dim_erp_keep": set(),
        "dim_erp_map": {},
        "dim_master_map": {},
        "attr_erp_map": {},
        "attr_master_map": {}
    }
    if not path.is_file():
        logging.warning(f"Param file not found => {path}")
        return param

    try:
        dim_df = pd.read_excel(path, sheet_name="Dimension Parameters")
        dim_df.columns = dim_df.columns.astype(str).str.strip()

        def s(x): return str(x).strip() if pd.notna(x) else ""
        for _, row in dim_df.iterrows():
            fn = s(row.get("FileName",""))
            vsc= s(row.get("V S C",""))
            dim= s(row.get("Dimension",""))
            ev = s(row.get("ERP Values",""))
            if ev.lower()=="x" and vsc and dim:
                param["dim_erp_keep"].add(vsc)
            if vsc and dim:
                param["dim_erp_map"][vsc] = dim
            if fn and dim and ev.lower()=="x":
                param["dim_master_map"][fn] = dim

        attr_df = pd.read_excel(path, sheet_name="Attribute Parameters")
        attr_df.columns = attr_df.columns.astype(str).str.strip()
        for _, row in attr_df.iterrows():
            e_orig = s(row.get("ERP Original Attributes",""))
            m_orig = s(row.get("Master Original Attributes",""))
            final_ = s(row.get("Attribute",""))
            onoff = s(row.get("On/Off",""))
            if onoff.lower()=="x" and final_:
                if e_orig:
                    param["attr_erp_map"][e_orig] = final_
                if m_orig:
                    param["attr_master_map"][m_orig] = final_
        return param
    except Exception as e:
        logging.error(f"Error reading param file => {e}")
        return param

# ---------------------------------------------------------------------------
# ERP Reading => skip 3 => keep Enabled
# ---------------------------------------------------------------------------
def read_erp_excel(path: Path) -> pd.DataFrame:
    if not path.is_file():
        logging.warning(f"ERP Excel not found => {path}")
        return pd.DataFrame()
    try:
        df = pd.read_excel(path, skiprows=3)
        df.columns = df.columns.str.strip()
        if "Enabled_Flag" in df.columns:
            df = df[df["Enabled_Flag"]=="Enabled"]
        return df
    except Exception as e:
        logging.error(f"Error reading ERP => {e}")
        return pd.DataFrame()

# ---------------------------------------------------------------------------
# MASTER => .txt => only try 'utf-8-sig' and 'utf-16-le'
# ---------------------------------------------------------------------------
def read_txt_2encodings(raw: bytes) -> pd.DataFrame:
    import pandas as pd
    for enc in ["utf-8-sig","utf-16-le"]:
        try:
            import io
            buf = io.BytesIO(raw)
            df = pd.read_csv(buf, encoding=enc, on_bad_lines="skip", engine="python")
            df.dropna(how="all", axis=0, inplace=True)
            df.dropna(how="all", axis=1, inplace=True)
            df.columns = df.columns.astype(str).str.strip()
            logging.info(f"[read_txt_2encodings] success with {enc}, shape={df.shape}")
            return df
        except Exception as e:
            logging.debug(f"[read_txt_2encodings] fail with {enc} => {e}")
    logging.error("[read_txt_2encodings] cannot parse .txt => empty.")
    return pd.DataFrame()

def convert_master_txt_to_csv(zip_path: Path, out_dir: Path) -> List[Path]:
    if not zip_path.is_file():
        logging.warning(f"[Master] ZIP not found => {zip_path}")
        return []
    if out_dir.exists():
        shutil.rmtree(out_dir, ignore_errors=True)
    out_dir.mkdir(parents=True, exist_ok=True)
    csvs = []
    with zipfile.ZipFile(zip_path,"r") as z:
        txt_files= [f for f in z.namelist() if f.lower().endswith(".txt")]
        for txt_file in txt_files:
            base_name = os.path.basename(txt_file)
            if not base_name:
                continue
            try:
                with z.open(txt_file) as fo:
                    raw = fo.read()
                df = read_txt_2encodings(raw)
                if df.empty:
                    continue
                df["RawFileName"] = base_name
                if "Name" not in df.columns and len(df.columns)>0:
                    first_col= df.columns[0]
                    df.rename(columns={first_col:"Name"}, inplace=True)
                out_csv = out_dir / (base_name.replace(".txt",".csv"))
                df.to_csv(out_csv, index=False, encoding="utf-8")
                csvs.append(out_csv)
            except Exception as e:
                logging.error(f"[Master] error reading {txt_file} => {e}")
    return csvs

def unify_master_csvs(csvs: List[Path]) -> pd.DataFrame:
    frames=[]
    for cp in csvs:
        if not cp.is_file():
            continue
        try:
            df = pd.read_csv(cp, encoding="utf-8", on_bad_lines="skip")
            df.columns = df.columns.str.strip()
            frames.append(df)
        except Exception as e:
            logging.error(f"[unify_master_csvs] reading {cp} => {e}")
    if frames:
        return pd.concat(frames, ignore_index=True)
    return pd.DataFrame()

# ---------------------------------------------------------------------------
# MELTDOWN => Param Filter => Preview
# ---------------------------------------------------------------------------
def meltdown_erp_for_preview(df: pd.DataFrame, param: Dict[str, object]) -> pd.DataFrame:
    """
    1) Filter rows => only V_S_C in param["dim_erp_keep"]
    2) Dimension => param["dim_erp_map"][vsc]
    3) Attributes => only in param["attr_erp_map"]. rename => final
    4) 'Value' => record Name
    5) Return long => then pivot => wide
    """
    if "V_S_C" not in df.columns:
        return pd.DataFrame()
    keep = param.get("dim_erp_keep", set())
    dmap = param.get("dim_erp_map", {})
    amap = param.get("attr_erp_map", {})

    df2 = df[df["V_S_C"].isin(keep)].copy()
    if df2.empty:
        return pd.DataFrame()

    # meltdown
    skip_cols = {"V_S_C","Enabled_Flag"}
    id_vars= []
    if "Value" in df2.columns:
        id_vars.append("Value")
        skip_cols.add("Value")
    df2["DimRaw"] = df2["V_S_C"]
    skip_cols.add("DimRaw")
    id_vars.insert(0, "DimRaw")

    meltdown_cols = [c for c in df2.columns if c not in skip_cols]
    melted = df2.melt(id_vars=id_vars, value_vars=meltdown_cols,
                      var_name="OrigAttr", value_name="ValX")

    def rename_dim(v):
        return dmap.get(v, v)
    melted["Dimension"] = melted["DimRaw"].apply(rename_dim)
    if "Value" in id_vars:
        melted.rename(columns={"Value":"Name"}, inplace=True)
    else:
        melted["Name"] = ""

    # filter attributes => only those in amap
    melted = melted[melted["OrigAttr"].isin(amap.keys())].copy()
    # rename
    melted["Attribute"] = melted["OrigAttr"].map(amap)

    # if attribute => Start/End => strip T
    def strip_t(val):
        if isinstance(val,str) and "T" in val:
            return val.split("T")[0]
        return val
    melted["Value"] = np.where(
        melted["Attribute"].isin(["Start Date","End Date"]),
        melted["ValX"].apply(strip_t),
        melted["ValX"]
    )

    # now we have [Dimension,Name,Attribute,Value]
    return melted[["Dimension","Name","Attribute","Value"]]

def meltdown_master_for_preview(df: pd.DataFrame, param: Dict[str, object]) -> pd.DataFrame:
    """
    1) only keep rows with RawFileName in param["dim_master_map"]
    2) rename dimension => param["dim_master_map"][rawFileName]
    3) only keep attributes in param["attr_master_map"]
    4) rename them => final name
    5) pivot => wide
    """
    if df.empty or "RawFileName" not in df.columns:
        return pd.DataFrame()
    keep_map = param.get("dim_master_map", {})
    amap = param.get("attr_master_map", {})

    df2 = df[df["RawFileName"].isin(keep_map.keys())].copy()
    if df2.empty:
        return pd.DataFrame()

    df2["DimRaw"] = df2["RawFileName"]

    skip_cols = {"RawFileName","DimRaw"}
    id_vars = ["DimRaw"]
    if "Name" in df2.columns:
        id_vars.append("Name")
        skip_cols.add("Name")

    meltdown_cols = [c for c in df2.columns if c not in skip_cols]
    melted = df2.melt(id_vars=id_vars, value_vars=meltdown_cols,
                      var_name="OrigAttr", value_name="ValX")
    def rename_dim(fn):
        return keep_map.get(fn, fn)
    melted["Dimension"] = melted["DimRaw"].apply(rename_dim)

    if "Name" in id_vars:
        melted.rename(columns={"Name":"Name"}, inplace=True)
    else:
        melted["Name"] = ""

    # filter attributes => only if in amap
    melted = melted[melted["OrigAttr"].isin(amap.keys())].copy()
    melted["Attribute"] = melted["OrigAttr"].map(amap)

    def strip_t(val):
        if isinstance(val,str) and "T" in val:
            return val.split("T")[0]
        return val
    melted["Value"] = np.where(
        melted["Attribute"].isin(["Start Date","End Date"]),
        melted["ValX"].apply(strip_t),
        melted["ValX"]
    )
    return melted[["Dimension","Name","Attribute","Value"]]

def pivot_for_preview(df: pd.DataFrame) -> pd.DataFrame:
    """
    Remove duplicates [Dimension,Name,Attribute], pivot => wide
    """
    df2 = df.copy()
    if not df2.empty and {"Dimension","Name","Attribute"}.issubset(df2.columns):
        df2.drop_duplicates(subset=["Dimension","Name","Attribute"], inplace=True)
        try:
            df2 = df2.pivot(index=["Dimension","Name"], columns="Attribute", values="Value").reset_index()
        except Exception as e:
            logging.error(f"Pivot error => {e}")
    return df2

# ---------------------------------------------------------------------------
# Compare => meltdown the user-filtered wide data back to long, produce missing items
# ---------------------------------------------------------------------------
def melt_back(df: pd.DataFrame) -> pd.DataFrame:
    """
    The user sees wide [Dimension,Name, <attr1>, <attr2>, ...].
    We melt it back to [Dimension,Name,Attribute,Value].
    skip dimension, name themselves, meltdown other columns
    """
    if df.empty or "Dimension" not in df.columns or "Name" not in df.columns:
        return pd.DataFrame()
    skip_cols = {"Dimension","Name"}
    meltdown_cols = [c for c in df.columns if c not in skip_cols]
    # meltdown
    melted = df.melt(id_vars=["Dimension","Name"], value_vars=meltdown_cols,
                     var_name="Attribute", value_name="Value")
    return melted[["Dimension","Name","Attribute","Value"]]

def build_keys(df: pd.DataFrame)-> pd.DataFrame:
    df = df.copy()
    for c in ["Dimension","Name","Attribute","Value"]:
        if c not in df.columns:
            df[c] = ""
        df[c] = df[c].fillna("").astype(str).str.strip()
    df["GroupKey"] = df["Dimension"] + " | " + df["Name"]
    df["Key"] = df["Dimension"] + " | " + df["Name"] + " | " + df["Attribute"] + " | " + df["Value"]
    df["Comments_1"] = ""
    df["Comments_2"] = ""
    df["Action Item"] = ""
    df["Missing In"] = ""
    return df

def compare_mode2(df_erp: pd.DataFrame, df_mst: pd.DataFrame) -> pd.DataFrame:
    def to_dict(d):
        out={}
        for gk, grp in d.groupby("GroupKey"):
            rec={}
            nm= grp["Name"].iloc[0] if not grp.empty else ""
            rec["Name"] = nm
            for _, row in grp.iterrows():
                rec[row["Attribute"]] = row["Value"]
            out[gk] = rec
        return out
    e_dict = to_dict(df_erp)
    m_dict = to_dict(df_mst)
    all_gk = set(e_dict.keys())| set(m_dict.keys())
    results=[]
    for gk in all_gk:
        dim= gk.split(" | ")[0]
        a_data= e_dict.get(gk,{})
        b_data= m_dict.get(gk,{})
        name_a= a_data.get("Name","")
        name_b= b_data.get("Name","")
        if name_a and name_b and name_a==name_b:
            all_attrs= (set(a_data.keys())| set(b_data.keys())) - {"Name"}
            for at in all_attrs:
                va= a_data.get(at,"")
                vb= b_data.get(at,"")
                if va!=vb:
                    if va and not vb:
                        results.append({"Dimension":dim,"Name":name_a,"Attribute":at,"Value":va,"Missing In":"MASTER"})
                    elif vb and not va:
                        results.append({"Dimension":dim,"Name":name_a,"Attribute":at,"Value":vb,"Missing In":"ERP"})
                    else:
                        results.append({"Dimension":dim,"Name":name_a,"Attribute":at,"Value":va,"Missing In":"MASTER"})
                        results.append({"Dimension":dim,"Name":name_a,"Attribute":at,"Value":vb,"Missing In":"ERP"})
        else:
            if name_a and not name_b:
                results.append({"Dimension":dim,"Name":name_a,"Attribute":"Name","Value":name_a,"Missing In":"MASTER"})
            elif name_b and not name_a:
                results.append({"Dimension":dim,"Name":name_b,"Attribute":"Name","Value":name_b,"Missing In":"ERP"})
    df_res= pd.DataFrame(results)
    if not df_res.empty:
        df_res["Key"]= (df_res["Dimension"].str.strip()+" | "+
                        df_res["Name"].str.strip()+" | "+
                        df_res["Attribute"].str.strip()+" | "+
                        df_res["Value"].str.strip())
    return df_res

def read_exception_table(path: Path)-> pd.DataFrame:
    if not path.is_file():
        logging.warning(f"Exception table not found => {path}")
        return pd.DataFrame()
    try:
        df = pd.read_excel(path)
        df.columns = df.columns.astype(str).str.strip()
        return df
    except Exception as e:
        logging.error(f"Error reading exception => {e}")
        return pd.DataFrame()

def merge_exceptions(df: pd.DataFrame, df_exc: pd.DataFrame)-> pd.DataFrame:
    if df.empty or df_exc.empty or "Key" not in df.columns:
        return df
    keep = [c for c in df_exc.columns if c in ["Key","Comments_1","Comments_2","hide exception"]]
    if not keep:
        return df
    exc = df_exc[keep].copy()
    exc["Key"] = exc["Key"].astype(str).str.strip()
    merged = df.merge(exc, on="Key", how="left", suffixes=("","_exc"))
    merged["hide exception"] = merged.get("hide exception","").fillna("").str.lower()
    final = merged[merged["hide exception"]!="yes"].copy()
    if "Comments_1_exc" in final.columns:
        final["Comments_1"] = np.where(final["Comments_1_exc"].notna(), final["Comments_1_exc"], final["Comments_1"])
        final.drop(columns=["Comments_1_exc"], inplace=True)
    if "Comments_2_exc" in final.columns:
        final["Comments_2"] = np.where(final["Comments_2_exc"].notna(), final["Comments_2_exc"], final["Comments_2"])
        final.drop(columns=["Comments_2_exc"], inplace=True)
    if "hide exception" in final.columns:
        final.drop(columns=["hide exception"], inplace=True)
    return final

def write_missing_items(df: pd.DataFrame, out_path: Path):
    if df.empty:
        logging.info("No missing items => skip writing.")
        return
    out_path.parent.mkdir(parents=True, exist_ok=True)
    final_cols= ["Key","Dimension","Name","Attribute","Value","Comments_1","Comments_2","Action Item","Missing In"]
    for c in final_cols:
        if c not in df.columns:
            df[c] = ""
    df = df[final_cols]
    wb= Workbook()
    ws= wb.active
    ws.title= "Missing Items"
    ws.append(final_cols)
    for rowvals in df.itertuples(index=False):
        ws.append(rowvals)
    header_font= Font(bold=True)
    fill= PatternFill(start_color="DDDDDD", end_color="DDDDDD", fill_type="solid")
    for cell in ws[1]:
        cell.font= header_font
        cell.fill= fill
        cell.alignment= Alignment(horizontal="center")
    for col in ws.columns:
        max_len=0
        letter= col[0].column_letter
        for cell in col:
            val = str(cell.value) if cell.value else ""
            max_len= max(max_len, len(val))
        ws.column_dimensions[letter].width = max_len+2
    ws.freeze_panes = "A2"
    wb.save(out_path)
    logging.info(f"Missing items => {out_path}")

# ---------------------------------------------------------------------------
# SIMPLE PREVIEW => advanced meltdown done beforehand
# ---------------------------------------------------------------------------
class SimplePreview(ctk.CTkFrame):
    """
    Shows data in wide format, only Start/End Date can be filtered.
    """
    FILTERABLE = {"Start Date","End Date"}
    def __init__(self, parent, name: str):
        super().__init__(parent)
        self.name = name
        self.df = pd.DataFrame()
        self.filters: Dict[str, Set] = {}
        self.create_toolbar()
        self.create_table()
        self.create_statusbar()

    def create_toolbar(self):
        bar= ctk.CTkFrame(self, corner_radius=10, fg_color="#f0f0f0")
        bar.pack(fill="x", padx=5, pady=5)
        ctk.CTkLabel(bar, text=f"{self.name} Preview", fg_color="#800020", corner_radius=8).pack(side="left", padx=5)
        ctk.CTkButton(bar, text="ⓘ", width=30, command=self.show_info,
                      fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)
        ctk.CTkButton(bar, text="Clear Date Filters", command=self.clear_filters,
                      fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)

    def show_info(self):
        messagebox.showinfo("Info", f"{self.name} data after meltdown & param.\nOnly Start/End Date columns filterable.")

    def create_table(self):
        container = ctk.CTkFrame(self)
        container.pack(fill="both", expand=True, padx=5, pady=5)
        self.tree = ttk.Treeview(container, show="headings")
        vsb = ttk.Scrollbar(container, orient="vertical", command=self.tree.yview)
        hsb = ttk.Scrollbar(container, orient="horizontal", command=self.tree.xview)
        self.tree.configure(yscrollcommand=vsb.set, xscrollcommand=hsb.set)
        self.tree.grid(row=0, column=0, sticky="nsew")
        vsb.grid(row=0, column=1, sticky="ns")
        hsb.grid(row=1, column=0, sticky="ew")
        container.rowconfigure(0, weight=1)
        container.columnconfigure(0, weight=1)

    def create_statusbar(self):
        self.status_label = ctk.CTkLabel(self, text="0 rows")
        self.status_label.pack(fill="x")

    def set_data(self, df: pd.DataFrame):
        self.filters.clear()
        self.df = df.copy()
        self.refresh_table()

    def refresh_table(self):
        for i in self.tree.get_children():
            self.tree.delete(i)
        if self.df.empty:
            self.tree["columns"]= []
            self.status_label.configure(text="0 rows")
            return
        cols = list(self.df.columns)
        self.tree["columns"] = cols
        for c in cols:
            self.tree.heading(c, text=c, anchor="w",
                              command=lambda col=c:self.on_heading_click(col))
            self.tree.column(c, anchor="w", width=150)
        df_f = self.apply_filters()
        for _, row in df_f.iterrows():
            rowvals = [row[c] for c in cols]
            self.tree.insert("", "end", values=rowvals)
        self.status_label.configure(text=f"{len(df_f)} rows")

    def apply_filters(self)-> pd.DataFrame:
        df_f = self.df.copy()
        for col, allowed in self.filters.items():
            if col in df_f.columns:
                df_f = df_f[df_f[col].isin(allowed)]
        return df_f

    def on_heading_click(self, col_name: str):
        if col_name in self.FILTERABLE:
            self.show_filter_popup(col_name)

    def show_filter_popup(self, col_name: str):
        if self.df.empty or col_name not in self.df.columns:
            return
        popup= tk.Toplevel(self)
        popup.title(f"Filter: {col_name}")
        popup.geometry("300x400")
        frame= ctk.CTkFrame(popup)
        frame.pack(fill="both", expand=True, padx=5, pady=5)

        unique_vals= self.df[col_name].unique()
        display_map={}
        for v in unique_vals:
            if pd.isna(v):
                dsp= "(NaN)"
            elif isinstance(v,str) and not v.strip():
                dsp= "(blank)"
            else:
                dsp= str(v)
            display_map[v]= dsp
        sorted_vals= sorted(display_map.keys(), key=lambda x: display_map[x].lower())
        curr_filter= self.filters.get(col_name, set(unique_vals))

        selall_var= tk.BooleanVar(value=True)
        def toggle_all():
            check= selall_var.get()
            for vb in var_dict.values():
                vb.set(check)

        ctk.CTkCheckBox(frame, text="Select All", variable=selall_var, command=toggle_all,
                        fg_color="#800020", hover_color="#a52a2a").pack(anchor="w", pady=5)

        scroll= ctk.CTkScrollableFrame(frame, width=250, height=250)
        scroll.pack(fill="both", expand=True, padx=5, pady=5)
        var_dict={}
        for rv in sorted_vals:
            in_filter= rv in curr_filter
            bvar= tk.BooleanVar(value=in_filter)
            var_dict[rv]= bvar
            ctk.CTkCheckBox(scroll, text=display_map[rv], variable=bvar,
                            fg_color="#800020", hover_color="#a52a2a").pack(anchor="w")

        def apply_():
            sel = {rv for rv,vb in var_dict.items() if vb.get()}
            if sel == set(sorted_vals) or not sel:
                self.filters.pop(col_name,None)
            else:
                self.filters[col_name] = sel
            popup.destroy()
            self.refresh_table()

        bf= ctk.CTkFrame(frame)
        bf.pack(fill="x", pady=5)
        ctk.CTkButton(bf, text="Apply", command=apply_,
                      fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)
        ctk.CTkButton(bf, text="Cancel", command=popup.destroy,
                      fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)

    def clear_filters(self):
        self.filters.clear()
        self.refresh_table()

    def get_filtered_df(self)-> pd.DataFrame:
        return self.apply_filters()

# ---------------------------------------------------------------------------
# ADVANCED DASHBOARD WITH 8 CHARTS + dimension/attribute/time filter
# ---------------------------------------------------------------------------
class AdvancedDashboard(ctk.CTkFrame):
    """
    Contains:
     - dimension & attribute filter popups
     - date range or quick last7/30/90
     - 8 chart frames: Heatmap, Lollipop, Circular, Scatter, Radar, Normal Pie, Normal Bar, Band Chart
     - PDF export placeholders
     - metric cards
    """
    def __init__(self, parent):
        super().__init__(parent)
        self.df_current = pd.DataFrame()   # For the latest run
        self.df_history = pd.DataFrame()   # All runs
        self.selected_dims: Set[str] = set()
        self.selected_attrs: Set[str] = set()

        topbar = ctk.CTkFrame(self, corner_radius=10, fg_color="#f0f0f0")
        topbar.pack(fill="x", padx=5, pady=5)
        # Metric placeholders
        self.metric_label = ctk.CTkLabel(topbar, text="Metrics: 0 missing, 0 dimension", width=300)
        self.metric_label.pack(side="left", padx=5)

        ctk.CTkButton(topbar, text="Filter Dimension", command=self.show_dimension_filter,
                      fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)
        ctk.CTkButton(topbar, text="Filter Attribute", command=self.show_attribute_filter,
                      fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)

        # Quick date filters
        ctk.CTkButton(topbar, text="Last 7 Days", command=lambda: self.set_quick_range(7),
                      fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)
        ctk.CTkButton(topbar, text="Last 30 Days", command=lambda: self.set_quick_range(30),
                      fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)
        ctk.CTkButton(topbar, text="Last 90 Days", command=lambda: self.set_quick_range(90),
                      fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)
        ctk.CTkButton(topbar, text="All Time", command=lambda: self.set_quick_range(9999),
                      fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)

        self.start_date_var = tk.StringVar(value=(datetime.now()-timedelta(days=30)).strftime("%Y-%m-%d"))
        self.end_date_var = tk.StringVar(value=datetime.now().strftime("%Y-%m-%d"))

        ctk.CTkEntry(topbar, textvariable=self.start_date_var, width=100).pack(side="left", padx=5)
        ctk.CTkEntry(topbar, textvariable=self.end_date_var, width=100).pack(side="left", padx=5)

        ctk.CTkButton(topbar, text="Update Timeline", command=self.update_data_filters,
                      fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)

        ctk.CTkButton(topbar, text="Export PDF", command=lambda: messagebox.showinfo("Export","PDF Export..."),
                      fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)

        # Notebook for 8 charts
        self.notebook = ttk.Notebook(self)
        self.notebook.pack(fill="both", expand=True)

        self.frames = {}
        chart_names = ["Heatmap","Lollipop","Circular","Scatter","Radar","Normal Pie","Normal Bar","Band Chart"]
        for lbl in chart_names:
            fr = ctk.CTkFrame(self.notebook)
            self.notebook.add(fr, text=lbl)
            self.frames[lbl] = fr

    def set_quick_range(self, days: int):
        if days>9000:
            # all time
            self.start_date_var.set("1900-01-01")
            self.end_date_var.set("2100-12-31")
        else:
            dt_end = datetime.now()
            dt_start = dt_end - timedelta(days=days)
            self.start_date_var.set(dt_start.strftime("%Y-%m-%d"))
            self.end_date_var.set(dt_end.strftime("%Y-%m-%d"))
        self.update_data_filters()

    def show_dimension_filter(self):
        self.show_filter_popup("Dimension")

    def show_attribute_filter(self):
        self.show_filter_popup("Attribute")

    def show_filter_popup(self, col: str):
        base_df = self.df_history if not self.df_history.empty else self.df_current
        if base_df.empty or col not in base_df.columns:
            return
        popup = tk.Toplevel(self)
        popup.title(f"Filter: {col}")
        popup.geometry("300x400")
        frame= ctk.CTkFrame(popup)
        frame.pack(fill="both", expand=True, padx=5, pady=5)

        unique_vals= base_df[col].unique()
        display_map={}
        for v in unique_vals:
            if pd.isna(v):
                dsp= "(NaN)"
            elif isinstance(v,str) and not v.strip():
                dsp= "(blank)"
            else:
                dsp= str(v)
            display_map[v]= dsp
        sorted_vals= sorted(display_map.keys(), key=lambda x: display_map[x].lower())

        if col=="Dimension":
            curr = self.selected_dims
        else:
            curr = self.selected_attrs

        if not curr:
            curr = set(unique_vals)

        selall_var= tk.BooleanVar(value=True)
        def toggle_all():
            check= selall_var.get()
            for vb in var_dict.values():
                vb.set(check)

        ctk.CTkCheckBox(frame, text="Select All", variable=selall_var, command=toggle_all,
                        fg_color="#800020", hover_color="#a52a2a").pack(anchor="w", pady=5)

        scroll= ctk.CTkScrollableFrame(frame, width=250, height=250)
        scroll.pack(fill="both", expand=True, padx=5, pady=5)
        var_dict={}
        for rv in sorted_vals:
            in_filter= rv in curr
            bvar= tk.BooleanVar(value=in_filter)
            var_dict[rv]= bvar
            ctk.CTkCheckBox(scroll, text=display_map[rv], variable=bvar,
                            fg_color="#800020", hover_color="#a52a2a").pack(anchor="w")

        def apply_():
            sel= {rv for rv,vb in var_dict.items() if vb.get()}
            if col=="Dimension":
                self.selected_dims = sel
            else:
                self.selected_attrs = sel
            popup.destroy()
            self.update_data_filters()

        bf= ctk.CTkFrame(frame)
        bf.pack(fill="x", pady=5)
        ctk.CTkButton(bf, text="Apply", command=apply_,
                      fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)
        ctk.CTkButton(bf, text="Cancel", command=popup.destroy,
                      fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)

    def update_data(self, df_current: pd.DataFrame, df_history: pd.DataFrame):
        self.df_current = df_current.copy()
        self.df_history = df_history.copy()
        self.update_data_filters()

    def update_data_filters(self):
        # dimension/attribute/time filtering
        dfc = self.df_current.copy()
        if not dfc.empty:
            if self.selected_dims:
                dfc = dfc[dfc["Dimension"].isin(self.selected_dims)]
            if self.selected_attrs:
                dfc = dfc[dfc["Attribute"].isin(self.selected_attrs)]

        # also time filter if "RunDate" in df
        if "RunDate" in dfc.columns:
            try:
                start = datetime.strptime(self.start_date_var.get(), "%Y-%m-%d")
                end = datetime.strptime(self.end_date_var.get(), "%Y-%m-%d")
                dfc["RunDate_dt"] = pd.to_datetime(dfc["RunDate"], format="%Y-%m-%d", errors="coerce")
                dfc = dfc[(dfc["RunDate_dt"]>= start) & (dfc["RunDate_dt"]<= end)]
            except Exception as e:
                logging.error(f"Date filter error => {e}")

        # update metric
        mism = len(dfc)
        dims = dfc["Dimension"].nunique() if not dfc.empty and "Dimension" in dfc.columns else 0
        self.metric_label.configure(text=f"Mismatches: {mism}, Dims: {dims}")

        self.plotHeatmap(dfc)
        self.plotLollipop(dfc)
        self.plotCircular(dfc)
        self.plotScatter(dfc)
        self.plotRadar(dfc)
        self.plotNormalPie(dfc)
        self.plotNormalBar(dfc)
        self.plotBandChart()

    def plot_chart(self, frame, fig):
        for w in frame.winfo_children():
            w.destroy()
        canvas = FigureCanvasTkAgg(fig, master=frame)
        canvas.draw()
        canvas.get_tk_widget().pack(fill="both", expand=True)

    def plotHeatmap(self, dfc: pd.DataFrame):
        fr= self.frames["Heatmap"]
        for w in fr.winfo_children():
            w.destroy()
        df_m= dfc[dfc["Missing In"]!=""] if not dfc.empty and "Missing In" in dfc.columns else pd.DataFrame()
        if df_m.empty or not {"Dimension","Attribute"}.issubset(df_m.columns):
            return
        pivot= df_m.groupby(["Dimension","Attribute"]).size().unstack(fill_value=0)
        fig, ax= plt.subplots(figsize=(6,5))
        cax= ax.imshow(pivot, aspect="auto", cmap="Reds")
        ax.set_xticks(range(len(pivot.columns)))
        ax.set_xticklabels(pivot.columns, rotation=90)
        ax.set_yticks(range(len(pivot.index)))
        ax.set_yticklabels(pivot.index)
        fig.colorbar(cax, ax=ax)
        ax.set_title("Heatmap: Missing Items")
        self.plot_chart(fr, fig)

    def plotLollipop(self, dfc: pd.DataFrame):
        fr= self.frames["Lollipop"]
        for w in fr.winfo_children():
            w.destroy()
        if dfc.empty or "Missing In" not in dfc.columns:
            return
        df_m= dfc[dfc["Missing In"]!=""]
        if df_m.empty:
            return
        cdim= df_m.groupby("Dimension")["Key"].count().sort_values(ascending=False).head(10)
        if cdim.empty:
            return
        fig, ax= plt.subplots(figsize=(6,5))
        ax.hlines(y=cdim.index, xmin=0, xmax=cdim.values, color="skyblue")
        ax.plot(cdim.values, cdim.index, "o", color="skyblue")
        ax.set_title("Lollipop: Missing Dimensions")
        ax.set_xlabel("Missing Count")
        self.plot_chart(fr, fig)

    def plotCircular(self, dfc: pd.DataFrame):
        fr= self.frames["Circular"]
        for w in fr.winfo_children():
            w.destroy()
        if dfc.empty or "Missing In" not in dfc.columns:
            return
        df_m= dfc[dfc["Missing In"]!=""]
        if df_m.empty:
            return
        cattr= df_m.groupby("Attribute")["Key"].count().sort_values(ascending=False).head(10)
        if cattr.empty:
            return
        cat= cattr.index.tolist()
        val= cattr.values
        angles= np.linspace(0,2*np.pi,len(cat), endpoint=False)
        fig= plt.figure(figsize=(6,6))
        ax= fig.add_subplot(111, polar=True)
        ax.set_theta_offset(np.pi/2)
        ax.set_theta_direction(-1)
        ax.set_xticks(angles)
        ax.set_xticklabels(cat, fontsize=9)
        ax.bar(angles, val, width=0.4, color="orange", alpha=0.6)
        ax.set_title("Circular: Missing Attributes", y=1.05)
        self.plot_chart(fr, fig)

    def plotScatter(self, dfc: pd.DataFrame):
        fr= self.frames["Scatter"]
        for w in fr.winfo_children():
            w.destroy()
        if dfc.empty or "Missing In" not in dfc.columns:
            return
        df_m= dfc[dfc["Missing In"]!=""]
        if df_m.empty:
            return
        cdim= df_m.groupby("Dimension")["Key"].count().reset_index(name="Count")
        cdim.sort_values("Count", ascending=False, inplace=True)
        if cdim.empty:
            return
        xvals= np.arange(len(cdim))
        yvals= cdim["Count"].values
        labels= cdim["Dimension"].values
        fig, ax= plt.subplots(figsize=(6,5))
        ax.scatter(xvals,yvals,color="green")
        for i, txt in enumerate(labels):
            ax.text(xvals[i], yvals[i], txt, ha="center", va="bottom", rotation=60)
        ax.set_xticks([])
        ax.set_ylabel("Missing Count")
        ax.set_title("Scatter: Missing by Dimension")
        self.plot_chart(fr, fig)

    def plotRadar(self, dfc: pd.DataFrame):
        fr= self.frames["Radar"]
        for w in fr.winfo_children():
            w.destroy()
        if dfc.empty or "Missing In" not in dfc.columns:
            return
        df_m= dfc[dfc["Missing In"]!=""]
        if df_m.empty:
            return
        cdim= df_m.groupby("Dimension")["Key"].count().sort_values(ascending=False).head(5)
        if cdim.empty:
            return
        cat= cdim.index.tolist()
        val= cdim.values.tolist()
        N= len(cat)
        angles= np.linspace(0,2*np.pi,N, endpoint=False).tolist()
        angles+= angles[:1]
        val+= val[:1]
        fig= plt.figure(figsize=(6,6))
        ax= fig.add_subplot(111, polar=True)
        ax.set_theta_offset(np.pi/2)
        ax.set_theta_direction(-1)
        ax.set_xticks(angles[:-1])
        ax.set_xticklabels(cat, fontsize=9)
        ax.plot(angles, val, color="red", linewidth=2)
        ax.fill(angles, val, color="red", alpha=0.3)
        ax.set_title("Radar: top 5 missing dims", y=1.08)
        self.plot_chart(fr, fig)

    def plotNormalPie(self, dfc: pd.DataFrame):
        fr= self.frames["Normal Pie"]
        for w in fr.winfo_children():
            w.destroy()
        if dfc.empty or "Missing In" not in dfc.columns:
            return
        df_m= dfc[dfc["Missing In"]!=""]
        if df_m.empty:
            return
        dist= df_m["Missing In"].value_counts()
        fig, ax= plt.subplots(figsize=(5,5))
        ax.pie(dist.values, labels=dist.index, autopct="%.1f%%", startangle=140)
        ax.set_title("Pie: Missing In distribution")
        self.plot_chart(fr, fig)

    def plotNormalBar(self, dfc: pd.DataFrame):
        fr= self.frames["Normal Bar"]
        for w in fr.winfo_children():
            w.destroy()
        if dfc.empty or "Missing In" not in dfc.columns:
            return
        df_m= dfc[dfc["Missing In"]!=""]
        if df_m.empty:
            return
        cattr= df_m.groupby("Attribute")["Key"].count().sort_values(ascending=False).head(10)
        fig, ax= plt.subplots(figsize=(6,4))
        cattr.plot(kind="bar", ax=ax, color="blue")
        ax.set_ylabel("Missing Count")
        ax.set_title("Bar: top 10 missing attributes")
        self.plot_chart(fr, fig)

    def plotBandChart(self):
        fr= self.frames["Band Chart"]
        for w in fr.winfo_children():
            w.destroy()
        if self.df_history.empty or "RunDate" not in self.df_history.columns:
            return
        date_ct= self.df_history.groupby("RunDate")["Key"].count().reset_index(name="Count")
        date_ct.sort_values("RunDate", inplace=True)
        date_ct["Count_min"] = date_ct["Count"]*0.9
        date_ct["Count_max"] = date_ct["Count"]*1.1
        fig, ax= plt.subplots(figsize=(6,4))
        ax.plot(date_ct["RunDate"], date_ct["Count"], color="purple", marker="o", label="Missing Count")
        ax.fill_between(date_ct["RunDate"], date_ct["Count_min"], date_ct["Count_max"],
                        color="purple", alpha=0.2, label="±10% band")
        ax.set_title("Band Chart Over Time")
        ax.set_xlabel("RunDate")
        ax.set_ylabel("Missing Count")
        plt.xticks(rotation=45)
        ax.legend()
        for i, row in date_ct.iterrows():
            ax.text(row["RunDate"], row["Count"], str(row["Count"]), ha="center", va="bottom")
        self.plot_chart(fr, fig)

# ---------------------------------------------------------------------------
# MAIN APP
# ---------------------------------------------------------------------------
class MainApp(ctk.CTk):
    def __init__(self):
        super().__init__()
        self.title("Ultra-Mega Reconciliation: Param-based, Full Dashboard")
        self.geometry("1600x900")
        ctk.set_appearance_mode("light")

        # Load config + param
        self.config_dict = load_config(Path(DEFAULT_PATHS["CONFIG_PATH"]))
        self.param_dict = read_param_file(Path(self.config_dict["paths"].get("PARAMETER_PATH", DEFAULT_PATHS["PARAMETER_PATH"])))
        self.history_df = pd.DataFrame()  # for storing multiple runs

        self.tabs = ttk.Notebook(self)
        self.tabs.pack(fill="both", expand=True)

        # 1) Paths Tab
        self.tab_paths = ctk.CTkFrame(self.tabs)
        self.tabs.add(self.tab_paths, text="Paths")
        self.build_paths_tab(self.tab_paths)

        # 2) ERP Preview
        self.tab_erp = ctk.CTkFrame(self.tabs)
        self.erp_preview = SimplePreview(self.tab_erp, "ERP")
        self.erp_preview.pack(fill="both", expand=True)
        self.tabs.add(self.tab_erp, text="ERP Preview")

        # 3) Master Preview
        self.tab_master = ctk.CTkFrame(self.tabs)
        self.master_preview = SimplePreview(self.tab_master, "Master")
        self.master_preview.pack(fill="both", expand=True)
        self.tabs.add(self.tab_master, text="Master Preview")

        # 4) Compare
        self.tab_compare = ctk.CTkFrame(self.tabs)
        self.build_compare_tab(self.tab_compare)
        self.tabs.add(self.tab_compare, text="Compare")

        # 5) Dashboard
        self.dashboard_tab = AdvancedDashboard(self.tabs)
        self.tabs.add(self.dashboard_tab, text="Dashboard")

        # Logging
        self.log_box = ctk.CTkTextbox(self, height=120)
        self.log_box.pack(fill="both")
        self.log_box.configure(state="disabled")
        handler = TextHandler(self.log_box)
        handler.setLevel(logging.INFO)
        logging.getLogger().addHandler(handler)

        # Master CSV dir
        self.temp_csv_dir = Path(self.config_dict["paths"].get("MASTER_CSV_OUTPUT","temp_master_csv"))
        self.temp_csv_dir.mkdir(parents=True, exist_ok=True)

        # Auto load => meltdown -> pivot => show
        self.refresh_erp()
        self.refresh_master()

    def build_paths_tab(self, parent):
        frm= ctk.CTkFrame(parent)
        frm.pack(fill="both", expand=True, padx=10, pady=10)
        self.erp_var= tk.StringVar(value=self.config_dict["paths"].get("ERP_EXCEL_PATH", DEFAULT_PATHS["ERP_EXCEL_PATH"]))
        self.mast_var= tk.StringVar(value=self.config_dict["paths"].get("MASTER_ZIP_PATH", DEFAULT_PATHS["MASTER_ZIP_PATH"]))
        self.exc_var= tk.StringVar(value=self.config_dict["paths"].get("EXCEPTION_PATH", DEFAULT_PATHS["EXCEPTION_PATH"]))
        self.out_var= tk.StringVar(value=self.config_dict["paths"].get("OUTPUT_PATH", DEFAULT_PATHS["OUTPUT_PATH"]))
        self.cfg_var= tk.StringVar(value=self.config_dict["paths"].get("CONFIG_PATH", DEFAULT_PATHS["CONFIG_PATH"]))
        self.par_var= tk.StringVar(value=self.config_dict["paths"].get("PARAMETER_PATH", DEFAULT_PATHS["PARAMETER_PATH"]))
        self.csv_var= tk.StringVar(value=self.config_dict["paths"].get("MASTER_CSV_OUTPUT", DEFAULT_PATHS["MASTER_CSV_OUTPUT"]))

        def mkrow(lbl, var, is_dir=False):
            rowf= ctk.CTkFrame(frm)
            rowf.pack(fill="x", pady=5)
            ctk.CTkLabel(rowf, text=lbl, width=180).pack(side="left", padx=5)
            e = ctk.CTkEntry(rowf, textvariable=var, width=600)
            e.pack(side="left", padx=5)
            def br():
                if is_dir:
                    p= filedialog.askdirectory()
                else:
                    p= filedialog.askopenfilename()
                if p:
                    var.set(p)
            ctk.CTkButton(rowf, text="Browse", command=br,
                          fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)

        mkrow("ERP Excel:", self.erp_var)
        mkrow("Master ZIP:", self.mast_var)
        mkrow("Exception Path:", self.exc_var)
        mkrow("Missing Items Output:", self.out_var)
        mkrow("JSON Config Path:", self.cfg_var)
        mkrow("Parameter File:", self.par_var)
        mkrow("Master CSV Folder:", self.csv_var, is_dir=True)

        bf= ctk.CTkFrame(frm)
        bf.pack(fill="x", pady=10)
        ctk.CTkButton(bf, text="Save Config", command=self.save_all_config,
                      fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)
        ctk.CTkButton(bf, text="Refresh ERP", command=self.refresh_erp,
                      fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)
        ctk.CTkButton(bf, text="Refresh Master", command=self.refresh_master,
                      fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)

    def build_compare_tab(self, parent):
        frm= ctk.CTkFrame(parent)
        frm.pack(fill="both", expand=True, padx=10, pady=10)
        ctk.CTkLabel(frm, text="Generate Missing Items", font=("Arial",16)).pack(pady=5)
        ctk.CTkButton(frm, text="Run Reconciliation", command=self.run_comparison,
                      fg_color="#800020", hover_color="#a52a2a").pack(pady=10)

    def refresh_erp(self):
        # read ERP => meltdown => pivot => preview
        erp_path= Path(self.erp_var.get().strip())
        raw_erp = read_erp_excel(erp_path)
        if raw_erp.empty:
            self.erp_preview.set_data(pd.DataFrame())
            return
        # meltdown param
        param = {
            "dim_erp_keep": self.param_dict.get("dim_erp_keep", set()),
            "dim_erp_map": self.param_dict.get("dim_erp_map", {}),
            "attr_erp_map": self.param_dict.get("attr_erp_map", {})
        }
        melted = meltdown_erp_for_preview(raw_erp, param)
        # pivot
        pivoted = pivot_for_preview(melted)
        self.erp_preview.set_data(pivoted)

    def refresh_master(self):
        zip_path= Path(self.mast_var.get().strip())
        out_dir= Path(self.csv_var.get().strip())
        csvs= convert_master_txt_to_csv(zip_path, out_dir)
        raw_mast = unify_master_csvs(csvs)
        if raw_mast.empty:
            self.master_preview.set_data(pd.DataFrame())
            return
        param = {
            "dim_master_map": self.param_dict.get("dim_master_map", {}),
            "attr_master_map": self.param_dict.get("attr_master_map", {})
        }
        melted = meltdown_master_for_preview(raw_mast, param)
        pivoted = pivot_for_preview(melted)
        self.master_preview.set_data(pivoted)

    def run_comparison(self):
        # get user-filtered wide data from previews
        df_erp_wide = self.erp_preview.get_filtered_df()
        df_mast_wide= self.master_preview.get_filtered_df()

        # melt them back to [Dimension,Name,Attribute,Value]
        erp_long = melt_back(df_erp_wide)
        erp_long = build_keys(erp_long)
        mast_long= melt_back(df_mast_wide)
        mast_long= build_keys(mast_long)

        # compare => missing items
        df_diff= compare_mode2(erp_long, mast_long)

        # exceptions
        exc_path= Path(self.exc_var.get().strip())
        df_exc= read_exception_table(exc_path)
        final= merge_exceptions(df_diff, df_exc)

        # write
        out_path= Path(self.out_var.get().strip())
        write_missing_items(final, out_path)

        # update dash
        run_date= datetime.now().strftime("%Y-%m-%d")
        final["RunDate"] = run_date
        if self.history_df.empty:
            self.history_df= final.copy()
        else:
            self.history_df= pd.concat([self.history_df, final], ignore_index=True)

        self.dashboard_tab.update_data(final, self.history_df)
        self.tabs.select(self.dashboard_tab)

        messagebox.showinfo("Done", f"Missing items => {out_path}")

    def save_all_config(self):
        self.config_dict["paths"]["ERP_EXCEL_PATH"] = self.erp_var.get().strip()
        self.config_dict["paths"]["MASTER_ZIP_PATH"] = self.mast_var.get().strip()
        self.config_dict["paths"]["EXCEPTION_PATH"] = self.exc_var.get().strip()
        self.config_dict["paths"]["OUTPUT_PATH"] = self.out_var.get().strip()
        self.config_dict["paths"]["CONFIG_PATH"] = self.cfg_var.get().strip()
        self.config_dict["paths"]["PARAMETER_PATH"] = self.par_var.get().strip()
        self.config_dict["paths"]["MASTER_CSV_OUTPUT"] = self.csv_var.get().strip()

        save_config(self.config_dict, Path(self.config_dict["paths"]["CONFIG_PATH"]))
        messagebox.showinfo("Saved", "Paths & Config saved successfully.")

def main():
    app= MainApp()
    app.mainloop()

if __name__=="__main__":
    main()
