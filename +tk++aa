"""
ULTRA-MEGA Data Reconciliation Script (Tkinter) with:
  - Scrollable Tabs
  - Edit Button (Single-col & Rename Treeviews)
  - Color-blind–friendly coloring
  - Larger bar charts
  - Hide exception logic
  - Keep logic with Do Not Keep override
  - No 'NaN' in final Key
Single-file solution.
"""

import logging
import os
import zipfile
import tkinter as tk
from tkinter import ttk, filedialog, scrolledtext, simpledialog
from pathlib import Path
from typing import List, Dict, Tuple, Optional

import pandas as pd
import matplotlib
matplotlib.use("Agg")
import matplotlib.pyplot as plt
from openpyxl import load_workbook
from openpyxl.styles import PatternFill, Font
from io import BytesIO
from PIL import Image, ImageTk

# ------------------------------------------------------------------------------
# 0) DEFAULT CONFIG
# ------------------------------------------------------------------------------
DEFAULT_ALFA_PATH = "AlfaData.xlsx"
DEFAULT_GAMMA_PATH = "GammaData.zip"
DEFAULT_EXCEPTION_PATH = "Exception_Table.xlsx"
DEFAULT_OUTPUT_PATH = "Missing_Items.xlsx"

DEFAULT_ALFA_BAD_DIMS = ["AlfaDim1"]
DEFAULT_ALFA_BAD_ATTRS = ["AlfaAttr1"]
DEFAULT_GAMMA_BAD_DIMS = ["GammaDimX"]
DEFAULT_GAMMA_BAD_ATTRS = ["GammaAttrY"]

DEFAULT_ALFA_DIM_RENAMES = [("AlfaDimOld", "AlfaDimNew")]
DEFAULT_ALFA_ATTR_RENAMES = [("AlfaAttrOld", "AlfaAttrNew")]
DEFAULT_GAMMA_DIM_RENAMES = [("GammaDimOld", "GammaDimNew")]
DEFAULT_GAMMA_ATTR_RENAMES = [("GammaAttrOld", "GammaAttrNew")]

# Alfa => Keep(AND), Negative(OR)
DEFAULT_ALFA_KEEP_RULES = [
    ("SomeAlfaColumn", "KeepVal1"),
    ("OtherAlfaCol", "KeepVal2,KeepVal3")
]
DEFAULT_ALFA_NEGATIVE_RULES = [
    ("AlfaColToExclude", "X, Y")
]

# Gamma => Keep(OR), Negative(OR)
DEFAULT_GAMMA_KEEP_RULES = []
DEFAULT_GAMMA_NEGATIVE_RULES = [
    ("GammaColExclude", "BadX, BadY")
]

# ------------------------------------------------------------------------------
# 1) LOG HANDLER FOR TKINTER
# ------------------------------------------------------------------------------
class TextHandler(logging.Handler):
    def __init__(self, text_widget: scrolledtext.ScrolledText):
        super().__init__()
        self.text_widget = text_widget

    def emit(self, record):
        msg = self.format(record)
        self.text_widget.configure(state="normal")
        self.text_widget.insert(tk.END, msg + "\n")
        self.text_widget.configure(state="disabled")
        self.text_widget.see(tk.END)

def setup_logging(log_file: Path, text_widget: scrolledtext.ScrolledText) -> None:
    logger = logging.getLogger()
    logger.setLevel(logging.DEBUG)
    logger.handlers.clear()

    # Console logs
    ch = logging.StreamHandler()
    ch.setLevel(logging.INFO)
    ch.setFormatter(logging.Formatter("%(levelname)s: %(message)s"))
    logger.addHandler(ch)

    # File logs
    fh = logging.FileHandler(log_file, mode="w", encoding="utf-8")
    fh.setLevel(logging.DEBUG)
    fh.setFormatter(logging.Formatter("%(asctime)s - %(levelname)s - %(message)s"))
    logger.addHandler(fh)

    # Tk text logs
    th = TextHandler(text_widget)
    th.setLevel(logging.INFO)
    th.setFormatter(logging.Formatter("%(levelname)s: %(message)s"))
    logger.addHandler(th)

    logging.debug("Logging initialized.")

# ------------------------------------------------------------------------------
# 2) SCROLLABLE FRAME FOR TABS
# ------------------------------------------------------------------------------
class ScrollableFrame(ttk.Frame):
    """
    A frame that adds a vertical scrollbar if contents exceed the visible area.
    """
    def __init__(self, parent, *args, **kwargs):
        super().__init__(parent, *args, **kwargs)

        self.canvas = tk.Canvas(self, highlightthickness=0)
        self.vscrollbar = ttk.Scrollbar(self, orient="vertical", command=self.canvas.yview)
        self.canvas.configure(yscrollcommand=self.vscrollbar.set)

        self.scrollable_area = ttk.Frame(self.canvas)
        self.scrollable_area.bind(
            "<Configure>",
            lambda e: self.canvas.configure(scrollregion=self.canvas.bbox("all"))
        )

        self.canvas.create_window((0,0), window=self.scrollable_area, anchor="nw")

        self.canvas.pack(side="left", fill="both", expand=True)
        self.vscrollbar.pack(side="right", fill="y")

        self.bind("<Configure>", self._on_frame_resized)

    def _on_frame_resized(self, event=None):
        self.canvas.config(width=self.winfo_width(), height=self.winfo_height())

# ------------------------------------------------------------------------------
# 3) FILTER PRE-MELT
# ------------------------------------------------------------------------------
def filter_pre_melt(df: pd.DataFrame, exclude_rules: Optional[List[Tuple[str, List[str]]]] = None) -> pd.DataFrame:
    if not exclude_rules:
        return df
    df = df.copy(deep=True)

    combined_mask = pd.Series(False, index=df.index)
    for col, bad_vals in exclude_rules:
        if col in df.columns:
            mask = df[col].isin(bad_vals)
            combined_mask |= mask
            logging.debug(f"[filter_pre_melt] Excluding {mask.sum()} rows in '{col}' with {bad_vals}")
        else:
            logging.warning(f"[filter_pre_melt] Column '{col}' not found => skip {bad_vals}")

    return df[~combined_mask].copy(deep=True)

# ------------------------------------------------------------------------------
# 4) EXCLUDE DIMENSION ATTRIBUTE
# ------------------------------------------------------------------------------
def exclude_dimension_attribute(df: pd.DataFrame,
                                bad_dims: List[str],
                                bad_attrs: List[str]) -> pd.DataFrame:
    df = df.copy(deep=True)
    if bad_dims:
        initial = len(df)
        df = df[~df["Dimension"].isin(bad_dims)]
        logging.debug(f"[exclude_dimension_attribute] Excluded {initial - len(df)} dims in {bad_dims}")
    if bad_attrs:
        initial = len(df)
        df = df[~df["Attribute"].isin(bad_attrs)]
        logging.debug(f"[exclude_dimension_attribute] Excluded {initial - len(df)} attrs in {bad_attrs}")
    return df

# ------------------------------------------------------------------------------
# 5) READ EXCEPTION TABLE
# ------------------------------------------------------------------------------
def read_exception_table(exc_path: Path) -> pd.DataFrame:
    if not exc_path.is_file():
        logging.warning(f"[read_exception_table] File not found => {exc_path}")
        return pd.DataFrame()
    try:
        df = pd.read_excel(exc_path, sheet_name="Sheet1")
        return df.copy(deep=True)
    except Exception as e:
        logging.exception(f"[read_exception_table] Could not read => {e}")
        return pd.DataFrame()

# ------------------------------------------------------------------------------
# 6) ALFA KEEP & DISALLOW
# ------------------------------------------------------------------------------
def filter_alfa_keep_and_disallow(
    df: pd.DataFrame,
    keep_rules: List[Tuple[str, str]],
    disallow_rules: List[Tuple[str, str]]
) -> pd.DataFrame:
    df = df.copy(deep=True)

    # keep => AND
    if keep_rules:
        combined_mask = pd.Series(True, index=df.index)
        for (col, val_str) in keep_rules:
            if col not in df.columns:
                logging.warning(f"[AlfaKeep] Missing col '{col}' => skip {val_str}")
                continue
            allowed = {x.strip() for x in val_str.split(",") if x.strip()}
            mask = df[col].isin(allowed)
            combined_mask = combined_mask & mask
            logging.debug(f"[AlfaKeep] '{col}' => keep {mask.sum()} in {allowed}")
        df = df[combined_mask].copy(deep=True)

    # disallow => OR
    if disallow_rules:
        combined_mask = pd.Series(False, index=df.index)
        for (col, val_str) in disallow_rules:
            if col not in df.columns:
                logging.warning(f"[AlfaDisallow] Missing '{col}' => skip {val_str}")
                continue
            not_allowed = {x.strip() for x in val_str.split(",") if x.strip()}
            mask = df[col].isin(not_allowed)
            combined_mask = combined_mask | mask
        exclude_count = combined_mask.sum()
        df = df[~combined_mask].copy(deep=True)
        logging.debug(f"[AlfaDisallow] Excluded {exclude_count} by OR logic.")

    return df

# ------------------------------------------------------------------------------
# 7) GAMMA KEEP & DISALLOW
# ------------------------------------------------------------------------------
def filter_gamma_keep_and_disallow(
    df: pd.DataFrame,
    keep_rules: List[Tuple[str, str]],
    disallow_rules: List[Tuple[str, str]]
) -> pd.DataFrame:
    df = df.copy(deep=True)

    # keep => OR
    if keep_rules:
        combined_mask = pd.Series(False, index=df.index)
        for (col, val_str) in keep_rules:
            if col not in df.columns:
                logging.warning(f"[GammaKeep] Missing '{col}' => skip {val_str}")
                continue
            allowed = {x.strip() for x in val_str.split(",") if x.strip()}
            mask = df[col].isin(allowed)
            combined_mask = combined_mask | mask
            logging.debug(f"[GammaKeep] '{col}' => keep {mask.sum()} in {allowed}")
        df = df[combined_mask].copy(deep=True)

    # disallow => OR
    if disallow_rules:
        combined_mask = pd.Series(False, index=df.index)
        for (col, val_str) in disallow_rules:
            if col not in df.columns:
                logging.warning(f"[GammaDisallow] Missing '{col}' => skip {val_str}")
                continue
            not_allowed = {x.strip() for x in val_str.split(",") if x.strip()}
            mask = df[col].isin(not_allowed)
            combined_mask = combined_mask | mask
        exclude_count = combined_mask.sum()
        df = df[~combined_mask].copy(deep=True)
        logging.debug(f"[GammaDisallow] Excluded {exclude_count} by OR logic.")

    return df

# ------------------------------------------------------------------------------
# 8) TRANSFORM ALFA
# ------------------------------------------------------------------------------
def transform_alfa(
    file_path: Path,
    alfa_keep_and: List[Tuple[str, str]],
    alfa_disallow: List[Tuple[str, str]],
    exclude_rules: List[Tuple[str, List[str]]],
    bad_dims: List[str],
    bad_attrs: List[str],
    dim_renames: List[Tuple[str, str]],
    attr_renames: List[Tuple[str, str]],
    sheet_name: str = "Sheet1",
    skip_rows: int = 3
) -> pd.DataFrame:
    if not file_path.is_file():
        logging.error(f"[Alfa] File not found => {file_path}")
        return pd.DataFrame()
    try:
        df = pd.read_excel(file_path, sheet_name=sheet_name, skiprows=skip_rows)
        df = df.copy(deep=True)
        logging.info(f"[Alfa] Loaded {len(df)} from '{file_path.name}'")

        if "Dimension_Name" in df.columns:
            df.rename(columns={"Dimension_Name":"Dimension"}, inplace=True)
        else:
            third_col = df.columns[2]
            df.rename(columns={third_col:"Dimension"}, inplace=True)

        if "Name" not in df.columns:
            fourth_col = df.columns[3]
            df.rename(columns={fourth_col:"Name"}, inplace=True)

        df["RecordID"] = df.index.astype(str)

        df = filter_alfa_keep_and_disallow(df, alfa_keep_and, alfa_disallow)
        df = filter_pre_melt(df, exclude_rules)

        id_vars=["Dimension","RecordID"]
        value_vars=[c for c in df.columns if c not in id_vars]
        melted=df.melt(id_vars=id_vars, value_vars=value_vars, var_name="Attribute", value_name="Value")

        # Renames
        if dim_renames:
            rename_map={}
            for row in dim_renames:
                if len(row)==2:
                    rename_map[row[0]]=row[1]
            melted["Dimension"]=melted["Dimension"].replace(rename_map)
        if attr_renames:
            rename_map={}
            for row in attr_renames:
                if len(row)==2:
                    rename_map[row[0]]=row[1]
            melted["Attribute"]=melted["Attribute"].replace(rename_map)

        melted=exclude_dimension_attribute(melted,bad_dims,bad_attrs)

        ref_df=melted[melted["Attribute"]=="Name"][["RecordID","Value"]].drop_duplicates("RecordID")
        ref_df.rename(columns={"Value":"RefName"}, inplace=True)
        melted=melted.merge(ref_df, on="RecordID", how="left")

        for col in ["Dimension","Attribute","Value","RefName"]:
            melted[col]=melted[col].fillna("").astype(str)

        melted["GroupKey"]=melted["Dimension"].str.strip()+" | "+melted["RefName"].str.strip()
        melted["Key"]=(melted["Dimension"].str.strip()
                       +" | "+melted["RefName"].str.strip()
                       +" | "+melted["Attribute"].str.strip()
                       +" | "+melted["Value"].str.strip())
        melted.drop_duplicates(inplace=True)
        logging.info(f"[Alfa] Final => {len(melted)} rows.")
        return melted
    except Exception as e:
        logging.exception(f"[Alfa] Error => {e}")
        return pd.DataFrame()

# ------------------------------------------------------------------------------
# 9) TRANSFORM GAMMA
# ------------------------------------------------------------------------------
def transform_gamma(
    zip_file_path: Path,
    gamma_keep_or: List[Tuple[str, str]],
    gamma_disallow: List[Tuple[str, str]],
    exclude_rules: List[Tuple[str, List[str]]],
    bad_dims: List[str],
    bad_attrs: List[str],
    dim_renames: List[Tuple[str, str]],
    attr_renames: List[Tuple[str, str]],
    delimiter: str = ",",
    remove_substring: str = "_ceaster.txt",
    encoding: str = "utf-8"
) -> pd.DataFrame:
    if not zip_file_path.is_file():
        logging.error(f"[Gamma] ZIP not found => {zip_file_path}")
        return pd.DataFrame()

    all_dfs=[]
    try:
        with zipfile.ZipFile(zip_file_path,"r") as z:
            txt_files=[f for f in z.namelist() if f.lower().endswith(".txt")]
            if not txt_files:
                logging.warning("[Gamma] No .txt => empty.")
                return pd.DataFrame()

            for txt_file in txt_files:
                try:
                    base_name=os.path.basename(txt_file)
                    if remove_substring in base_name:
                        base_name=base_name.replace(remove_substring,"")
                    else:
                        base_name,_=os.path.splitext(base_name)
                    dimension=base_name.replace("_"," ").strip()

                    with z.open(txt_file) as fo:
                        df=pd.read_csv(fo, delimiter=delimiter, encoding=encoding)
                        df=df.copy(deep=True)
                    if df.empty:
                        logging.warning(f"[Gamma] '{txt_file}' empty => skip.")
                        continue

                    first_col=df.columns[0]
                    df.rename(columns={first_col:"Name"}, inplace=True)
                    df["Name"]=df["Name"].fillna("Unknown").astype(str)

                    df=filter_gamma_keep_and_disallow(df, gamma_keep_or, gamma_disallow)
                    df=filter_pre_melt(df, exclude_rules)

                    df["Dimension"]=dimension
                    df["RecordID"]=df.index.astype(str)

                    id_vars=["Dimension","RecordID"]
                    value_vars=[c for c in df.columns if c not in id_vars]
                    melted=df.melt(id_vars=id_vars,value_vars=value_vars,
                                   var_name="Attribute", value_name="Value")

                    if dim_renames:
                        rename_map={}
                        for row in dim_renames:
                            if len(row)==2:
                                rename_map[row[0]]=row[1]
                        melted["Dimension"]=melted["Dimension"].replace(rename_map)
                    if attr_renames:
                        rename_map={}
                        for row in attr_renames:
                            if len(row)==2:
                                rename_map[row[0]]=row[1]
                        melted["Attribute"]=melted["Attribute"].replace(rename_map)

                    melted=exclude_dimension_attribute(melted,bad_dims,bad_attrs)

                    ref_df=melted[melted["Attribute"]=="Name"][["RecordID","Value"]].drop_duplicates("RecordID")
                    ref_df.rename(columns={"Value":"RefName"}, inplace=True)
                    melted=melted.merge(ref_df, on="RecordID", how="left")

                    for col in ["Dimension","Attribute","Value","RefName"]:
                        melted[col]=melted[col].fillna("").astype(str)

                    melted["GroupKey"]=melted["Dimension"].str.strip()+" | "+melted["RefName"].str.strip()
                    melted["Key"]=(melted["Dimension"].str.strip()
                                   +" | "+melted["RefName"].str.strip()
                                   +" | "+melted["Attribute"].str.strip()
                                   +" | "+melted["Value"].str.strip())
                    melted.drop_duplicates(inplace=True)
                    logging.info(f"[Gamma] '{txt_file}' => {len(melted)} rows.")
                    all_dfs.append(melted.copy(deep=True))
                except Exception as e2:
                    logging.error(f"[Gamma] Error '{txt_file}' => {e2}")
                    continue

        if all_dfs:
            df_gamma=pd.concat(all_dfs, ignore_index=True)
            logging.info(f"[Gamma] Combined => {len(df_gamma)} total.")
            return df_gamma
        else:
            logging.warning("[Gamma] No valid data => empty.")
            return pd.DataFrame()
    except Exception as e:
        logging.exception(f"[Gamma] ZIP read => {e}")
        return pd.DataFrame()

# ------------------------------------------------------------------------------
# 10) CREATE MISSING ITEMS EXCEL
# ------------------------------------------------------------------------------
def create_missing_items_excel(
    df_alfa: pd.DataFrame,
    df_gamma: pd.DataFrame,
    df_exceptions: pd.DataFrame,
    output_path: Path
) -> pd.DataFrame:
    df_missing=pd.DataFrame()
    if "GroupKey" not in df_alfa.columns or "GroupKey" not in df_gamma.columns:
        logging.error("[Missing Items] 'GroupKey' missing => empty df.")
        return df_missing

    def build_map(df: pd.DataFrame)->Dict[str,Dict[str,str]]:
        attr_map={}
        for gk, subdf in df.groupby("GroupKey"):
            row_map={}
            for attr, s_subdf in subdf.groupby("Attribute"):
                row_map[attr] = str(s_subdf["Value"].iloc[0])
            attr_map[gk]=row_map
        return attr_map

    alfa_map=build_map(df_alfa)
    gamma_map=build_map(df_gamma)
    all_keys=set(alfa_map.keys()).union(set(gamma_map.keys()))
    items=[]
    for group_key in all_keys:
        a_dict=alfa_map.get(group_key)
        g_dict=gamma_map.get(group_key)
        parts=group_key.split(" | ", maxsplit=1)
        dimension=parts[0] if len(parts)>0 else ""
        ref_name=parts[1] if len(parts)>1 else ""

        if a_dict is None and g_dict is not None:
            if "Name" in g_dict:
                items.append({
                    "Dimension":dimension,"Name":g_dict["Name"],
                    "Attribute":"Name","Value":g_dict["Name"],
                    "Missing In":"Alfa"
                })
            continue
        if g_dict is None and a_dict is not None:
            if "Name" in a_dict:
                items.append({
                    "Dimension":dimension,"Name":a_dict["Name"],
                    "Attribute":"Name","Value":a_dict["Name"],
                    "Missing In":"Gamma"
                })
            continue

        if a_dict and g_dict:
            has_name_a=("Name" in a_dict)
            has_name_g=("Name" in g_dict)
            if not has_name_a and has_name_g:
                items.append({
                    "Dimension":dimension,"Name":g_dict["Name"],
                    "Attribute":"Name","Value":g_dict["Name"],
                    "Missing In":"Alfa"
                })
                continue
            if not has_name_g and has_name_a:
                items.append({
                    "Dimension":dimension,"Name":a_dict["Name"],
                    "Attribute":"Name","Value":a_dict["Name"],
                    "Missing In":"Gamma"
                })
                continue

            all_attrs=set(a_dict.keys()).union(set(g_dict.keys()))
            if "Name" in all_attrs:
                all_attrs.remove("Name")
            for attr in all_attrs:
                a_val=a_dict.get(attr)
                g_val=g_dict.get(attr)
                if a_val is None and g_val is not None:
                    items.append({
                        "Dimension":dimension,"Name":g_dict["Name"],
                        "Attribute":attr,"Value":g_val,
                        "Missing In":"Alfa"
                    })
                elif g_val is None and a_val is not None:
                    items.append({
                        "Dimension":dimension,"Name":a_dict["Name"],
                        "Attribute":attr,"Value":a_val,
                        "Missing In":"Gamma"
                    })
                elif a_val != g_val:
                    items.append({
                        "Dimension":dimension,"Name":a_dict["Name"],
                        "Attribute":attr,"Value":a_val,
                        "Missing In":"Gamma"
                    })
                    items.append({
                        "Dimension":dimension,"Name":a_dict["Name"],
                        "Attribute":attr,"Value":g_val,
                        "Missing In":"Alfa"
                    })

    df_missing=pd.DataFrame(items)
    logging.info(f"[Missing Items] Found {len(df_missing)} mismatch rows.")

    if df_missing.empty:
        logging.info("[Missing Items] No differences => empty Excel.")
        empty_cols=["Key","Dimension","Name","Attribute","Value","Comments_1","Comments_2","Action Item","Missing In"]
        pd.DataFrame(columns=empty_cols).to_excel(output_path,sheet_name="Missing_Items",index=False)
        return df_missing

    for c in ["Dimension","Name","Attribute","Value"]:
        df_missing[c]=df_missing[c].fillna("")

    df_missing["Key"]= (df_missing["Dimension"].str.strip()
                        +" | "+ df_missing["Name"].str.strip()
                        +" | "+ df_missing["Attribute"].str.strip()
                        +" | "+ df_missing["Value"].str.strip())

    # Hide exception
    if not df_exceptions.empty:
        valid_cols={"Key","Comments_1","Comments_2","hide exception"}
        exc=df_exceptions[[x for x in df_exceptions.columns if x in valid_cols]].copy()
        exc["Key"]=exc["Key"].astype(str).str.strip()
        df_missing=df_missing.merge(exc,on="Key",how="left",suffixes=("","_EXC"))
        df_missing["hide exception"]=df_missing["hide exception"].fillna("no").str.lower()
        before_len=len(df_missing)
        df_missing=df_missing[df_missing["hide exception"]!="yes"]
        after_len=len(df_missing)
        logging.debug(f"[Missing Items] Excluded {before_len - after_len} hidden")

    if "Action Item" not in df_missing.columns:
        df_missing["Action Item"]=""

    final_cols=["Key","Dimension","Name","Attribute","Value","Comments_1","Comments_2","Action Item","Missing In"]
    df_missing=df_missing.reindex(columns=final_cols)

    df_missing.to_excel(output_path, sheet_name="Missing_Items",index=False)
    logging.info(f"[Missing Items] Wrote {len(df_missing)} => {output_path}")

    # color-blind–friendly
    try:
        wb=load_workbook(output_path)
        ws=wb["Missing_Items"]

        header_font=Font(bold=True)
        fill_header=PatternFill(start_color="E0E0E0", end_color="E0E0E0", fill_type="solid")
        fill_gamma=PatternFill(start_color="A6D96A", end_color="A6D96A", fill_type="solid")
        fill_alfa=PatternFill(start_color="67A9CF", end_color="67A9CF", fill_type="solid")

        header_row=next(ws.iter_rows(min_row=1, max_row=1))
        headers={cell.value: cell.column for cell in header_row}
        for cell in header_row:
            cell.font=header_font
            cell.fill=fill_header

        missing_col=headers.get("Missing In")
        if missing_col is None:
            logging.warning("[Missing Items] 'Missing In' col not found => no shading.")
        else:
            max_col=ws.max_column
            for row_idx in range(2,ws.max_row+1):
                val=str(ws.cell(row=row_idx,column=missing_col).value).strip().lower()
                if val=="gamma":
                    fill=fill_gamma
                elif val=="alfa":
                    fill=fill_alfa
                else:
                    fill=None
                if fill:
                    for col_idx in range(1,max_col+1):
                        ws.cell(row=row_idx,column=col_idx).fill=fill

        ws.freeze_panes="A2"
        wb.save(output_path)
        logging.info("[Missing Items] Applied color-blind–friendly colors.")
    except Exception as e:
        logging.exception(f"[Missing Items] Excel color error => {e}")

    return df_missing

# ------------------------------------------------------------------------------
# 11) CREATE DISCREPANCY GRAPHS (BIGGER)
# ------------------------------------------------------------------------------
def create_discrepancy_graphs(df_missing: pd.DataFrame) -> Dict[str, ImageTk.PhotoImage]:
    images={}
    if df_missing.empty:
        return images

    from io import BytesIO
    from PIL import Image, ImageTk

    # By dimension => bigger
    by_dim=df_missing.groupby("Dimension").size().reset_index(name="Count")
    fig1,ax1=plt.subplots(figsize=(7,4))
    ax1.bar(by_dim["Dimension"], by_dim["Count"], color="#5698c4")
    ax1.set_title("Discrepancies by Dimension", fontsize=12)
    ax1.tick_params(axis='x',rotation=45)
    fig1.tight_layout()
    buf1=BytesIO()
    fig1.savefig(buf1,format="png",dpi=100)
    buf1.seek(0)
    img1=Image.open(buf1)
    images["by_dimension"]=ImageTk.PhotoImage(img1)
    plt.close(fig1)

    # By Missing In => bigger
    by_miss=df_missing.groupby("Missing In").size().reset_index(name="Count")
    fig2,ax2=plt.subplots(figsize=(7,4))
    ax2.bar(by_miss["Missing In"], by_miss["Count"], color="#a6d96a")
    ax2.set_title("Discrepancies by 'Missing In'", fontsize=12)
    ax2.tick_params(axis='x',rotation=0)
    fig2.tight_layout()
    buf2=BytesIO()
    fig2.savefig(buf2,format="png",dpi=100)
    buf2.seek(0)
    img2=Image.open(buf2)
    images["by_missing"]=ImageTk.PhotoImage(img2)
    plt.close(fig2)

    # By Attribute => bigger
    by_attr=df_missing.groupby("Attribute").size().reset_index(name="Count")
    fig3,ax3=plt.subplots(figsize=(7,4))
    ax3.bar(by_attr["Attribute"], by_attr["Count"], color="#fdb863")
    ax3.set_title("Discrepancies by Attribute", fontsize=12)
    ax3.tick_params(axis='x',rotation=45)
    fig3.tight_layout()
    buf3=BytesIO()
    fig3.savefig(buf3,format="png",dpi=100)
    buf3.seek(0)
    img3=Image.open(buf3)
    images["by_attribute"]=ImageTk.PhotoImage(img3)
    plt.close(fig3)

    return images

# ------------------------------------------------------------------------------
# 12) MASTER RUN
# ------------------------------------------------------------------------------
def run_reconciliation(
    alfa_path: Path,
    gamma_path: Path,
    exc_path: Optional[Path],
    alfa_bad_dims: List[str],
    alfa_bad_attrs: List[str],
    gamma_bad_dims: List[str],
    gamma_bad_attrs: List[str],
    alfa_dim_renames: List[Tuple[str, str]],
    alfa_attr_renames: List[Tuple[str, str]],
    gamma_dim_renames: List[Tuple[str, str]],
    gamma_attr_renames: List[Tuple[str, str]],
    alfa_keep_and: List[Tuple[str, str]],
    alfa_disallow: List[Tuple[str, str]],
    gamma_keep_or: List[Tuple[str, str]],
    gamma_disallow: List[Tuple[str, str]],
    output_path: Path,
    progress_callback=None
) -> pd.DataFrame:
    step=0
    def step_incr():
        nonlocal step
        step+=1
        if progress_callback:
            progress_callback(step)

    step_incr()
    df_exceptions=pd.DataFrame()
    if exc_path and exc_path.is_file():
        df_exceptions=read_exception_table(exc_path)

    exclude_rules=[]

    step_incr()
    df_alfa=transform_alfa(
        file_path=alfa_path,
        alfa_keep_and=alfa_keep_and,
        alfa_disallow=alfa_disallow,
        exclude_rules=exclude_rules,
        bad_dims=alfa_bad_dims,
        bad_attrs=alfa_bad_attrs,
        dim_renames=alfa_dim_renames,
        attr_renames=alfa_attr_renames
    )

    step_incr()
    df_gamma=transform_gamma(
        zip_file_path=gamma_path,
        gamma_keep_or=gamma_keep_or,
        gamma_disallow=gamma_disallow,
        exclude_rules=exclude_rules,
        bad_dims=gamma_bad_dims,
        bad_attrs=gamma_bad_attrs,
        dim_renames=gamma_dim_renames,
        attr_renames=gamma_attr_renames
    )

    step_incr()
    df_missing=create_missing_items_excel(df_alfa, df_gamma, df_exceptions, output_path)

    step_incr()
    return df_missing

# ------------------------------------------------------------------------------
# 13) MAIN TKINTER APP
# ------------------------------------------------------------------------------
class ReconciliationApp(tk.Tk):
    """
    Each tab is a ScrollableFrame => vertical scroll.
    We add "Edit" buttons in single-col and two-col treeviews.
    """
    def __init__(self):
        super().__init__()
        self.title("ULTRA-MEGA Data Reconciliation (Scrollable + Edit Buttons + Larger Graphs)")
        self.geometry("1100x900")

        style=ttk.Style(self)
        style.theme_use("clam")

        self.notebook=ttk.Notebook(self)
        self.notebook.pack(expand=True, fill="both")

        self.tab_paths=ScrollableFrame(self.notebook)
        self.tab_exclusions=ScrollableFrame(self.notebook)
        self.tab_keep=ScrollableFrame(self.notebook)
        self.tab_run=ScrollableFrame(self.notebook)
        self.tab_graphs=ScrollableFrame(self.notebook)

        self.notebook.add(self.tab_paths, text="Paths")
        self.notebook.add(self.tab_exclusions, text="Exclusions & Renames")
        self.notebook.add(self.tab_keep, text="Keep-Only Rules")
        self.notebook.add(self.tab_run, text="Run & Progress")
        self.notebook.add(self.tab_graphs, text="Graphs & Analysis")

        # Build UI in each scrollable_area
        self.build_tab_paths(self.tab_paths.scrollable_area)
        self.build_tab_exclusions(self.tab_exclusions.scrollable_area)
        self.build_tab_keep(self.tab_keep.scrollable_area)
        self.build_tab_run(self.tab_run.scrollable_area)
        self.build_tab_graphs(self.tab_graphs.scrollable_area)

        # Logging area
        log_frame=ttk.Frame(self)
        log_frame.pack(expand=True, fill="both")
        ttk.Label(log_frame, text="Log Output:", font=("TkDefaultFont",10,"bold")).pack(anchor="w")
        self.scrolled_log=scrolledtext.ScrolledText(log_frame, state="disabled", height=10)
        self.scrolled_log.pack(expand=True, fill="both", padx=5, pady=5)

        setup_logging(Path("script.log"), self.scrolled_log)
        self.df_missing=pd.DataFrame()

        # Populate
        self.populate_defaults()

    # 13a) BUILD TAB PATHS
    def build_tab_paths(self, parent: ttk.Frame):
        row=0
        ttk.Label(parent, text="Alfa Excel (.xlsx):").grid(row=row, column=0, sticky="w", padx=5, pady=5)
        self.entry_alfa = ttk.Entry(parent, width=70)
        self.entry_alfa.insert(0, DEFAULT_ALFA_PATH)
        self.entry_alfa.grid(row=row, column=1, padx=5, pady=5)
        ttk.Button(parent, text="Browse", command=self.on_browse_alfa).grid(row=row, column=2, padx=5, pady=5)
        row+=1

        ttk.Label(parent, text="Gamma ZIP (.zip):").grid(row=row, column=0, sticky="w", padx=5, pady=5)
        self.entry_gamma = ttk.Entry(parent, width=70)
        self.entry_gamma.insert(0, DEFAULT_GAMMA_PATH)
        self.entry_gamma.grid(row=row, column=1, padx=5, pady=5)
        ttk.Button(parent, text="Browse", command=self.on_browse_gamma).grid(row=row, column=2, padx=5, pady=5)
        row+=1

        ttk.Label(parent, text="Exception Table (optional):").grid(row=row, column=0, sticky="w", padx=5, pady=5)
        self.entry_exc = ttk.Entry(parent, width=70)
        self.entry_exc.insert(0, DEFAULT_EXCEPTION_PATH)
        self.entry_exc.grid(row=row, column=1, padx=5, pady=5)
        ttk.Button(parent, text="Browse", command=self.on_browse_exc).grid(row=row, column=2, padx=5, pady=5)
        row+=1

        ttk.Label(parent, text="Output Missing Items (.xlsx):").grid(row=row, column=0, sticky="w", padx=5, pady=5)
        self.entry_out = ttk.Entry(parent, width=70)
        self.entry_out.insert(0, DEFAULT_OUTPUT_PATH)
        self.entry_out.grid(row=row, column=1, padx=5, pady=5)
        ttk.Button(parent, text="Browse", command=self.on_browse_out).grid(row=row, column=2, padx=5, pady=5)

    # 13b) BUILD TAB EXCLUSIONS & RENAMES
    def build_tab_exclusions(self, parent: ttk.Frame):
        frm_ex = ttk.Frame(parent)
        frm_ex.pack(expand=True, fill="both", padx=5, pady=5)

        self.tv_alfa_bad_dims = self.make_singlecol_tree(frm_ex, "Alfa Bad Dims", 0)
        self.tv_alfa_bad_attrs= self.make_singlecol_tree(frm_ex, "Alfa Bad Attrs", 1)
        self.tv_gamma_bad_dims= self.make_singlecol_tree(frm_ex, "Gamma Bad Dims", 2)
        self.tv_gamma_bad_attrs= self.make_singlecol_tree(frm_ex, "Gamma Bad Attrs", 3)

        frm_rn = ttk.Frame(parent)
        frm_rn.pack(expand=True, fill="both", padx=5, pady=5)

        self.tv_alfa_dim_ren= self.make_twocol_tree(frm_rn, "Alfa Dim Renames", 0)
        self.tv_alfa_attr_ren= self.make_twocol_tree(frm_rn, "Alfa Attr Renames", 1)
        self.tv_gamma_dim_ren= self.make_twocol_tree(frm_rn, "Gamma Dim Renames", 2)
        self.tv_gamma_attr_ren= self.make_twocol_tree(frm_rn, "Gamma Attr Renames", 3)

    def make_singlecol_tree(self, parent: ttk.Frame, label_text: str, row_idx: int) -> ttk.Treeview:
        lbl=ttk.Label(parent, text=label_text, font=("TkDefaultFont",9,"bold"))
        lbl.grid(row=row_idx, column=0, sticky="w", pady=5)

        frame_tree = ttk.Frame(parent)
        frame_tree.grid(row=row_idx, column=1, sticky="nw", padx=5)

        tv = ttk.Treeview(frame_tree, columns=("Value",), show="headings", height=4)
        tv.heading("Value", text="Value")
        tv.column("Value", width=200)

        scroll_y = ttk.Scrollbar(frame_tree, orient="vertical", command=tv.yview)
        tv.configure(yscrollcommand=scroll_y.set)
        scroll_y.pack(side="right", fill="y")
        tv.pack(side="left", fill="both", expand=True)

        frame_btn = ttk.Frame(parent)
        frame_btn.grid(row=row_idx, column=2, sticky="n", padx=5)
        ttk.Button(frame_btn, text="Add", command=lambda: self.on_add_value(tv)).pack(side="top", fill="x", pady=2)
        ttk.Button(frame_btn, text="Edit", command=lambda: self.on_edit_singlecol(tv)).pack(side="top", fill="x", pady=2)
        ttk.Button(frame_btn, text="Remove", command=lambda: self.on_remove_item(tv)).pack(side="top", fill="x")

        return tv

    def on_add_value(self, tv: ttk.Treeview):
        val = simpledialog.askstring("Add Value", "Enter a new value:")
        if val and val.strip():
            tv.insert("", tk.END, values=(val.strip(),))

    def on_edit_singlecol(self, tv: ttk.Treeview):
        selection = tv.selection()
        if not selection:
            return
        item_id = selection[0]
        row_vals = tv.item(item_id, "values")
        if row_vals and len(row_vals)==1:
            old_val=row_vals[0]
            new_val=simpledialog.askstring("Edit Value", f"Current: {old_val}\nEnter new value:", initialvalue=old_val)
            if new_val is not None and new_val.strip():
                tv.item(item_id, values=(new_val.strip(),))

    def make_twocol_tree(self, parent: ttk.Frame, label_text: str, row_idx: int) -> ttk.Treeview:
        lbl=ttk.Label(parent, text=label_text, font=("TkDefaultFont",9,"bold"))
        lbl.grid(row=row_idx, column=0, sticky="w", pady=5)

        frame_tree = ttk.Frame(parent)
        frame_tree.grid(row=row_idx, column=1, sticky="nw", padx=5)

        tv = ttk.Treeview(frame_tree, columns=("Old","New"), show="headings", height=4)
        tv.heading("Old", text="Old Value")
        tv.heading("New", text="New Value")
        tv.column("Old", width=100)
        tv.column("New", width=100)

        scroll_y = ttk.Scrollbar(frame_tree, orient="vertical", command=tv.yview)
        tv.configure(yscrollcommand=scroll_y.set)
        scroll_y.pack(side="right", fill="y")
        tv.pack(side="left", fill="both", expand=True)

        frame_btn=ttk.Frame(parent)
        frame_btn.grid(row=row_idx, column=2, sticky="n", padx=5)
        ttk.Button(frame_btn, text="Add", command=lambda: self.on_add_rename(tv)).pack(side="top", fill="x", pady=2)
        ttk.Button(frame_btn, text="Edit", command=lambda: self.on_edit_rename(tv)).pack(side="top", fill="x", pady=2)
        ttk.Button(frame_btn, text="Remove", command=lambda: self.on_remove_item(tv)).pack(side="top", fill="x")

        return tv

    def on_add_rename(self, tv: ttk.Treeview):
        oldval=simpledialog.askstring("Add Rename","Enter OLD name:")
        if not oldval or not oldval.strip():
            return
        newval=simpledialog.askstring("Add Rename",f"Enter NEW name for '{oldval}':", initialvalue="")
        if newval is None or not newval.strip():
            return
        tv.insert("", tk.END, values=(oldval.strip(), newval.strip()))

    def on_edit_rename(self, tv: ttk.Treeview):
        selection = tv.selection()
        if not selection:
            return
        item_id = selection[0]
        row_vals = tv.item(item_id, "values")
        if row_vals and len(row_vals)==2:
            old_old = row_vals[0]
            old_new = row_vals[1]

            # Ask new "Old" value
            new_old = simpledialog.askstring("Edit Rename", f"OLD value:", initialvalue=old_old)
            if new_old is None or not new_old.strip():
                return
            # Ask new "New" value
            new_new = simpledialog.askstring("Edit Rename", f"NEW value for '{new_old}':", initialvalue=old_new)
            if new_new is None or not new_new.strip():
                return

            tv.item(item_id, values=(new_old.strip(), new_new.strip()))

    def on_remove_item(self, tv: ttk.Treeview):
        selection = tv.selection()
        for sel in selection:
            tv.delete(sel)

    # 13c) BUILD TAB KEEP
    def build_tab_keep(self, parent: ttk.Frame):
        frm=ttk.Frame(parent)
        frm.pack(expand=True, fill="both", padx=5, pady=5)

        self.tv_alfa_keep = self.make_keep_tree(frm, "Alfa Keep (AND)", 0)
        self.tv_alfa_neg  = self.make_keep_tree(frm, "Alfa DoNotKeep (OR)", 1)
        self.tv_gamma_keep= self.make_keep_tree(frm, "Gamma Keep (OR)", 2)
        self.tv_gamma_neg = self.make_keep_tree(frm, "Gamma DoNotKeep (OR)", 3)

    def make_keep_tree(self, parent: ttk.Frame, label_text: str, row_idx: int) -> ttk.Treeview:
        lbl=ttk.Label(parent, text=label_text, font=("TkDefaultFont",9,"bold"))
        lbl.grid(row=row_idx, column=0, sticky="w", pady=5)

        frame_tree = ttk.Frame(parent)
        frame_tree.grid(row=row_idx, column=1, sticky="nw", padx=5)

        tv = ttk.Treeview(frame_tree, columns=("Column","Values"), show="headings", height=4)
        tv.heading("Column", text="Column Name")
        tv.heading("Values", text="Values (comma-sep)")
        tv.column("Column", width=120)
        tv.column("Values", width=180)

        scroll_y = ttk.Scrollbar(frame_tree, orient="vertical", command=tv.yview)
        tv.configure(yscrollcommand=scroll_y.set)
        scroll_y.pack(side="right", fill="y")
        tv.pack(side="left", fill="both", expand=True)

        frame_btn = ttk.Frame(parent)
        frame_btn.grid(row=row_idx, column=2, sticky="n", padx=5)

        ttk.Button(frame_btn, text="Add", command=lambda: self.on_add_keeprule(tv)).pack(side="top", fill="x", pady=2)
        ttk.Button(frame_btn, text="Edit", command=lambda: self.on_edit_keeprule(tv)).pack(side="top", fill="x", pady=2)
        ttk.Button(frame_btn, text="Remove", command=lambda: self.on_remove_item(tv)).pack(side="top", fill="x")

        return tv

    def on_add_keeprule(self, tv: ttk.Treeview):
        colname = simpledialog.askstring("Keep Rule","Enter column name:")
        if not colname or not colname.strip():
            return
        valstr = simpledialog.askstring("Keep Rule",f"Enter comma-sep values for '{colname}':")
        if valstr is None:
            return
        tv.insert("", tk.END, values=(colname.strip(), valstr.strip()))

    def on_edit_keeprule(self, tv: ttk.Treeview):
        selection=tv.selection()
        if not selection:
            return
        item_id=selection[0]
        row_vals=tv.item(item_id,"values")
        if row_vals and len(row_vals)==2:
            old_col=row_vals[0]
            old_vals=row_vals[1]

            new_col = simpledialog.askstring("Edit Keep Rule", "Column Name:", initialvalue=old_col)
            if new_col is None or not new_col.strip():
                return
            new_vals= simpledialog.askstring("Edit Keep Rule", f"Values (comma-sep) for '{new_col}':", initialvalue=old_vals)
            if new_vals is None or not new_vals.strip():
                return

            tv.item(item_id, values=(new_col.strip(), new_vals.strip()))

    # 13d) BUILD TAB RUN
    def build_tab_run(self, parent: ttk.Frame):
        ttk.Label(parent, text="Click 'Run' to start.").pack(anchor="w", padx=5, pady=5)

        self.progress_bar = ttk.Progressbar(parent, orient="horizontal", length=600, mode="determinate")
        self.progress_bar.pack(pady=5)
        self.progress_bar["maximum"] = 5

        frm_btn=ttk.Frame(parent)
        frm_btn.pack(pady=5)
        ttk.Button(frm_btn, text="Run", command=self.on_run_clicked).pack(side="left", padx=5)
        ttk.Button(frm_btn, text="Exit", command=self.destroy).pack(side="left", padx=5)

        self.label_status=ttk.Label(parent, text="", foreground="blue")
        self.label_status.pack(anchor="w", padx=5, pady=5)

    # 13e) BUILD TAB GRAPHS
    def build_tab_graphs(self, parent: ttk.Frame):
        ttk.Label(parent, text="Discrepancies by Dimension", font=("TkDefaultFont",10,"bold")).pack(padx=5,pady=5)
        self.canvas_graph_dim=ttk.Label(parent)
        self.canvas_graph_dim.pack(padx=5,pady=5)

        ttk.Label(parent, text="Discrepancies by 'Missing In'", font=("TkDefaultFont",10,"bold")).pack(padx=5,pady=5)
        self.canvas_graph_missing=ttk.Label(parent)
        self.canvas_graph_missing.pack(padx=5,pady=5)

        ttk.Label(parent, text="Discrepancies by Attribute", font=("TkDefaultFont",10,"bold")).pack(padx=5,pady=5)
        self.canvas_graph_attr=ttk.Label(parent)
        self.canvas_graph_attr.pack(padx=5,pady=5)

    # ----------------------
    # Populate
    # ----------------------
    def populate_defaults(self):
        # Exclusions
        for val in DEFAULT_ALFA_BAD_DIMS:
            self.tv_alfa_bad_dims.insert("", tk.END, values=(val,))
        for val in DEFAULT_ALFA_BAD_ATTRS:
            self.tv_alfa_bad_attrs.insert("", tk.END, values=(val,))
        for val in DEFAULT_GAMMA_BAD_DIMS:
            self.tv_gamma_bad_dims.insert("", tk.END, values=(val,))
        for val in DEFAULT_GAMMA_BAD_ATTRS:
            self.tv_gamma_bad_attrs.insert("", tk.END, values=(val,))

        # Renames
        for (o,n) in DEFAULT_ALFA_DIM_RENAMES:
            self.tv_alfa_dim_ren.insert("", tk.END, values=(o,n))
        for (o,n) in DEFAULT_ALFA_ATTR_RENAMES:
            self.tv_alfa_attr_ren.insert("", tk.END, values=(o,n))
        for (o,n) in DEFAULT_GAMMA_DIM_RENAMES:
            self.tv_gamma_dim_ren.insert("", tk.END, values=(o,n))
        for (o,n) in DEFAULT_GAMMA_ATTR_RENAMES:
            self.tv_gamma_attr_ren.insert("", tk.END, values=(o,n))

        # Keep
        for (c,v) in DEFAULT_ALFA_KEEP_RULES:
            self.tv_alfa_keep.insert("", tk.END, values=(c,v))
        for (c,v) in DEFAULT_ALFA_NEGATIVE_RULES:
            self.tv_alfa_neg.insert("", tk.END, values=(c,v))
        for (c,v) in DEFAULT_GAMMA_KEEP_RULES:
            self.tv_gamma_keep.insert("", tk.END, values=(c,v))
        for (c,v) in DEFAULT_GAMMA_NEGATIVE_RULES:
            self.tv_gamma_neg.insert("", tk.END, values=(c,v))

    # ----------------------
    # Gathering
    # ----------------------
    def gather_singlecol(self, tv: ttk.Treeview) -> List[str]:
        out=[]
        for child in tv.get_children():
            row=tv.item(child,"values")
            if row and len(row)==1:
                out.append(row[0])
        return out

    def gather_twocol(self, tv: ttk.Treeview) -> List[Tuple[str,str]]:
        out=[]
        for child in tv.get_children():
            row=tv.item(child,"values")
            if row and len(row)==2:
                oldval=row[0].strip()
                newval=row[1].strip()
                if oldval and newval:
                    out.append((oldval,newval))
        return out

    def gather_keep_rules(self, tv: ttk.Treeview) -> List[Tuple[str,str]]:
        out=[]
        for child in tv.get_children():
            row=tv.item(child,"values")
            if row and len(row)==2:
                col=row[0].strip()
                valstr=row[1].strip()
                if col and valstr:
                    out.append((col,valstr))
        return out

    # ----------------------
    # Browsers
    # ----------------------
    def on_browse_alfa(self):
        path=filedialog.askopenfilename(filetypes=[("Excel Files","*.xlsx"),("All Files","*.*")])
        if path:
            self.entry_alfa.delete(0, tk.END)
            self.entry_alfa.insert(0, path)

    def on_browse_gamma(self):
        path=filedialog.askopenfilename(filetypes=[("ZIP Files","*.zip"),("All Files","*.*")])
        if path:
            self.entry_gamma.delete(0, tk.END)
            self.entry_gamma.insert(0, path)

    def on_browse_exc(self):
        path=filedialog.askopenfilename(filetypes=[("Excel Files","*.xlsx"),("All Files","*.*")])
        if path:
            self.entry_exc.delete(0, tk.END)
            self.entry_exc.insert(0, path)

    def on_browse_out(self):
        path=filedialog.asksaveasfilename(defaultextension=".xlsx",
                                          filetypes=[("Excel Files","*.xlsx"),("All Files","*.*")])
        if path:
            self.entry_out.delete(0, tk.END)
            self.entry_out.insert(0, path)

    # ----------------------
    # RUN
    # ----------------------
    def on_run_clicked(self):
        logging.info("[GUI] 'Run' clicked.")
        self.progress_bar["value"]=0
        self.label_status.configure(text="", foreground="blue")
        self.update_idletasks()

        alfa_path_str=self.entry_alfa.get().strip()
        gamma_path_str=self.entry_gamma.get().strip()
        exc_path_str=self.entry_exc.get().strip()
        out_path_str=self.entry_out.get().strip()

        if not alfa_path_str or not os.path.isfile(alfa_path_str):
            self.label_status.configure(text="Error: invalid Alfa path", foreground="red")
            return
        if not gamma_path_str or not os.path.isfile(gamma_path_str):
            self.label_status.configure(text="Error: invalid Gamma path", foreground="red")
            return
        if not out_path_str.lower().endswith(".xlsx"):
            out_path_str += ".xlsx"

        # gather
        alfa_bd = self.gather_singlecol(self.tv_alfa_bad_dims)
        alfa_ba = self.gather_singlecol(self.tv_alfa_bad_attrs)
        gamma_bd= self.gather_singlecol(self.tv_gamma_bad_dims)
        gamma_ba= self.gather_singlecol(self.tv_gamma_bad_attrs)

        alfa_dr= self.gather_twocol(self.tv_alfa_dim_ren)
        alfa_ar= self.gather_twocol(self.tv_alfa_attr_ren)
        gamma_dr=self.gather_twocol(self.tv_gamma_dim_ren)
        gamma_ar=self.gather_twocol(self.tv_gamma_attr_ren)

        alfa_keep= self.gather_keep_rules(self.tv_alfa_keep)
        alfa_neg = self.gather_keep_rules(self.tv_alfa_neg)
        gamma_keep= self.gather_keep_rules(self.tv_gamma_keep)
        gamma_neg = self.gather_keep_rules(self.tv_gamma_neg)

        def progress_callback(step: int):
            self.progress_bar["value"]=step
            self.update_idletasks()

        self.label_status.configure(text="Processing... please wait.", foreground="blue")
        self.update_idletasks()

        try:
            from pathlib import Path
            df_missing=run_reconciliation(
                alfa_path=Path(alfa_path_str),
                gamma_path=Path(gamma_path_str),
                exc_path=Path(exc_path_str) if exc_path_str and os.path.isfile(exc_path_str) else None,
                alfa_bad_dims=alfa_bd,
                alfa_bad_attrs=alfa_ba,
                gamma_bad_dims=gamma_bd,
                gamma_bad_attrs=gamma_ba,
                alfa_dim_renames=alfa_dr,
                alfa_attr_renames=alfa_ar,
                gamma_dim_renames=gamma_dr,
                gamma_attr_renames=gamma_ar,
                alfa_keep_and=alfa_keep,
                alfa_disallow=alfa_neg,
                gamma_keep_or=gamma_keep,
                gamma_disallow=gamma_neg,
                output_path=Path(out_path_str),
                progress_callback=progress_callback
            )
            self.df_missing=df_missing
            self.label_status.configure(
                text=f"Done! Results => '{out_path_str}'. Check 'Graphs & Analysis' tab.",
                foreground="green"
            )
            self.generate_and_display_graphs()
        except Exception as e:
            logging.exception(f"[GUI] Error => {e}")
            self.label_status.configure(text=f"Error => {e}", foreground="red")

    def generate_and_display_graphs(self):
        for w in (self.canvas_graph_dim,self.canvas_graph_missing,self.canvas_graph_attr):
            w.config(image="")
            w.image=None

        if self.df_missing.empty:
            logging.info("[GUI] No mismatches => no graphs.")
            return

        images=create_discrepancy_graphs(self.df_missing)
        if "by_dimension" in images:
            self.canvas_graph_dim.config(image=images["by_dimension"])
            self.canvas_graph_dim.image=images["by_dimension"]
        if "by_missing" in images:
            self.canvas_graph_missing.config(image=images["by_missing"])
            self.canvas_graph_missing.image=images["by_missing"]
        if "by_attribute" in images:
            self.canvas_graph_attr.config(image=images["by_attribute"])
            self.canvas_graph_attr.image=images["by_attribute"]

def main():
    app=ReconciliationApp()
    app.mainloop()

if __name__=="__main__":
    main()
