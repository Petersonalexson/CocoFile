#!/usr/bin/env python3
"""
Ultra-Mega Reconciliation
Key Points:
 - Internally, meltdown maps V_S_C/FileName => the full dimension name from param,
   so the comparison uses the full dimension name.
 - In the final missing_items.xlsx, we rename dimension to the short "V_S_C" code
   (the short code) for appearance in the Mismatch/Case_Differences sheets.
 - 2-sheet Excel (Mismatch & Case_Differences), with columns:
   Key, Dimension, Name, Attribute, Master, ERP, Comments_1, Comments_2, Gap In
 - 8-chart dashboard, each with mplcursors hover if installed.
 - History double-click => Show Summary or Load Data for Charts. The band chart
   always includes the entire history, while the other charts use the loaded run.
 - No date filters in the GUI; End Date is automatically filtered (blank or future).
"""

import os
import json
import math
import logging
import zipfile
import shutil
import io
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, List, Set, Tuple

import tkinter as tk
from tkinter import ttk, filedialog, messagebox
import customtkinter as ctk

import pandas as pd
import numpy as np

import matplotlib
matplotlib.use("TkAgg")
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg
from matplotlib.backends.backend_pdf import PdfPages

try:
    import mplcursors
    MPLCURSORS_AVAILABLE = True
except ImportError:
    MPLCURSORS_AVAILABLE = False

from openpyxl import Workbook
from openpyxl.styles import PatternFill, Font, Alignment

logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")

# ----------------------------------------------------------------------------
# CONFIG & SAVE/LOAD
# ----------------------------------------------------------------------------
DEFAULT_PATHS = {
    "ERP_EXCEL_PATH": "data/ERP_Config.xlsx",
    "MASTER_ZIP_PATH": "data/Master_Config.zip",
    "EXCEPTION_PATH": "data/Exception_Table.xlsx",
    "OUTPUT_PATH": "output/missing_items.xlsx",
    "CONFIG_PATH": "config/ui_config.json",   # hidden in GUI
    "PARAMETER_PATH": "data/parameters.xlsx",
    "MASTER_CSV_OUTPUT": "temp_master_csv",   # hidden
    "PDF_EXPORT_PATH": "output/dashboard_report.pdf",
    "LOGO_PATH": "images/company_logo.png",   # hidden
    "HISTORY_PATH": "history_runs",           # hidden
    "BAND_CHART_JSON_PATH": "data/bollinger_data.json"  # hidden
}

def default_config() -> Dict:
    return {
        "paths": DEFAULT_PATHS.copy(),
        "erp_grid": {"filters": {}},
        "master_grid": {"filters": {}},
        "dashboard_state": {
            "selected_dims": [],
            "selected_attrs": [],
            "top_n": 10
        }
    }

def load_config(path: Path) -> Dict:
    if path.is_file():
        try:
            with open(path,"r",encoding="utf-8") as f:
                return json.load(f)
        except Exception as e:
            logging.warning(f"Cannot load config => {e}")
    return default_config()

def save_config(cfg: Dict, path: Path):
    path.parent.mkdir(parents=True, exist_ok=True)
    try:
        with open(path,"w",encoding="utf-8") as f:
            json.dump(cfg, f, indent=2)
        logging.info(f"Saved config => {path}")
    except Exception as e:
        logging.error(f"Error saving config => {e}")

# ----------------------------------------------------------------------------
# LOGGING
# ----------------------------------------------------------------------------
class TextHandler(logging.Handler):
    def __init__(self, widget: ctk.CTkTextbox):
        super().__init__()
        self.widget= widget
    def emit(self, record):
        msg= self.format(record) + "\n"
        self.widget.after(0, self._append, msg)
    def _append(self, msg):
        self.widget.configure(state="normal")
        self.widget.insert("end",msg)
        self.widget.see("end")
        self.widget.configure(state="disabled")

# ----------------------------------------------------------------------------
# MPLCURSORS
# ----------------------------------------------------------------------------
def enable_hover(ax, polar=False):
    if not MPLCURSORS_AVAILABLE:
        return
    cursor= mplcursors.cursor(ax, hover=True)
    @cursor.connect("add")
    def on_add(sel):
        coords= sel.target
        if polar:
            # (theta, r)
            sel.annotation.set_text(f"r={coords[1]:.0f}")
        else:
            if isinstance(coords,(tuple,list)) and len(coords)==2:
                xval, yval= coords
                sel.annotation.set_text(f"{yval:.0f}")
            else:
                sel.annotation.set_text(str(coords))

# ----------------------------------------------------------------------------
# PARAM
# ----------------------------------------------------------------------------
def read_param_file(path: Path)-> Dict[str,object]:
    param= {
        "dim_erp_keep": set(),
        "dim_erp_map": {},      # vsc => FullDimensionName
        "dim_master_map": {},   # filename => FullDimensionName
        "attr_erp_map": {},
        "attr_master_map": {}
    }
    if not path.is_file():
        logging.warning(f"Param not found => {path}")
        return param
    try:
        dim_df= pd.read_excel(path, sheet_name="Dimension Parameters")
        dim_df.columns= dim_df.columns.astype(str).str.strip()

        def s(x): return str(x).strip() if pd.notna(x) else ""

        for _, row in dim_df.iterrows():
            fn= s(row.get("FileName",""))
            vsc= s(row.get("V S C",""))
            dim= s(row.get("Dimension",""))
            ev=  s(row.get("ERP Values",""))
            if ev.lower()=="x" and vsc and dim:
                param["dim_erp_keep"].add(vsc)
                param["dim_erp_map"][vsc]= dim
            if fn and dim and ev.lower()=="x":
                param["dim_master_map"][fn]= dim

        attr_df= pd.read_excel(path, sheet_name="Attribute Parameters")
        attr_df.columns= attr_df.columns.astype(str).str.strip()
        for _, row in attr_df.iterrows():
            e_orig= s(row.get("ERP Original Attributes",""))
            m_orig= s(row.get("Master Original Attributes",""))
            final_= s(row.get("Attribute",""))
            onoff= s(row.get("On/Off",""))
            if onoff.lower()=="x" and final_:
                if e_orig:
                    param["attr_erp_map"][e_orig]= final_
                if m_orig:
                    param["attr_master_map"][m_orig]= final_
        return param
    except Exception as e:
        logging.error(f"Error reading param => {e}")
        return param

# ----------------------------------------------------------------------------
# ERP reading
# ----------------------------------------------------------------------------
def read_erp_excel(path: Path)-> pd.DataFrame:
    if not path.is_file():
        logging.warning(f"ERP Excel not found => {path}")
        return pd.DataFrame()
    try:
        df= pd.read_excel(path, skiprows=3)
        df.columns= df.columns.str.strip()
        if "Enabled_Flag" in df.columns:
            df= df[df["Enabled_Flag"]=="Enabled"]
        return df
    except Exception as e:
        logging.error(f"Error reading ERP => {e}")
        return pd.DataFrame()

# ----------------------------------------------------------------------------
# MASTER reading
# ----------------------------------------------------------------------------
def read_txt_2encodings(raw: bytes)-> pd.DataFrame:
    import io
    for enc in ["utf-8-sig","utf-16-le"]:
        try:
            buf= io.BytesIO(raw)
            df= pd.read_csv(buf, encoding=enc, on_bad_lines="skip", engine="python")
            df.dropna(how="all", axis=0,inplace=True)
            df.dropna(how="all", axis=1,inplace=True)
            df.columns= df.columns.astype(str).str.strip()
            logging.info(f"[read_txt_2encodings] success => {enc}, shape={df.shape}")
            return df
        except Exception as e:
            logging.debug(f"[read_txt_2encodings] fail => {enc}: {e}")
    logging.error("[read_txt_2encodings] cannot parse => empty")
    return pd.DataFrame()

def convert_master_txt_to_csv(zip_path: Path, out_dir: Path)-> List[Path]:
    if not zip_path.is_file():
        logging.warning(f"[Master] ZIP not found => {zip_path}")
        return []
    if out_dir.exists():
        shutil.rmtree(out_dir, ignore_errors=True)
    out_dir.mkdir(parents=True, exist_ok=True)
    csvs=[]
    with zipfile.ZipFile(zip_path,"r") as z:
        txt_files= [f for f in z.namelist() if f.lower().endswith(".txt")]
        for txt_file in txt_files:
            bname= os.path.basename(txt_file)
            if not bname:
                continue
            try:
                with z.open(txt_file) as fo:
                    raw= fo.read()
                df= read_txt_2encodings(raw)
                if df.empty:
                    continue
                df["RawFileName"]= bname
                if "Name" not in df.columns and len(df.columns)>0:
                    first_col= df.columns[0]
                    df.rename(columns={first_col:"Name"}, inplace=True)
                out_csv= out_dir / (bname.replace(".txt",".csv"))
                df.to_csv(out_csv, index=False, encoding="utf-8")
                csvs.append(out_csv)
            except Exception as e:
                logging.error(f"[Master] {txt_file} => {e}")
    return csvs

def unify_master_csvs(csvs: List[Path])-> pd.DataFrame:
    frames=[]
    for c in csvs:
        if not c.is_file():
            continue
        try:
            df= pd.read_csv(c, encoding="utf-8", on_bad_lines="skip")
            df.columns= df.columns.str.strip()
            frames.append(df)
        except Exception as e:
            logging.error(f"[unify_master_csvs] => {c}: {e}")
    if frames:
        return pd.concat(frames, ignore_index=True)
    return pd.DataFrame()

# ----------------------------------------------------------------------------
# END DATE FILTER HELPER
# ----------------------------------------------------------------------------
def keep_valid_end_date(attr: str, val: str)-> bool:
    if attr!="End Date":
        return True
    if not val.strip():
        return True
    try:
        dt= datetime.strptime(val, "%Y-%m-%d").date()
        return dt> datetime.now().date()
    except:
        return False

# ----------------------------------------------------------------------------
# MELTDOWN => using FULL dimension from param
# ----------------------------------------------------------------------------
def meltdown_erp_for_preview(df: pd.DataFrame, param: Dict[str,object]) -> pd.DataFrame:
    """
    We map 'V_S_C' => full dimension name from param["dim_erp_map"].
    But we store the short code in 'DimCode' for use later in the final Excel appearance.
    """
    if "V_S_C" not in df.columns:
        return pd.DataFrame()
    keep= param.get("dim_erp_keep", set())
    dmap= param.get("dim_erp_map", {})
    amap= param.get("attr_erp_map", {})

    df2= df[df["V_S_C"].isin(keep)].copy()
    if df2.empty:
        return pd.DataFrame()

    skip_cols= {"V_S_C","Enabled_Flag"}
    id_vars= []
    if "Value" in df2.columns:
        id_vars.append("Value")
        skip_cols.add("Value")

    df2["DimCode"]= df2["V_S_C"]          # keep short code
    df2["Dimension"]= df2["V_S_C"].map(dmap).fillna(df2["V_S_C"])  # full dimension if param found
    skip_cols.add("Dimension")
    skip_cols.add("DimCode")
    skip_cols.add("V_S_C")

    id_vars.insert(0,"Dimension")
    id_vars.insert(0,"DimCode")

    meltdown_cols= [c for c in df2.columns if c not in skip_cols]
    melted= df2.melt(id_vars=id_vars, value_vars=meltdown_cols,
                     var_name="OrigAttr", value_name="ValX")

    if "Value" in id_vars:
        melted.rename(columns={"Value":"Name"}, inplace=True)
    else:
        melted["Name"]= ""

    melted= melted[melted["OrigAttr"].isin(amap.keys())].copy()
    melted["Attribute"]= melted["OrigAttr"].map(amap)

    def strip_t(val):
        if isinstance(val,str) and "T" in val:
            return val.split("T")[0]
        return val
    melted["Value"]= melted["ValX"].apply(strip_t)

    keep_rows=[]
    for _, row in melted.iterrows():
        if keep_valid_end_date(row["Attribute"], row["Value"]):
            keep_rows.append(row)
    outdf= pd.DataFrame(keep_rows)

    return outdf[["DimCode","Dimension","Name","Attribute","Value"]]


def meltdown_master_for_preview(df: pd.DataFrame, param: Dict[str,object]) -> pd.DataFrame:
    """
    We map 'RawFileName' => full dimension name from param["dim_master_map"].
    We also store the short code in 'DimCode' just for final Excel's "Dimension" column.
    """
    if df.empty or "RawFileName" not in df.columns:
        return pd.DataFrame()
    amap= param.get("attr_master_map", {})
    dmap= param.get("dim_master_map", {})  # filename => full dimension name

    df2= df[df["RawFileName"].isin(dmap.keys())].copy()
    if df2.empty:
        return pd.DataFrame()

    df2["DimCode"]= df2["RawFileName"]                  # default short code is the filename or a code
    df2["Dimension"]= df2["RawFileName"].map(dmap).fillna(df2["RawFileName"]) 
    skip_cols= {"RawFileName","DimCode","Dimension"}
    id_vars= ["DimCode","Dimension"]
    if "Name" in df2.columns:
        id_vars.append("Name")
        skip_cols.add("Name")

    meltdown_cols= [c for c in df2.columns if c not in skip_cols]
    melted= df2.melt(
        id_vars=id_vars,
        value_vars=meltdown_cols,
        var_name="OrigAttr",
        value_name="ValX"
    )

    melted= melted[melted["OrigAttr"].isin(amap.keys())].copy()
    melted["Attribute"]= melted["OrigAttr"].map(amap)

    def strip_t(val):
        if isinstance(val,str) and "T" in val:
            return val.split("T")[0]
        return val
    melted["Value"]= melted["ValX"].apply(strip_t)

    keep_rows=[]
    for _, row in melted.iterrows():
        if keep_valid_end_date(row["Attribute"], row["Value"]):
            keep_rows.append(row)
    outdf= pd.DataFrame(keep_rows)

    if "Name" not in outdf.columns:
        outdf["Name"]= ""
    return outdf[["DimCode","Dimension","Name","Attribute","Value"]]


def pivot_for_preview(df: pd.DataFrame)-> pd.DataFrame:
    if not df.empty and {"DimCode","Dimension","Name","Attribute"}.issubset(df.columns):
        df= df.drop_duplicates(subset=["DimCode","Dimension","Name","Attribute"])
        try:
            df= df.pivot(index=["DimCode","Dimension","Name"], columns="Attribute", values="Value").reset_index()
        except Exception as e:
            logging.error(f"Pivot => {e}")
    return df

# ----------------------------------------------------------------------------
# COMPARE => we only store the full Dimension name in meltdown
# ----------------------------------------------------------------------------
def compare_erp_master(erp_df: pd.DataFrame, mast_df: pd.DataFrame)-> pd.DataFrame:
    """
    Input meltdown data has columns [DimCode, Dimension, Name, Attribute, Value].
    We rename Value->ERP or Master. We do the ignoring-case compare.
    We'll keep 'Dimension' as the full dimension name for the internal logic.

    The final DataFrame => columns:
      Key, Dimension, Name, Attribute, Master, ERP, Comments_1, Comments_2, Gap In
    We'll also keep 'DimCode' hidden to do the final 'Dimension' swap => short code if we want.
    """
    e2= erp_df.copy()
    e2.rename(columns={"Value":"ERP"}, inplace=True)
    m2= mast_df.copy()
    m2.rename(columns={"Value":"Master"}, inplace=True)

    key_cols= ["DimCode","Dimension","Name","Attribute"]
    merged= e2.merge(m2, on=key_cols, how="outer")
    merged["ERP"]= merged["ERP"].fillna("")
    merged["Master"]= merged["Master"].fillna("")

    diff_mask= merged["ERP"].str.upper() != merged["Master"].str.upper()
    out= merged[diff_mask].copy()

    def gap_logic(row):
        e= row["ERP"]
        ms= row["Master"]
        if e and not ms:
            return "MASTER"
        elif ms and not e:
            return "ERP"
        else:
            return "MISMATCH"
    out["Gap In"]= out.apply(gap_logic, axis=1)

    out["Comments_1"]= ""
    out["Comments_2"]= ""

    # build Key uppercase: use the full dimension name for the "Dimension" portion
    # but we can do uppercase/trimming
    out["Key"]= (
        out["Dimension"].str.upper().str.strip() + " | " +
        out["Name"].str.upper().str.strip() + " | " +
        out["Attribute"].str.upper().str.strip()
    )

    final_cols= ["DimCode","Dimension","Name","Attribute","Master","ERP","Comments_1","Comments_2","Gap In","Key"]
    return out[final_cols]

def separate_case_diffs(df: pd.DataFrame)-> Tuple[pd.DataFrame,pd.DataFrame]:
    same_lower= df["Master"].str.lower()== df["ERP"].str.lower()
    diff= df["Master"] != df["ERP"]
    mask= same_lower & diff
    case_only= df[mask].copy()
    mismatch= df[~mask].copy()
    return mismatch, case_only

# ----------------------------------------------------------------------------
# Exceptions & Write
# ----------------------------------------------------------------------------
def read_exception_table(path: Path)-> pd.DataFrame:
    if not path.is_file():
        logging.warning(f"Exception table => {path} not found")
        return pd.DataFrame()
    try:
        df= pd.read_excel(path)
        df.columns= df.columns.astype(str).str.strip()
        return df
    except Exception as e:
        logging.error(f"Error reading exception => {e}")
        return pd.DataFrame()

def merge_exceptions(df: pd.DataFrame, df_exc: pd.DataFrame)-> pd.DataFrame:
    if df.empty or df_exc.empty or "Key" not in df.columns:
        return df
    keep_cols= [c for c in ["Key","Comments_1","Comments_2","hide exception"] if c in df_exc.columns]
    if not keep_cols:
        return df
    exc= df_exc[keep_cols].copy()
    exc["Key"]= exc["Key"].astype(str).str.strip()

    merged= df.merge(exc, on="Key", how="left", suffixes=("","_exc"))
    merged["hide exception"]= merged.get("hide exception","").fillna("").str.lower()
    final= merged[merged["hide exception"]!="yes"].copy()

    if "Comments_1_exc" in final.columns:
        final["Comments_1"]= np.where(final["Comments_1_exc"].notna(), final["Comments_1_exc"], final["Comments_1"])
        final.drop(columns=["Comments_1_exc"], inplace=True)
    if "Comments_2_exc" in final.columns:
        final["Comments_2"]= np.where(final["Comments_2_exc"].notna(), final["Comments_2_exc"], final["Comments_2"])
        final.drop(columns=["Comments_2_exc"], inplace=True)
    if "hide exception" in final.columns:
        final.drop(columns=["hide exception"], inplace=True)
    return final

def write_two_sheet_excel(mismatch: pd.DataFrame, case_only: pd.DataFrame, out_path: Path):
    """
    We have columns: DimCode, Dimension, Name, Attribute, Master, ERP, Comments_1, Comments_2, Gap In, Key
    but we want final columns => Key, Dimension, Name, ...
    However, user wants "Dimension" = short code => 'DimCode' column in final.
    We'll rename 'Dimension' => 'DimFull' and 'DimCode' => 'Dimension' before writing.
    """
    out_path.parent.mkdir(parents=True, exist_ok=True)
    main_cols= ["Key","Dimension","Name","Attribute","Master","ERP","Comments_1","Comments_2","Gap In"]

    def finalize(df: pd.DataFrame)-> pd.DataFrame:
        df2= df.copy()
        # rename 'Dimension' => 'DimFull'
        # rename 'DimCode' => 'Dimension'
        # if we used .loc, let's do simpler approach:
        if "Dimension" in df2.columns and "DimCode" in df2.columns:
            df2.rename(columns={"Dimension":"DimFull","DimCode":"Dimension"}, inplace=True)
        # ensure we have all columns
        for c in main_cols:
            if c not in df2.columns:
                df2[c]= ""
        return df2[main_cols]

    mismatch_f= finalize(mismatch)
    case_f= finalize(case_only)

    wb= Workbook()

    ws_m= wb.active
    ws_m.title= "Mismatch"
    ws_m.append(main_cols)
    for rowvals in mismatch_f.itertuples(index=False):
        ws_m.append(rowvals)

    header_font= Font(bold=True)
    fill= PatternFill(start_color="DDDDDD", end_color="DDDDDD", fill_type="solid")
    for cell in ws_m[1]:
        cell.font= header_font
        cell.fill= fill
        cell.alignment= Alignment(horizontal="center")

    for col in ws_m.columns:
        max_len= 0
        let= col[0].column_letter
        for cell in col:
            val= str(cell.value) if cell.value else ""
            max_len= max(max_len, len(val))
        ws_m.column_dimensions[let].width= max_len+2
    ws_m.freeze_panes= "A2"

    ws_c= wb.create_sheet("Case_Differences")
    ws_c.append(main_cols)
    for rowvals in case_f.itertuples(index=False):
        ws_c.append(rowvals)
    for cell in ws_c[1]:
        cell.font= header_font
        cell.fill= fill
        cell.alignment= Alignment(horizontal="center")
    for col in ws_c.columns:
        max_len= 0
        let= col[0].column_letter
        for cell in col:
            val= str(cell.value) if cell.value else ""
            max_len= max(max_len, len(val))
        ws_c.column_dimensions[let].width= max_len+2
    ws_c.freeze_panes= "A2"

    wb.save(out_path)
    logging.info(f"Missing => {out_path}")

# ----------------------------------------------------------------------------
# 8-CHARTS
# ----------------------------------------------------------------------------
def plot_dashboard_charts(df_current: pd.DataFrame, df_history: pd.DataFrame)-> Dict[str,plt.Figure]:
    charts={}
    # We'll define 8 chart functions similarly. 
    # The dimension in df_current is the "Dimension" column => the full name. 
    # If user wants short code for the charts, we could do it, but you said we want full dimension for logic. 
    # We'll just plot them as is.

    # 1) Heatmap
    def create_heatmap(df):
        if df.empty or not {"Dimension","Attribute"}.issubset(df.columns):
            return None
        pivot= df.groupby(["Dimension","Attribute"]).size().unstack(fill_value=0)
        if pivot.empty:
            return None
        fig, ax= plt.subplots(figsize=(6,4))
        im= ax.imshow(pivot, aspect="auto", cmap="Reds")
        ax.set_xticks(range(len(pivot.columns)))
        ax.set_xticklabels(pivot.columns, rotation=45, ha="right")
        ax.set_yticks(range(len(pivot.index)))
        ax.set_yticklabels(pivot.index)
        plt.colorbar(im, ax=ax)
        ax.set_title("Heatmap: Dim x Attr")
        enable_hover(ax)
        return fig
    charts["Heatmap"]= create_heatmap(df_current)

    # 2) Lollipop
    def create_lollipop(df):
        if df.empty or "Dimension" not in df.columns or "Key" not in df.columns:
            return None
        cdim= df.groupby("Dimension")["Key"].count().sort_values(ascending=True).tail(10)
        if cdim.empty:
            return None
        fig, ax= plt.subplots(figsize=(6,4))
        ax.hlines(y=range(len(cdim)), xmin=0, xmax=cdim.values, color="skyblue")
        ax.plot(cdim.values, range(len(cdim)), 'o', color="skyblue")
        ax.set_yticks(range(len(cdim)))
        ax.set_yticklabels(cdim.index)
        ax.set_title("Top 10 Dim => Lollipop")
        enable_hover(ax)
        return fig
    charts["Lollipop"]= create_lollipop(df_current)

    # 3) Circular
    def create_circular(df):
        if df.empty or "Attribute" not in df.columns or "Key" not in df.columns:
            return None
        cattr= df.groupby("Attribute")["Key"].count().sort_values(ascending=False).head(8)
        if cattr.empty:
            return None
        fig= plt.figure(figsize=(6,6))
        ax= fig.add_subplot(111, polar=True)
        angles= np.linspace(0, 2*np.pi, len(cattr), endpoint=False)
        bars= ax.bar(angles, cattr.values, width=0.5, alpha=0.7)
        ax.set_xticks(angles)
        ax.set_xticklabels(cattr.index, rotation=45)
        ax.set_title("Top 8 Attr => Circular")
        enable_hover(ax, polar=True)
        return fig
    charts["Circular"]= create_circular(df_current)

    # 4) Scatter
    def create_scatter(df):
        if df.empty or "Dimension" not in df.columns or "Key" not in df.columns:
            return None
        cdim= df.groupby("Dimension")["Key"].count().reset_index(name="Count")
        cdim= cdim.sort_values("Count", ascending=False).head(10)
        if cdim.empty:
            return None
        fig, ax= plt.subplots(figsize=(6,4))
        ax.scatter(range(len(cdim)), cdim["Count"], color="green")
        for i, val in enumerate(cdim["Count"]):
            ax.text(i,val,str(val), ha="center", va="bottom")
        ax.set_xticks(range(len(cdim)))
        ax.set_xticklabels(cdim["Dimension"], rotation=45, ha="right")
        ax.set_title("Top 10 Dim => Scatter")
        enable_hover(ax)
        return fig
    charts["Scatter"]= create_scatter(df_current)

    # 5) Radar
    def create_radar(df):
        if df.empty or "Dimension" not in df.columns or "Key" not in df.columns:
            return None
        cdim= df.groupby("Dimension")["Key"].count().sort_values(ascending=False).head(8)
        if cdim.empty:
            return None
        angles= np.linspace(0, 2*np.pi, len(cdim), endpoint=False)
        vals= cdim.values
        angles= np.concatenate((angles, [angles[0]]))
        vals= np.concatenate((vals, [vals[0]]))
        fig, ax= plt.subplots(figsize=(6,6), subplot_kw={"polar":True})
        ax.plot(angles, vals, color="red", linewidth=2)
        ax.fill(angles, vals, color="red", alpha=0.25)
        ax.set_xticks(angles[:-1])
        ax.set_xticklabels(cdim.index)
        ax.set_title("Top 8 Dim => Radar")
        enable_hover(ax, polar=True)
        return fig
    charts["Radar"]= create_radar(df_current)

    # 6) Pie => "Gap In"
    def create_pie(df):
        if df.empty or "Gap In" not in df.columns:
            return None
        dist= df["Gap In"].value_counts()
        if dist.empty:
            return None
        fig, ax= plt.subplots(figsize=(6,4))
        ax.pie(dist.values, labels=dist.index, autopct="%1.1f%%")
        ax.set_title("Pie => Gap In distribution")
        return fig
    charts["Pie"]= create_pie(df_current)

    # 7) Bar => top 10 attributes
    def create_bar(df):
        if df.empty or "Attribute" not in df.columns or "Key" not in df.columns:
            return None
        cattr= df.groupby("Attribute")["Key"].count().sort_values(ascending=False).head(10)
        if cattr.empty:
            return None
        fig, ax= plt.subplots(figsize=(6,4))
        bars= ax.bar(range(len(cattr)), cattr.values, color="blue")
        for i, bar in enumerate(bars):
            h= bar.get_height()
            ax.text(bar.get_x()+bar.get_width()/2., h, str(int(h)), ha="center", va="bottom")
        ax.set_xticks(range(len(cattr)))
        ax.set_xticklabels(cattr.index, rotation=45, ha="right")
        ax.set_title("Top 10 Attr => Bar")
        enable_hover(ax)
        return fig
    charts["Bar"]= create_bar(df_current)

    # 8) Band => entire df_history
    def create_band(df_hist):
        if df_hist.empty or "RunDate" not in df_hist.columns or "Key" not in df_hist.columns:
            return None
        date_ct= df_hist.groupby("RunDate")["Key"].count().reset_index(name="Count")
        date_ct["dt"]= pd.to_datetime(date_ct["RunDate"], errors="coerce")
        date_ct.sort_values("dt", inplace=True)
        if date_ct.empty:
            return None
        fig, ax= plt.subplots(figsize=(6,4))
        xvals= np.arange(len(date_ct))
        ax.plot(xvals, date_ct["Count"], marker="o", color="purple", label="Count")
        # simple band => rolling mean +-2std
        avg= date_ct["Count"].rolling(3,min_periods=1).mean()
        std= date_ct["Count"].rolling(3,min_periods=1).std(ddof=0)
        upper= avg + 2*std
        lower= avg - 2*std
        ax.fill_between(xvals, lower, upper, color="purple", alpha=0.2, label="±2σ band")
        for i, r in date_ct.iterrows():
            ax.text(i, r["Count"], str(int(r["Count"])), ha="center", va="bottom")
        ax.set_xticks(xvals)
        ax.set_xticklabels([d.strftime("%Y-%m-%d") if not pd.isna(d) else "" for d in date_ct["dt"]], rotation=45, ha="right")
        ax.set_title("Band => entire history")
        ax.legend()
        enable_hover(ax)
        return fig
    charts["Band"]= create_band(df_history)

    return charts

# ----------------------------------------------------------------------------
# HISTORY UI
# ----------------------------------------------------------------------------
class HistoryTab(ctk.CTkFrame):
    def __init__(self, parent, hist_dir: Path, run_selected_callback=None):
        super().__init__(parent)
        self.hist_dir= hist_dir
        self.run_selected_callback= run_selected_callback
        self.build_ui()

    def build_ui(self):
        lbl= ctk.CTkLabel(self, text="History", font=("Arial",16))
        lbl.pack(pady=5)

        self.tree= ttk.Treeview(self, columns=("File",), show="headings", height=15)
        self.tree.heading("File", text="History File")
        self.tree.pack(fill="both", expand=True, padx=10, pady=10)

        self.tree.bind("<Double-1>", self.on_double_click)

        btn= ctk.CTkButton(self, text="Refresh", command=self.refresh_history,
                           fg_color="#800020", hover_color="#a52a2a", text_color="white")
        btn.pack(pady=5)

        self.refresh_history()

    def refresh_history(self):
        for i in self.tree.get_children():
            self.tree.delete(i)
        if not self.hist_dir.is_dir():
            self.hist_dir.mkdir(parents=True, exist_ok=True)
        files= sorted(self.hist_dir.glob("run_*.json"), reverse=True)
        for f in files:
            self.tree.insert("", "end", values=(f.name,))

    def on_double_click(self, event):
        sel= self.tree.focus()
        if not sel:
            return
        fname= self.tree.item(sel,"values")[0]
        path= self.hist_dir / fname
        if not path.is_file():
            return
        try:
            with open(path,"r",encoding="utf-8") as f:
                data= json.load(f)
            popup= tk.Toplevel(self)
            popup.title("History Run")
            popup.geometry("400x200")

            lbl= ctk.CTkLabel(popup, text=f"{fname}\nItems => {len(data)}")
            lbl.pack(pady=10)

            def show_summary():
                df_run= pd.DataFrame(data)
                c= len(df_run)
                messagebox.showinfo("Summary", f"Items => {c}\n(If timestamp stored, we'd show it here.)")
                popup.destroy()

            def load_charts():
                if self.run_selected_callback:
                    self.run_selected_callback(path, data)
                popup.destroy()

            frm= ctk.CTkFrame(popup)
            frm.pack(pady=10)

            ctk.CTkButton(frm, text="Show Summary", command=show_summary,
                          fg_color="#800020", hover_color="#a52a2a", text_color="white").pack(side="left", padx=10)
            ctk.CTkButton(frm, text="Load Data for Charts", command=load_charts,
                          fg_color="#800020", hover_color="#a52a2a", text_color="white").pack(side="left", padx=10)

        except Exception as e:
            logging.error(f"History => {e}")


# ----------------------------------------------------------------------------
# ADVANCED DASHBOARD => 8 charts
# ----------------------------------------------------------------------------
class AdvancedDashboard(ctk.CTkFrame):
    def __init__(self, parent):
        super().__init__(parent)
        self.df_current= pd.DataFrame()
        self.df_history= pd.DataFrame()
        self.selected_dims= set()
        self.selected_attrs= set()
        self.top_n= 10

        topbar= ctk.CTkScrollableFrame(self, orientation="horizontal", height=60)
        topbar.pack(fill="x", pady=5)
        self.metric_label= ctk.CTkLabel(topbar, text="Metrics: 0 mismatch, 0 dimension", width=300)
        self.metric_label.pack(side="left", padx=5)

        ctk.CTkButton(topbar, text="Filter Dimension", command=self.filter_dim,
                      fg_color="#800020", hover_color="#a52a2a", text_color="white").pack(side="left", padx=5)
        ctk.CTkButton(topbar, text="Filter Attribute", command=self.filter_attr,
                      fg_color="#800020", hover_color="#a52a2a", text_color="white").pack(side="left", padx=5)
        ctk.CTkButton(topbar, text="Toggle Top 10/All", command=self.toggle_top_n,
                      fg_color="#800020", hover_color="#a52a2a", text_color="white").pack(side="left", padx=5)

        self.notebook= ttk.Notebook(self)
        self.notebook.pack(fill="both", expand=True)
        self.frames= {}
        chart_names= ["Heatmap","Lollipop","Circular","Scatter","Radar","Pie","Bar","Band"]
        for lbl in chart_names:
            fr= ctk.CTkFrame(self.notebook)
            self.notebook.add(fr, text=lbl)
            self.frames[lbl]= fr

    def filter_dim(self):
        messagebox.showinfo("Filter","Dimension filter not implemented")

    def filter_attr(self):
        messagebox.showinfo("Filter","Attribute filter not implemented")

    def toggle_top_n(self):
        if self.top_n==10:
            self.top_n= None
        else:
            self.top_n= 10
        self.update_charts()

    def set_data(self, df_current: pd.DataFrame, df_history: pd.DataFrame):
        self.df_current= df_current.copy()
        self.df_history= df_history.copy()
        self.update_charts()

    def update_charts(self):
        mism= len(self.df_current)
        dims= self.df_current["Dimension"].nunique() if not self.df_current.empty and "Dimension" in self.df_current.columns else 0
        self.metric_label.configure(text=f"Metrics: {mism} mismatch, {dims} dimension")

        charts= plot_dashboard_charts(self.df_current, self.df_history)
        for k, fig in charts.items():
            if k in self.frames:
                fr= self.frames[k]
                for w in fr.winfo_children():
                    w.destroy()
                if fig is not None:
                    canvas= FigureCanvasTkAgg(fig, master=fr)
                    canvas.draw()
                    canvas.get_tk_widget().pack(fill="both", expand=True)
                plt.close(fig)

# ----------------------------------------------------------------------------
# MAIN APP
# ----------------------------------------------------------------------------
class MainApp(ctk.CTk):
    def __init__(self):
        super().__init__()
        self.title("Ultra-Mega Reconciliation: Full Dim logic, short code in final Excel")
        self.geometry("1400x800")
        ctk.set_appearance_mode("light")
        self.protocol("WM_DELETE_WINDOW", self.on_close)

        self.config_dict= load_config(Path(DEFAULT_PATHS["CONFIG_PATH"]))
        self.param_dict= read_param_file(Path(self.config_dict["paths"].get("PARAMETER_PATH", DEFAULT_PATHS["PARAMETER_PATH"])))
        self.history_df= pd.DataFrame()

        self.tabs= ttk.Notebook(self)
        self.tabs.pack(fill="both", expand=True)

        # 1) Paths
        self.tab_paths= ctk.CTkFrame(self.tabs)
        self.build_paths_tab(self.tab_paths)
        self.tabs.add(self.tab_paths, text="Paths")

        # 2) ERP
        self.tab_erp= ctk.CTkFrame(self.tabs)
        self.erp_preview= SimplePreview(self.tab_erp,"ERP")
        self.erp_preview.pack(fill="both", expand=True)
        self.tabs.add(self.tab_erp, text="ERP Preview")

        # 3) Master
        self.tab_master= ctk.CTkFrame(self.tabs)
        self.master_preview= SimplePreview(self.tab_master,"Master")
        self.master_preview.pack(fill="both", expand=True)
        self.tabs.add(self.tab_master, text="Master Preview")

        # 4) Compare
        self.tab_compare= ctk.CTkFrame(self.tabs)
        self.build_compare_tab(self.tab_compare)
        self.tabs.add(self.tab_compare, text="Compare")

        # 5) Dashboard
        self.dashboard_tab= AdvancedDashboard(self.tabs)
        self.tabs.add(self.dashboard_tab, text="Dashboard")

        # 6) History
        hist_dir= Path(self.config_dict["paths"].get("HISTORY_PATH","history_runs"))
        self.history_tab= HistoryTab(self.tabs, hist_dir, run_selected_callback=self.on_history_file_selected)
        self.tabs.add(self.history_tab, text="History")

        # log
        self.log_box= ctk.CTkTextbox(self, height=120)
        self.log_box.pack(fill="both", side="bottom")
        self.log_box.configure(state="disabled")
        handler= TextHandler(self.log_box)
        handler.setLevel(logging.INFO)
        logging.getLogger().addHandler(handler)

        self.temp_csv_dir= Path(self.config_dict["paths"].get("MASTER_CSV_OUTPUT","temp_master_csv"))
        self.temp_csv_dir.mkdir(parents=True, exist_ok=True)

        # load older runs
        self.load_history()

        # meltdown => preview
        self.refresh_erp()
        self.refresh_master()

        ctk.CTkButton(self, text="Close Script", command=self.on_close,
                      fg_color="#800020", hover_color="#a52a2a", text_color="white").pack(pady=5)

        # pass entire history => band chart
        self.dashboard_tab.set_data(pd.DataFrame(), self.history_df)

    def build_paths_tab(self, parent):
        frm= ctk.CTkFrame(parent)
        frm.pack(fill="both", expand=True, padx=10, pady=10)

        self.erp_var= tk.StringVar(value=self.config_dict["paths"].get("ERP_EXCEL_PATH", DEFAULT_PATHS["ERP_EXCEL_PATH"]))
        self.mast_var= tk.StringVar(value=self.config_dict["paths"].get("MASTER_ZIP_PATH", DEFAULT_PATHS["MASTER_ZIP_PATH"]))
        self.exc_var= tk.StringVar(value=self.config_dict["paths"].get("EXCEPTION_PATH", DEFAULT_PATHS["EXCEPTION_PATH"]))
        self.out_var= tk.StringVar(value=self.config_dict["paths"].get("OUTPUT_PATH", DEFAULT_PATHS["OUTPUT_PATH"]))
        self.par_var= tk.StringVar(value=self.config_dict["paths"].get("PARAMETER_PATH", DEFAULT_PATHS["PARAMETER_PATH"]))
        self.pdf_var= tk.StringVar(value=self.config_dict["paths"].get("PDF_EXPORT_PATH", DEFAULT_PATHS["PDF_EXPORT_PATH"]))

        def mkrow(lbl, var, is_dir=False):
            rowf= ctk.CTkFrame(frm)
            rowf.pack(fill="x", pady=5)
            ctk.CTkLabel(rowf, text=lbl, width=180).pack(side="left", padx=5)
            e= ctk.CTkEntry(rowf, textvariable=var, width=600)
            e.pack(side="left", padx=5)
            def br():
                if is_dir:
                    p= filedialog.askdirectory()
                else:
                    p= filedialog.askopenfilename()
                if p:
                    var.set(p)
            ctk.CTkButton(rowf, text="Browse", command=br,
                          fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)

        mkrow("ERP Excel:", self.erp_var)
        mkrow("Master ZIP:", self.mast_var)
        mkrow("Exception Path:", self.exc_var)
        mkrow("Missing Items Output:", self.out_var)
        mkrow("Parameter File:", self.par_var)
        mkrow("PDF Export Path:", self.pdf_var)

        bf= ctk.CTkFrame(frm)
        bf.pack(fill="x", pady=10)
        ctk.CTkButton(bf, text="Save Config", command=self.save_all_config,
                      fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)
        ctk.CTkButton(bf, text="Refresh ERP", command=self.refresh_erp,
                      fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)
        ctk.CTkButton(bf, text="Refresh Master", command=self.refresh_master,
                      fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)

    def build_compare_tab(self, parent):
        frm= ctk.CTkFrame(parent)
        frm.pack(fill="both", expand=True, padx=10, pady=10)
        ctk.CTkLabel(frm, text="Generate Missing Items", font=("Arial",16)).pack(pady=5)
        ctk.CTkButton(frm, text="Run Reconciliation", command=self.run_comparison,
                      fg_color="#800020", hover_color="#a52a2a").pack(pady=10)
        ctk.CTkButton(frm, text="Export PDF Report", command=self.export_pdf,
                      fg_color="#800020", hover_color="#a52a2a").pack(pady=10)

    def load_history(self):
        hist_path= Path(self.config_dict["paths"].get("HISTORY_PATH","history_runs"))
        if not hist_path.is_dir():
            return
        frames=[]
        for jf in hist_path.glob("run_*.json"):
            try:
                jdf= pd.read_json(jf, orient="records")
                frames.append(jdf)
            except Exception as e:
                logging.error(f"Error reading => {jf}: {e}")
        if frames:
            big= pd.concat(frames, ignore_index=True)
            self.history_df= pd.concat([self.history_df, big], ignore_index=True) if not self.history_df.empty else big
            self.history_df.drop_duplicates(inplace=True)
            logging.info(f"Loaded older runs => {len(self.history_df)} items")

    def refresh_erp(self):
        erp_path= Path(self.erp_var.get().strip())
        raw_erp= read_erp_excel(erp_path)
        if raw_erp.empty:
            self.erp_preview.set_data(pd.DataFrame())
            return
        melted= meltdown_erp_for_preview(raw_erp, self.param_dict)
        # pivot => [DimCode, Dimension, Name, ...]
        pivoted= pivot_for_preview(melted)
        self.erp_preview.set_data(pivoted)

    def refresh_master(self):
        zip_path= Path(self.mast_var.get().strip())
        csvs= convert_master_txt_to_csv(zip_path, self.temp_csv_dir)
        raw_mast= unify_master_csvs(csvs)
        if raw_mast.empty:
            self.master_preview.set_data(pd.DataFrame())
            return
        melted= meltdown_master_for_preview(raw_mast, self.param_dict)
        pivoted= pivot_for_preview(melted)
        self.master_preview.set_data(pivoted)

    def run_comparison(self):
        # unpivot
        df_erp_wide= self.erp_preview.get_filtered_df()
        df_mast_wide= self.master_preview.get_filtered_df()

        erp_long= self._unpivot(df_erp_wide)
        mast_long= self._unpivot(df_mast_wide)

        # compare => we keep dimension as the full param dimension,
        # but have a hidden "DimCode" for final swap
        df_diff= compare_erp_master(erp_long, mast_long)

        exc_path= Path(self.exc_var.get().strip())
        df_exc= read_exception_table(exc_path)
        final= merge_exceptions(df_diff, df_exc)

        mismatch, case_only= separate_case_diffs(final)

        # final write => we rename dimension => short code from 'DimCode'
        out_path= Path(self.out_var.get().strip())
        write_two_sheet_excel(mismatch, case_only, out_path)

        # store in history
        rt= datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        mismatch["RunDate"]= rt
        case_only["RunDate"]= rt
        appended= pd.concat([mismatch, case_only], ignore_index=True)
        self.history_df= pd.concat([self.history_df, appended], ignore_index=True)

        # save JSON
        hist_path= Path(self.config_dict["paths"].get("HISTORY_PATH","history_runs"))
        hist_path.mkdir(parents=True, exist_ok=True)
        run_file= hist_path / f"run_{rt.replace(':','-')}.json"
        appended.to_json(run_file, orient="records", indent=2)

        logging.info(f"Run => {run_file}")
        self.dashboard_tab.set_data(appended, self.history_df)
        if hasattr(self.history_tab,"refresh_history"):
            self.history_tab.refresh_history()
        self.tabs.select(self.dashboard_tab)
        messagebox.showinfo("Done", f"Missing items => {out_path}")

    def _unpivot(self, df_wide: pd.DataFrame)-> pd.DataFrame:
        """
        The pivoted DF => [DimCode, Dimension, Name, ... attributes].
        We unpivot => columns: DimCode, Dimension, Name, Attribute, Value
        """
        if df_wide.empty:
            return pd.DataFrame(columns=["DimCode","Dimension","Name","Attribute","Value"])
        id_vars= ["DimCode","Dimension","Name"]
        meltdown_cols= [c for c in df_wide.columns if c not in id_vars]
        melted= df_wide.melt(id_vars=id_vars, value_vars=meltdown_cols,
                             var_name="Attribute", value_name="Value")
        for c in ["DimCode","Dimension","Name","Attribute","Value"]:
            if c not in melted.columns:
                melted[c]= ""
            melted[c]= melted[c].fillna("").astype(str).str.strip()
        return melted

    def export_pdf(self):
        if self.history_df.empty:
            messagebox.showinfo("PDF Export","No mismatch => history empty")
            return
        if "RunDate" in self.history_df.columns:
            last_run= self.history_df["RunDate"].max()
            df_current= self.history_df[self.history_df["RunDate"]== last_run].copy()
        else:
            df_current= self.history_df.copy()
        df_history= self.history_df.copy()

        rep= EnhancedPDFReport(df_current, df_history)
        pdf_path= rep.generate()
        messagebox.showinfo("PDF Export", f"PDF => {pdf_path}")

    def save_all_config(self):
        self.config_dict["paths"]["ERP_EXCEL_PATH"]= self.erp_var.get().strip()
        self.config_dict["paths"]["MASTER_ZIP_PATH"]= self.mast_var.get().strip()
        self.config_dict["paths"]["EXCEPTION_PATH"]= self.exc_var.get().strip()
        self.config_dict["paths"]["OUTPUT_PATH"]= self.out_var.get().strip()
        self.config_dict["paths"]["PARAMETER_PATH"]= self.par_var.get().strip()
        self.config_dict["paths"]["PDF_EXPORT_PATH"]= self.pdf_var.get().strip()

        # store dash state if needed
        # ... skipping for brevity
        cfg_path= Path(self.config_dict["paths"].get("CONFIG_PATH","config/ui_config.json"))
        save_config(self.config_dict, cfg_path)
        messagebox.showinfo("Saved","Paths & config saved")

    def on_history_file_selected(self, file_path, data):
        df_run= pd.DataFrame(data)
        if not df_run.empty and "RunDate" in df_run.columns:
            run_date= df_run["RunDate"].iloc[0]
            self.history_df= self.history_df[self.history_df["RunDate"]!= run_date]
        self.history_df= pd.concat([self.history_df, df_run], ignore_index=True)
        self.dashboard_tab.set_data(df_run, self.history_df)
        self.tabs.select(self.dashboard_tab)

    def on_close(self):
        self.save_all_config()
        # optionally store bollinger data from entire self.history_df
        self.destroy()


# ----------------------------------------------------------------------------
# PDF REPORT EXAMPLE
# ----------------------------------------------------------------------------
class EnhancedPDFReport:
    def __init__(self, df_current: pd.DataFrame, df_history: pd.DataFrame):
        self.df_current= df_current
        self.df_history= df_history

    def generate(self)-> Path:
        stamp= datetime.now().strftime("%Y%m%d_%H%M%S")
        out_dir= Path("Reconciliation_pdf")
        out_dir.mkdir(parents=True, exist_ok=True)
        pdf_path= out_dir / f"reconciliation_{stamp}.pdf"
        with PdfPages(pdf_path) as pdf:
            # cover
            fig= plt.figure(figsize=(8.5,11))
            plt.axis("off")
            plt.text(0.5,0.6,"Reconciliation Report",ha="center", fontsize=24, weight="bold")
            pdf.savefig(fig)
            plt.close(fig)

            # summary
            fig= plt.figure(figsize=(8.5,11))
            plt.axis("off")
            txt= f"Current => {len(self.df_current)} items\nHistory => {len(self.df_history)} total"
            plt.text(0.5,0.9,txt, ha="center", fontsize=12)
            pdf.savefig(fig)
            plt.close(fig)
        logging.info(f"PDF => {pdf_path}")
        return pdf_path

def main():
    app= MainApp()
    app.mainloop()

if __name__=="__main__":
    main()
