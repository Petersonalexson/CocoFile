import os
import sys
import json
import math
import logging
import zipfile
import shutil
import io
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, Set, List, Optional

import tkinter as tk
from tkinter import ttk, filedialog, messagebox
import customtkinter as ctk

import pandas as pd
import numpy as np

import matplotlib
matplotlib.use("TkAgg")
import matplotlib.pyplot as plt
from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg, NavigationToolbar2Tk
from matplotlib.backends.backend_pdf import PdfPages
from matplotlib.figure import Figure

try:
    import chardet
except ImportError:
    chardet = None

try:
    import psutil
except ImportError:
    psutil = None

from openpyxl import Workbook
from openpyxl.styles import PatternFill, Font, Alignment

from PIL import Image

# ----------------------------------------------------------------------------
# Constants and Configuration
# ----------------------------------------------------------------------------

DEFAULT_PATHS = {
    "ERP_EXCEL_PATH": "data/ERP_Config.xlsx",
    "MASTER_ZIP_PATH": "data/Master_Config.zip",
    "EXCEPTION_PATH": "data/Exception_Table.xlsx",
    "OUTPUT_PATH": "output/missing_items.xlsx",
    "CONFIG_PATH": "config/ui_config.json",
    "PARAMETER_PATH": "data/parameters.xlsx",
    "MASTER_CSV_OUTPUT": "temp_master_csv",
    "PDF_EXPORT_PATH": "output/dashboard_reports",
    "LOGO_PATH": "images/company_logo.png"
}

# ----------------------------------------------------------------------------
# LOGGING
# ----------------------------------------------------------------------------
logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")

# ----------------------------------------------------------------------------
# DEFAULT CONFIG & SAVE/LOAD (including run_history)
# ----------------------------------------------------------------------------
def default_config() -> Dict:
    return {
        "paths": DEFAULT_PATHS.copy(),
        "erp_grid": {
            "filters": {}  # {column: [selected_values]}
        },
        "master_grid": {
            "filters": {}
        },
        "run_history": [],  # List of dicts: [{"date": "YYYY-MM-DD", "missing": 123}]
        "dashboard": {
            "start_date": (datetime.now() - timedelta(days=30)).strftime("%Y-%m-%d"),
            "end_date": datetime.now().strftime("%Y-%m-%d"),
            "selected_dims": [],
            "selected_attrs": [],
            "top_n_mode": True,  # True for Top 10, False for All
            "active_chart": "Heatmap"
        }
    }

def load_config(path: Path) -> Dict:
    if path.is_file():
        try:
            with open(path, "r", encoding="utf-8") as f:
                config = json.load(f)
            # Migration: add any missing keys from default_config
            default = default_config()
            for key, default_value in default.items():
                if key not in config:
                    config[key] = default_value
                elif isinstance(default_value, dict):
                    for sub_key, sub_default in default_value.items():
                        if sub_key not in config[key]:
                            config[key][sub_key] = sub_default
            if "run_history" in config and isinstance(config["run_history"], list):
                for run_entry in config["run_history"]:
                    if not isinstance(run_entry, dict) or "date" not in run_entry or "missing" not in run_entry:
                        config["run_history"] = default["run_history"]
                        break
            else:
                config["run_history"] = default["run_history"]
            return config
        except Exception as e:
            logging.warning(f"Could not load config: {e}.  Using defaults.")
    return default_config()

def save_config(cfg: Dict, path: Path):
    # Convert any set values to lists for JSON serialization.
    for grid in ["erp_grid", "master_grid"]:
        if grid in cfg and "filters" in cfg[grid]:
            for key, value in cfg[grid]["filters"].items():
                if isinstance(value, set):
                    cfg[grid]["filters"][key] = list(value)
    path.parent.mkdir(parents=True, exist_ok=True)
    try:
        # Convert datetime objects in run_history to strings if needed.
        if "run_history" in cfg:
            for entry in cfg["run_history"]:
                if isinstance(entry.get("date"), datetime):
                    entry["date"] = entry["date"].strftime("%Y-%m-%d")
        with open(path, "w", encoding="utf-8") as f:
            json.dump(cfg, f, indent=2)
        logging.info(f"Saved config to {path}")
    except Exception as e:
        logging.error(f"Error saving config: {e}")

# ----------------------------------------------------------------------------
# TEXT LOGGER HANDLER
# ----------------------------------------------------------------------------
class TextHandler(logging.Handler):
    def __init__(self, widget: ctk.CTkTextbox):
        super().__init__()
        self.widget = widget
    def emit(self, record):
        msg = self.format(record) + "\n"
        self.widget.after(0, self._append, msg)
    def _append(self, msg):
        self.widget.configure(state="normal")
        self.widget.insert("end", msg)
        self.widget.see("end")
        self.widget.configure(state="disabled")

# ----------------------------------------------------------------------------
# PARAMETER READING
# ----------------------------------------------------------------------------
def read_param_file(path: Path) -> Dict[str, object]:
    param = {
        "dim_erp_keep": set(),
        "dim_erp_map": {},
        "dim_master_map": {},
        "attr_erp_map": {},
        "attr_master_map": {}
    }
    if not path.is_file():
        logging.warning(f"Param file not found => {path}")
        return param
    try:
        dim_df = pd.read_excel(path, sheet_name="Dimension Parameters")
        dim_df.columns = dim_df.columns.astype(str).str.strip()
        def s(x): return str(x).strip() if pd.notna(x) else ""
        for _, row in dim_df.iterrows():
            fn = s(row.get("FileName", ""))
            vsc = s(row.get("V S C", ""))
            dim = s(row.get("Dimension", ""))
            ev  = s(row.get("ERP Values", ""))
            if ev.lower() == "x" and vsc and dim:
                param["dim_erp_keep"].add(vsc)
            if vsc and dim:
                param["dim_erp_map"][vsc] = dim
            if fn and dim and ev.lower() == "x":
                param["dim_master_map"][fn] = dim
        attr_df = pd.read_excel(path, sheet_name="Attribute Parameters")
        attr_df.columns = attr_df.columns.astype(str).str.strip()
        for _, row in attr_df.iterrows():
            e_orig = s(row.get("ERP Original Attributes", ""))
            m_orig = s(row.get("Master Original Attributes", ""))
            final_ = s(row.get("Attribute", ""))
            onoff  = s(row.get("On/Off", ""))
            if onoff.lower() == "x" and final_:
                if e_orig:
                    param["attr_erp_map"][e_orig] = final_
                if m_orig:
                    param["attr_master_map"][m_orig] = final_
        return param
    except Exception as e:
        logging.error(f"Error reading param file => {e}")
        return param

# ----------------------------------------------------------------------------
# ERP & MASTER READING
# ----------------------------------------------------------------------------
def read_erp_excel(path: Path) -> pd.DataFrame:
    if not path.is_file():
        logging.warning(f"ERP Excel not found => {path}")
        return pd.DataFrame()
    try:
        df = pd.read_excel(path, skiprows=3)
        df.columns = df.columns.str.strip()
        if "Enabled_Flag" in df.columns:
            df = df[df["Enabled_Flag"]=="Enabled"]
        return df
    except Exception as e:
        logging.error(f"Error reading ERP => {e}")
        return pd.DataFrame()

def read_txt_2encodings(raw: bytes) -> pd.DataFrame:
    import io
    for enc in ["utf-8-sig", "utf-16-le"]:
        try:
            buf = io.BytesIO(raw)
            df = pd.read_csv(buf, encoding=enc, on_bad_lines="skip", engine="python")
            df.dropna(how="all", axis=0, inplace=True)
            df.dropna(how="all", axis=1, inplace=True)
            df.columns = df.columns.astype(str).str.strip()
            logging.info(f"[read_txt_2encodings] success with {enc}, shape={df.shape}")
            return df
        except Exception as e:
            logging.debug(f"[read_txt_2encodings] fail with {enc} => {e}")
    logging.error("[read_txt_2encodings] cannot parse .txt => empty.")
    return pd.DataFrame()

def convert_master_txt_to_csv(zip_path: Path, out_dir: Path) -> List[Path]:
    if not zip_path.is_file():
        logging.warning(f"[Master] ZIP not found => {zip_path}")
        return []
    if out_dir.exists():
        shutil.rmtree(out_dir, ignore_errors=True)
    out_dir.mkdir(parents=True, exist_ok=True)
    csvs = []
    with zipfile.ZipFile(zip_path, "r") as z:
        txt_files = [f for f in z.namelist() if f.lower().endswith(".txt")]
        for txt_file in txt_files:
            base_name = os.path.basename(txt_file)
            if not base_name:
                continue
            try:
                with z.open(txt_file) as fo:
                    raw = fo.read()
                df = read_txt_2encodings(raw)
                if df.empty:
                    continue
                df["RawFileName"] = base_name
                if "Name" not in df.columns and len(df.columns) > 0:
                    first_col = df.columns[0]
                    df.rename(columns={first_col:"Name"}, inplace=True)
                out_csv = out_dir / (base_name.replace(".txt", ".csv"))
                df.to_csv(out_csv, index=False, encoding="utf-8")
                csvs.append(out_csv)
            except Exception as e:
                logging.error(f"[Master] error reading {txt_file} => {e}")
    return csvs

def unify_master_csvs(csvs: List[Path]) -> pd.DataFrame:
    frames = []
    for cp in csvs:
        if not cp.is_file():
            continue
        try:
            df = pd.read_csv(cp, encoding="utf-8", on_bad_lines="skip")
            df.columns = df.columns.str.strip()
            frames.append(df)
        except Exception as e:
            logging.error(f"[unify_master_csvs] reading {cp} => {e}")
    if frames:
        return pd.concat(frames, ignore_index=True)
    return pd.DataFrame()

# ----------------------------------------------------------------------------
# MELTDOWN FUNCTIONS (to convert wide to long)
# ----------------------------------------------------------------------------
def meltdown_erp_for_preview(df: pd.DataFrame, param: Dict[str, object]) -> pd.DataFrame:
    if "V_S_C" not in df.columns:
        return pd.DataFrame()
    keep = param.get("dim_erp_keep", set())
    dmap = param.get("dim_erp_map", {})
    amap = param.get("attr_erp_map", {})

    df2 = df[df["V_S_C"].isin(keep)].copy()
    if df2.empty:
        return pd.DataFrame()

    skip_cols = {"V_S_C", "Enabled_Flag"}
    id_vars = []
    if "Value" in df2.columns:
        id_vars.append("Value")
        skip_cols.add("Value")
    df2["DimRaw"] = df2["V_S_C"]
    skip_cols.add("DimRaw")
    id_vars.insert(0, "DimRaw")

    meltdown_cols = [c for c in df2.columns if c not in skip_cols]
    melted = df2.melt(id_vars=id_vars, value_vars=meltdown_cols,
                      var_name="OrigAttr", value_name="ValX")
    def rename_dim(v):
        return dmap.get(v, v)
    melted["Dimension"] = melted["DimRaw"].apply(rename_dim)
    if "Value" in id_vars:
        melted.rename(columns={"Value": "Name"}, inplace=True)
    else:
        melted["Name"] = ""
    melted = melted[melted["OrigAttr"].isin(amap.keys())].copy()
    melted["Attribute"] = melted["OrigAttr"].map(amap)

    def handle_dates(val):
        if isinstance(val, str):
            return val.split("T")[0] if "T" in val else val
        return str(val) if pd.notna(val) else 'NaN'
    melted["Value"] = np.where(melted["Attribute"].isin(["Start Date", "End Date"]),
                               melted["ValX"].apply(handle_dates), melted["ValX"])
    return melted[["Dimension", "Name", "Attribute", "Value"]]

def meltdown_master_for_preview(df: pd.DataFrame, param: Dict[str, object]) -> pd.DataFrame:
    if df.empty or "RawFileName" not in df.columns:
        return pd.DataFrame()
    keep_map = param.get("dim_master_map", {})
    amap = param.get("attr_master_map", {})

    df2 = df[df["RawFileName"].isin(keep_map.keys())].copy()
    if df2.empty:
        return pd.DataFrame()

    df2["DimRaw"] = df2["RawFileName"]

    skip_cols = {"RawFileName", "DimRaw"}
    id_vars = ["DimRaw"]
    if "Name" in df2.columns:
        id_vars.append("Name")
        skip_cols.add("Name")

    meltdown_cols = [c for c in df2.columns if c not in skip_cols]
    melted = df2.melt(id_vars=id_vars, value_vars=meltdown_cols,
                      var_name="OrigAttr", value_name="ValX")
    def rename_dim(fn):
        return keep_map.get(fn, fn)
    melted["Dimension"] = melted["DimRaw"].apply(rename_dim)
    if "Name" in id_vars:
        melted.rename(columns={"Name": "Name"}, inplace=True)
    else:
        melted["Name"] = ""
    melted = melted[melted["OrigAttr"].isin(amap.keys())].copy()
    melted["Attribute"] = melted["OrigAttr"].map(amap)
    def handle_dates(val):
        if isinstance(val, str):
            return val.split("T")[0] if "T" in val else val
        return str(val) if pd.notna(val) else 'NaN'
    melted["Value"] = np.where(melted["Attribute"].isin(["Start Date", "End Date"]),
                               melted["ValX"].apply(handle_dates), melted["ValX"])
    return melted[["Dimension", "Name", "Attribute", "Value"]]

def pivot_for_preview(df: pd.DataFrame) -> pd.DataFrame:
    if not df.empty and {"Dimension", "Name", "Attribute"}.issubset(df.columns):
        df = df.drop_duplicates(subset=["Dimension", "Name", "Attribute"])
        try:
            df = df.pivot(index=["Dimension", "Name"], columns="Attribute", values="Value").reset_index()
            for col in df.columns:
                if df[col].dtype == 'object':
                    df[col] = df[col].fillna('')
        except Exception as e:
            logging.error(f"Pivot error => {e}")
    return df

# ----------------------------------------------------------------------------
# Compare Functions: Melt back wide data and produce missing items
# ----------------------------------------------------------------------------
def melt_back(df: pd.DataFrame) -> pd.DataFrame:
    if df.empty or "Dimension" not in df.columns or "Name" not in df.columns:
        return pd.DataFrame()
    skip_cols = {"Dimension", "Name"}
    meltdown_cols = [c for c in df.columns if c not in skip_cols]
    melted = df.melt(id_vars=["Dimension", "Name"], value_vars=meltdown_cols,
                     var_name="Attribute", value_name="Value")
    return melted[["Dimension", "Name", "Attribute", "Value"]]

def build_keys(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    for c in ["Dimension", "Name", "Attribute", "Value"]:
        if c not in df.columns:
            df[c] = ""
        df[c] = df[c].fillna("").astype(str).str.strip()
    df["GroupKey"] = df["Dimension"] + " | " + df["Name"]
    df["Key"] = df["Dimension"] + " | " + df["Name"] + " | " + df["Attribute"] + " | " + df["Value"]
    df["Comments_1"] = ""
    df["Comments_2"] = ""
    df["Action Item"] = ""
    df["Missing In"] = ""
    return df

def compare_mode2(df_erp: pd.DataFrame, df_mst: pd.DataFrame) -> pd.DataFrame:
    def to_dict(d):
        out = {}
        for gk, grp in d.groupby("GroupKey"):
            rec = {}
            nm = grp["Name"].iloc[0] if not grp.empty else ""
            rec["Name"] = nm
            for _, row in grp.iterrows():
                rec[row["Attribute"]] = row["Value"]
            out[gk] = rec
        return out
    e_dict = to_dict(df_erp)
    m_dict = to_dict(df_mst)
    all_gk = set(e_dict.keys()) | set(m_dict.keys())
    results = []
    for gk in all_gk:
        dim = gk.split(" | ")[0]
        a_data = e_dict.get(gk, {})
        b_data = m_dict.get(gk, {})
        name_a = a_data.get("Name", "")
        name_b = b_data.get("Name", "")
        if name_a and name_b and name_a == name_b:
            all_attrs = (set(a_data.keys()) | set(b_data.keys())) - {"Name"}
            for at in all_attrs:
                va = a_data.get(at, "")
                vb = b_data.get(at, "")
                if va != vb:
                    if va and not vb:
                        results.append({"Dimension": dim, "Name": name_a, "Attribute": at, "Value": va, "Missing In": "MASTER"})
                    elif vb and not va:
                        results.append({"Dimension": dim, "Name": name_a, "Attribute": at, "Value": vb, "Missing In": "ERP"})
                    else:
                        results.append({"Dimension": dim, "Name": name_a, "Attribute": at, "Value": va, "Missing In": "MASTER"})
                        results.append({"Dimension": dim, "Name": name_a, "Attribute": at, "Value": vb, "Missing In": "ERP"})
        else:
            if name_a and not name_b:
                results.append({"Dimension": dim, "Name": name_a, "Attribute": "Name", "Value": name_a, "Missing In": "MASTER"})
            elif name_b and not name_a:
                results.append({"Dimension": dim, "Name": name_b, "Attribute": "Name", "Value": name_b, "Missing In": "ERP"})
    df_res = pd.DataFrame(results)
    if not df_res.empty:
        df_res["Key"] = (df_res["Dimension"].str.strip() + " | " +
                         df_res["Name"].str.strip() + " | " +
                         df_res["Attribute"].str.strip() + " | " +
                         df_res["Value"].str.strip())
    return df_res

def read_exception_table(path: Path) -> pd.DataFrame:
    if not path.is_file():
        logging.warning(f"Exception table not found => {path}")
        return pd.DataFrame()
    try:
        df = pd.read_excel(path)
        df.columns = df.columns.astype(str).str.strip()
        return df
    except Exception as e:
        logging.error(f"Error reading exception => {e}")
        return pd.DataFrame()

def merge_exceptions(df: pd.DataFrame, df_exc: pd.DataFrame) -> pd.DataFrame:
    if df.empty or df_exc.empty or "Key" not in df.columns:
        return df
    keep = [c for c in df_exc.columns if c in ["Key", "Comments_1", "Comments_2", "hide exception"]]
    if not keep:
        return df
    exc = df_exc[keep].copy()
    exc["Key"] = exc["Key"].astype(str).str.strip()
    merged = df.merge(exc, on="Key", how="left", suffixes=("", "_exc"))
    merged["hide exception"] = merged.get("hide exception", "").fillna("").str.lower()
    final = merged[merged["hide exception"] != "yes"].copy()
    if "Comments_1_exc" in final.columns:
        final["Comments_1"] = np.where(final["Comments_1_exc"].notna(), final["Comments_1_exc"], final["Comments_1"])
        final.drop(columns=["Comments_1_exc"], inplace=True)
    if "Comments_2_exc" in final.columns:
        final["Comments_2"] = np.where(final["Comments_2_exc"].notna(), final["Comments_2_exc"], final["Comments_2"])
        final.drop(columns=["Comments_2_exc"], inplace=True)
    if "hide exception" in final.columns:
        final.drop(columns=["hide exception"], inplace=True)
    return final

def write_missing_items(df: pd.DataFrame, out_path: Path):
    if df.empty:
        logging.info("No missing items => skip writing.")
        return
    out_path.parent.mkdir(parents=True, exist_ok=True)
    final_cols = ["Key", "Dimension", "Name", "Attribute", "Value", "Comments_1", "Comments_2", "Action Item", "Missing In"]
    for c in final_cols:
        if c not in df.columns:
            df[c] = ""
    df = df[final_cols]
    wb = Workbook()
    ws = wb.active
    ws.title = "Missing Items"
    ws.append(final_cols)
    for rowvals in df.itertuples(index=False):
        ws.append(rowvals)
    header_font = Font(bold=True)
    fill = PatternFill(start_color="DDDDDD", end_color="DDDDDD", fill_type="solid")
    for cell in ws[1]:
        cell.font = header_font
        cell.fill = fill
        cell.alignment = Alignment(horizontal="center")
    for col in ws.columns:
        max_len = 0
        letter = col[0].column_letter
        for cell in col:
            val = str(cell.value) if cell.value else ""
            max_len = max(max_len, len(val))
        ws.column_dimensions[letter].width = max_len + 2
    ws.freeze_panes = "A2"
    wb.save(out_path)
    logging.info(f"Missing items => {out_path}")

# ----------------------------------------------------------------------------
# SIMPLE PREVIEW (for ERP/Master previews) with robust date filtering
# ----------------------------------------------------------------------------
class SimplePreview(ctk.CTkFrame):
    """Enhanced preview with robust date filtering for columns such as 'Start Date' and 'End Date'."""

    FILTERABLE_COLUMNS = ["Start Date", "End Date"]

    def __init__(self, parent, name: str):
        super().__init__(parent)
        self.name = name
        self.df = pd.DataFrame()
        # filters is a dictionary: {column: [selected_values]}
        self.filters: Dict[str, List[str]] = {}
        self.create_toolbar()
        self.create_table()
        self.create_statusbar()

    def standardize_value(self, value) -> str:
        """Convert any value to a standardized string representation."""
        if pd.isna(value):
            return "(Empty/NaN)"
        if isinstance(value, str) and not value.strip():
            return "(Blank)"
        return str(value).strip()

    def show_filter_popup(self, col_name: str):
        if self.df.empty or col_name not in self.df.columns:
            return

        popup = tk.Toplevel(self)
        popup.title(f"Filter: {col_name}")
        popup.geometry("300x400")
        frame = ctk.CTkFrame(popup)
        frame.pack(fill="both", expand=True, padx=5, pady=5)

        # Obtain unique values and standardize them.
        unique_vals = self.df[col_name].unique()
        value_map = {}
        for val in unique_vals:
            std_val = self.standardize_value(val)
            value_map[std_val] = val

        sorted_values = sorted(value_map.keys(), key=lambda x: (x not in ["(Empty/NaN)", "(Blank)"], x))

        if col_name in self.filters:
            current_selections = {self.standardize_value(v) for v in self.filters[col_name]}
        else:
            current_selections = set(sorted_values)

        scroll_frame = ctk.CTkScrollableFrame(frame, height=300)
        scroll_frame.pack(fill="both", expand=True, padx=5, pady=5)

        select_all_var = tk.BooleanVar(value=len(current_selections) == len(sorted_values))
        checkboxes = {}

        def toggle_all():
            for var in checkboxes.values():
                var.set(select_all_var.get())

        select_all_cb = ctk.CTkCheckBox(frame, text="Select All",
                                        variable=select_all_var,
                                        command=toggle_all,
                                        fg_color="#800020", hover_color="#a52a2a")
        select_all_cb.pack(anchor="w", pady=5)

        for std_val in sorted_values:
            var = tk.BooleanVar(value=std_val in current_selections)
            checkboxes[std_val] = var
            ctk.CTkCheckBox(scroll_frame, text=std_val,
                           variable=var,
                           fg_color="#800020", hover_color="#a52a2a").pack(anchor="w")

        def apply_filters():
            selected_std = [disp for disp, var in checkboxes.items() if var.get()]
            selected_values = [value_map[disp] for disp in selected_std]
            if selected_values:
                self.filters[col_name] = selected_values
            else:
                self.filters.pop(col_name, None)
            popup.destroy()
            self.refresh_table()

        button_frame = ctk.CTkFrame(frame)
        button_frame.pack(fill="x", pady=5)
        ctk.CTkButton(button_frame, text="Apply",
                     command=apply_filters,
                     fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)
        ctk.CTkButton(button_frame, text="Cancel",
                     command=popup.destroy,
                     fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)

    def create_toolbar(self):
        bar = ctk.CTkFrame(self, corner_radius=10, fg_color="#f0f0f0")
        bar.pack(fill="x", padx=5, pady=5)
        ctk.CTkLabel(bar, text=f"{self.name} Preview", fg_color="#800020", corner_radius=8).pack(side="left", padx=5)
        ctk.CTkButton(bar, text="ⓘ", width=30, command=self.show_info,
                      fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)
        ctk.CTkButton(bar, text="Clear Date Filters", command=self.clear_filters,
                      fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)

    def show_info(self):
        messagebox.showinfo("Info", f"{self.name} data after meltdown & param.\nFilterable columns: Start/End Date.")

    def create_table(self):
        container = ctk.CTkFrame(self)
        container.pack(fill="both", expand=True, padx=5, pady=5)
        self.tree = ttk.Treeview(container, show="headings")
        vsb = ttk.Scrollbar(container, orient="vertical", command=self.tree.yview)
        hsb = ttk.Scrollbar(container, orient="horizontal", command=self.tree.xview)
        self.tree.configure(yscrollcommand=vsb.set, xscrollcommand=hsb.set)
        self.tree.grid(row=0, column=0, sticky="nsew")
        vsb.grid(row=0, column=1, sticky="ns")
        hsb.grid(row=1, column=0, sticky="ew")
        container.rowconfigure(0, weight=1)
        container.columnconfigure(0, weight=1)

    def create_statusbar(self):
        self.status_label = ctk.CTkLabel(self, text="0 rows")
        self.status_label.pack(fill="x")

    def set_data(self, df: pd.DataFrame):
        self.df = df.copy()
        self.refresh_table()

    def refresh_table(self):
        for i in self.tree.get_children():
            self.tree.delete(i)
        if self.df.empty:
            self.tree["columns"] = []
            self.status_label.configure(text="0 rows")
            return

        cols = list(self.df.columns)
        self.tree["columns"] = cols
        for c in cols:
            self.tree.heading(c, text=c, anchor="w",
                              command=lambda col=c: self.on_heading_click(col))
            self.tree.column(c, anchor="w", width=150)
        df_filtered = self.apply_filters()
        for _, row in df_filtered.iterrows():
            rowvals = [row[c] for c in cols]
            self.tree.insert("", "end", values=rowvals)
        self.status_label.configure(text=f"{len(df_filtered)} rows")

    def apply_filters(self) -> pd.DataFrame:
        if not self.filters:
            return self.df.copy()
        df_filtered = self.df.copy()
        for col, selected_values in self.filters.items():
            mask = pd.Series(False, index=df_filtered.index)
            for val in selected_values:
                std_val = self.standardize_value(val)
                if std_val == "(Empty/NaN)":
                    mask |= df_filtered[col].isna()
                elif std_val == "(Blank)":
                    mask |= (df_filtered[col] == "")
                else:
                    mask |= (df_filtered[col] == val)
            df_filtered = df_filtered[mask]
        return df_filtered

    def clear_filters(self):
        self.filters.clear()
        self.refresh_table()

    def get_filtered_df(self) -> pd.DataFrame:
        return self.apply_filters()

    def set_filters(self, filters: Dict):
        self.filters = filters
        self.refresh_table()

# ----------------------------------------------------------------------------
# ENHANCED PDF REPORT
# ----------------------------------------------------------------------------
class EnhancedPDFReport:
    """
    Creates a PDF report with letter-sized pages (8.5×11 in). Each page (except the cover,
    summary, and top dims/attrs) displays one chart in a single axes that fills the page with
    1-inch margins.
    """
    def __init__(self, df_current: pd.DataFrame, df_history: pd.DataFrame, config: Dict):
        self.df_current = df_current
        self.df_history = df_history
        self.config = config
        self.colors = {
            'primary': '#800020',
            'text': '#2C1810',
            'background': '#FFFFFF'
        }
        self.logo_path = self.config["paths"].get("LOGO_PATH", "images/company_logo.png")
        self.PAGE_WIDTH = 8.5
        self.PAGE_HEIGHT = 11
        self.WATERMARK_X = 1
        self.WATERMARK_Y = self.PAGE_HEIGHT - 1

    def _stamp_logo(self, fig):
        if not self.logo_path or not os.path.exists(self.logo_path):
            return
        try:
            img = plt.imread(self.logo_path)
            fig.figimage(img, xo=int(self.WATERMARK_X*72), yo=int((self.PAGE_HEIGHT - self.WATERMARK_Y)*72), alpha=0.15, zorder=10)
        except Exception as e:
            logging.error(f"Watermark error => {e}")

    def _new_page(self):
        fig = plt.figure(figsize=(self.PAGE_WIDTH, self.PAGE_HEIGHT))
        fig.patch.set_facecolor(self.colors['background'])
        plt.axis('off')
        return fig

    def _title_at_1inch(self, text, fontsize=18):
        fig = plt.gcf()
        plt.text(0.5, 1 - (1/ self.PAGE_HEIGHT), text, ha='center', fontsize=fontsize, fontweight='bold',
                 color=self.colors['primary'], transform=fig.transFigure)

    def _add_cover_page(self, pdf: PdfPages):
        fig = self._new_page()
        self._stamp_logo(fig)
        plt.text(0.5, 0.6, "Reconciliation Analysis Report", ha='center', fontsize=24, fontweight='bold',
                 color=self.colors['primary'], transform=fig.transFigure)
        plt.text(0.5, 0.53, f"Generated on {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
                 ha='center', fontsize=12, color=self.colors['text'], transform=fig.transFigure)
        plt.text(0.5, 0.1, "CONFIDENTIAL", ha='center', fontsize=9, color=self.colors['text'], transform=fig.transFigure)
        plt.text(0.5, 0.08, "Ultra-Mega Reconciliation System", ha='center', fontsize=9, color=self.colors['text'], transform=fig.transFigure)
        pdf.savefig(fig)
        plt.close(fig)

    def _add_summary_page(self, pdf: PdfPages):
        fig = self._new_page()
        self._title_at_1inch("Reconciliation Summary", fontsize=18)
        y = 0.75
        if self.df_current.empty:
            plt.text(0.5, y, "No mismatches found this run.", ha='center', fontsize=14, color=self.colors['text'], transform=fig.transFigure)
        else:
            total = len(self.df_current)
            erp_missing = (self.df_current["Missing In"]=="ERP").sum()
            master_missing = (self.df_current["Missing In"]=="MASTER").sum()
            summary = f"Total Mismatches: {total}\nMissing in ERP: {erp_missing}\nMissing in Master: {master_missing}"
            plt.text(0.5, y, summary, ha='center', fontsize=14, color=self.colors['text'], transform=fig.transFigure)
        pdf.savefig(fig)
        plt.close(fig)

    def _add_topdimsattrs_page(self, pdf: PdfPages):
        fig = self._new_page()
        self._title_at_1inch("Top Dimensions & Top Attributes", fontsize=18)
        if self.df_current.empty:
            plt.text(0.5, 0.7, "No data for top dims/attrs.", ha='center', fontsize=12, color=self.colors['text'], transform=fig.transFigure)
        else:
            if "Dimension" in self.df_current.columns:
                dims = self.df_current["Dimension"].value_counts().head(5)
                lines = [f"{k} ({v})" for k, v in dims.items()]
                plt.text(0.2, 0.7, "Top Dimensions:\n" + "\n".join(lines), fontsize=12, color=self.colors['text'], transform=fig.transFigure)
            if "Attribute" in self.df_current.columns:
                attrs = self.df_current["Attribute"].value_counts().head(5)
                lines = [f"{k} ({v})" for k, v in attrs.items()]
                plt.text(0.6, 0.7, "Top Attributes:\n" + "\n".join(lines), fontsize=12, color=self.colors['text'], transform=fig.transFigure)
        pdf.savefig(fig)
        plt.close(fig)

    def _add_all_charts(self, pdf: PdfPages):
        dfc = self.df_current
        if dfc.empty:
            return
        df_m = dfc[dfc["Missing In"] != ""]
        if not df_m.empty and {"Dimension", "Attribute"}.issubset(df_m.columns):
            pivot = df_m.groupby(["Dimension", "Attribute"]).size().unstack(fill_value=0)
            if not pivot.empty:
                self._add_chart_page(pdf, "Heatmap", self._plot_heatmap, pivot=pivot)
        cdim = df_m.groupby("Dimension")["Key"].count().sort_values(ascending=False).head(10)
        if not cdim.empty:
            self._add_chart_page(pdf, "Lollipop", self._plot_lollipop, cdim=cdim)
        cattr = df_m.groupby("Attribute")["Key"].count().sort_values(ascending=False).head(10)
        if not cattr.empty:
            self._add_chart_page(pdf, "Circular", self._plot_circular, cattr=cattr)
        if not self.df_history.empty and "RunDate" in self.df_history.columns:
            date_ct = self.df_history.groupby("RunDate")["Key"].count().reset_index(name="Count")
            date_ct.sort_values("RunDate", inplace=True)
            if not date_ct.empty:
                self._add_chart_page(pdf, "Band Chart Over Time", self._plot_bandchart, date_ct=date_ct)

    def _add_chart_page(self, pdf: PdfPages, title: str, plot_func, **kwargs):
        fig = self._new_page()
        self._title_at_1inch(title, fontsize=14)
        left = 1 / self.PAGE_WIDTH
        bottom = 1 / self.PAGE_HEIGHT
        width = (self.PAGE_WIDTH - 2) / self.PAGE_WIDTH
        height = (self.PAGE_HEIGHT - 2) / self.PAGE_HEIGHT
        ax = fig.add_axes([left, bottom, width, height])
        ax.grid(False)
        try:
            plot_func(ax, **kwargs)
            pdf.savefig(fig)
        except Exception as e:
            logging.error(f"{title} chart error => {e}")
        finally:
            plt.close(fig)

    def _plot_heatmap(self, ax, pivot):
        im = ax.imshow(pivot, aspect="auto", cmap="Reds")
        ax.set_xticks(range(len(pivot.columns)))
        ax.set_xticklabels(pivot.columns, rotation=45, ha="right")
        ax.set_yticks(range(len(pivot.index)))
        ax.set_yticklabels(pivot.index)
        plt.colorbar(im, ax=ax)

    def _plot_lollipop(self, ax, cdim):
        ax.hlines(y=cdim.index, xmin=0, xmax=cdim.values, color="skyblue")
        ax.plot(cdim.values, cdim.index, "o", color="skyblue")
        ax.set_xlabel("Missing Count")

    def _plot_circular(self, ax, cattr):
        angles = np.linspace(0, 2*np.pi, len(cattr), endpoint=False)
        ax.set_theta_offset(np.pi/2)
        ax.set_theta_direction(-1)
        ax.set_xticks(angles)
        ax.set_xticklabels(cattr.index, fontsize=9)
        ax.bar(angles, cattr.values, width=0.4, color="orange", alpha=0.6)

    def _plot_bandchart(self, ax, date_ct):
        date_ct["Count_min"] = date_ct["Count"] * 0.9
        date_ct["Count_max"] = date_ct["Count"] * 1.1
        ax.plot(date_ct["RunDate"], date_ct["Count"], color="purple", marker="o", label="Missing Count")
        ax.fill_between(date_ct["RunDate"], date_ct["Count_min"], date_ct["Count_max"],
                        color="purple", alpha=0.2, label="±10% band")
        ax.set_xlabel("RunDate")
        ax.set_ylabel("Missing Count")
        plt.xticks(rotation=45, ha="right")
        ax.legend()

    def generate(self) -> Path:
        pdf_dir = Path(self.config["paths"].get("PDF_EXPORT_PATH"))
        pdf_dir.mkdir(parents=True, exist_ok=True)
        stamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        pdf_path = pdf_dir / f"dashboard_report_{stamp}.pdf"
        with PdfPages(pdf_path) as pdf:
            self._add_cover_page(pdf)
            self._add_summary_page(pdf)
            self._add_topdimsattrs_page(pdf)
            self._add_all_charts(pdf)
        logging.info(f"PDF exported => {pdf_path}")
        return pdf_path

# ----------------------------------------------------------------------------
# ADVANCED DASHBOARD
# ----------------------------------------------------------------------------
class AdvancedDashboard(ctk.CTkFrame):
    def __init__(self, parent):
        super().__init__(parent)
        self.df_current = pd.DataFrame()
        self.df_history = pd.DataFrame()
        self.selected_dims: List[str] = []
        self.selected_attrs: List[str] = []
        self.top_n_mode = True

        topbar = ctk.CTkFrame(self, corner_radius=10, fg_color="#f0f0f0")
        topbar.pack(fill="x", padx=5, pady=5)

        self.metric_label = ctk.CTkLabel(topbar, text="Metrics: 0 missing, 0 dimension", width=300)
        self.metric_label.pack(side="left", padx=5)

        ctk.CTkButton(topbar, text="Filter Dimension", command=self.show_dimension_filter,
                      fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)
        ctk.CTkButton(topbar, text="Filter Attribute", command=self.show_attribute_filter,
                      fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)

        ctk.CTkButton(topbar, text="Last 7 Days", command=lambda: self.set_quick_range(7),
                      fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)
        ctk.CTkButton(topbar, text="Last 30 Days", command=lambda: self.set_quick_range(30),
                      fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)
        ctk.CTkButton(topbar, text="Last 90 Days", command=lambda: self.set_quick_range(90),
                      fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)
        ctk.CTkButton(topbar, text="All Time", command=lambda: self.set_quick_range(9999),
                      fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)

        self.start_date_var = tk.StringVar(value=(datetime.now()-timedelta(days=30)).strftime("%Y-%m-%d"))
        self.end_date_var = tk.StringVar(value=datetime.now().strftime("%Y-%m-%d"))

        ctk.CTkEntry(topbar, textvariable=self.start_date_var, width=100).pack(side="left", padx=5)
        ctk.CTkEntry(topbar, textvariable=self.end_date_var, width=100).pack(side="left", padx=5)

        ctk.CTkButton(topbar, text="Update Timeline", command=self.update_data_filters,
                      fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)
        ctk.CTkButton(topbar, text="Toggle Top 10 / All", command=self.toggle_top_n,
                      fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)

        ctk.CTkButton(topbar, text="Export PDF", command=self.export_dashboard_pdf,
                      fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)

        self.scrollable_frame = ctk.CTkScrollableFrame(self, width=1500, height=700)
        self.scrollable_frame.pack(fill="both", expand=True)

        self.frames: Dict[str, ctk.CTkFrame] = {}
        chart_names = ["Heatmap", "Lollipop", "Circular", "Scatter", "Radar", "Normal Pie", "Normal Bar", "Band Chart"]
        for lbl in chart_names:
            fr = ctk.CTkFrame(self.scrollable_frame)
            fr.pack(side="top", fill="both", expand=True, padx=10, pady=5)
            self.frames[lbl] = fr

    def _filter_by_date(self, df: pd.DataFrame) -> pd.DataFrame:
        if "RunDate" not in df.columns:
            return df
        try:
            start_date = pd.to_datetime(self.start_date_var.get())
            end_date = pd.to_datetime(self.end_date_var.get())
            if pd.isna(start_date) or pd.isna(end_date):
                messagebox.showerror("Error", "Invalid date format. Using all dates.")
                return df
            if end_date < start_date:
                messagebox.showerror("Error", "End date cannot be before start date. Using all dates.")
                return df
            df["RunDate_dt"] = pd.to_datetime(df["RunDate"], errors="coerce")
            df_filtered = df[(df["RunDate_dt"] >= start_date) & (df["RunDate_dt"] <= end_date)].copy()
            df_filtered.drop(columns=["RunDate_dt"], inplace=True)
            if df_filtered.empty and not df.empty:
                messagebox.showwarning("Warning", "No data in selected date range")
            return df_filtered
        except Exception as e:
            messagebox.showerror("Error", f"Date filtering error: {str(e)}")
            return df

    def set_quick_range(self, days: int):
        if days > 9000:
            self.start_date_var.set("1900-01-01")
            self.end_date_var.set("2100-12-31")
        else:
            dt_end = datetime.now()
            dt_start = dt_end - timedelta(days=days)
            self.start_date_var.set(dt_start.strftime("%Y-%m-%d"))
            self.end_date_var.set(dt_end.strftime("%Y-%m-%d"))
        self.update_data_filters()

    def toggle_top_n(self):
        self.top_n_mode = not self.top_n_mode
        self.update_data_filters()

    def show_dimension_filter(self):
        self.show_filter_popup("Dimension")

    def show_attribute_filter(self):
        self.show_filter_popup("Attribute")

    def show_filter_popup(self, col: str):
        base_df = self.df_history if not self.df_history.empty else self.df_current
        if base_df.empty or col not in base_df.columns:
            return

        popup = tk.Toplevel(self)
        popup.title(f"Filter: {col}")
        popup.geometry("300x400")
        frame = ctk.CTkFrame(popup)
        frame.pack(fill="both", expand=True, padx=5, pady=5)

        unique_values = [str(x) if pd.notna(x) else 'NaN' for x in base_df[col].unique()]
        unique_values = sorted(list(set(unique_values)))
        current_selection = self.selected_dims if col == "Dimension" else self.selected_attrs
        if not current_selection:
            current_selection = unique_values

        var_dict = {}
        for value in unique_values:
            display_value = value
            if value.lower() == 'nan':
                display_value = "(NaN)"
            elif value.strip() == '':
                display_value = "(Blank)"
            var = tk.BooleanVar(value=value in current_selection)
            var_dict[value] = var
            ctk.CTkCheckBox(frame, text=display_value, variable=var,
                            fg_color="#800020", hover_color="#a52a2a").pack(anchor="w")

        select_all_var = tk.BooleanVar(value=set(current_selection) == set(unique_values))
        def toggle_all():
            for var in var_dict.values():
                var.set(select_all_var.get())
        select_all_check = ctk.CTkCheckBox(frame, text="Select All", variable=select_all_var, command=toggle_all,
                                          fg_color="#800020", hover_color="#a52a2a")
        select_all_check.pack(anchor="w", pady=5)

        def apply_filters():
            selected_values = [value for value, var in var_dict.items() if var.get()]
            if col == "Dimension":
                self.selected_dims = selected_values
            else:
                self.selected_attrs = selected_values
            popup.destroy()
            self.update_data_filters()

        button_frame = ctk.CTkFrame(frame)
        button_frame.pack(fill="x", pady=5)
        ctk.CTkButton(button_frame, text="Apply", command=apply_filters,
                      fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)
        ctk.CTkButton(button_frame, text="Cancel", command=popup.destroy,
                      fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)

    def update_data(self, df_current: pd.DataFrame, df_history: pd.DataFrame):
        self.df_current = df_current.copy()
        self.df_history = df_history.copy()
        config = self.master.config_dict.get("dashboard", {})
        self.start_date_var.set(config.get("start_date", (datetime.now() - timedelta(days=30)).strftime("%Y-%m-%d")))
        self.end_date_var.set(config.get("end_date", datetime.now().strftime("%Y-%m-%d")))
        self.selected_dims = config.get("selected_dims", [])
        self.selected_attrs = config.get("selected_attrs", [])
        self.top_n_mode = config.get("top_n_mode", True)
        self.update_data_filters()

    def update_data_filters(self):
        self.master.config_dict["dashboard"].update({
            "start_date": self.start_date_var.get(),
            "end_date": self.end_date_var.get(),
            "selected_dims": self.selected_dims,
            "selected_attrs": self.selected_attrs,
            "top_n_mode": self.top_n_mode
        })

        dfc = self.df_current.copy()
        if self.selected_dims:
            dfc = dfc[dfc["Dimension"].isin(self.selected_dims)]
        if self.selected_attrs:
            dfc = dfc[dfc["Attribute"].isin(self.selected_attrs)]

        df_history_filtered = self._filter_by_date(self.df_history.copy())
        if "RunDate" in dfc.columns:
            dfc = self._filter_by_date(dfc.copy())

        mism = len(dfc)
        dims = dfc["Dimension"].nunique() if not dfc.empty and "Dimension" in dfc.columns else 0
        self.metric_label.configure(text=f"Mismatches: {mism}, Dims: {dims}")

        self.plotHeatmap(dfc)
        self.plotLollipop(dfc)
        self.plotCircular(dfc)
        self.plotScatter(dfc)
        self.plotRadar(dfc)
        self.plotNormalPie(dfc)
        self.plotNormalBar(dfc)
        self.plotBandChart(df_history_filtered)

    def plot_chart(self, frame, fig):
        for w in frame.winfo_children():
            w.destroy()
        canvas = FigureCanvasTkAgg(fig, master=frame)
        canvas.draw()
        canvas.get_tk_widget().pack(side="top", fill="both", expand=True)
        toolbar = NavigationToolbar2Tk(canvas, frame, pack_toolbar=False)
        toolbar.update()
        toolbar.pack(side="bottom", fill="x")

    def plotHeatmap(self, dfc: pd.DataFrame):
        fr = self.frames["Heatmap"]
        for w in fr.winfo_children():
            w.destroy()
        if dfc.empty or "Missing In" not in dfc.columns:
            return
        df_m = dfc[dfc["Missing In"] != ""]
        if df_m.empty or not {"Dimension", "Attribute"}.issubset(df_m.columns):
            return
        pivot = df_m.groupby(["Dimension", "Attribute"]).size().unstack(fill_value=0)
        fig, ax = plt.subplots(figsize=(6,5))
        if not pivot.empty:
            im = ax.imshow(pivot, aspect="auto", cmap="Reds")
            ax.set_xticks(range(len(pivot.columns)))
            ax.set_xticklabels(pivot.columns, rotation=90)
            ax.set_yticks(range(len(pivot.index)))
            ax.set_yticklabels(pivot.index)
            plt.colorbar(im, ax=ax)
            ax.set_title("Heatmap: Missing Items")
        self.plot_chart(fr, fig)

    def plotLollipop(self, dfc: pd.DataFrame):
        fr = self.frames["Lollipop"]
        for w in fr.winfo_children():
            w.destroy()
        if dfc.empty or "Missing In" not in dfc.columns:
            return
        df_m = dfc[dfc["Missing In"] != ""]
        if df_m.empty or "Dimension" not in df_m:
            return
        if self.top_n_mode:
            cdim = df_m.groupby("Dimension")["Key"].count().sort_values(ascending=False).head(10)
        else:
            cdim = df_m.groupby("Dimension")["Key"].count().sort_values(ascending=False)
        if cdim.empty:
            return
        fig, ax = plt.subplots(figsize=(6,5))
        ax.hlines(y=cdim.index, xmin=0, xmax=cdim.values, color="skyblue")
        ax.plot(cdim.values, cdim.index, "o", color="skyblue")
        ax.set_title("Lollipop: Missing Dimensions")
        ax.set_xlabel("Missing Count")
        self.plot_chart(fr, fig)

    def plotCircular(self, dfc: pd.DataFrame):
        fr = self.frames["Circular"]
        for w in fr.winfo_children():
            w.destroy()
        if dfc.empty or "Missing In" not in dfc.columns:
            return
        df_m = dfc[dfc["Missing In"] != ""]
        if df_m.empty or "Attribute" not in df_m:
            return
        if self.top_n_mode:
            cattr = df_m.groupby("Attribute")["Key"].count().sort_values(ascending=False).head(10)
        else:
            cattr = df_m.groupby("Attribute")["Key"].count().sort_values(ascending=False)
        if cattr.empty:
            return
        fig = plt.figure(figsize=(6,6))
        ax = fig.add_subplot(111, polar=True)
        angles = np.linspace(0, 2*np.pi, len(cattr), endpoint=False)
        ax.set_theta_offset(np.pi/2)
        ax.set_theta_direction(-1)
        ax.set_xticks(angles)
        ax.set_xticklabels(cattr.index, fontsize=9)
        ax.bar(angles, cattr.values, width=0.4, color="orange", alpha=0.6)
        ax.set_title("Circular: Missing Attributes", y=1.05)
        self.plot_chart(fr, fig)

    def plotScatter(self, dfc: pd.DataFrame):
        fr = self.frames["Scatter"]
        for w in fr.winfo_children():
            w.destroy()
        if dfc.empty or "Missing In" not in dfc.columns:
            return
        df_m = dfc[dfc["Missing In"] != ""]
        if df_m.empty or "Dimension" not in df_m:
            return
        if self.top_n_mode:
             cdim = df_m.groupby("Dimension")["Key"].count().sort_values(ascending=False).head(10).reset_index(name="Count")
        else:
            cdim = df_m.groupby("Dimension")["Key"].count().sort_values(ascending=False).reset_index(name="Count")
        if cdim.empty:
            return
        fig, ax = plt.subplots(figsize=(6,5))
        xvals = np.arange(len(cdim))
        ax.scatter(xvals, cdim["Count"].values, color="green")
        for i, txt in enumerate(cdim["Dimension"].values):
            ax.text(xvals[i], cdim["Count"].values[i], txt, ha="center", va="bottom", rotation=60)
        ax.set_xticks([])
        ax.set_ylabel("Missing Count")
        ax.set_title("Scatter: Missing by Dimension")
        self.plot_chart(fr, fig)

    def plotRadar(self, dfc: pd.DataFrame):
        fr = self.frames["Radar"]
        for w in fr.winfo_children():
            w.destroy()
        if dfc.empty or "Missing In" not in dfc.columns:
            return
        df_m = dfc[dfc["Missing In"] != ""]
        if df_m.empty or "Dimension" not in df_m:
            return
        cdim = df_m.groupby("Dimension")["Key"].count().sort_values(ascending=False).head(5)
        if cdim.empty:
            return
        fig = plt.figure(figsize=(6,6))
        ax = fig.add_subplot(111, polar=True)
        cat = cdim.index.tolist()
        val = cdim.values.tolist()
        N = len(cat)
        angles = np.linspace(0, 2*np.pi, N, endpoint=False).tolist()
        angles += angles[:1]
        val += val[:1]
        ax.set_theta_offset(np.pi/2)
        ax.set_theta_direction(-1)
        ax.set_xticks(angles[:-1])
        ax.set_xticklabels(cat, fontsize=9)
        ax.plot(angles, val, color="red", linewidth=2)
        ax.fill(angles, val, color="red", alpha=0.3)
        ax.set_title("Radar: Top 5 Missing Dims", y=1.08)
        self.plot_chart(fr, fig)

    def plotNormalPie(self, dfc: pd.DataFrame):
        fr = self.frames["Normal Pie"]
        for w in fr.winfo_children():
            w.destroy()
        if dfc.empty or "Missing In" not in dfc.columns:
            return
        df_m = dfc[dfc["Missing In"] != ""]
        if df_m.empty:
            return
        dist = df_m["Missing In"].value_counts()
        fig, ax = plt.subplots(figsize=(5,5))
        ax.pie(dist.values, labels=dist.index, autopct="%.1f%%", startangle=140)
        ax.set_title("Pie: Missing In Distribution")
        self.plot_chart(fr, fig)

    def plotNormalBar(self, dfc: pd.DataFrame):
        fr = self.frames["Normal Bar"]
        for w in fr.winfo_children():
            w.destroy()
        if dfc.empty or "Missing In" not in dfc.columns:
            return
        df_m = dfc[dfc["Missing In"] != ""]
        if df_m.empty or "Attribute" not in df_m:
            return
        if self.top_n_mode:
            cattr = df_m.groupby("Attribute")["Key"].count().sort_values(ascending=False).head(10)
        else:
            cattr = df_m.groupby("Attribute")["Key"].count().sort_values(ascending=False)
        fig, ax = plt.subplots(figsize=(6,4))
        if not cattr.empty:
            cattr.plot(kind="bar", ax=ax, color="blue")
            ax.set_ylabel("Missing Count")
            ax.set_title("Bar: Top 10 Missing Attributes")
            plt.xticks(rotation=45, ha="right")
        self.plot_chart(fr, fig)

    def plotBandChart(self, df_history: pd.DataFrame):
        fr = self.frames["Band Chart"]
        for w in fr.winfo_children():
            w.destroy()
        if df_history.empty or "RunDate" not in df_history.columns:
            return
        date_ct = df_history.groupby("RunDate")["Key"].count().reset_index(name="Count")
        date_ct.sort_values("RunDate", inplace=True)
        date_ct["Count_min"] = date_ct["Count"] * 0.9
        date_ct["Count_max"] = date_ct["Count"] * 1.1
        fig, ax = plt.subplots(figsize=(6,4))
        if not date_ct.empty:
            ax.plot(date_ct["RunDate"], date_ct["Count"], color="purple", marker="o", label="Missing Count")
            ax.fill_between(date_ct["RunDate"], date_ct["Count_min"], date_ct["Count_max"],
                            color="purple", alpha=0.2, label="±10% band")
            ax.set_title("Band Chart Over Time")
            ax.set_xlabel("RunDate")
            ax.set_ylabel("Missing Count")
            plt.xticks(rotation=45, ha="right")
            ax.legend()
            for i, row in date_ct.iterrows():
                ax.text(row["RunDate"], row["Count"], str(row["Count"]), ha="center", va="bottom")
        self.plot_chart(fr, fig)

    def export_dashboard_pdf(self):
        report = EnhancedPDFReport(self.df_current, self.df_history, self.master.config_dict)
        report.generate()
        messagebox.showinfo("PDF Export", f"Dashboard exported to PDF. Check the log for the exact path.")

# ----------------------------------------------------------------------------
# MAIN APP
# ----------------------------------------------------------------------------
class MainApp(ctk.CTk):
    def __init__(self):
        super().__init__()
        self.title("Ultra-Mega Reconciliation: Param-based, Full Dashboard")
        self.geometry("1600x900")
        ctk.set_appearance_mode("light")

        self.config_dict = load_config(Path(DEFAULT_PATHS["CONFIG_PATH"]))
        self.param_dict = read_param_file(Path(self.config_dict["paths"].get("PARAMETER_PATH", DEFAULT_PATHS["PARAMETER_PATH"])))
        self.history_df = pd.DataFrame()

        self.tabs = ttk.Notebook(self)
        self.tabs.pack(fill="both", expand=True)

        # Paths Tab
        self.tab_paths = ctk.CTkFrame(self.tabs)
        self.tabs.add(self.tab_paths, text="Paths")
        self.build_paths_tab(self.tab_paths)

        # ERP Preview
        self.tab_erp = ctk.CTkFrame(self.tabs)
        self.erp_preview = SimplePreview(self.tab_erp, "ERP")
        self.erp_preview.pack(fill="both", expand=True)
        self.tabs.add(self.tab_erp, text="ERP Preview")

        # Master Preview
        self.tab_master = ctk.CTkFrame(self.tabs)
        self.master_preview = SimplePreview(self.tab_master, "Master")
        self.master_preview.pack(fill="both", expand=True)
        self.tabs.add(self.tab_master, text="Master Preview")

        # Compare
        self.tab_compare = ctk.CTkFrame(self.tabs)
        self.build_compare_tab(self.tab_compare)
        self.tabs.add(self.tab_compare, text="Compare")

        # Dashboard
        self.dashboard_tab = AdvancedDashboard(self.tabs)
        self.dashboard_tab.master = self
        self.tabs.add(self.dashboard_tab, text="Dashboard")

        # Logging
        self.log_box = ctk.CTkTextbox(self, height=120)
        self.log_box.pack(fill="both")
        self.log_box.configure(state="disabled")
        handler = TextHandler(self.log_box)
        handler.setLevel(logging.INFO)
        logging.getLogger().addHandler(handler)

        self.add_status_bar()

        self.temp_csv_dir = Path(self.config_dict["paths"].get("MASTER_CSV_OUTPUT", "temp_master_csv"))
        self.temp_csv_dir.mkdir(parents=True, exist_ok=True)

        self.refresh_erp()
        self.refresh_master()
        self.load_saved_filters()

        self.protocol("WM_DELETE_WINDOW", self.on_close)

    def add_status_bar(self):
        self.status_bar = ctk.CTkFrame(self)
        self.status_bar.pack(fill="x", side="bottom")
        self.status_label = ctk.CTkLabel(self.status_bar, text="Ready")
        self.status_label.pack(side="left", padx=5)
        self.memory_label = ctk.CTkLabel(self.status_bar, text="")
        self.memory_label.pack(side="right", padx=5)
        self.update_status_bar()

    def update_status_bar(self):
        if psutil is not None:
            mem = psutil.Process().memory_info().rss / 1024 / 1024
            self.memory_label.configure(text=f"Memory: {mem:.1f} MB")
        else:
            self.memory_label.configure(text="psutil not installed")
        self.after(1000, self.update_status_bar)

    def build_paths_tab(self, parent):
        frm = ctk.CTkFrame(parent)
        frm.pack(fill="both", expand=True, padx=10, pady=10)
        self.erp_var = tk.StringVar(value=self.config_dict["paths"].get("ERP_EXCEL_PATH", DEFAULT_PATHS["ERP_EXCEL_PATH"]))
        self.mast_var = tk.StringVar(value=self.config_dict["paths"].get("MASTER_ZIP_PATH", DEFAULT_PATHS["MASTER_ZIP_PATH"]))
        self.exc_var = tk.StringVar(value=self.config_dict["paths"].get("EXCEPTION_PATH", DEFAULT_PATHS["EXCEPTION_PATH"]))
        self.out_var = tk.StringVar(value=self.config_dict["paths"].get("OUTPUT_PATH", DEFAULT_PATHS["OUTPUT_PATH"]))
        self.cfg_var = tk.StringVar(value=self.config_dict["paths"].get("CONFIG_PATH", DEFAULT_PATHS["CONFIG_PATH"]))
        self.par_var = tk.StringVar(value=self.config_dict["paths"].get("PARAMETER_PATH", DEFAULT_PATHS["PARAMETER_PATH"]))
        self.csv_var = tk.StringVar(value=self.config_dict["paths"].get("MASTER_CSV_OUTPUT", DEFAULT_PATHS["MASTER_CSV_OUTPUT"]))
        def mkrow(lbl, var, is_dir=False):
            row = ctk.CTkFrame(frm)
            row.pack(fill="x", pady=5)
            ctk.CTkLabel(row, text=lbl, width=180).pack(side="left", padx=5)
            e = ctk.CTkEntry(row, textvariable=var, width=600)
            e.pack(side="left", padx=5)
            def br():
                p = filedialog.askdirectory() if is_dir else filedialog.askopenfilename()
                if p:
                    var.set(p)
            ctk.CTkButton(row, text="Browse", command=br,
                          fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)
        mkrow("ERP Excel:", self.erp_var)
        mkrow("Master ZIP:", self.mast_var)
        mkrow("Exception Path:", self.exc_var)
        mkrow("Missing Items Output:", self.out_var)
        mkrow("JSON Config Path:", self.cfg_var)
        mkrow("Parameter File:", self.par_var)
        mkrow("Master CSV Folder:", self.csv_var, is_dir=True)
        bf = ctk.CTkFrame(frm)
        bf.pack(fill="x", pady=10)
        ctk.CTkButton(bf, text="Save Config", command=self.save_all_config,
                      fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)
        ctk.CTkButton(bf, text="Refresh ERP", command=self.refresh_erp,
                      fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)
        ctk.CTkButton(bf, text="Refresh Master", command=self.refresh_master,
                      fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)

    def build_compare_tab(self, parent):
        frm = ctk.CTkFrame(parent)
        frm.pack(fill="both", expand=True, padx=10, pady=10)
        btn_frame = ctk.CTkFrame(frm)
        btn_frame.pack(fill="x", pady=5)
        ctk.CTkButton(btn_frame, text="Refresh All Data", command=self.refresh_all_data,
                      fg_color="#800020", hover_color="#a52a2a", height=40).pack(side="left", padx=5)
        comp_frame = ctk.CTkFrame(frm)
        comp_frame.pack(fill="x", pady=10)
        ctk.CTkLabel(comp_frame, text="Generate Missing Items Report", font=("Arial",16)).pack(pady=5)
        ctk.CTkButton(comp_frame, text="Run Reconciliation", command=self.run_comparison,
                      fg_color="#800020", hover_color="#a52a2a", height=40).pack(pady=5)
        self.status_frame = ctk.CTkFrame(frm)
        self.status_frame.pack(fill="x", pady=5)
        self.last_run_label = ctk.CTkLabel(self.status_frame, text="Last Run: Never")
        self.last_run_label.pack(pady=5)

    def load_saved_filters(self):
        if "erp_grid" in self.config_dict and "filters" in self.config_dict["erp_grid"]:
            self.erp_preview.set_filters(self.config_dict["erp_grid"]["filters"])
        if "master_grid" in self.config_dict and "filters" in self.config_dict["master_grid"]:
            self.master_preview.set_filters(self.config_dict["master_grid"]["filters"])

    def refresh_all_data(self):
        try:
            self.param_dict = read_param_file(Path(self.config_dict["paths"].get("PARAMETER_PATH", DEFAULT_PATHS["PARAMETER_PATH"])))
            self.refresh_erp()
            self.refresh_master()
            now = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            self.last_run_label.configure(text=f"Last Refresh: {now}")
            messagebox.showinfo("Success", "All data refreshed successfully!")
        except Exception as e:
            logging.error(f"Error refreshing data: {e}")
            messagebox.showerror("Error", f"Error refreshing data: {str(e)}")

    def refresh_erp(self):
        erp_path = Path(self.erp_var.get().strip()).resolve()
        raw_erp = read_erp_excel(erp_path)
        if raw_erp.empty:
            self.erp_preview.set_data(pd.DataFrame())
            return
        param = {
            "dim_erp_keep": self.param_dict.get("dim_erp_keep", set()),
            "dim_erp_map": self.param_dict.get("dim_erp_map", {}),
            "attr_erp_map": self.param_dict.get("attr_erp_map", {})
        }
        melted = meltdown_erp_for_preview(raw_erp, param)
        pivoted = pivot_for_preview(melted)
        self.erp_preview.set_data(pivoted)

    def refresh_master(self):
        zip_path = Path(self.mast_var.get().strip()).resolve()
        out_dir = Path(self.csv_var.get().strip()).resolve()
        csvs = convert_master_txt_to_csv(zip_path, out_dir)
        raw_mast = unify_master_csvs(csvs)
        if raw_mast.empty:
            self.master_preview.set_data(pd.DataFrame())
            return
        param = {
            "dim_master_map": self.param_dict.get("dim_master_map", {}),
            "attr_master_map": self.param_dict.get("attr_master_map", {})
        }
        melted = meltdown_master_for_preview(raw_mast, param)
        pivoted = pivot_for_preview(melted)
        self.master_preview.set_data(pivoted)

    def run_comparison(self):
        df_erp_wide = self.erp_preview.get_filtered_df()
        df_mast_wide = self.master_preview.get_filtered_df()

        erp_long = melt_back(df_erp_wide)
        erp_long = build_keys(erp_long)
        mast_long = melt_back(df_mast_wide)
        mast_long = build_keys(mast_long)

        df_diff = compare_mode2(erp_long, mast_long)
        exc_path = Path(self.config_dict["paths"].get("EXCEPTION_PATH", DEFAULT_PATHS["EXCEPTION_PATH"])).resolve()
        df_exc = read_exception_table(exc_path)
        final = merge_exceptions(df_diff, df_exc)
        out_path = Path(self.config_dict["paths"].get("OUTPUT_PATH", DEFAULT_PATHS["OUTPUT_PATH"])).resolve()
        write_missing_items(final, out_path)

        run_date = datetime.now().strftime("%Y-%m-%d")
        final["RunDate"] = run_date

        if self.history_df.empty:
            self.history_df = final.copy()
        else:
            self.history_df = pd.concat([self.history_df, final], ignore_index=True)

        run_summary = {"date": run_date, "missing": len(final)}
        self.config_dict["run_history"].append(run_summary)

        self.dashboard_tab.update_data(final, self.history_df)
        self.last_run_label.configure(text=f"Last Run: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        self.tabs.select(self.dashboard_tab)
        messagebox.showinfo("Done", f"Missing items written to {out_path}")

    def save_all_config(self):
        self.config_dict["paths"]["ERP_EXCEL_PATH"] = self.erp_var.get().strip()
        self.config_dict["paths"]["MASTER_ZIP_PATH"] = self.mast_var.get().strip()
        self.config_dict["paths"]["EXCEPTION_PATH"] = self.exc_var.get().strip()
        self.config_dict["paths"]["OUTPUT_PATH"] = self.out_var.get().strip()
        self.config_dict["paths"]["CONFIG_PATH"] = self.cfg_var.get().strip()
        self.config_dict["paths"]["PARAMETER_PATH"] = self.par_var.get().strip()
        self.config_dict["paths"]["MASTER_CSV_OUTPUT"] = self.csv_var.get().strip()

        self.config_dict["erp_grid"]["filters"] = self.erp_preview.filters
        self.config_dict["master_grid"]["filters"] = self.master_preview.filters

        if hasattr(self, 'dashboard_tab'):
            self.config_dict["dashboard"].update({
                "start_date": self.dashboard_tab.start_date_var.get(),
                "end_date": self.dashboard_tab.end_date_var.get(),
                "selected_dims": self.dashboard_tab.selected_dims,
                "selected_attrs": self.dashboard_tab.selected_attrs,
                "top_n_mode": self.dashboard_tab.top_n_mode
            })

        save_config(self.config_dict, Path(self.config_dict["paths"]["CONFIG_PATH"]))
        messagebox.showinfo("Saved", "Paths & Config saved successfully.")

    def on_close(self):
        try:
            self.save_all_config()
            logging.info("Application state saved successfully")
        except Exception as e:
            logging.error(f"Error saving application state: {e}")
            messagebox.showerror("Error", "Failed to save application state")
        self.destroy()

def main():
    app = MainApp()
    app.mainloop()

if __name__ == "__main__":
    main()
