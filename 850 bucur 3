#!/usr/bin/env python3
"""
Ultra-Mega Reconciliation (2-sheet, SHIFTED PDF with 8 charts + Bollinger),
Name-as-attribute => If Name missing/diff => single row => skip other attributes
We also:
 - Use "Status" (Missing in Master / Missing in ERP / Difference in both) 
 - Provide a "Trim Key" toggle
 - Provide a "Future End Date?" toggle in SimplePreview
 - 2 sheet Excel (Mismatch + Case) + "Charts" sheet with a sample openpyxl bar chart
 - AdvancedDashboard for mismatch
 - HistoryTab
 - meltdown_to_long & meltdown_erp_for_preview / meltdown_master_for_preview
One single file.

Dependencies:
 - pandas, numpy, openpyxl, customtkinter, matplotlib, tk, python 3.7+
"""

import os
import sys
import json
import logging
import zipfile
import shutil
import io
from pathlib import Path
from datetime import datetime, date
from typing import Dict, Set, List, Tuple

import tkinter as tk
from tkinter import ttk, filedialog, messagebox
import customtkinter as ctk

import pandas as pd
import numpy as np

import matplotlib
matplotlib.use("TkAgg")
import matplotlib.pyplot as plt
from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg, NavigationToolbar2Tk
from matplotlib.backends.backend_pdf import PdfPages

from openpyxl import Workbook
from openpyxl.styles import PatternFill, Font, Alignment
from openpyxl.utils import get_column_letter
from openpyxl.worksheet.table import Table, TableStyleInfo
from openpyxl.chart import BarChart, Reference

# ----------------------------------------------------------------------------
# LOGGING
# ----------------------------------------------------------------------------
logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")

# ----------------------------------------------------------------------------
# DEFAULT CONFIG
# ----------------------------------------------------------------------------
DEFAULT_PATHS = {
    "ERP_EXCEL_PATH": "data/ERP_Config.xlsx",
    "MASTER_ZIP_PATH": "data/Master_Config.zip",
    "MASTER_TXT_FOLDER": "",
    "EXCEPTION_PATH": "data/Exception_Table.xlsx",
    "OUTPUT_PATH": "output/missing_items.xlsx",
    "CONFIG_PATH": "config/ui_config.json",
    "PARAMETER_PATH": "data/parameters.xlsx",
    "MASTER_CSV_OUTPUT": "temp_master_csv",
    "PDF_EXPORT_PATH": "output/dashboard_report.pdf",
    "LOGO_PATH": "images/company_logo.png",
    "HISTORY_PATH": "history_runs",
    "BAND_CHART_JSON_PATH": "data/bollinger_data.json"
}

def default_config() -> Dict:
    return {
        "paths": DEFAULT_PATHS.copy(),
        "erp_grid": {
            "filters": {},
            "future_end_toggle": False
        },
        "master_grid": {
            "filters": {},
            "future_end_toggle": False
        },
        "dashboard": {
            "selected_dims": [],
            "selected_attrs": [],
            "top_n": 10
        },
        "trim_key_toggle": False
    }

def load_config(path: Path)-> Dict:
    if path.is_file():
        try:
            with open(path,"r",encoding="utf-8") as f:
                return json.load(f)
        except Exception as e:
            logging.warning(f"Could not load config => {e}")
    return default_config()

def save_config(cfg: Dict, path: Path):
    path.parent.mkdir(parents=True, exist_ok=True)
    try:
        # sets->lists in erp_grid
        if "erp_grid" in cfg and "filters" in cfg["erp_grid"]:
            new_erp={}
            for col,valset in cfg["erp_grid"]["filters"].items():
                new_erp[col]= list(valset)
            cfg["erp_grid"]["filters"]= new_erp

        # sets->lists in master_grid
        if "master_grid" in cfg and "filters" in cfg["master_grid"]:
            new_m={}
            for col,valset in cfg["master_grid"]["filters"].items():
                new_m[col]= list(valset)
            cfg["master_grid"]["filters"]= new_m

        with open(path,"w",encoding="utf-8") as f:
            json.dump(cfg, f, indent=2)
        logging.info(f"Saved config => {path}")
    except Exception as e:
        logging.error(f"Error saving config => {e}")

# ----------------------------------------------------------------------------
# TEXT LOGGER
# ----------------------------------------------------------------------------
class TextHandler(logging.Handler):
    def __init__(self, widget: ctk.CTkTextbox):
        super().__init__()
        self.widget= widget
    def emit(self, record):
        msg= self.format(record)+ "\n"
        self.widget.after(0, self._append, msg)
    def _append(self, msg):
        self.widget.configure(state="normal")
        self.widget.insert("end", msg)
        self.widget.see("end")
        self.widget.configure(state="disabled")

# ----------------------------------------------------------------------------
# READ PARAM
# ----------------------------------------------------------------------------
def read_param_file(path: Path)-> Dict[str,object]:
    param= {
        "dim_erp_keep": set(),
        "dim_erp_map": {},
        "dim_master_map": {},
        "attr_erp_map": {},
        "attr_master_map": {}
    }
    if not path.is_file():
        logging.warning(f"Param => not found => {path}")
        return param
    try:
        dim_df= pd.read_excel(path, sheet_name="Dimension Parameters")
        dim_df.columns= dim_df.columns.astype(str).str.strip()

        def s(x)-> str: return str(x).strip() if pd.notna(x) else ""
        for _, row in dim_df.iterrows():
            fn= s(row.get("FileName",""))
            vsc= s(row.get("V S C",""))
            dim= s(row.get("Dimension",""))
            ev= s(row.get("ERP Values",""))
            if ev.lower()=="x" and vsc and dim:
                param["dim_erp_keep"].add(vsc)
            if vsc and dim:
                param["dim_erp_map"][vsc]= dim
            if fn and dim and ev.lower()=="x":
                param["dim_master_map"][fn]= dim

        attr_df= pd.read_excel(path, sheet_name="Attribute Parameters")
        attr_df.columns= attr_df.columns.astype(str).str.strip()
        for _, row in attr_df.iterrows():
            e_orig= s(row.get("ERP Original Attributes",""))
            m_orig= s(row.get("Master Original Attributes",""))
            final_= s(row.get("Attribute",""))
            onoff= s(row.get("On/Off",""))
            if onoff.lower()=="x" and final_:
                if e_orig:
                    param["attr_erp_map"][e_orig]= final_
                if m_orig:
                    param["attr_master_map"][m_orig]= final_
        return param
    except Exception as e:
        logging.error(f"read_param_file => {e}")
        return param

# ----------------------------------------------------------------------------
# ERP
# ----------------------------------------------------------------------------
def read_erp_excel(path: Path)-> pd.DataFrame:
    if not path.is_file():
        logging.warning(f"ERP => not found => {path}")
        return pd.DataFrame()
    try:
        df= pd.read_excel(path, skiprows=3)
        df.columns= df.columns.str.strip()
        if "Enabled_Flag" in df.columns:
            df= df[df["Enabled_Flag"]=="Enabled"]
        return df
    except Exception as e:
        logging.error(f"read_erp_excel => {e}")
        return pd.DataFrame()

# ----------------------------------------------------------------------------
# MASTER => local folder or zip
# ----------------------------------------------------------------------------
def try_read_csv_bytes(raw: bytes)-> pd.DataFrame:
    encs= ["utf-8-sig","utf-16-le","utf-16-be","cp1252","latin-1","ascii"]
    import io
    for e in encs:
        try:
            buf= io.BytesIO(raw)
            df= pd.read_csv(buf, encoding=e, on_bad_lines="skip", engine="python")
            df.dropna(how="all",axis=0,inplace=True)
            df.dropna(how="all",axis=1,inplace=True)
            df.columns= df.columns.astype(str).str.strip()
            if "Name" not in df.columns and len(df.columns)>0:
                first_col= df.columns[0]
                df.rename(columns={first_col:"Name"}, inplace=True)
            return df
        except:
            pass
    logging.error("All enc fail => empty DF")
    return pd.DataFrame()

def unify_master_txt_in_folder(folder: Path)-> pd.DataFrame:
    if not folder.is_dir():
        logging.warning(f"Master folder => not exist => {folder}")
        return pd.DataFrame()
    txts= list(folder.glob("*.txt"))
    frames=[]
    for f in txts:
        try:
            raw= f.read_bytes()
            df= try_read_csv_bytes(raw)
            if not df.empty:
                df["RawFileName"]= f.name
                frames.append(df)
        except Exception as e:
            logging.error(f"unify_master_txt_in_folder => {f} => {e}")
    if frames:
        return pd.concat(frames, ignore_index=True)
    return pd.DataFrame()

def convert_master_txt_to_csv(zip_path: Path, out_dir: Path)-> List[Path]:
    if not zip_path.is_file():
        logging.warning(f"Master ZIP => not exist => {zip_path}")
        return []
    if out_dir.exists():
        shutil.rmtree(out_dir, ignore_errors=True)
    out_dir.mkdir(parents=True,exist_ok=True)
    csvs=[]
    with zipfile.ZipFile(zip_path,"r") as z:
        txt_files= [f for f in z.namelist() if f.lower().endswith(".txt")]
        for txtf in txt_files:
            bn= os.path.basename(txtf)
            if not bn:
                continue
            try:
                with z.open(txtf) as fo:
                    raw= fo.read()
                df= try_read_csv_bytes(raw)
                if df.empty:
                    continue
                df["RawFileName"]= bn
                out_csv= out_dir/(bn.replace(".txt",".csv"))
                df.to_csv(out_csv,index=False,encoding="utf-8")
                csvs.append(out_csv)
            except Exception as e:
                logging.error(f"Reading {txtf} => {e}")
    return csvs

def unify_master_csvs(csvs: List[Path])-> pd.DataFrame:
    frames=[]
    for c in csvs:
        if not c.is_file():
            continue
        try:
            df= pd.read_csv(c, encoding="utf-8", on_bad_lines="skip")
            df.columns= df.columns.str.strip()
            frames.append(df)
        except Exception as e:
            logging.error(f"unify_master_csvs => {c} => {e}")
    if frames:
        return pd.concat(frames, ignore_index=True)
    return pd.DataFrame()

# ----------------------------------------------------------------------------
# meltdown => meltdown_erp_for_preview, meltdown_master_for_preview
# ----------------------------------------------------------------------------
def meltdown_erp_for_preview(df: pd.DataFrame, param: Dict[str,object])-> pd.DataFrame:
    if "V_S_C" not in df.columns:
        return pd.DataFrame()
    keep= param["dim_erp_keep"]
    dmap= param["dim_erp_map"]
    amap= param["attr_erp_map"]

    df2= df[df["V_S_C"].isin(keep)].copy()
    if df2.empty:
        return pd.DataFrame()

    skip= {"V_S_C","Enabled_Flag"}
    idv=[]
    if "Value" in df2.columns:
        idv.append("Value")
        skip.add("Value")
    df2["DimRaw"]= df2["V_S_C"]
    skip.add("DimRaw")
    idv.insert(0,"DimRaw")

    meltdown_cols= [c for c in df2.columns if c not in skip]
    melted= df2.melt(
        id_vars=idv,
        value_vars= meltdown_cols,
        var_name="OrigAttr",
        value_name="ValX"
    )

    def rename_dim(x):
        return dmap.get(x,x)
    melted["Dimension"]= melted["DimRaw"].apply(rename_dim)

    if "Value" in idv:
        melted.rename(columns={"Value":"Name"}, inplace=True)
    else:
        melted["Name"]= ""

    def strip_t(v):
        if isinstance(v,str) and "T" in v:
            return v.split("T")[0]
        return v

    melted= melted[melted["OrigAttr"].isin(amap.keys())].copy()
    melted["Attribute"]= melted["OrigAttr"].map(amap)
    melted["Value"]= np.where(
        melted["Attribute"].isin(["Start Date","End Date"]),
        melted["ValX"].apply(strip_t),
        melted["ValX"]
    )
    return melted[["Dimension","Name","Attribute","Value"]]

def meltdown_master_for_preview(df: pd.DataFrame, param: Dict[str,object])-> pd.DataFrame:
    if df.empty or "RawFileName" not in df.columns:
        return pd.DataFrame()
    keep_map= param["dim_master_map"]
    amap= param["attr_master_map"]

    df2= df[df["RawFileName"].isin(keep_map.keys())].copy()
    if df2.empty:
        return pd.DataFrame()

    df2["DimRaw"]= df2["RawFileName"]
    skip= {"RawFileName","DimRaw"}
    idv= ["DimRaw"]
    if "Name" in df2.columns:
        idv.append("Name")
        skip.add("Name")

    meltdown_cols= [c for c in df2.columns if c not in skip]
    melted= df2.melt(
        id_vars=idv,
        value_vars= meltdown_cols,
        var_name="OrigAttr",
        value_name="ValX"
    )

    def rename_dim(x):
        return keep_map.get(x,x)
    melted["Dimension"]= melted["DimRaw"].apply(rename_dim)

    if "Name" in idv:
        melted.rename(columns={"Name":"Name"}, inplace=True)
    else:
        melted["Name"]= ""

    def strip_t(v):
        if isinstance(v,str) and "T" in v:
            return v.split("T")[0]
        return v

    melted= melted[melted["OrigAttr"].isin(amap.keys())].copy()
    melted["Attribute"]= melted["OrigAttr"].map(amap)
    melted["Value"]= np.where(
        melted["Attribute"].isin(["Start Date","End Date"]),
        melted["ValX"].apply(strip_t),
        melted["ValX"]
    )
    return melted[["Dimension","Name","Attribute","Value"]]

def pivot_for_preview(df: pd.DataFrame)-> pd.DataFrame:
    if df.empty or not {"Dimension","Name","Attribute"}.issubset(df.columns):
        return pd.DataFrame()
    df2= df.drop_duplicates(subset=["Dimension","Name","Attribute"])
    try:
        return df2.pivot(index=["Dimension","Name"],columns="Attribute",values="Value").reset_index()
    except:
        return pd.DataFrame()

# ----------------------------------------------------------------------------
# meltdown => wide->long
# ----------------------------------------------------------------------------
def meltdown_to_long(df_wide: pd.DataFrame)-> pd.DataFrame:
    if df_wide.empty or {"Dimension","Name"}.difference(df_wide.columns):
        return pd.DataFrame()
    meltdown_cols= [c for c in df_wide.columns if c not in ("Dimension","Name")]
    melted= df_wide.melt(
        id_vars=["Dimension","Name"],
        value_vars= meltdown_cols,
        var_name="Attribute",
        value_name="Value"
    )
    melted["Value"]= melted["Value"].fillna("")
    return melted

# ----------------------------------------------------------------------------
# NAME FIRST => mismatch + case => "Status"
# ----------------------------------------------------------------------------
def compare_name_first(erp_long: pd.DataFrame, mast_long: pd.DataFrame, trim_key=False)\
    -> Tuple[pd.DataFrame,pd.DataFrame]:
    """
    Name-first logic:
      - If (Dimension, Name) missing => single row => skip
      - If Name differs => single row => skip
      - Else => compare other attributes
      - CASE => second sheet
    "Status" => Missing in Master / Missing in ERP / Difference in both
    """
    def build_dict(d):
        out={}
        for (dim,nm), grp in d.groupby(["Dimension","Name"]):
            rec={}
            for _, row in grp.iterrows():
                rec[row["Attribute"]]= row["Value"]
            out[(dim,nm)]= rec
        return out

    mismatch_rows=[]
    case_rows=[]
    e_dict= build_dict(erp_long)
    m_dict= build_dict(mast_long)
    all_dn= set(e_dict.keys())| set(m_dict.keys())

    for dn in all_dn:
        dim,nm= dn
        e_map= e_dict.get(dn,{})
        m_map= m_dict.get(dn,{})

        e_name= e_map.get("Name","")
        m_name= m_map.get("Name","")

        name_issue= False
        # missing in ERP
        if dn not in e_dict and dn in m_dict:
            row= {
                "Dimension":dim,"Name":nm,"Attribute":"Name",
                "Master":m_name,"ERP":"",
                "Comments_1":"","Comments_2":"",
                "Status":"Missing in ERP"
            }
            raw= f"{dim}|{nm}|Name|{m_name}|".upper()
            if trim_key:
                raw= raw.replace(" ","")
            row["Key"]= raw
            mismatch_rows.append(row)
            name_issue= True
        # missing in Master
        elif dn in e_dict and dn not in m_dict:
            row= {
                "Dimension":dim,"Name":nm,"Attribute":"Name",
                "Master":"",
                "ERP":e_name,
                "Comments_1":"","Comments_2":"",
                "Status":"Missing in Master"
            }
            raw= f"{dim}|{nm}|Name||{e_name}".upper()
            if trim_key:
                raw= raw.replace(" ","")
            row["Key"]= raw
            mismatch_rows.append(row)
            name_issue= True
        # both => name differ
        elif e_name and m_name and e_name!= m_name:
            if e_name.lower()== m_name.lower():
                # case
                row= {
                    "Dimension":dim,"Name":nm,"Attribute":"Name",
                    "Master":m_name,"ERP":e_name,
                    "Comments_1":"","Comments_2":"",
                    "Status":"CASE"
                }
                raw= f"{dim}|{nm}|Name|{m_name}|{e_name}".upper()
                if trim_key:
                    raw= raw.replace(" ","")
                row["Key"]= raw
                case_rows.append(row)
            else:
                # difference in both
                row= {
                    "Dimension":dim,"Name":nm,"Attribute":"Name",
                    "Master":m_name,"ERP":e_name,
                    "Comments_1":"","Comments_2":"",
                    "Status":"Difference in both"
                }
                raw= f"{dim}|{nm}|Name|{m_name}|{e_name}".upper()
                if trim_key:
                    raw= raw.replace(" ","")
                row["Key"]= raw
                mismatch_rows.append(row)
            name_issue= True

        if name_issue:
            continue

        # name matched => compare other attributes
        all_atts= set(e_map.keys())| set(m_map.keys())
        all_atts.discard("Name")
        for at in all_atts:
            ev= e_map.get(at,"")
            mv= m_map.get(at,"")
            if ev.lower()== mv.lower() and ev!= mv and ev and mv:
                row= {
                    "Dimension":dim,"Name":nm,"Attribute":at,
                    "Master":mv,"ERP":ev,
                    "Comments_1":"","Comments_2":"",
                    "Status":"CASE"
                }
                raw= f"{dim}|{nm}|{at}|{mv}|{ev}".upper()
                if trim_key:
                    raw= raw.replace(" ","")
                row["Key"]= raw
                case_rows.append(row)
            else:
                if ev== mv:
                    continue
                if ev and not mv:
                    st= "Missing in Master"
                    ms= ""
                    es= ev
                elif mv and not ev:
                    st= "Missing in ERP"
                    ms= mv
                    es= ""
                else:
                    st= "Difference in both"
                    ms= mv
                    es= ev
                row= {
                    "Dimension":dim,"Name":nm,"Attribute":at,
                    "Master":ms,"ERP":es,
                    "Comments_1":"","Comments_2":"",
                    "Status": st
                }
                raw= f"{dim}|{nm}|{at}|{ms}|{es}".upper()
                if trim_key:
                    raw= raw.replace(" ","")
                row["Key"]= raw
                mismatch_rows.append(row)

    c= ["Key","Dimension","Name","Attribute","Master","ERP","Comments_1","Comments_2","Status"]
    mismatch_df= pd.DataFrame(mismatch_rows, columns=c) if mismatch_rows else pd.DataFrame(columns=c)
    case_df= pd.DataFrame(case_rows, columns=c) if case_rows else pd.DataFrame(columns=c)
    return mismatch_df, case_df

# ----------------------------------------------------------------------------
# EXCEPTIONS
# ----------------------------------------------------------------------------
def read_exception_table(path: Path)-> pd.DataFrame:
    if not path.is_file():
        logging.warning(f"Exception => not exist => {path}")
        return pd.DataFrame()
    try:
        df= pd.read_excel(path)
        df.columns= df.columns.astype(str).str.strip()
        return df
    except:
        return pd.DataFrame()

def merge_exceptions(df: pd.DataFrame, df_exc: pd.DataFrame)-> pd.DataFrame:
    if df.empty or df_exc.empty or "Key" not in df.columns:
        return df
    keep= [c for c in df_exc.columns if c in ("Key","Comments_1","Comments_2","hide exception")]
    if not keep:
        return df
    exc_= df_exc[keep].copy()
    exc_["Key"]= exc_["Key"].astype(str).str.strip()

    merged= df.merge(exc_,on="Key",how="left",suffixes=("","_exc"))
    merged["hide exception"]= merged.get("hide exception","").fillna("").str.lower()

    final= merged[merged["hide exception"]!="yes"].copy()
    if "Comments_1_exc" in final.columns:
        final["Comments_1"]= np.where(final["Comments_1_exc"].notna(),
                                      final["Comments_1_exc"],
                                      final["Comments_1"])
        final.drop(columns=["Comments_1_exc"],inplace=True)
    if "Comments_2_exc" in final.columns:
        final["Comments_2"]= np.where(final["Comments_2_exc"].notna(),
                                      final["Comments_2_exc"],
                                      final["Comments_2"])
        final.drop(columns=["Comments_2_exc"],inplace=True)
    if "hide exception" in final.columns:
        final.drop(columns=["hide exception"],inplace=True)
    return final

# ----------------------------------------------------------------------------
# 2-SHEET XLSX => plus "Charts" sheet
# ----------------------------------------------------------------------------
def write_2sheet_excel(mismatch_df: pd.DataFrame,
                       case_df: pd.DataFrame,
                       out_path: Path):
    if mismatch_df.empty and case_df.empty:
        logging.info("No mismatches => skip writing xlsx.")
        return
    out_path.parent.mkdir(parents=True,exist_ok=True)

    cols= ["Key","Dimension","Name","Attribute","Master","ERP","Comments_1","Comments_2","Status"]
    for c in cols:
        if c not in mismatch_df.columns:
            mismatch_df[c]= ""
        if c not in case_df.columns:
            case_df[c]= ""

    wb= Workbook()
    ws_m= wb.active
    ws_m.title= "Mismatch"
    ws_m.append(cols)
    for rv in mismatch_df[cols].itertuples(index=False):
        ws_m.append(rv)

    ws_c= wb.create_sheet("Case_Differences")
    ws_c.append(cols)
    for rv in case_df[cols].itertuples(index=False):
        ws_c.append(rv)

    # "Charts" sheet => a sample bar chart with mismatch dimension counts
    ws_ch= wb.create_sheet("Charts")

    # style => burgundy header
    head_font= Font(bold=True, color="FFFFFF")
    head_fill= PatternFill(start_color="800020",end_color="800020",fill_type="solid")

    def style_sheet(sheet, tab_name:str):
        if sheet.max_row<1:
            return
        # header
        for cell in sheet[1]:
            cell.font= head_font
            cell.fill= head_fill
            cell.alignment= Alignment(horizontal="center")
        # auto-size
        for col in sheet.columns:
            max_len=0
            letter= col[0].column_letter
            for cell_ in col:
                val= str(cell_.value) if cell_.value else ""
                max_len= max(max_len,len(val))
            sheet.column_dimensions[letter].width= max_len+2
        sheet.freeze_panes= "A2"
        if sheet.max_row>1:
            last_r= sheet.max_row
            last_c= sheet.max_column
            ref= f"A1:{get_column_letter(last_c)}{last_r}"
            tb= Table(displayName=tab_name, ref=ref)
            style= TableStyleInfo(name="TableStyleMedium9", showRowStripes=True,
                                  showColumnStripes=False, showFirstColumn=True)
            tb.tableStyleInfo= style
            sheet.add_table(tb)

    style_sheet(ws_m,"MismatchTable")
    style_sheet(ws_c,"CaseTable")

    # fill "Charts" with dimension counts
    ws_ch["A1"]= "Dimension"
    ws_ch["B1"]= "Count"
    dim_ct= mismatch_df["Dimension"].value_counts().reset_index()
    dim_ct.columns= ["Dimension","Count"]
    row_i=2
    for _, rowv in dim_ct.iterrows():
        ws_ch.cell(row=row_i,column=1,value=rowv["Dimension"])
        ws_ch.cell(row=row_i,column=2,value=rowv["Count"])
        row_i+=1

    # style "Charts"
    for cell in ws_ch[1]:
        cell.font= head_font
        cell.fill= head_fill
        cell.alignment= Alignment(horizontal="center")
    for col in ws_ch.columns:
        max_len=0
        letter= col[0].column_letter
        for cell_ in col:
            val= str(cell_.value) if cell_.value else ""
            max_len= max(max_len,len(val))
        ws_ch.column_dimensions[letter].width= max_len+2
    ws_ch.freeze_panes= "A2"

    # create bar chart
    if not dim_ct.empty:
        chart= BarChart()
        chart.title= "Mismatch by Dimension"
        cat_ref= Reference(ws_ch, min_col=1, min_row=2, max_row=1+len(dim_ct))
        val_ref= Reference(ws_ch, min_col=2, min_row=2, max_row=1+len(dim_ct))
        chart.add_data(val_ref, titles_from_data=False)
        chart.set_categories(cat_ref)
        ws_ch.add_chart(chart, "D2")

    wb.save(out_path)
    logging.info(f"Missing items => {out_path}")

    # also timestamped
    st= datetime.now().strftime("%Y%m%d_%H%M%S")
    stamped= out_path.parent/f"{out_path.stem}_{st}{out_path.suffix}"
    wb.save(stamped)
    logging.info(f"Timestamped => {stamped}")

# ----------------------------------------------------------------------------
# SHIFTED PDF => 8 charts + Bollinger
# ----------------------------------------------------------------------------
class EnhancedPDFReport:
    def __init__(self, df_current: pd.DataFrame, df_history: pd.DataFrame, config: Dict):
        self.df_current= df_current
        self.df_history= df_history
        self.config= config
        self.page_count=0
        self.colors= {
            "primary":"#800020",
            "text":"#2C1810",
            "background":"#FFFFFF"
        }
        self.logo_path= self.config["paths"].get("LOGO_PATH","images/company_logo.png")
        self.PAGE_WIDTH= 8.5
        self.PAGE_HEIGHT= 11

    def generate(self)-> Path:
        stamp= datetime.now().strftime("%Y%m%d_%H%M%S")
        out_dir= Path("Reconciliation_pdf")
        out_dir.mkdir(parents=True,exist_ok=True)
        pdf_name= f"Reconciliation_{stamp}.pdf"
        pdf_path= out_dir/pdf_name
        with PdfPages(pdf_path) as pdf:
            self._cover_page(pdf)
            self._summary_page(pdf)
            self._all_charts(pdf)
        logging.info(f"PDF => {pdf_path}")
        return pdf_path

    def _new_page(self)-> plt.Figure:
        fig= plt.figure(figsize=(self.PAGE_WIDTH,self.PAGE_HEIGHT))
        fig.patch.set_facecolor(self.colors["background"])
        plt.axis("off")
        self.page_count+=1

        if self.logo_path and os.path.exists(self.logo_path):
            try:
                import matplotlib.image as mpimg
                img= mpimg.imread(self.logo_path)
                ax_img= fig.add_axes([0.65,0.75,0.3,0.2])
                ax_img.imshow(img, alpha=0.2)
                ax_img.axis("off")
            except:
                pass

        fig.text(0.5,0.98,"Reconciliation Report",ha="center",fontsize=10,color="gray")
        fig.text(0.9,0.03,f"Page {self.page_count}",ha="right",fontsize=8,color="gray")
        fig.text(0.5,0.02,"Â© Ultra-Mega Reconciliation",ha="center",fontsize=8,color="gray")
        return fig

    def _cover_page(self, pdf: PdfPages):
        fig= self._new_page()
        plt.text(0.5,0.7,"Reconciliation Analysis Report",
                 ha="center",fontsize=24,fontweight="bold",color=self.colors["primary"],
                 transform=fig.transFigure)
        plt.text(0.5,0.6,f"Generated on {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
                 ha="center",fontsize=12,color=self.colors["text"],
                 transform=fig.transFigure)
        plt.text(0.5,0.15,"CONFIDENTIAL",
                 ha="center",fontsize=9,color=self.colors["text"],
                 transform=fig.transFigure)
        pdf.savefig(fig)
        plt.close(fig)

    def _summary_page(self, pdf: PdfPages):
        fig= self._new_page()
        plt.text(0.5,0.92,"Reconciliation Summary",
                 ha="center",fontsize=18,fontweight="bold",color=self.colors["primary"],
                 transform=fig.transFigure)
        if self.df_current.empty:
            plt.text(0.5,0.75,"No mismatches found.",
                     ha="center",fontsize=14,color=self.colors["text"],
                     transform=fig.transFigure)
        else:
            tot= len(self.df_current)
            c_erp= (self.df_current["Status"]=="Missing in ERP").sum()
            c_mas= (self.df_current["Status"]=="Missing in Master").sum()
            c_both= (self.df_current["Status"]=="Difference in both").sum()
            text= f"Total: {tot}\nERP: {c_erp}\nMASTER: {c_mas}\nBOTH: {c_both}"
            plt.text(0.5,0.75,text,
                     ha="center",fontsize=14,color=self.colors["text"],
                     transform=fig.transFigure)
        pdf.savefig(fig)
        plt.close(fig)

    def _chart_page(self, pdf: PdfPages, title:str, plot_func, **kwargs):
        fig= self._new_page()
        fig.suptitle(title, fontsize=14, fontweight="bold", color=self.colors["primary"], y=0.93)

        ax= fig.add_axes([0.30, 0.2, 0.65, 0.55])  # SHIFT ~1" left
        try:
            plot_func(ax, **kwargs)
            pdf.savefig(fig)
        except Exception as e:
            logging.error(f"{title} => {e}")
        plt.close(fig)

    def _all_charts(self, pdf: PdfPages):
        dfc= self.df_current.copy()
        if dfc.empty:
            return

        # We'll produce 8 charts => Heatmap, Lollipop, Circular, Scatter, Radar,
        # Normal Pie, Normal Bar, Bollinger
        # We'll rename "Status" usage
        df_m= dfc[dfc["Status"]!=""]
        # Heatmap
        if not df_m.empty and {"Dimension","Attribute"}.issubset(df_m.columns):
            pivot= df_m.groupby(["Dimension","Attribute"]).size().unstack(fill_value=0)
            if not pivot.empty:
                self._chart_page(pdf,"Heatmap",self._plot_heatmap,pivot=pivot)

        # Lollipop
        cdim= df_m.groupby("Dimension")["Key"].count().sort_values(ascending=False).head(10)
        if not cdim.empty:
            self._chart_page(pdf,"Lollipop", self._plot_lollipop, cdim=cdim)

        # Circular
        cattr= df_m.groupby("Attribute")["Key"].count().sort_values(ascending=False).head(10)
        if not cattr.empty:
            self._chart_page(pdf,"Circular", self._plot_circular, cattr=cattr)

        # Scatter
        cdim_sc= df_m.groupby("Dimension")["Key"].count().reset_index(name="Count")
        cdim_sc.sort_values("Count", ascending=False, inplace=True)
        cdim_sc= cdim_sc.head(10)
        if not cdim_sc.empty:
            self._chart_page(pdf,"Scatter", self._plot_scatter, cdim=cdim_sc)

        # Radar
        cdim_ra= df_m.groupby("Dimension")["Key"].count().sort_values(ascending=False).head(10)
        if not cdim_ra.empty and len(cdim_ra)>1:
            self._chart_page(pdf,"Radar", self._plot_radar, cdim=cdim_ra)

        # Pie
        dist= df_m["Status"].value_counts()
        if not dist.empty:
            self._chart_page(pdf,"Pie: Status distribution", self._plot_pie, dist=dist)

        # Bar
        cattr_b= df_m.groupby("Attribute")["Key"].count().sort_values(ascending=False).head(10)
        if not cattr_b.empty:
            self._chart_page(pdf,"Bar: Missing Attributes", self._plot_bar, cattr=cattr_b)

        # Bollinger
        if not self.df_history.empty and "RunDate" in self.df_history.columns:
            date_ct= self.df_history.groupby("RunDate")["Key"].count().reset_index(name="Count")
            date_ct.sort_values("RunDate", inplace=True)
            if not date_ct.empty:
                self._chart_page(pdf,"Bollinger Over Time", self._plot_bollinger, date_ct=date_ct)

    # chart helpers
    def _plot_heatmap(self, ax, pivot):
        im= ax.imshow(pivot,aspect="auto",cmap="Reds")
        ax.set_xticks(range(len(pivot.columns)))
        ax.set_xticklabels(pivot.columns,rotation=45,ha="right")
        ax.set_yticks(range(len(pivot.index)))
        ax.set_yticklabels(pivot.index)
        ax.set_title("Heatmap (Shifted Left)")
        plt.colorbar(im, ax=ax)

    def _plot_lollipop(self, ax, cdim):
        ax.hlines(y= cdim.index, xmin=0, xmax= cdim.values, color="skyblue")
        ax.plot(cdim.values, cdim.index, "o", color="skyblue")
        ax.set_xlabel("Count")
        ax.set_title("Lollipop Chart")

    def _plot_circular(self, ax, cattr):
        angles= np.linspace(0,2*np.pi,len(cattr),endpoint=False)
        ax.set_theta_offset(np.pi/2)
        ax.set_theta_direction(-1)
        ax.set_xticks(angles)
        ax.set_xticklabels(cattr.index,fontsize=8)
        ax.bar(angles, cattr.values,width=0.4,color="orange",alpha=0.6)
        ax.set_title("Circular Chart")

    def _plot_scatter(self, ax, cdim):
        xvals= np.arange(len(cdim))
        yvals= cdim["Count"].values
        labs= cdim["Dimension"].values
        ax.scatter(xvals,yvals,color="green")
        for i,d in enumerate(labs):
            ax.text(xvals[i],yvals[i],d,ha="center",va="bottom",rotation=60,fontsize=8)
        ax.set_xticks([])
        ax.set_ylabel("Count")
        ax.set_title("Scatter Chart")

    def _plot_radar(self, ax, cdim):
        cat= cdim.index.tolist()
        val= cdim.values.tolist()
        angles= np.linspace(0,2*np.pi,len(cat),endpoint=False).tolist()
        angles+= angles[:1]
        val+= val[:1]
        ax.set_theta_offset(np.pi/2)
        ax.set_theta_direction(-1)
        ax.set_xticks(angles[:-1])
        ax.set_xticklabels(cat,fontsize=8)
        ax.plot(angles,val,color="red",linewidth=2)
        ax.fill(angles,val,color="red",alpha=0.3)
        ax.set_title("Radar Chart")

    def _plot_pie(self, ax, dist):
        ax.pie(dist.values, labels=dist.index, autopct="%.1f%%", startangle=140)
        ax.set_title("Pie Chart")

    def _plot_bar(self, ax, cattr):
        bars= ax.bar(range(len(cattr)), cattr.values, color="blue")
        ax.set_xticks(range(len(cattr)))
        ax.set_xticklabels(cattr.index,rotation=45,ha="right",fontsize=8)
        ax.set_ylabel("Count")
        ax.set_title("Bar Chart")
        for b in bars:
            h= b.get_height()
            ax.text(b.get_x()+ b.get_width()/2.,h,str(int(h)),ha="center",va="bottom")

    def _plot_bollinger(self, ax, date_ct):
        date_ct["RunDate_dt"]= pd.to_datetime(date_ct["RunDate"], errors="coerce")
        date_ct.sort_values("RunDate_dt", inplace=True)
        date_ct.reset_index(drop=True,inplace=True)
        date_ct["rolling_mean"]= date_ct["Count"].rolling(3,min_periods=1).mean()
        date_ct["rolling_std"]= date_ct["Count"].rolling(3,min_periods=1).std(ddof=0)
        date_ct["upper_band"]= date_ct["rolling_mean"]+2*date_ct["rolling_std"]
        date_ct["lower_band"]= date_ct["rolling_mean"]-2*date_ct["rolling_std"]
        xvals= np.arange(len(date_ct))
        ax.plot(xvals,date_ct["rolling_mean"],color="blue",label="Mean")
        ax.fill_between(xvals,date_ct["lower_band"],date_ct["upper_band"],color="blue",alpha=0.2)
        ax.scatter(xvals,date_ct["Count"],color="red",label="Count")
        ax.set_xticks(xvals)
        xlabels= [d.strftime("%Y-%m-%d") if not pd.isna(d) else "" for d in date_ct["RunDate_dt"]]
        ax.set_xticklabels(xlabels,rotation=45,ha="right")
        ax.set_xlabel("RunDate")
        ax.set_ylabel("Mismatch Count")
        ax.set_title("Bollinger Chart")
        ax.legend()

# ----------------------------------------------------------------------------
# SIMPLE PREVIEW => with future_end_toggle
# ----------------------------------------------------------------------------
class SimplePreview(ctk.CTkFrame):
    FILTERABLE= {"Start Date","End Date"}

    def __init__(self, parent, name:str, grid_cfg:Dict):
        """
        grid_cfg => { "filters": {...}, "future_end_toggle": bool }
        """
        super().__init__(parent)
        self.name= name
        self.df= pd.DataFrame()

        # parse filters
        self.filters: Dict[str,Set[str]]= {}
        self.future_var= tk.BooleanVar(value=False)
        if "filters" in grid_cfg:
            for col,arr in grid_cfg["filters"].items():
                if isinstance(arr,list):
                    self.filters[col]= set(arr)
        if "future_end_toggle" in grid_cfg:
            self.future_var.set(bool(grid_cfg["future_end_toggle"]))

        self.build_ui()

    def build_ui(self):
        top= ctk.CTkFrame(self, fg_color="#f0f0f0")
        top.pack(fill="x", padx=5, pady=5)

        ctk.CTkLabel(top, text=f"{self.name} Preview",
                     fg_color="#800020", corner_radius=8,
                     text_color="white",
                     font=ctk.CTkFont(size=14, weight="bold"))\
            .pack(side="left",padx=5)

        ctk.CTkCheckBox(
            top, text="Future End Date?", variable=self.future_var,
            command=self.refresh_table,
            fg_color="#800020", hover_color="#a52a2a", text_color="black"
        ).pack(side="left",padx=5)

        ctk.CTkButton(
            top, text="Clear Date Filters", command=self.clear_filters,
            fg_color="#800020", hover_color="#a52a2a", text_color="white"
        ).pack(side="left",padx=5)

        container= ctk.CTkFrame(self)
        container.pack(fill="both", expand=True)
        self.tree= ttk.Treeview(container, show="headings")
        vsb= ttk.Scrollbar(container, orient="vertical", command=self.tree.yview)
        hsb= ttk.Scrollbar(container, orient="horizontal", command=self.tree.xview)
        self.tree.configure(yscrollcommand=vsb.set, xscrollcommand=hsb.set)

        self.tree.grid(row=0,column=0,sticky="nsew")
        vsb.grid(row=0,column=1,sticky="ns")
        hsb.grid(row=1,column=0,sticky="ew")
        container.rowconfigure(0,weight=1)
        container.columnconfigure(0,weight=1)

        self.stat_lab= ctk.CTkLabel(self, text="0 rows", fg_color="#f0f0f0", text_color="black")
        self.stat_lab.pack(fill="x")

    def set_data(self, df: pd.DataFrame):
        self.df= df.copy()
        self.refresh_table()

    def get_filters(self)-> Dict[str,Set[str]]:
        return self.filters

    def get_future_toggle(self)-> bool:
        return bool(self.future_var.get())

    def get_filtered_df(self)-> pd.DataFrame:
        return self.apply_filters()

    def refresh_table(self):
        for i in self.tree.get_children():
            self.tree.delete(i)
        if self.df.empty:
            self.tree["columns"]=[]
            self.stat_lab.configure(text="0 rows")
            return

        cols= list(self.df.columns)
        self.tree["columns"]= cols
        for c in cols:
            self.tree.heading(c,text=c,anchor="w",command=lambda col=c:self.on_col_click(col))
            self.tree.column(c,anchor="w",width=150)

        df_f= self.apply_filters()
        for _, row in df_f.iterrows():
            rowvals= [row.get(cc,"") for cc in cols]
            self.tree.insert("", "end", values=rowvals)
        self.stat_lab.configure(text=f"{len(df_f)} rows")

    def on_col_click(self, col_name:str):
        if col_name in self.FILTERABLE:
            self.show_filter_popup(col_name)

    def apply_filters(self)-> pd.DataFrame:
        df_f= self.df.copy()
        # normal manual filters
        for col, allowed in self.filters.items():
            if col not in df_f.columns:
                continue
            if not allowed:
                return df_f.iloc[0:0]
            def keeper(x):
                if pd.isna(x):
                    return ("<<NaN>>" in allowed)
                elif isinstance(x,str) and not x.strip():
                    return ("<<BLANK>>" in allowed)
                else:
                    return str(x) in allowed
            df_f= df_f[df_f[col].apply(keeper)]
        # future end date toggle
        if self.future_var.get() and "End Date" in df_f.columns:
            today_= date.today()
            keep_vals= set()
            for v in df_f["End Date"].unique():
                if pd.isna(v) or (isinstance(v,str) and not v.strip()):
                    keep_vals.add(v)
                    continue
                sval= str(v).strip()
                yes=False
                try:
                    dtp= datetime.strptime(sval,"%Y-%m-%d")
                    if dtp.date()>= today_ or dtp.year>2200:
                        yes=True
                except:
                    if "9999" in sval:
                        yes=True
                    else:
                        import re
                        yrs= re.findall(r"\d{4}", sval)
                        for y_ in yrs:
                            try:
                                if int(y_)>2200:
                                    yes=True
                                    break
                            except:
                                pass
                if yes:
                    keep_vals.add(v)
            df_f= df_f[df_f["End Date"].isin(keep_vals)]
        return df_f

    def show_filter_popup(self, col_name:str):
        if self.df.empty or col_name not in self.df.columns:
            return
        pop= tk.Toplevel(self)
        pop.title(f"Filter: {col_name}")
        pop.geometry("300x400")

        fr= ctk.CTkFrame(pop)
        fr.pack(fill="both",expand=True,padx=5,pady=5)

        unq= self.df[col_name].unique()
        dsp_map={}
        rev_map={}
        for v in unq:
            if pd.isna(v):
                dsp= "(NaN)"
                sen= "<<NaN>>"
            elif isinstance(v,str) and not v.strip():
                dsp= "(blank)"
                sen= "<<BLANK>>"
            else:
                dsp= str(v)
                sen= dsp
            dsp_map[v]= dsp
            rev_map[dsp]= sen
        sortd= sorted(dsp_map.values(),key=lambda x:x.lower())

        curr= self.filters.get(col_name,set())
        all_sens= set(rev_map.values())
        selall_var= tk.BooleanVar(value=(curr==all_sens or not curr))

        def toggle_all():
            c= selall_var.get()
            for vb in var_dict.values():
                vb.set(c)

        ctk.CTkCheckBox(fr,text="Select All",variable=selall_var,command=toggle_all,
                        fg_color="#800020",hover_color="#a52a2a",text_color="black")\
            .pack(anchor="w",pady=5)

        scr= ctk.CTkScrollableFrame(fr,width=250,height=250)
        scr.pack(fill="both",expand=True,padx=5,pady=5)
        var_dict={}
        for dsp in sortd:
            sen= rev_map[dsp]
            in_f= (sen in curr) or (not curr)
            bvar= tk.BooleanVar(value=in_f)
            var_dict[dsp]= bvar
            ctk.CTkCheckBox(scr,text=dsp,variable=bvar,
                            fg_color="#800020",hover_color="#a52a2a",text_color="black")\
                .pack(anchor="w")

        def apply_():
            sel= {rev_map[d] for d,bv in var_dict.items() if bv.get()}
            if sel==all_sens or not sel:
                if col_name in self.filters:
                    del self.filters[col_name]
            else:
                self.filters[col_name]= sel
            pop.destroy()
            self.refresh_table()

        bf= ctk.CTkFrame(fr)
        bf.pack(fill="x",pady=5)
        ctk.CTkButton(bf,text="Apply",command=apply_,
                      fg_color="#800020",hover_color="#a52a2a",text_color="white")\
            .pack(side="left",padx=5)
        ctk.CTkButton(bf,text="Cancel",command=pop.destroy,
                      fg_color="#800020",hover_color="#a52a2a",text_color="white")\
            .pack(side="left",padx=5)

    def clear_filters(self):
        to_delete= []
        for c in self.filters.keys():
            if c in self.FILTERABLE:
                to_delete.append(c)
        for d in to_delete:
            del self.filters[d]
        self.future_var.set(False)
        self.refresh_table()

# ----------------------------------------------------------------------------
# HISTORY TAB
# ----------------------------------------------------------------------------
class HistoryTab(ctk.CTkFrame):
    def __init__(self, parent, hist_dir: Path):
        super().__init__(parent)
        self.history_dir= hist_dir
        self.tree= None
        self.build_ui()

    def build_ui(self):
        lbl= ctk.CTkLabel(self,text="Reconciliation Runs History",font=("Arial",16))
        lbl.pack(pady=5)
        self.tree= ttk.Treeview(self,columns=("Filename",),show="headings",height=15)
        self.tree.heading("Filename", text="History File")
        self.tree.pack(fill="both",expand=True,padx=10,pady=10)

        self.tree.bind("<Double-1>",self.on_double_click)

        ctk.CTkButton(self,text="Refresh",command=self.refresh_history,
                      fg_color="#800020",hover_color="#a52a2a",text_color="white")\
            .pack(pady=5)
        self.refresh_history()

    def refresh_history(self):
        for i in self.tree.get_children():
            self.tree.delete(i)
        if not self.history_dir.is_dir():
            self.history_dir.mkdir(parents=True,exist_ok=True)
        files= sorted(self.history_dir.glob("run_*.json"),reverse=True)
        for f in files:
            self.tree.insert("", "end", values=(f.name,))

    def on_double_click(self,event):
        it= self.tree.focus()
        if not it:
            return
        fn= self.tree.item(it,"values")[0]
        path= self.history_dir/fn
        if not path.is_file():
            return
        try:
            with open(path,"r",encoding="utf-8") as ff:
                content= ff.read()
            pop= tk.Toplevel(self)
            pop.title(f"Viewing {fn}")
            txt= ctk.CTkTextbox(pop,width=800,height=600)
            txt.pack(fill="both",expand=True)
            txt.insert("end",content)
            txt.configure(state="disabled")
        except Exception as e:
            logging.error(f"HistoryTab => {e}")

# ----------------------------------------------------------------------------
# ADVANCED DASHBOARD => mismatch only
# ----------------------------------------------------------------------------
class AdvancedDashboard(ctk.CTkFrame):
    def __init__(self, parent, config: Dict):
        super().__init__(parent)
        dash= config.get("dashboard",{})
        self.config= config
        self.selected_dims= set(dash.get("selected_dims",[]))
        self.selected_attrs= set(dash.get("selected_attrs",[]))
        self.top_n= dash.get("top_n",10)

        self.df_current= pd.DataFrame()
        self.df_history= pd.DataFrame()

        top= ctk.CTkScrollableFrame(self, orientation="horizontal", height=60)
        top.pack(fill="x",pady=5)
        self.metric_label= ctk.CTkLabel(top,text="Metrics: 0 mismatch, 0 dimension",width=300)
        self.metric_label.pack(side="left",padx=5)

        ctk.CTkButton(
            top,text="Filter Dimension",command=self.show_dim_filter,
            fg_color="#800020",hover_color="#a52a2a",text_color="white"
        ).pack(side="left",padx=5)
        ctk.CTkButton(
            top,text="Filter Attribute",command=self.show_attr_filter,
            fg_color="#800020",hover_color="#a52a2a",text_color="white"
        ).pack(side="left",padx=5)
        ctk.CTkButton(
            top,text="Toggle Top10/All",command=self.toggle_top_n,
            fg_color="#800020",hover_color="#a52a2a",text_color="white"
        ).pack(side="left",padx=5)

        main= ctk.CTkFrame(self)
        main.pack(fill="both",expand=True)
        self.tree= ttk.Treeview(main, show="headings")
        vsb= ttk.Scrollbar(main,orient="vertical",command=self.tree.yview)
        hsb= ttk.Scrollbar(main,orient="horizontal",command=self.tree.xview)
        self.tree.configure(yscrollcommand=vsb.set,xscrollcommand=hsb.set)

        self.tree.grid(row=0,column=0,sticky="nsew")
        vsb.grid(row=0,column=1,sticky="ns")
        hsb.grid(row=1,column=0,sticky="ew")
        main.rowconfigure(0,weight=1)
        main.columnconfigure(0,weight=1)

    def toggle_top_n(self):
        if self.top_n==10:
            self.top_n=None
        else:
            self.top_n=10
        self.update_data_filters()

    def show_dim_filter(self):
        self.show_filter("Dimension")

    def show_attr_filter(self):
        self.show_filter("Attribute")

    def show_filter(self, col:str):
        base= self.df_history if not self.df_history.empty else self.df_current
        if base.empty or col not in base.columns:
            return
        pop= tk.Toplevel(self)
        pop.title(f"Filter: {col}")
        pop.geometry("300x400")

        fr= ctk.CTkFrame(pop)
        fr.pack(fill="both", expand=True, padx=5, pady=5)

        unq= base[col].dropna().unique()
        dsp_map={}
        for v in unq:
            dsp= str(v) if (isinstance(v,str) and v.strip()) else "(blank)"
            dsp_map[v]= dsp
        svals= sorted(dsp_map.keys(), key=lambda x: dsp_map[x].lower())

        if col=="Dimension":
            curr= self.selected_dims
        else:
            curr= self.selected_attrs
        if not curr:
            curr= set(svals)
        all_vals= set(svals)

        selall_var= tk.BooleanVar(value=(curr== all_vals or not curr))

        def toggle_all():
            c= selall_var.get()
            for vb in var_dict.values():
                vb.set(c)

        ctk.CTkCheckBox(
            fr,text="Select All",variable=selall_var,command=toggle_all,
            fg_color="#800020",hover_color="#a52a2a",text_color="black"
        ).pack(anchor="w",pady=5)

        scr= ctk.CTkScrollableFrame(fr, width=250, height=250)
        scr.pack(fill="both", expand=True, padx=5, pady=5)
        var_dict={}
        for v in svals:
            in_f= (v in curr) or (not curr)
            bvar= tk.BooleanVar(value=in_f)
            var_dict[v]= bvar
            ctk.CTkCheckBox(
                scr,text=dsp_map[v],variable=bvar,
                fg_color="#800020",hover_color="#a52a2a",text_color="black"
            ).pack(anchor="w")

        def apply_():
            sel= {k for k,bv in var_dict.items() if bv.get()}
            if col=="Dimension":
                self.selected_dims= sel
            else:
                self.selected_attrs= sel
            pop.destroy()
            self.update_data_filters()

        bf= ctk.CTkFrame(fr)
        bf.pack(fill="x", pady=5)
        ctk.CTkButton(
            bf,text="Apply",command=apply_,
            fg_color="#800020",hover_color="#a52a2a",text_color="white"
        ).pack(side="left",padx=5)
        ctk.CTkButton(
            bf,text="Cancel",command=pop.destroy,
            fg_color="#800020",hover_color="#a52a2a",text_color="white"
        ).pack(side="left",padx=5)

    def update_data(self, df_current: pd.DataFrame, df_history: pd.DataFrame):
        self.df_current= df_current.copy()
        self.df_history= df_history.copy()
        self.update_data_filters()

    def update_data_filters(self):
        dfc= self.df_current.copy()
        # apply dimension / attribute filters
        if not dfc.empty:
            if self.selected_dims:
                dfc= dfc[dfc["Dimension"].isin(self.selected_dims)]
            if self.selected_attrs:
                dfc= dfc[dfc["Attribute"].isin(self.selected_attrs)]
        mism= len(dfc)
        dims= dfc["Dimension"].nunique() if not dfc.empty and "Dimension" in dfc.columns else 0
        self.metric_label.configure(text=f"Mismatches: {mism}, Dims: {dims}")

        for i in self.tree.get_children():
            self.tree.delete(i)
        if dfc.empty:
            self.tree["columns"]=[]
            return
        ccols= list(dfc.columns)
        self.tree["columns"]= ccols
        for c in ccols:
            self.tree.heading(c,text=c,anchor="w")
            self.tree.column(c,anchor="w",width=150)
        for _, row in dfc.iterrows():
            rowvals= [row.get(cc,"") for cc in ccols]
            self.tree.insert("", "end", values=rowvals)

# ----------------------------------------------------------------------------
# MAIN APP
# ----------------------------------------------------------------------------
class MainApp(ctk.CTk):
    def __init__(self):
        super().__init__()
        self.title("Ultra-Mega Reconciliation => SHIFTED PDF + 2-sheets + toggles + Name as attribute + chart sheet")
        self.geometry("1600x900")
        ctk.set_appearance_mode("light")

        self.config_dict= load_config(Path(DEFAULT_PATHS["CONFIG_PATH"]))
        self.param_dict= read_param_file(Path(self.config_dict["paths"].get("PARAMETER_PATH",DEFAULT_PATHS["PARAMETER_PATH"])))
        self.history_df= pd.DataFrame()

        self.tabs= ttk.Notebook(self)
        self.tabs.pack(fill="both", expand=True)

        # 1) Paths
        self.tab_paths= ctk.CTkFrame(self.tabs)
        self.build_paths_tab(self.tab_paths)
        self.tabs.add(self.tab_paths, text="Paths")

        # 2) ERP
        e_cfg= self.config_dict.get("erp_grid",{"filters":{},"future_end_toggle":False})
        self.tab_erp= ctk.CTkFrame(self.tabs)
        self.erp_preview= SimplePreview(self.tab_erp,"ERP", e_cfg)
        self.erp_preview.pack(fill="both",expand=True)
        self.tabs.add(self.tab_erp, text="ERP Preview")

        # 3) Master
        m_cfg= self.config_dict.get("master_grid",{"filters":{},"future_end_toggle":False})
        self.tab_master= ctk.CTkFrame(self.tabs)
        self.master_preview= SimplePreview(self.tab_master,"Master", m_cfg)
        self.master_preview.pack(fill="both",expand=True)
        self.tabs.add(self.tab_master, text="Master Preview")

        # 4) Compare => name-first
        self.tab_compare= ctk.CTkFrame(self.tabs)
        self.build_compare_tab(self.tab_compare)
        self.tabs.add(self.tab_compare, text="Compare")

        # 5) Dashboard => mismatch only
        self.dashboard_tab= AdvancedDashboard(self.tabs,self.config_dict)
        self.tabs.add(self.dashboard_tab, text="Dashboard")

        # 6) History
        histp= Path(self.config_dict["paths"].get("HISTORY_PATH","history_runs"))
        self.history_tab= HistoryTab(self.tabs,histp)
        self.tabs.add(self.history_tab, text="History")

        # Logging area
        self.log_box= ctk.CTkTextbox(self, height=120)
        self.log_box.pack(fill="both", side="bottom")
        self.log_box.configure(state="disabled")
        handler= TextHandler(self.log_box)
        handler.setLevel(logging.INFO)
        logging.getLogger().addHandler(handler)

        # ephemeral CSV dir
        self.temp_csv_dir= Path(self.config_dict["paths"].get("MASTER_CSV_OUTPUT","temp_master_csv"))
        self.temp_csv_dir.mkdir(parents=True,exist_ok=True)

        self.load_runs()
        self.refresh_erp()
        self.refresh_master()
        # pass empty => dash sees entire hist
        self.dashboard_tab.update_data(pd.DataFrame(), self.history_df)

        ctk.CTkButton(
            self, text="Close", command=self.on_close,
            fg_color="#800020",hover_color="#a52a2a",text_color="white"
        ).pack(pady=5)

    def build_paths_tab(self, parent):
        frm= ctk.CTkFrame(parent)
        frm.pack(fill="both",expand=True,padx=10,pady=10)

        self.erp_var= tk.StringVar(value=self.config_dict["paths"].get("ERP_EXCEL_PATH",DEFAULT_PATHS["ERP_EXCEL_PATH"]))
        self.mast_zip_var= tk.StringVar(value=self.config_dict["paths"].get("MASTER_ZIP_PATH",DEFAULT_PATHS["MASTER_ZIP_PATH"]))
        self.mast_folder_var= tk.StringVar(value=self.config_dict["paths"].get("MASTER_TXT_FOLDER",""))
        self.exc_var= tk.StringVar(value=self.config_dict["paths"].get("EXCEPTION_PATH",DEFAULT_PATHS["EXCEPTION_PATH"]))
        self.out_var= tk.StringVar(value=self.config_dict["paths"].get("OUTPUT_PATH",DEFAULT_PATHS["OUTPUT_PATH"]))
        self.par_var= tk.StringVar(value=self.config_dict["paths"].get("PARAMETER_PATH",DEFAULT_PATHS["PARAMETER_PATH"]))
        self.pdf_var= tk.StringVar(value=self.config_dict["paths"].get("PDF_EXPORT_PATH",DEFAULT_PATHS["PDF_EXPORT_PATH"]))

        def mkrow(lbl,var,is_dir=False):
            rowf= ctk.CTkFrame(frm)
            rowf.pack(fill="x", pady=5)
            ctk.CTkLabel(rowf,text=lbl,width=200).pack(side="left",padx=5)
            e= ctk.CTkEntry(rowf,textvariable=var,width=600)
            e.pack(side="left",padx=5)
            def br():
                if is_dir:
                    p= filedialog.askdirectory()
                else:
                    p= filedialog.askopenfilename()
                if p:
                    var.set(p)
            ctk.CTkButton(
                rowf, text="Browse", command=br,
                fg_color="#800020",hover_color="#a52a2a",text_color="white"
            ).pack(side="left",padx=5)

        mkrow("ERP Excel:", self.erp_var)
        mkrow("Master ZIP:", self.mast_zip_var)
        mkrow("Master Folder:", self.mast_folder_var, True)
        mkrow("Exception Path:", self.exc_var)
        mkrow("Missing Items Output:", self.out_var)
        mkrow("Parameter File:", self.par_var)
        mkrow("PDF Export Path:", self.pdf_var)

        bf= ctk.CTkFrame(frm)
        bf.pack(fill="x", pady=10)
        ctk.CTkButton(
            bf,text="Save Config", command=self.save_all_config,
            fg_color="#800020",hover_color="#a52a2a",text_color="white"
        ).pack(side="left",padx=5)
        ctk.CTkButton(
            bf,text="Refresh ERP", command=self.refresh_erp,
            fg_color="#800020",hover_color="#a52a2a",text_color="white"
        ).pack(side="left",padx=5)
        ctk.CTkButton(
            bf,text="Refresh Master", command=self.refresh_master,
            fg_color="#800020",hover_color="#a52a2a",text_color="white"
        ).pack(side="left",padx=5)

    def build_compare_tab(self, parent):
        frm= ctk.CTkFrame(parent)
        frm.pack(fill="both",expand=True,padx=10,pady=10)
        ctk.CTkLabel(frm,text="Generate Missing Items => 2-sheets + chart sheet, SHIFTED PDF, etc.", font=("Arial",16))\
            .pack(pady=5)

        self.trim_key_var= tk.BooleanVar(value=self.config_dict.get("trim_key_toggle",False))
        ctk.CTkCheckBox(
            frm,text="Trim Key?",variable=self.trim_key_var,
            fg_color="#800020",hover_color="#a52a2a",text_color="black"
        ).pack(pady=5)

        ctk.CTkButton(
            frm,text="Run Reconciliation",command=self.run_comparison,
            fg_color="#800020",hover_color="#a52a2a",text_color="white"
        ).pack(pady=10)

        ctk.CTkButton(
            frm,text="Export PDF Report",command=self.export_pdf,
            fg_color="#800020",hover_color="#a52a2a",text_color="white"
        ).pack(pady=10)

    def load_runs(self):
        hist= Path(self.config_dict["paths"].get("HISTORY_PATH","history_runs"))
        if not hist.is_dir():
            return
        frames=[]
        for jf in hist.glob("run_*.json"):
            try:
                df_= pd.read_json(jf, orient="records")
                frames.append(df_)
            except Exception as e:
                logging.error(f"History => {jf} => {e}")
        if frames:
            big= pd.concat(frames,ignore_index=True).drop_duplicates()
            if self.history_df.empty:
                self.history_df= big
            else:
                self.history_df= pd.concat([self.history_df,big],ignore_index=True).drop_duplicates()
            logging.info(f"Loaded runs => total {len(self.history_df)} records")

    def refresh_erp(self):
        p= Path(self.erp_var.get().strip())
        df= read_erp_excel(p)
        if df.empty:
            self.erp_preview.set_data(pd.DataFrame())
            return
        meltdown= meltdown_erp_for_preview(df,self.param_dict)
        pivoted= pivot_for_preview(meltdown)
        self.erp_preview.set_data(pivoted)

    def refresh_master(self):
        folder= self.mast_folder_var.get().strip()
        zpath= self.mast_zip_var.get().strip()
        if folder:
            dfm= unify_master_txt_in_folder(Path(folder))
        else:
            cfiles= convert_master_txt_to_csv(Path(zpath), self.temp_csv_dir)
            dfm= unify_master_csvs(cfiles)
        if dfm.empty:
            self.master_preview.set_data(pd.DataFrame())
            return
        meltdown= meltdown_master_for_preview(dfm,self.param_dict)
        pivoted= pivot_for_preview(meltdown)
        self.master_preview.set_data(pivoted)

    def run_comparison(self):
        df_erp_w= self.erp_preview.get_filtered_df()
        df_mast_w= self.master_preview.get_filtered_df()

        erp_long= meltdown_to_long(df_erp_w)
        mast_long= meltdown_to_long(df_mast_w)

        trim_flag= bool(self.trim_key_var.get())
        from functools import partial
        mismatch_df, case_df= compare_name_first(erp_long,mast_long,trim_key=trim_flag)

        excp= Path(self.config_dict["paths"].get("EXCEPTION_PATH",""))
        df_exc= read_exception_table(excp)
        mismatch_df= merge_exceptions(mismatch_df, df_exc)
        case_df= merge_exceptions(case_df, df_exc)

        outp= Path(self.config_dict["paths"].get("OUTPUT_PATH","output/missing_items.xlsx"))
        write_2sheet_excel(mismatch_df, case_df, outp)

        run_ts= datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        mismatch_df["RunDate"]= run_ts
        if self.history_df.empty:
            self.history_df= mismatch_df.copy()
        else:
            self.history_df= pd.concat([self.history_df,mismatch_df],ignore_index=True).drop_duplicates()

        histp= Path(self.config_dict["paths"].get("HISTORY_PATH","history_runs"))
        histp.mkdir(parents=True,exist_ok=True)
        runf= histp/f"run_{run_ts.replace(':','-').replace(' ','_')}.json"
        try:
            mismatch_df.to_json(runf, orient="records", indent=2)
            logging.info(f"Saved run => {runf}")
        except Exception as e:
            logging.error(f"Saving JSON => {e}")

        # update dash
        self.dashboard_tab.update_data(mismatch_df, self.history_df)
        self.history_tab.refresh_history()
        self.tabs.select(self.dashboard_tab)
        messagebox.showinfo("Done", f"Missing items => {outp}")

    def export_pdf(self):
        if self.history_df.empty:
            messagebox.showinfo("PDF Export","No mismatch => empty history.")
            return
        if "RunDate" in self.history_df.columns:
            last_run= self.history_df["RunDate"].max()
            df_curr= self.history_df[self.history_df["RunDate"]== last_run].copy()
        else:
            df_curr= self.history_df.copy()
        rep= EnhancedPDFReport(df_curr, self.history_df, self.config_dict)
        pdfp= rep.generate()
        messagebox.showinfo("PDF Export", f"PDF => {pdfp}")

    def save_all_config(self):
        self.config_dict["paths"]["ERP_EXCEL_PATH"]= self.erp_var.get().strip()
        self.config_dict["paths"]["MASTER_ZIP_PATH"]= self.mast_zip_var.get().strip()
        self.config_dict["paths"]["MASTER_TXT_FOLDER"]= self.mast_folder_var.get().strip()
        self.config_dict["paths"]["EXCEPTION_PATH"]= self.exc_var.get().strip()
        self.config_dict["paths"]["OUTPUT_PATH"]= self.out_var.get().strip()
        self.config_dict["paths"]["PARAMETER_PATH"]= self.par_var.get().strip()
        self.config_dict["paths"]["PDF_EXPORT_PATH"]= self.pdf_var.get().strip()

        self.config_dict["trim_key_toggle"]= bool(self.trim_key_var.get())

        e_cfg= self.config_dict.setdefault("erp_grid",{})
        e_cfg["filters"]= self.erp_preview.get_filters()
        e_cfg["future_end_toggle"]= self.erp_preview.get_future_toggle()

        m_cfg= self.config_dict.setdefault("master_grid",{})
        m_cfg["filters"]= self.master_preview.get_filters()
        m_cfg["future_end_toggle"]= self.master_preview.get_future_toggle()

        dash= self.config_dict.setdefault("dashboard",{})
        dash["selected_dims"]= list(self.dashboard_tab.selected_dims)
        dash["selected_attrs"]= list(self.dashboard_tab.selected_attrs)
        dash["top_n"]= self.dashboard_tab.top_n

        cfgp= Path(self.config_dict["paths"].get("CONFIG_PATH","config/ui_config.json"))
        save_config(self.config_dict,cfgp)

    def on_close(self):
        self.save_all_config()
        band_path= self.config_dict["paths"].get("BAND_CHART_JSON_PATH","")
        if band_path and not self.history_df.empty and "RunDate" in self.history_df.columns:
            try:
                outp= Path(band_path)
                date_ct= self.history_df.groupby("RunDate")["Key"].count().reset_index(name="Count")
                date_ct["RunDate_dt"]= pd.to_datetime(date_ct["RunDate"],errors="coerce")
                date_ct.sort_values("RunDate_dt",inplace=True)
                date_ct.reset_index(drop=True,inplace=True)
                date_ct["rolling_mean"]= date_ct["Count"].rolling(3,min_periods=1).mean()
                date_ct["rolling_std"]= date_ct["Count"].rolling(3,min_periods=1).std(ddof=0)
                date_ct["upper_band"]= date_ct["rolling_mean"]+2*date_ct["rolling_std"]
                date_ct["lower_band"]= date_ct["rolling_mean"]-2*date_ct["rolling_std"]
                date_ct["RunDate"]= date_ct["RunDate_dt"].dt.strftime("%Y-%m-%d %H:%M:%S")
                date_ct.drop(columns=["RunDate_dt"],inplace=True)
                date_ct.to_json(outp, orient="records", indent=2)
                logging.info(f"Bollinger => {outp}")
            except Exception as e:
                logging.error(f"Bollinger => {e}")
        self.destroy()

def main():
    app= MainApp()
    app.mainloop()

if __name__=="__main__":
    main()
