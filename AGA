# AGA
"""
Ultra-Mega Reconciliation: Single-file CustomTkinter
with meltdown logic, compare, Start/End Date (NaN) filters, top10 toggle,
PDF export path, tag image top-right, dark mode (Ctrl+D), session saving,
memory usage, professional multi-page PDF (cover + recs).
"""

import os
import sys
import json
import logging
import zipfile
import shutil
import io
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, Set, List

import tkinter as tk
from tkinter import ttk, filedialog, messagebox
import customtkinter as ctk

import pandas as pd
import numpy as np

import matplotlib
matplotlib.use("TkAgg")
import matplotlib.pyplot as plt
from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg

try:
    import psutil
except ImportError:
    psutil = None

from openpyxl import Workbook
from openpyxl.styles import PatternFill, Font, Alignment

# -----------------------------------------------------------------------------
# LOGGING
# -----------------------------------------------------------------------------
logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")

# -----------------------------------------------------------------------------
# DEFAULT PATHS & CONFIG
# -----------------------------------------------------------------------------
DEFAULT_PATHS = {
    "ERP_EXCEL_PATH": "data/ERP_Config.xlsx",
    "MASTER_ZIP_PATH": "data/Master_Config.zip",
    "EXCEPTION_PATH": "data/Exception_Table.xlsx",
    "OUTPUT_PATH": "output/missing_items.xlsx",
    "CONFIG_PATH": "config/ui_config.json",
    "PARAMETER_PATH": "data/parameters.xlsx",
    "MASTER_CSV_OUTPUT": "temp_master_csv",
    "PDF_EXPORT_PATH": "output/dashboard_reports"
}

def default_config() -> Dict:
    return {
        "paths": DEFAULT_PATHS.copy(),
        "comparison_option": 2,
        "erp_grid": {"columns": [], "filters": {}},
        "master_grid": {"columns": [], "filters": {}}
    }

def load_config(path: Path) -> Dict:
    if path.is_file():
        try:
            with open(path, "r", encoding="utf-8") as f:
                return json.load(f)
        except Exception as e:
            logging.warning(f"Could not load config: {e}")
    return default_config()

def save_config(cfg: Dict, path: Path):
    path.parent.mkdir(parents=True, exist_ok=True)
    try:
        with open(path, "w", encoding="utf-8") as f:
            json.dump(cfg, f, indent=2)
        logging.info(f"Saved config to {path}")
    except Exception as e:
        logging.error(f"Error saving config: {e}")

# Tag images for top-right
IMG_PATH_GUI = "tag_small_gui.png"   # top-right in GUI
IMG_PATH_PDF = "tag_small_pdf.png"   # top-right on PDF cover

# -----------------------------------------------------------------------------
# LOG TEXT HANDLER
# -----------------------------------------------------------------------------
class TextHandler(logging.Handler):
    def __init__(self, widget: ctk.CTkTextbox):
        super().__init__()
        self.widget = widget
    def emit(self, record):
        msg = self.format(record) + "\n"
        self.widget.after(0, self._append, msg)
    def _append(self, msg):
        self.widget.configure(state="normal")
        self.widget.insert("end", msg)
        self.widget.see("end")
        self.widget.configure(state="disabled")


# -----------------------------------------------------------------------------
# PARAM + MELTDOWN + COMPARE LOGIC
# -----------------------------------------------------------------------------
def read_param_file(path: Path) -> Dict[str, object]:
    """
    Reads dimension + attribute parameters from two sheets:
    'Dimension Parameters' & 'Attribute Parameters'.
    If not found, returns default empty param.
    """
    param = {
        "dim_erp_keep": set(),
        "dim_erp_map": {},
        "dim_master_map": {},
        "attr_erp_map": {},
        "attr_master_map": {}
    }
    if not path.is_file():
        logging.warning(f"Param file not found => {path}")
        return param
    try:
        dim_df = pd.read_excel(path, sheet_name="Dimension Parameters")
        dim_df.columns = dim_df.columns.astype(str).str.strip()

        def s(x): return str(x).strip() if pd.notna(x) else ""
        for _, row in dim_df.iterrows():
            fn = s(row.get("FileName",""))
            vsc= s(row.get("V S C",""))
            dim= s(row.get("Dimension",""))
            ev = s(row.get("ERP Values",""))
            if ev.lower()=="x" and vsc and dim:
                param["dim_erp_keep"].add(vsc)
            if vsc and dim:
                param["dim_erp_map"][vsc] = dim
            if fn and dim and ev.lower()=="x":
                param["dim_master_map"][fn] = dim

        attr_df = pd.read_excel(path, sheet_name="Attribute Parameters")
        attr_df.columns = attr_df.columns.astype(str).str.strip()
        for _, row in attr_df.iterrows():
            e_orig = s(row.get("ERP Original Attributes",""))
            m_orig = s(row.get("Master Original Attributes",""))
            final_ = s(row.get("Attribute",""))
            onoff = s(row.get("On/Off",""))
            if onoff.lower()=="x" and final_:
                if e_orig:
                    param["attr_erp_map"][e_orig] = final_
                if m_orig:
                    param["attr_master_map"][m_orig] = final_
        return param
    except Exception as e:
        logging.error(f"Error reading param file => {e}")
        return param

def read_erp_excel(path: Path) -> pd.DataFrame:
    if not path.is_file():
        logging.warning(f"ERP Excel not found => {path}")
        return pd.DataFrame()
    try:
        df = pd.read_excel(path, skiprows=3)
        df.columns = df.columns.str.strip()
        # filter by "Enabled_Flag"==Enabled
        if "Enabled_Flag" in df.columns:
            df = df[df["Enabled_Flag"]=="Enabled"]
        return df
    except Exception as e:
        logging.error(f"Error reading ERP => {e}")
        return pd.DataFrame()

def read_txt_2encodings(raw: bytes) -> pd.DataFrame:
    for enc in ["utf-8-sig","utf-16-le"]:
        try:
            buf = io.BytesIO(raw)
            df = pd.read_csv(buf, encoding=enc, on_bad_lines="skip", engine="python")
            df.dropna(how="all", axis=0, inplace=True)
            df.dropna(how="all", axis=1, inplace=True)
            df.columns = df.columns.astype(str).str.strip()
            logging.info(f"[read_txt_2encodings] success with {enc}, shape={df.shape}")
            return df
        except Exception as e:
            logging.debug(f"[read_txt_2encodings] fail with {enc} => {e}")
    logging.error("[read_txt_2encodings] cannot parse .txt => empty.")
    return pd.DataFrame()

def convert_master_txt_to_csv(zip_path: Path, out_dir: Path) -> List[Path]:
    """Extract .txt from zip, parse w/ read_txt_2encodings => unify => store as .csv."""
    if not zip_path.is_file():
        logging.warning(f"[Master] ZIP not found => {zip_path}")
        return []
    if out_dir.exists():
        shutil.rmtree(out_dir, ignore_errors=True)
    out_dir.mkdir(parents=True, exist_ok=True)
    csvs=[]
    with zipfile.ZipFile(zip_path,"r") as z:
        txt_files= [f for f in z.namelist() if f.lower().endswith(".txt")]
        for txt_file in txt_files:
            base_name= os.path.basename(txt_file)
            if not base_name:
                continue
            try:
                with z.open(txt_file) as fo:
                    raw= fo.read()
                df= read_txt_2encodings(raw)
                if df.empty:
                    continue
                df["RawFileName"]= base_name
                # If no "Name" col => rename first col
                if "Name" not in df.columns and len(df.columns)>0:
                    first_col= df.columns[0]
                    df.rename(columns={first_col:"Name"}, inplace=True)
                out_csv= out_dir/(base_name.replace(".txt",".csv"))
                df.to_csv(out_csv, index=False, encoding="utf-8")
                csvs.append(out_csv)
            except Exception as e:
                logging.error(f"[Master] error => {txt_file} => {e}")
    return csvs

def unify_master_csvs(csvs: List[Path]) -> pd.DataFrame:
    frames=[]
    for cp in csvs:
        if cp.is_file():
            try:
                df = pd.read_csv(cp, encoding="utf-8", on_bad_lines="skip")
                df.columns= df.columns.str.strip()
                frames.append(df)
            except Exception as e:
                logging.error(f"[unify_master_csvs] reading {cp} => {e}")
    if frames:
        return pd.concat(frames, ignore_index=True)
    return pd.DataFrame()

def meltdown_erp_for_preview(df: pd.DataFrame, param: Dict[str, object]) -> pd.DataFrame:
    """Filter by 'V_S_C in param[dim_erp_keep]', rename dims, meltdown => pivot => wide."""
    if "V_S_C" not in df.columns:
        return pd.DataFrame()
    keep= param.get("dim_erp_keep", set())
    dmap= param.get("dim_erp_map", {})
    amap= param.get("attr_erp_map", {})

    df2= df[df["V_S_C"].isin(keep)].copy()
    if df2.empty:
        return pd.DataFrame()

    skip_cols= {"V_S_C","Enabled_Flag"}
    id_vars=[]
    if "Value" in df2.columns:
        id_vars.append("Value")
        skip_cols.add("Value")
    df2["DimRaw"]= df2["V_S_C"]
    skip_cols.add("DimRaw")
    id_vars.insert(0,"DimRaw")

    meltdown_cols= [c for c in df2.columns if c not in skip_cols]
    melted= df2.melt(
        id_vars=id_vars,
        value_vars= meltdown_cols,
        var_name="OrigAttr",
        value_name="ValX"
    )

    def rename_dim(v):
        return dmap.get(v,v)
    melted["Dimension"]= melted["DimRaw"].apply(rename_dim)
    if "Value" in id_vars:
        melted.rename(columns={"Value":"Name"}, inplace=True)
    else:
        melted["Name"]= ""

    melted= melted[melted["OrigAttr"].isin(amap.keys())].copy()
    melted["Attribute"]= melted["OrigAttr"].map(amap)

    # strip T for Start/End
    def strip_t(val):
        if isinstance(val,str) and "T" in val:
            return val.split("T")[0]
        return val
    melted["Value"]= np.where(
        melted["Attribute"].isin(["Start Date","End Date"]),
        melted["ValX"].apply(strip_t),
        melted["ValX"]
    )
    return melted[["Dimension","Name","Attribute","Value"]]

def meltdown_master_for_preview(df: pd.DataFrame, param: Dict[str, object]) -> pd.DataFrame:
    """Filter by 'RawFileName in param[dim_master_map]', rename dims, meltdown => pivot => wide."""
    if df.empty or "RawFileName" not in df.columns:
        return pd.DataFrame()
    keep_map= param.get("dim_master_map", {})
    amap= param.get("attr_master_map", {})

    df2= df[df["RawFileName"].isin(keep_map.keys())].copy()
    if df2.empty:
        return pd.DataFrame()

    df2["DimRaw"]= df2["RawFileName"]
    skip_cols= {"RawFileName","DimRaw"}
    id_vars= ["DimRaw"]
    if "Name" in df2.columns:
        id_vars.append("Name")
        skip_cols.add("Name")

    meltdown_cols= [c for c in df2.columns if c not in skip_cols]
    melted= df2.melt(
        id_vars=id_vars,
        value_vars= meltdown_cols,
        var_name="OrigAttr",
        value_name="ValX"
    )

    def rename_dim(fn):
        return keep_map.get(fn,fn)
    melted["Dimension"]= melted["DimRaw"].apply(rename_dim)

    if "Name" in id_vars:
        melted.rename(columns={"Name":"Name"}, inplace=True)
    else:
        melted["Name"]= ""

    melted= melted[melted["OrigAttr"].isin(amap.keys())].copy()
    melted["Attribute"]= melted["OrigAttr"].map(amap)

    def strip_t(val):
        if isinstance(val,str) and "T" in val:
            return val.split("T")[0]
        return val
    melted["Value"]= np.where(
        melted["Attribute"].isin(["Start Date","End Date"]),
        melted["ValX"].apply(strip_t),
        melted["ValX"]
    )
    return melted[["Dimension","Name","Attribute","Value"]]

def pivot_for_preview(df: pd.DataFrame) -> pd.DataFrame:
    """Pivot => wide after meltdown."""
    if df.empty or not {"Dimension","Name","Attribute"}.issubset(df.columns):
        return df
    df2= df.copy()
    df2.drop_duplicates(subset=["Dimension","Name","Attribute"], inplace=True)
    try:
        df2= df2.pivot(index=["Dimension","Name"], columns="Attribute", values="Value").reset_index()
    except Exception as e:
        logging.error(f"Pivot => {e}")
    return df2

def melt_back(df: pd.DataFrame) -> pd.DataFrame:
    """Melt pivoted wide data [Dimension,Name,*attrs*] => long [Dimension,Name,Attribute,Value]."""
    if df.empty or "Dimension" not in df.columns or "Name" not in df.columns:
        return pd.DataFrame()
    skip_cols= {"Dimension","Name"}
    meltdown_cols= [c for c in df.columns if c not in skip_cols]
    melted= df.melt(id_vars=["Dimension","Name"], value_vars= meltdown_cols,
                    var_name="Attribute", value_name="Value")
    return melted[["Dimension","Name","Attribute","Value"]]

def build_keys(df: pd.DataFrame)-> pd.DataFrame:
    """Ensure columns exist, add GroupKey=Dimension|Name, Key=Dimension|Name|Attr|Value."""
    df= df.copy()
    for c in ["Dimension","Name","Attribute","Value"]:
        if c not in df.columns:
            df[c]= ""
        df[c]= df[c].fillna("").astype(str).str.strip()
    df["GroupKey"]= df["Dimension"]+" | "+df["Name"]
    df["Key"]= (df["Dimension"].str.strip()+" | "+
                df["Name"].str.strip()+" | "+
                df["Attribute"].str.strip()+" | "+
                df["Value"].str.strip())
    df["Comments_1"]= ""
    df["Comments_2"]= ""
    df["Action Item"]= ""
    df["Missing In"]= ""
    return df

def compare_mode2(df_erp: pd.DataFrame, df_mast: pd.DataFrame) -> pd.DataFrame:
    """Compare meltdown => missing items, ignoring 'Name' vs. 'Name' if same => compare other attrs."""
    def to_dict(d):
        out={}
        for gk, grp in d.groupby("GroupKey"):
            rec={}
            nm= grp["Name"].iloc[0] if not grp.empty else ""
            rec["Name"]= nm
            for _, row in grp.iterrows():
                rec[row["Attribute"]]= row["Value"]
            out[gk]= rec
        return out
    e_dict= to_dict(df_erp)
    m_dict= to_dict(df_mast)
    all_gk= set(e_dict.keys())| set(m_dict.keys())
    results=[]
    for gk in all_gk:
        dim= gk.split(" | ")[0]
        a_data= e_dict.get(gk,{})
        b_data= m_dict.get(gk,{})
        name_a= a_data.get("Name","")
        name_b= b_data.get("Name","")
        if name_a and name_b and name_a==name_b:
            all_attrs= (set(a_data.keys())| set(b_data.keys()))- {"Name"}
            for at in all_attrs:
                va= a_data.get(at,"")
                vb= b_data.get(at,"")
                if va!= vb:
                    if va and not vb:
                        results.append({"Dimension":dim,"Name":name_a,"Attribute":at,"Value":va,"Missing In":"MASTER"})
                    elif vb and not va:
                        results.append({"Dimension":dim,"Name":name_a,"Attribute":at,"Value":vb,"Missing In":"ERP"})
                    else:
                        results.append({"Dimension":dim,"Name":name_a,"Attribute":at,"Value":va,"Missing In":"MASTER"})
                        results.append({"Dimension":dim,"Name":name_a,"Attribute":at,"Value":vb,"Missing In":"ERP"})
        else:
            if name_a and not name_b:
                results.append({"Dimension":dim,"Name":name_a,"Attribute":"Name","Value":name_a,"Missing In":"MASTER"})
            elif name_b and not name_a:
                results.append({"Dimension":dim,"Name":name_b,"Attribute":"Name","Value":name_b,"Missing In":"ERP"})
    df_res= pd.DataFrame(results)
    if not df_res.empty:
        df_res["Key"]= (df_res["Dimension"].str.strip()+" | "+
                        df_res["Name"].str.strip()+" | "+
                        df_res["Attribute"].str.strip()+" | "+
                        df_res["Value"].str.strip())
    return df_res

def read_exception_table(path: Path)-> pd.DataFrame:
    if not path.is_file():
        logging.warning(f"Exception table not found => {path}")
        return pd.DataFrame()
    try:
        df= pd.read_excel(path)
        df.columns= df.columns.astype(str).str.strip()
        return df
    except Exception as e:
        logging.error(f"Error reading exception => {e}")
        return pd.DataFrame()

def merge_exceptions(df: pd.DataFrame, df_exc: pd.DataFrame)-> pd.DataFrame:
    if df.empty or df_exc.empty or "Key" not in df.columns:
        return df
    keep= [c for c in df_exc.columns if c in ["Key","Comments_1","Comments_2","hide exception"]]
    if not keep:
        return df
    exc= df_exc[keep].copy()
    exc["Key"]= exc["Key"].astype(str).str.strip()
    merged= df.merge(exc, on="Key", how="left", suffixes=("","_exc"))
    merged["hide exception"]= merged.get("hide exception","").fillna("").str.lower()
    final= merged[merged["hide exception"]!="yes"].copy()
    if "Comments_1_exc" in final.columns:
        final["Comments_1"]= np.where(final["Comments_1_exc"].notna(), final["Comments_1_exc"], final["Comments_1"])
        final.drop(columns=["Comments_1_exc"], inplace=True)
    if "Comments_2_exc" in final.columns:
        final["Comments_2"]= np.where(final["Comments_2_exc"].notna(), final["Comments_2_exc"], final["Comments_2"])
        final.drop(columns=["Comments_2_exc"], inplace=True)
    if "hide exception" in final.columns:
        final.drop(columns=["hide exception"], inplace=True)
    return final

def write_missing_items(df: pd.DataFrame, out_path: Path):
    if df.empty:
        logging.info("No missing => skip writing.")
        return
    out_path.parent.mkdir(parents=True, exist_ok=True)
    final_cols= ["Key","Dimension","Name","Attribute","Value","Comments_1","Comments_2","Action Item","Missing In"]
    for c in final_cols:
        if c not in df.columns:
            df[c]= ""
    df= df[final_cols]
    wb= Workbook()
    ws= wb.active
    ws.title= "Missing Items"
    ws.append(final_cols)
    for rowvals in df.itertuples(index=False):
        ws.append(rowvals)
    header_font= Font(bold=True)
    fill= PatternFill(start_color="DDDDDD", end_color="DDDDDD", fill_type="solid")
    for cell in ws[1]:
        cell.font= header_font
        cell.fill= fill
        cell.alignment= Alignment(horizontal="center")
    # autosize
    for col in ws.columns:
        max_len=0
        letter= col[0].column_letter
        for cell in col:
            val= str(cell.value) if cell.value else ""
            max_len= max(max_len, len(val))
        ws.column_dimensions[letter].width= max_len+2
    ws.freeze_panes= "A2"
    wb.save(out_path)
    logging.info(f"Missing => {out_path}")


# -----------------------------------------------------------------------------
# SIMPLE PREVIEW CLASS
# (Erp & Master previews with Start/End Date filter, includes NaN)
# -----------------------------------------------------------------------------
class SimplePreview(ctk.CTkFrame):
    FILTERABLE = {"Start Date","End Date"}
    def __init__(self, parent, name: str):
        super().__init__(parent)
        self.name = name
        self.df = pd.DataFrame()
        self.filters: Dict[str, Set] = {}
        self.create_toolbar()
        self.create_table()
        self.create_statusbar()

    def create_toolbar(self):
        bar= ctk.CTkFrame(self, corner_radius=10, fg_color="#f0f0f0")
        bar.pack(fill="x", padx=5, pady=5)
        # White text on burgundy
        ctk.CTkLabel(
            bar, 
            text=f"{self.name} Preview", 
            fg_color="#800020", 
            text_color="white",
            corner_radius=8
        ).pack(side="left", padx=5)
        ctk.CTkButton(
            bar, 
            text="ⓘ", 
            width=30, 
            command=self.show_info,
            fg_color="#800020", 
            text_color="white",
            hover_color="#a52a2a"
        ).pack(side="left", padx=5)
        ctk.CTkButton(
            bar, 
            text="Clear Date Filters", 
            command=self.clear_filters,
            fg_color="#800020", 
            text_color="white",
            hover_color="#a52a2a"
        ).pack(side="left", padx=5)

    def show_info(self):
        messagebox.showinfo("Info", f"{self.name} data after meltdown & param.\nOnly Start/End Date columns filterable, including NaN.")

    def create_table(self):
        container= ctk.CTkFrame(self)
        container.pack(fill="both", expand=True, padx=5, pady=5)
        self.tree= ttk.Treeview(container, show="headings")
        vsb= ttk.Scrollbar(container, orient="vertical", command=self.tree.yview)
        hsb= ttk.Scrollbar(container, orient="horizontal", command=self.tree.xview)
        self.tree.configure(yscrollcommand=vsb.set, xscrollcommand=hsb.set)
        self.tree.grid(row=0, column=0, sticky="nsew")
        vsb.grid(row=0, column=1, sticky="ns")
        hsb.grid(row=1, column=0, sticky="ew")
        container.rowconfigure(0, weight=1)
        container.columnconfigure(0, weight=1)

    def create_statusbar(self):
        self.status_label= ctk.CTkLabel(self, text="0 rows")
        self.status_label.pack(fill="x")

    def set_data(self, df: pd.DataFrame):
        self.filters.clear()
        self.df= df.copy()
        self.refresh_table()

    def refresh_table(self):
        for i in self.tree.get_children():
            self.tree.delete(i)
        if self.df.empty:
            self.tree["columns"]= []
            self.status_label.configure(text="0 rows")
            return
        cols= list(self.df.columns)
        self.tree["columns"]= cols
        for c in cols:
            self.tree.heading(c, text=c, anchor="w",
                              command=lambda col=c:self.on_heading_click(col))
            self.tree.column(c, anchor="w", width=150)
        df_f= self.apply_filters()
        for _, row in df_f.iterrows():
            rowvals= [row[c] for c in cols]
            self.tree.insert("", "end", values=rowvals)
        self.status_label.configure(text=f"{len(df_f)} rows")

    def apply_filters(self)-> pd.DataFrame:
        df_f= self.df.copy()
        for col, allowed in self.filters.items():
            if col in df_f.columns:
                # interpret NaN => "(NaN)"
                def interpret_na(x):
                    if pd.isna(x):
                        return "(NaN)"
                    elif isinstance(x,str) and not x.strip():
                        return "(blank)"
                    else:
                        return str(x)
                df_f= df_f[df_f[col].apply(interpret_na).isin({str(a) for a in allowed})]
        return df_f

    def on_heading_click(self, col_name: str):
        if col_name in self.FILTERABLE:
            self.show_filter_popup(col_name)

    def show_filter_popup(self, col_name: str):
        if self.df.empty or col_name not in self.df.columns:
            return
        popup= tk.Toplevel(self)
        popup.title(f"Filter: {col_name}")
        popup.geometry("300x400")
        frame= ctk.CTkFrame(popup)
        frame.pack(fill="both", expand=True, padx=5, pady=5)

        unique_vals= self.df[col_name].unique()
        display_map={}
        def interpret_na(x):
            if pd.isna(x):
                return "(NaN)"
            elif isinstance(x,str) and not x.strip():
                return "(blank)"
            else:
                return str(x)
        for v in unique_vals:
            display_map[v]= interpret_na(v)

        sorted_vals= sorted(display_map.keys(), key=lambda x: display_map[x].lower())
        curr_filter= self.filters.get(col_name, set(sorted_vals))

        selall_var= tk.BooleanVar(value=True)
        def toggle_all():
            check= selall_var.get()
            for vb in var_dict.values():
                vb.set(check)

        ctk.CTkCheckBox(
            frame, 
            text="Select All", 
            variable=selall_var, 
            command=toggle_all,
            fg_color="#800020", 
            hover_color="#a52a2a"
        ).pack(anchor="w", pady=5)

        scroll= ctk.CTkScrollableFrame(frame, width=250, height=250)
        scroll.pack(fill="both", expand=True, padx=5, pady=5)

        var_dict= {}
        for rv in sorted_vals:
            in_filter= rv in curr_filter
            bvar= tk.BooleanVar(value=in_filter)
            var_dict[rv]= bvar
            ctk.CTkCheckBox(
                scroll, 
                text=display_map[rv], 
                variable=bvar,
                fg_color="#800020", 
                hover_color="#a52a2a"
            ).pack(anchor="w")

        def apply_():
            sel= {rv for rv, vb in var_dict.items() if vb.get()}
            if sel== set(sorted_vals) or not sel:
                self.filters.pop(col_name,None)
            else:
                self.filters[col_name]= sel
            popup.destroy()
            self.refresh_table()

        bf= ctk.CTkFrame(frame)
        bf.pack(fill="x", pady=5)
        ctk.CTkButton(bf, text="Apply", fg_color="#800020", hover_color="#a52a2a",
                      command=apply_).pack(side="left", padx=5)
        ctk.CTkButton(bf, text="Cancel", fg_color="#800020", hover_color="#a52a2a",
                      command=popup.destroy).pack(side="left", padx=5)

    def clear_filters(self):
        self.filters.clear()
        self.refresh_table()

    def get_filtered_df(self)-> pd.DataFrame:
        return self.apply_filters()


# -----------------------------------------------------------------------------
# ADVANCED DASHBOARD: 8 charts, top10 toggle, PDF (cover, summary, recs)
# -----------------------------------------------------------------------------
class AdvancedDashboard(ctk.CTkFrame):
    def __init__(self, parent):
        super().__init__(parent)
        self.df_current = pd.DataFrame()
        self.df_history = pd.DataFrame()
        self.selected_dims: Set[str] = set()
        self.selected_attrs: Set[str] = set()
        self.show_top10= False

        # top bar
        topbar= ctk.CTkFrame(self, corner_radius=10, fg_color="#f0f0f0")
        topbar.pack(fill="x", padx=5, pady=5)

        self.metric_label= ctk.CTkLabel(topbar, text="Metrics: 0 missing, 0 dimension", width=300)
        self.metric_label.pack(side="left", padx=5)

        # filter dimension/attribute
        ctk.CTkButton(
            topbar, text="Filter Dimension", 
            fg_color="#800020", text_color="white",
            hover_color="#a52a2a",
            command=lambda: self.show_filter_popup("Dimension")
        ).pack(side="left", padx=5)
        ctk.CTkButton(
            topbar, text="Filter Attribute",
            fg_color="#800020", text_color="white",
            hover_color="#a52a2a",
            command=lambda: self.show_filter_popup("Attribute")
        ).pack(side="left", padx=5)

        # top10
        self.top10_var= tk.BooleanVar(value=False)
        ctk.CTkCheckBox(
            topbar, text="Show Top 10", 
            variable=self.top10_var,
            command=self.update_data_filters,
            fg_color="#800020", hover_color="#a52a2a",
            text_color="white"
        ).pack(side="left", padx=5)

        # quick date
        ctk.CTkButton(topbar, text="Last 7",
                      fg_color="#800020", text_color="white", hover_color="#a52a2a",
                      command=lambda: self.set_quick_range(7)).pack(side="left", padx=5)
        ctk.CTkButton(topbar, text="Last 30",
                      fg_color="#800020", text_color="white", hover_color="#a52a2a",
                      command=lambda: self.set_quick_range(30)).pack(side="left", padx=5)
        ctk.CTkButton(topbar, text="Last 90",
                      fg_color="#800020", text_color="white", hover_color="#a52a2a",
                      command=lambda: self.set_quick_range(90)).pack(side="left", padx=5)
        ctk.CTkButton(topbar, text="All Time",
                      fg_color="#800020", text_color="white", hover_color="#a52a2a",
                      command=lambda: self.set_quick_range(9999)).pack(side="left", padx=5)

        self.start_date_var= tk.StringVar(value=(datetime.now()-timedelta(days=30)).strftime("%Y-%m-%d"))
        self.end_date_var= tk.StringVar(value=datetime.now().strftime("%Y-%m-%d"))

        ctk.CTkEntry(topbar, textvariable=self.start_date_var, width=100).pack(side="left", padx=5)
        ctk.CTkEntry(topbar, textvariable=self.end_date_var, width=100).pack(side="left", padx=5)

        ctk.CTkButton(
            topbar, text="Update Timeline", 
            fg_color="#800020", text_color="white", hover_color="#a52a2a",
            command=self.update_data_filters
        ).pack(side="left", padx=5)

        ctk.CTkButton(
            topbar, text="Export PDF", 
            fg_color="#800020", text_color="white", hover_color="#a52a2a",
            command=self.export_enhanced_pdf_report
        ).pack(side="left", padx=5)

        # Notebook
        self.notebook= ttk.Notebook(self)
        self.notebook.pack(fill="both", expand=True)

        self.frames= {}
        chart_names= ["Heatmap","Lollipop","Circular","Scatter","Radar","Normal Pie","Normal Bar","Band Chart"]
        for nm in chart_names:
            tab_fr= ctk.CTkFrame(self.notebook)
            self.notebook.add(tab_fr, text=nm)
            scroller= ctk.CTkScrollableFrame(tab_fr, width=800, height=600)
            scroller.pack(fill="both", expand=True)
            self.frames[nm]= scroller

    def set_quick_range(self, days:int):
        if days>9000:
            self.start_date_var.set("1900-01-01")
            self.end_date_var.set("2100-12-31")
        else:
            end_= datetime.now()
            start_= end_ - timedelta(days=days)
            self.start_date_var.set(start_.strftime("%Y-%m-%d"))
            self.end_date_var.set(end_.strftime("%Y-%m-%d"))
        self.update_data_filters()

    def show_filter_popup(self, col:str):
        base_df= self.df_history if not self.df_history.empty else self.df_current
        if base_df.empty or col not in base_df.columns:
            return
        popup= tk.Toplevel(self)
        popup.title(f"Filter: {col}")
        popup.geometry("300x400")
        frame= ctk.CTkFrame(popup)
        frame.pack(fill="both", expand=True, padx=5, pady=5)

        unique_vals= base_df[col].unique()
        display_map={}
        for v in unique_vals:
            if pd.isna(v):
                dsp= "(NaN)"
            elif isinstance(v,str) and not v.strip():
                dsp= "(blank)"
            else:
                dsp= str(v)
            display_map[v]= dsp
        sorted_vals= sorted(display_map.keys(), key=lambda x: display_map[x].lower())

        if col=="Dimension":
            curr= self.selected_dims
        else:
            curr= self.selected_attrs
        if not curr:
            curr= set(unique_vals)

        selall_var= tk.BooleanVar(value=True)
        def toggle_all():
            check= selall_var.get()
            for vb in var_dict.values():
                vb.set(check)

        ctk.CTkCheckBox(
            frame, text="Select All", 
            variable=selall_var, command=toggle_all,
            fg_color="#800020", hover_color="#a52a2a",
            text_color="white"
        ).pack(anchor="w", pady=5)

        scroller= ctk.CTkScrollableFrame(frame, width=250, height=250)
        scroller.pack(fill="both", expand=True, padx=5, pady=5)
        var_dict= {}
        for rv in sorted_vals:
            in_filter= rv in curr
            bvar= tk.BooleanVar(value=in_filter)
            var_dict[rv]= bvar
            ctk.CTkCheckBox(
                scroller, 
                text=display_map[rv], 
                variable=bvar,
                fg_color="#800020", hover_color="#a52a2a", 
                text_color="white"
            ).pack(anchor="w")

        def apply_():
            sel= {rv for rv,vb in var_dict.items() if vb.get()}
            if col=="Dimension":
                self.selected_dims= sel
            else:
                self.selected_attrs= sel
            popup.destroy()
            self.update_data_filters()

        bf= ctk.CTkFrame(frame)
        bf.pack(fill="x", pady=5)
        ctk.CTkButton(bf, text="Apply", fg_color="#800020", text_color="white",
                      hover_color="#a52a2a", command=apply_).pack(side="left", padx=5)
        ctk.CTkButton(bf, text="Cancel", fg_color="#800020", text_color="white",
                      hover_color="#a52a2a", command=popup.destroy).pack(side="left", padx=5)

    def update_data(self, df_current: pd.DataFrame, df_history: pd.DataFrame):
        self.df_current= df_current.copy()
        self.df_history= df_history.copy()
        self.update_data_filters()

    def update_data_filters(self):
        dfc= self.df_current.copy()
        if not dfc.empty:
            if self.selected_dims:
                dfc= dfc[dfc["Dimension"].isin(self.selected_dims)]
            if self.selected_attrs:
                dfc= dfc[dfc["Attribute"].isin(self.selected_attrs)]
        # time filter if "RunDate" in df
        if "RunDate" in dfc.columns:
            try:
                s_= datetime.strptime(self.start_date_var.get(), "%Y-%m-%d")
                e_= datetime.strptime(self.end_date_var.get(), "%Y-%m-%d")
                dfc["RunDate_dt"]= pd.to_datetime(dfc["RunDate"], errors="coerce")
                dfc= dfc[(dfc["RunDate_dt"]>= s_) & (dfc["RunDate_dt"]<= e_)]
            except Exception as e:
                logging.error(f"Date filter => {e}")

        mism= len(dfc)
        dims= dfc["Dimension"].nunique() if not dfc.empty and "Dimension" in dfc.columns else 0
        self.metric_label.configure(text=f"Mismatches: {mism}, Dims: {dims}")

        self.show_top10= self.top10_var.get()

        self.plotHeatmap(dfc)
        self.plotLollipop(dfc)
        self.plotCircular(dfc)
        self.plotScatter(dfc)
        self.plotRadar(dfc)
        self.plotNormalPie(dfc)
        self.plotNormalBar(dfc)
        self.plotBandChart()

    def clear_frame(self, fr: ctk.CTkScrollableFrame):
        for w in fr.winfo_children():
            w.destroy()

    def _limit_if_top10(self, s: pd.Series)-> pd.Series:
        if self.show_top10:
            return s.head(10)
        return s

    def plotHeatmap(self, dfc: pd.DataFrame):
        fr= self.frames["Heatmap"]
        self.clear_frame(fr)
        if dfc.empty or "Missing In" not in dfc.columns:
            return
        df_m= dfc[dfc["Missing In"]!=""]
        if df_m.empty or not {"Dimension","Attribute"}.issubset(df_m.columns):
            return
        pivot= df_m.groupby(["Dimension","Attribute"]).size().unstack(fill_value=0)

        if self.show_top10:
            pivot= pivot.loc[pivot.sum(axis=1).sort_values(ascending=False).head(10).index]
            col_sum= pivot.sum(axis=0)
            pivot= pivot[col_sum.sort_values(ascending=False).head(10).index]

        fig, ax= plt.subplots(figsize=(6,5))
        cax= ax.imshow(pivot, aspect="auto", cmap="Reds")
        ax.set_xticks(range(len(pivot.columns)))
        ax.set_xticklabels(pivot.columns, rotation=90)
        ax.set_yticks(range(len(pivot.index)))
        ax.set_yticklabels(pivot.index)
        fig.colorbar(cax, ax=ax)
        ax.set_title("Heatmap: Missing Items")

        canvas= FigureCanvasTkAgg(fig, master=fr)
        canvas.draw()
        canvas.get_tk_widget().pack(fill="both", expand=True)

    def plotLollipop(self, dfc: pd.DataFrame):
        fr= self.frames["Lollipop"]
        self.clear_frame(fr)
        if dfc.empty or "Missing In" not in dfc.columns:
            return
        df_m= dfc[dfc["Missing In"]!=""]
        if df_m.empty:
            return
        cdim= df_m.groupby("Dimension")["Key"].count().sort_values(ascending=False)
        if self.show_top10:
            cdim= cdim.head(10)
        if cdim.empty:
            return
        fig, ax= plt.subplots(figsize=(6,5))
        ax.hlines(y=cdim.index, xmin=0, xmax=cdim.values, color="skyblue")
        ax.plot(cdim.values, cdim.index, "o", color="skyblue")
        ax.set_title("Lollipop: Missing Dimensions")
        ax.set_xlabel("Missing Count")

        canvas= FigureCanvasTkAgg(fig, master=fr)
        canvas.draw()
        canvas.get_tk_widget().pack(fill="both", expand=True)

    def plotCircular(self, dfc: pd.DataFrame):
        fr= self.frames["Circular"]
        self.clear_frame(fr)
        if dfc.empty or "Missing In" not in dfc.columns:
            return
        df_m= dfc[dfc["Missing In"]!=""]
        if df_m.empty:
            return
        cattr= df_m.groupby("Attribute")["Key"].count().sort_values(ascending=False)
        if self.show_top10:
            cattr= cattr.head(10)
        if cattr.empty:
            return
        cat= cattr.index.tolist()
        val= cattr.values
        angles= np.linspace(0,2*np.pi,len(cat), endpoint=False)
        fig= plt.figure(figsize=(6,6))
        ax= fig.add_subplot(111, polar=True)
        ax.set_theta_offset(np.pi/2)
        ax.set_theta_direction(-1)
        ax.set_xticks(angles)
        ax.set_xticklabels(cat, fontsize=9)
        ax.bar(angles, val, width=0.4, color="orange", alpha=0.6)
        ax.set_title("Circular: Missing Attributes", y=1.05)

        canvas= FigureCanvasTkAgg(fig, master=fr)
        canvas.draw()
        canvas.get_tk_widget().pack(fill="both", expand=True)

    def plotScatter(self, dfc: pd.DataFrame):
        fr= self.frames["Scatter"]
        self.clear_frame(fr)
        if dfc.empty or "Missing In" not in dfc.columns:
            return
        df_m= dfc[dfc["Missing In"]!=""]
        if df_m.empty:
            return
        cdim= df_m.groupby("Dimension")["Key"].count().reset_index(name="Count")
        cdim.sort_values("Count", ascending=False, inplace=True)
        if self.show_top10:
            cdim= cdim.head(10)
        if cdim.empty:
            return
        xvals= np.arange(len(cdim))
        yvals= cdim["Count"].values
        labels= cdim["Dimension"].values

        fig, ax= plt.subplots(figsize=(6,5))
        ax.scatter(xvals,yvals,color="green")
        for i, txt in enumerate(labels):
            ax.text(xvals[i], yvals[i], txt, ha="center", va="bottom", rotation=60)
        ax.set_xticks([])
        ax.set_ylabel("Missing Count")
        ax.set_title("Scatter: Missing by Dimension")

        canvas= FigureCanvasTkAgg(fig, master=fr)
        canvas.draw()
        canvas.get_tk_widget().pack(fill="both", expand=True)

    def plotRadar(self, dfc: pd.DataFrame):
        fr= self.frames["Radar"]
        self.clear_frame(fr)
        if dfc.empty or "Missing In" not in dfc.columns:
            return
        df_m= dfc[dfc["Missing In"]!=""]
        if df_m.empty:
            return
        cdim= df_m.groupby("Dimension")["Key"].count().sort_values(ascending=False)
        if self.show_top10:
            cdim= cdim.head(5)
        else:
            cdim= cdim.head(5)
        if cdim.empty:
            return
        cat= cdim.index.tolist()
        val= cdim.values.tolist()
        N= len(cat)
        angles= np.linspace(0,2*np.pi,N, endpoint=False).tolist()
        angles+= angles[:1]
        val+= val[:1]

        fig= plt.figure(figsize=(6,6))
        ax= fig.add_subplot(111, polar=True)
        ax.set_theta_offset(np.pi/2)
        ax.set_theta_direction(-1)
        ax.set_xticks(angles[:-1])
        ax.set_xticklabels(cat, fontsize=9)
        ax.plot(angles, val, color="red", linewidth=2)
        ax.fill(angles, val, color="red", alpha=0.3)
        ax.set_title("Radar: top 5 missing dims", y=1.08)

        canvas= FigureCanvasTkAgg(fig, master=fr)
        canvas.draw()
        canvas.get_tk_widget().pack(fill="both", expand=True)

    def plotNormalPie(self, dfc: pd.DataFrame):
        fr= self.frames["Normal Pie"]
        self.clear_frame(fr)
        if dfc.empty or "Missing In" not in dfc.columns:
            return
        df_m= dfc[dfc["Missing In"]!=""]
        if df_m.empty:
            return
        dist= df_m["Missing In"].value_counts()
        fig, ax= plt.subplots(figsize=(5,5))
        ax.pie(dist.values, labels=dist.index, autopct="%.1f%%", startangle=140)
        ax.set_title("Pie: Missing In distribution")

        canvas= FigureCanvasTkAgg(fig, master=fr)
        canvas.draw()
        canvas.get_tk_widget().pack(fill="both", expand=True)

    def plotNormalBar(self, dfc: pd.DataFrame):
        fr= self.frames["Normal Bar"]
        self.clear_frame(fr)
        if dfc.empty or "Missing In" not in dfc.columns:
            return
        df_m= dfc[dfc["Missing In"]!=""]
        if df_m.empty:
            return
        cattr= df_m.groupby("Attribute")["Key"].count().sort_values(ascending=False)
        if self.show_top10:
            cattr= cattr.head(10)
        fig, ax= plt.subplots(figsize=(6,4))
        cattr.plot(kind="bar", ax=ax, color="blue")
        ax.set_ylabel("Missing Count")
        ax.set_title("Bar: top 10 missing attributes")

        canvas= FigureCanvasTkAgg(fig, master=fr)
        canvas.draw()
        canvas.get_tk_widget().pack(fill="both", expand=True)

    def plotBandChart(self):
        fr= self.frames["Band Chart"]
        self.clear_frame(fr)
        if self.df_history.empty or "RunDate" not in self.df_history.columns:
            return
        date_ct= self.df_history.groupby("RunDate")["Key"].count().reset_index(name="Count")
        date_ct.sort_values("RunDate", inplace=True)
        date_ct["Count_min"]= date_ct["Count"]*0.9
        date_ct["Count_max"]= date_ct["Count"]*1.1
        fig, ax= plt.subplots(figsize=(6,4))
        ax.plot(date_ct["RunDate"], date_ct["Count"], color="purple", marker="o", label="Missing Count")
        ax.fill_between(date_ct["RunDate"], date_ct["Count_min"], date_ct["Count_max"],
                        color="purple", alpha=0.2, label="±10% band")
        ax.set_title("Band Chart Over Time")
        ax.set_xlabel("RunDate")
        ax.set_ylabel("Missing Count")
        plt.xticks(rotation=45)
        ax.legend()
        for i, row in date_ct.iterrows():
            ax.text(row["RunDate"], row["Count"], str(row["Count"]), ha="center", va="bottom")

        canvas= FigureCanvasTkAgg(fig, master=fr)
        canvas.draw()
        canvas.get_tk_widget().pack(fill="both", expand=True)

    def export_enhanced_pdf_report(self):
        """Pro PDF with cover page (tag image top-right), summary, all charts, recommendations."""
        from matplotlib.backends.backend_pdf import PdfPages
        pdf_dir= Path(self.master.config_dict["paths"].get("PDF_EXPORT_PATH","output/dashboard_reports"))
        pdf_dir.mkdir(parents=True, exist_ok=True)
        timestamp= datetime.now().strftime("%Y%m%d_%H%M%S")
        pdf_path= pdf_dir/f"reconciliation_report_{timestamp}.pdf"

        dfc= self.df_current.copy()
        dfh= self.df_history.copy()

        with PdfPages(pdf_path) as pdf:
            # Cover
            plt.figure(figsize=(8.5,11))
            plt.axis('off')
            if os.path.isfile(IMG_PATH_PDF):
                try:
                    img= plt.imread(IMG_PATH_PDF)
                    # place near top-right
                    plt.imshow(img, extent=[5,8.5,9,11], aspect='auto', alpha=0.7)
                except Exception as e:
                    logging.error(f"Tag image => {e}")

            plt.text(0.5, 0.85, "Reconciliation Analysis Report", ha='center', fontsize=24, fontweight='bold')
            plt.text(0.5, 0.75, f"Generated: {timestamp}", ha='center', fontsize=12)
            if not dfc.empty:
                plt.text(0.5, 0.65, f"Total Mismatches: {len(dfc)}", ha='center', fontsize=10)
            plt.text(0.5, 0.1, "CONFIDENTIAL", ha='center', fontsize=8)
            pdf.savefig()
            plt.close()

            # Exec Summary
            fig= plt.figure(figsize=(8.5,11))
            plt.axis('off')
            plt.text(0.5, 0.95, "Executive Summary", ha='center', fontsize=20, fontweight='bold')
            sum_txt= "This PDF provides an overview of ERP vs. Master mismatches, plus recommended actions."
            plt.text(0.1, 0.85, sum_txt, fontsize=10, wrap=True)
            pdf.savefig()
            plt.close()

            # Detailed charts
            self._export_all_charts(pdf)

            # Recommendations
            recs= self._generate_recommendations(dfc, dfh)
            fig= plt.figure(figsize=(8.5,11))
            plt.axis('off')
            plt.text(0.5, 0.95, "Recommendations", ha='center', fontsize=20, fontweight='bold')
            ypos= 0.85
            for r in recs:
                plt.text(0.1, ypos, r, fontsize=10)
                ypos-= 0.07
            pdf.savefig()
            plt.close()

        messagebox.showinfo("Exported", f"PDF => {pdf_path}")

    def _export_all_charts(self, pdf):
        for nm, scroller in self.frames.items():
            for widget in scroller.winfo_children():
                if isinstance(widget, FigureCanvasTkAgg):
                    pdf.savefig(widget.figure)

    def _generate_recommendations(self, dfc: pd.DataFrame, dfh: pd.DataFrame)-> List[str]:
        if dfc.empty:
            return ["No mismatches => no immediate actions required."]
        recs= []
        recs.append("1) Investigate top mismatch dimensions to reduce errors.")
        if not dfh.empty:
            recs.append("2) Monitor mismatch trend across runs for sustained improvements.")
        recs.append("3) Review param alignment & re-check any hidden exceptions.")
        return recs


# -----------------------------------------------------------------------------
# MAIN APP
# -----------------------------------------------------------------------------
class MainApp(ctk.CTk):
    def __init__(self):
        super().__init__()
        self.title("Ultra-Mega Reconciliation: Single-file Enhanced")
        self.geometry("1600x900")
        ctk.set_appearance_mode("light")

        # fallback style
        plt.style.use("ggplot")

        self.dark_mode= False

        # load config & param
        self.config_dict= load_config(Path(DEFAULT_PATHS["CONFIG_PATH"]))
        self.param_dict= read_param_file(Path(self.config_dict["paths"].get("PARAMETER_PATH", DEFAULT_PATHS["PARAMETER_PATH"])))
        self.history_df= pd.DataFrame()

        # place top-right GUI image (near the X)
        if os.path.isfile(IMG_PATH_GUI):
            try:
                self.tag_photo= tk.PhotoImage(file=IMG_PATH_GUI)
                # place with some offset near top-right
                self.tag_label= tk.Label(self, image=self.tag_photo, bg="#f0f0f0")
                # Adjust x,y for best position near top-right
                self.tag_label.place(relx=1.0, rely=0.0, anchor="ne", x=-10, y=30)
            except Exception as e:
                logging.error(f"GUI tag error => {e}")

        self.tabs= ttk.Notebook(self)
        self.tabs.pack(fill="both", expand=True)

        # 1) Paths
        self.tab_paths= ctk.CTkFrame(self.tabs)
        self.tabs.add(self.tab_paths, text="Paths")
        self.build_paths_tab(self.tab_paths)

        # 2) ERP
        self.tab_erp= ctk.CTkFrame(self.tabs)
        self.erp_preview= SimplePreview(self.tab_erp, "ERP")
        self.erp_preview.pack(fill="both", expand=True)
        self.tabs.add(self.tab_erp, text="ERP Preview")

        # 3) Master
        self.tab_master= ctk.CTkFrame(self.tabs)
        self.master_preview= SimplePreview(self.tab_master, "Master")
        self.master_preview.pack(fill="both", expand=True)
        self.tabs.add(self.tab_master, text="Master Preview")

        # 4) Compare
        self.tab_compare= ctk.CTkFrame(self.tabs)
        self.build_compare_tab(self.tab_compare)
        self.tabs.add(self.tab_compare, text="Compare")

        # 5) Dashboard
        self.dashboard_tab= AdvancedDashboard(self.tabs)
        self.dashboard_tab.master= self
        self.tabs.add(self.dashboard_tab, text="Dashboard")

        # Logging
        self.log_box= ctk.CTkTextbox(self, height=120)
        self.log_box.pack(fill="both")
        self.log_box.configure(state="disabled")
        handler= TextHandler(self.log_box)
        handler.setLevel(logging.INFO)
        logging.getLogger().addHandler(handler)

        # status bar
        self.add_status_bar()

        # ensure Master CSV folder
        Path(self.config_dict["paths"].get("MASTER_CSV_OUTPUT","temp_master_csv")).mkdir(parents=True, exist_ok=True)

        # meltdown auto
        self.refresh_erp()
        self.refresh_master()

        # shortcuts, tips, session
        self.setup_keyboard_shortcuts()
        self.add_tooltips()
        self.protocol("WM_DELETE_WINDOW", self.on_close)
        self.load_session()

    def build_paths_tab(self, parent):
        frm= ctk.CTkFrame(parent)
        frm.pack(fill="both", expand=True, padx=10, pady=10)

        self.erp_var= tk.StringVar(value=self.config_dict["paths"].get("ERP_EXCEL_PATH", DEFAULT_PATHS["ERP_EXCEL_PATH"]))
        self.mast_var= tk.StringVar(value=self.config_dict["paths"].get("MASTER_ZIP_PATH", DEFAULT_PATHS["MASTER_ZIP_PATH"]))
        self.exc_var= tk.StringVar(value=self.config_dict["paths"].get("EXCEPTION_PATH", DEFAULT_PATHS["EXCEPTION_PATH"]))
        self.out_var= tk.StringVar(value=self.config_dict["paths"].get("OUTPUT_PATH", DEFAULT_PATHS["OUTPUT_PATH"]))
        self.cfg_var= tk.StringVar(value=self.config_dict["paths"].get("CONFIG_PATH", DEFAULT_PATHS["CONFIG_PATH"]))
        self.par_var= tk.StringVar(value=self.config_dict["paths"].get("PARAMETER_PATH", DEFAULT_PATHS["PARAMETER_PATH"]))
        self.csv_var= tk.StringVar(value=self.config_dict["paths"].get("MASTER_CSV_OUTPUT", DEFAULT_PATHS["MASTER_CSV_OUTPUT"]))
        self.pdf_var= tk.StringVar(value=self.config_dict["paths"].get("PDF_EXPORT_PATH", DEFAULT_PATHS["PDF_EXPORT_PATH"]))

        def mkrow(lbl, var, is_dir=False):
            rowf= ctk.CTkFrame(frm)
            rowf.pack(fill="x", pady=5)
            ctk.CTkLabel(rowf, text=lbl, width=200).pack(side="left", padx=5)
            e= ctk.CTkEntry(rowf, textvariable=var, width=600)
            e.pack(side="left", padx=5)
            def br():
                if is_dir:
                    p= filedialog.askdirectory()
                    if p:
                        var.set(p)
                else:
                    f= filedialog.askopenfilename()
                    if f:
                        var.set(f)
            ctk.CTkButton(rowf, text="Browse", fg_color="#800020", text_color="white",
                          hover_color="#a52a2a", command=br).pack(side="left", padx=5)

        mkrow("ERP Excel:", self.erp_var)
        mkrow("Master ZIP:", self.mast_var)
        mkrow("Exception Path:", self.exc_var)
        mkrow("Missing Items Output:", self.out_var)
        mkrow("JSON Config Path:", self.cfg_var)
        mkrow("Parameter File:", self.par_var)
        mkrow("Master CSV Folder:", self.csv_var, True)
        mkrow("PDF Export Path:", self.pdf_var, True)

        bf= ctk.CTkFrame(frm)
        bf.pack(fill="x", pady=10)
        ctk.CTkButton(bf, text="Save Config", fg_color="#800020", text_color="white",
                      hover_color="#a52a2a", command=self.save_all_config).pack(side="left", padx=5)
        ctk.CTkButton(bf, text="Refresh ERP", fg_color="#800020", text_color="white",
                      hover_color="#a52a2a", command=self.refresh_erp).pack(side="left", padx=5)
        ctk.CTkButton(bf, text="Refresh Master", fg_color="#800020", text_color="white",
                      hover_color="#a52a2a", command=self.refresh_master).pack(side="left", padx=5)

    def build_compare_tab(self, parent):
        frm= ctk.CTkFrame(parent)
        frm.pack(fill="both", expand=True, padx=10, pady=10)

        bf= ctk.CTkFrame(frm)
        bf.pack(fill="x", pady=5)
        ctk.CTkButton(bf, text="🔄 Refresh All Data", fg_color="#800020", text_color="white",
                      hover_color="#a52a2a", command=self.refresh_all_data).pack(side="left", padx=5)

        ctk.CTkLabel(frm, text="Generate Missing Items Report", font=("Arial",16)).pack(pady=5)
        ctk.CTkButton(frm, text="Run Reconciliation", fg_color="#800020", text_color="white",
                      hover_color="#a52a2a", height=40, command=self.run_comparison).pack(pady=5)

        self.status_frame= ctk.CTkFrame(frm)
        self.status_frame.pack(fill="x", pady=5)
        self.last_run_label= ctk.CTkLabel(self.status_frame, text="Last Run: Never")
        self.last_run_label.pack(pady=5)

    def refresh_erp(self):
        erp_path= Path(self.config_dict["paths"].get("ERP_EXCEL_PATH","data/ERP_Config.xlsx")).resolve()
        raw_erp= read_erp_excel(erp_path)
        if raw_erp.empty:
            self.erp_preview.set_data(pd.DataFrame())
            return
        param= read_param_file(Path(self.config_dict["paths"].get("PARAMETER_PATH","data/parameters.xlsx")))
        melted= meltdown_erp_for_preview(raw_erp, param)
        pivoted= pivot_for_preview(melted)
        self.erp_preview.set_data(pivoted)

    def refresh_master(self):
        zip_path= Path(self.config_dict["paths"].get("MASTER_ZIP_PATH","data/Master_Config.zip")).resolve()
        out_dir= Path(self.config_dict["paths"].get("MASTER_CSV_OUTPUT","temp_master_csv")).resolve()
        csvs= convert_master_txt_to_csv(zip_path, out_dir)
        raw_m= unify_master_csvs(csvs)
        if raw_m.empty:
            self.master_preview.set_data(pd.DataFrame())
            return
        param= read_param_file(Path(self.config_dict["paths"].get("PARAMETER_PATH","data/parameters.xlsx")))
        melted= meltdown_master_for_preview(raw_m, param)
        pivoted= pivot_for_preview(melted)
        self.master_preview.set_data(pivoted)

    def refresh_all_data(self):
        """Refresh all data sources and update views."""
        try:
            # Reload parameter file
            self.param_dict= read_param_file(
                Path(self.config_dict["paths"].get("PARAMETER_PATH","data/parameters.xlsx"))
            )
            self.refresh_erp()
            self.refresh_master()
            now_s= datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            self.last_run_label.configure(text=f"Last Refresh: {now_s}")

            messagebox.showinfo("Success","All data refreshed successfully!")
        except Exception as e:
            logging.error(f"Error => {e}")
            messagebox.showerror("Error",str(e))

    def run_comparison(self):
        df_erp_wide= self.erp_preview.get_filtered_df()
        df_mast_wide= self.master_preview.get_filtered_df()

        erp_long= melt_back(df_erp_wide)
        erp_long= build_keys(erp_long)
        mast_long= melt_back(df_mast_wide)
        mast_long= build_keys(mast_long)

        df_diff= compare_mode2(erp_long, mast_long)

        exc_path= Path(self.config_dict["paths"].get("EXCEPTION_PATH","data/Exception_Table.xlsx")).resolve()
        df_exc= read_exception_table(exc_path)
        final= merge_exceptions(df_diff, df_exc)

        outp= Path(self.config_dict["paths"].get("OUTPUT_PATH","output/missing_items.xlsx")).resolve()
        write_missing_items(final, outp)

        run_date= datetime.now().strftime("%Y-%m-%d")
        final["RunDate"]= run_date
        if self.history_df.empty:
            self.history_df= final.copy()
        else:
            self.history_df= pd.concat([self.history_df, final], ignore_index=True)

        self.dashboard_tab.update_data(final, self.history_df)
        now_s= datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        self.last_run_label.configure(text=f"Last Run: {now_s}")
        messagebox.showinfo("Done", f"Missing => {outp}")

        self.tabs.select(self.dashboard_tab)

    def save_all_config(self):
        self.config_dict["paths"]["ERP_EXCEL_PATH"]= self.erp_var.get().strip()
        self.config_dict["paths"]["MASTER_ZIP_PATH"]= self.mast_var.get().strip()
        self.config_dict["paths"]["EXCEPTION_PATH"]= self.exc_var.get().strip()
        self.config_dict["paths"]["OUTPUT_PATH"]= self.out_var.get().strip()
        self.config_dict["paths"]["CONFIG_PATH"]= self.cfg_var.get().strip()
        self.config_dict["paths"]["PARAMETER_PATH"]= self.par_var.get().strip()
        self.config_dict["paths"]["MASTER_CSV_OUTPUT"]= self.csv_var.get().strip()
        self.config_dict["paths"]["PDF_EXPORT_PATH"]= self.pdf_var.get().strip()

        path= Path(self.config_dict["paths"]["CONFIG_PATH"])
        save_config(self.config_dict, path)
        messagebox.showinfo("Saved","Paths & Config saved successfully.")

    def setup_keyboard_shortcuts(self):
        """Setup keyboard shortcuts for common actions."""
        self.bind('<Control-r>', lambda e: self.refresh_all_data())
        self.bind('<Control-s>', lambda e: self.save_all_config())
        self.bind('<Control-e>', lambda e: self.dashboard_tab.export_enhanced_pdf_report())
        self.bind('<F5>', lambda e: self.refresh_all_data())
        # Dark mode => Ctrl+D
        self.bind('<Control-d>', lambda e: self.toggle_dark_mode())

    def toggle_dark_mode(self):
        self.dark_mode= not hasattr(self,"dark_mode") or not self.dark_mode
        if self.dark_mode:
            ctk.set_appearance_mode("dark")
        else:
            ctk.set_appearance_mode("light")

    def add_tooltips(self):
        pass

    def add_status_bar(self):
        self.status_bar= ctk.CTkFrame(self)
        self.status_bar.pack(fill="x", side="bottom")

        self.status_label= ctk.CTkLabel(self.status_bar, text="Ready")
        self.status_label.pack(side="left", padx=5)
        self.memory_label= ctk.CTkLabel(self.status_bar, text="")
        self.memory_label.pack(side="right", padx=5)

        self.update_status_bar()

    def update_status_bar(self):
        """Update memory usage once per second, if psutil installed."""
        if psutil:
            process= psutil.Process()
            mem_mb= process.memory_info().rss / (1024*1024)
            self.memory_label.configure(text=f"Memory: {mem_mb:.1f} MB")
        else:
            self.memory_label.configure(text="psutil not installed")
        self.after(1000, self.update_status_bar)

    def save_session(self):
        sess= {
            "config": self.config_dict,
            "filters":{
                "erp": self.erp_preview.filters,
                "master": self.master_preview.filters
            },
            "selected_dims": list(self.dashboard_tab.selected_dims),
            "selected_attrs": list(self.dashboard_tab.selected_attrs),
            "date_range":{
                "start": self.dashboard_tab.start_date_var.get(),
                "end": self.dashboard_tab.end_date_var.get()
            },
            "top10": self.dashboard_tab.top10_var.get()
        }
        cpath= Path(self.config_dict["paths"]["CONFIG_PATH"])
        session_file= cpath.parent/"last_session.json"
        try:
            with open(session_file,'w',encoding='utf-8') as f:
                json.dump(sess,f,indent=2)
            logging.info(f"Session saved => {session_file}")
        except Exception as e:
            logging.error(f"Session save => {e}")

    def load_session(self):
        cpath= Path(self.config_dict["paths"]["CONFIG_PATH"])
        session_file= cpath.parent/"last_session.json"
        if session_file.is_file():
            try:
                with open(session_file,'r',encoding='utf-8') as f:
                    sess= json.load(f)
                self.config_dict= sess["config"]
                self.erp_preview.filters= sess["filters"]["erp"]
                self.master_preview.filters= sess["filters"]["master"]
                self.dashboard_tab.selected_dims= set(sess["selected_dims"])
                self.dashboard_tab.selected_attrs= set(sess["selected_attrs"])
                self.dashboard_tab.start_date_var.set(sess["date_range"]["start"])
                self.dashboard_tab.end_date_var.set(sess["date_range"]["end"])
                self.dashboard_tab.top10_var.set(sess["top10"])
                logging.info("Session loaded.")
            except Exception as e:
                logging.error(f"Session load => {e}")

    def on_close(self):
        self.save_session()
        self.destroy()

def main():
    plt.style.use("ggplot")
    app= MainApp()
    app.mainloop()

if __name__=="__main__":
    main()
