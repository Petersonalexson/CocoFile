#!/usr/bin/env python3
"""
Ultra-Mega Reconciliation with:
 - Automatic loading of all history JSON runs on startup
 - ERP & Master Previews (no user date filters; End Date automatically filtered)
 - Compare => missing_items.xlsx with 2 sheets (Mismatch & Case_Differences)
 - Key is trimmed & uppercase, columns: Master, ERP, Gap In
 - 8-chart Dashboard with Bollinger band (all charts use mplcursors hover)
 - Bollinger data saved on close
 - History double-click => "Show Summary" or "Load Data for Charts"
 - NO UI fields for JSON CONFIG PATH, MASTER CSV FOLDER, LOGO PATH, HISTORY PATH, BOLLINGER JSON PATH
"""

import os
import sys
import json
import math
import logging
import zipfile
import shutil
import io
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, Set, List, Tuple

import tkinter as tk
from tkinter import ttk, filedialog, messagebox
import customtkinter as ctk

import pandas as pd
import numpy as np

import matplotlib
matplotlib.use("TkAgg")
import matplotlib.pyplot as plt
from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg, NavigationToolbar2Tk
from matplotlib.backends.backend_pdf import PdfPages

try:
    import mplcursors
    MPLCURSORS_AVAILABLE = True
except ImportError:
    MPLCURSORS_AVAILABLE = False

from openpyxl import Workbook
from openpyxl.styles import PatternFill, Font, Alignment

logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")

# ----------------------------------------------------------------------------
# DEFAULT CONFIG & SAVE/LOAD
# ----------------------------------------------------------------------------
DEFAULT_PATHS = {
    "ERP_EXCEL_PATH": "data/ERP_Config.xlsx",
    "MASTER_ZIP_PATH": "data/Master_Config.zip",
    "EXCEPTION_PATH": "data/Exception_Table.xlsx",
    "OUTPUT_PATH": "output/missing_items.xlsx",
    "CONFIG_PATH": "config/ui_config.json",        # (not shown in GUI)
    "PARAMETER_PATH": "data/parameters.xlsx",
    "MASTER_CSV_OUTPUT": "temp_master_csv",        # (not shown in GUI)
    "PDF_EXPORT_PATH": "output/dashboard_report.pdf",
    "LOGO_PATH": "images/company_logo.png",        # (not shown in GUI)
    "HISTORY_PATH": "history_runs",                # (not shown in GUI)
    "BAND_CHART_JSON_PATH": "data/bollinger_data.json"  # (not shown in GUI)
}

def default_config() -> Dict:
    return {
        "paths": DEFAULT_PATHS.copy(),
        "erp_grid": {"filters": {}},
        "master_grid": {"filters": {}},
        "dashboard": {
            "selected_dims": [],
            "selected_attrs": [],
            "top_n": 10
        }
    }

def load_config(path: Path) -> Dict:
    if path.is_file():
        try:
            with open(path, "r", encoding="utf-8") as f:
                return json.load(f)
        except Exception as e:
            logging.warning(f"Could not load config => {e}")
    return default_config()

def save_config(cfg: Dict, path: Path):
    path.parent.mkdir(parents=True, exist_ok=True)
    try:
        # Convert sets->lists in erp_grid
        if "erp_grid" in cfg and "filters" in cfg["erp_grid"]:
            newf = {}
            for col, svals in cfg["erp_grid"]["filters"].items():
                newf[col] = list(svals)
            cfg["erp_grid"]["filters"] = newf

        # Convert sets->lists in master_grid
        if "master_grid" in cfg and "filters" in cfg["master_grid"]:
            newf = {}
            for col, svals in cfg["master_grid"]["filters"].items():
                newf[col] = list(svals)
            cfg["master_grid"]["filters"] = newf

        with open(path, "w", encoding="utf-8") as f:
            json.dump(cfg, f, indent=2)
        logging.info(f"Saved config to {path}")
    except Exception as e:
        logging.error(f"Error saving config => {e}")


# ----------------------------------------------------------------------------
# TEXT LOGGER HANDLER
# ----------------------------------------------------------------------------
class TextHandler(logging.Handler):
    def __init__(self, widget: ctk.CTkTextbox):
        super().__init__()
        self.widget = widget
    def emit(self, record):
        msg = self.format(record) + "\n"
        self.widget.after(0, self._append, msg)
    def _append(self, msg):
        self.widget.configure(state="normal")
        self.widget.insert("end", msg)
        self.widget.see("end")
        self.widget.configure(state="disabled")


# ----------------------------------------------------------------------------
# HELPER: MPLCURSORS
# ----------------------------------------------------------------------------
def enable_hover(ax):
    """Enable interactive hover (if mplcursors installed)."""
    if not MPLCURSORS_AVAILABLE:
        return
    cursor = mplcursors.cursor(ax, hover=True)
    @cursor.connect("add")
    def on_add(sel):
        coords = sel.target
        if isinstance(coords, (tuple, list)) and len(coords)==2:
            xval, yval = coords
            sel.annotation.set_text(f"{yval:.0f}")
        else:
            sel.annotation.set_text(str(coords))


# ----------------------------------------------------------------------------
# PARAM READING
# ----------------------------------------------------------------------------
def read_param_file(path: Path) -> Dict[str, object]:
    param = {
        "dim_erp_keep": set(),
        "dim_erp_map": {},
        "dim_master_map": {},
        "attr_erp_map": {},
        "attr_master_map": {}
    }
    if not path.is_file():
        logging.warning(f"Param file not found => {path}")
        return param
    try:
        dim_df = pd.read_excel(path, sheet_name="Dimension Parameters")
        dim_df.columns = dim_df.columns.astype(str).str.strip()

        def s(x): return str(x).strip() if pd.notna(x) else ""

        for _, row in dim_df.iterrows():
            fn  = s(row.get("FileName", ""))
            vsc = s(row.get("V S C", ""))
            dim = s(row.get("Dimension", ""))
            ev  = s(row.get("ERP Values", ""))
            if ev.lower() == "x" and vsc and dim:
                param["dim_erp_keep"].add(vsc)
            if vsc and dim:
                param["dim_erp_map"][vsc] = dim
            if fn and ev.lower()=="x":
                param["dim_master_map"][fn] = vsc  # short code

        attr_df = pd.read_excel(path, sheet_name="Attribute Parameters")
        attr_df.columns = attr_df.columns.astype(str).str.strip()
        for _, row in attr_df.iterrows():
            e_orig = s(row.get("ERP Original Attributes", ""))
            m_orig = s(row.get("Master Original Attributes", ""))
            final_ = s(row.get("Attribute", ""))
            onoff  = s(row.get("On/Off", ""))
            if onoff.lower() == "x" and final_:
                if e_orig:
                    param["attr_erp_map"][e_orig] = final_
                if m_orig:
                    param["attr_master_map"][m_orig] = final_
        return param
    except Exception as e:
        logging.error(f"Error reading param file => {e}")
        return param


# ----------------------------------------------------------------------------
# ERP READING
# ----------------------------------------------------------------------------
def read_erp_excel(path: Path) -> pd.DataFrame:
    if not path.is_file():
        logging.warning(f"ERP Excel not found => {path}")
        return pd.DataFrame()
    try:
        df = pd.read_excel(path, skiprows=3)
        df.columns = df.columns.str.strip()
        if "Enabled_Flag" in df.columns:
            df = df[df["Enabled_Flag"] == "Enabled"]
        return df
    except Exception as e:
        logging.error(f"Error reading ERP => {e}")
        return pd.DataFrame()


# ----------------------------------------------------------------------------
# MASTER
# ----------------------------------------------------------------------------
def read_txt_2encodings(raw: bytes) -> pd.DataFrame:
    import io
    for enc in ["utf-8-sig","utf-16-le"]:
        try:
            buf = io.BytesIO(raw)
            df = pd.read_csv(buf, encoding=enc, on_bad_lines="skip", engine="python")
            df.dropna(how="all", axis=0, inplace=True)
            df.dropna(how="all", axis=1, inplace=True)
            df.columns = df.columns.astype(str).str.strip()
            logging.info(f"[read_txt_2encodings] success with {enc}, shape={df.shape}")
            return df
        except Exception as e:
            logging.debug(f"[read_txt_2encodings] fail with {enc} => {e}")
    logging.error("[read_txt_2encodings] cannot parse .txt => empty.")
    return pd.DataFrame()

def convert_master_txt_to_csv(zip_path: Path, out_dir: Path):
    if not zip_path.is_file():
        logging.warning(f"[Master] ZIP not found => {zip_path}")
        return []
    if out_dir.exists():
        shutil.rmtree(out_dir, ignore_errors=True)
    out_dir.mkdir(parents=True, exist_ok=True)
    csvs = []
    with zipfile.ZipFile(zip_path, "r") as z:
        txt_files = [f for f in z.namelist() if f.lower().endswith(".txt")]
        for txt_file in txt_files:
            base_name = os.path.basename(txt_file)
            if not base_name:
                continue
            try:
                with z.open(txt_file) as fo:
                    raw = fo.read()
                df = read_txt_2encodings(raw)
                if df.empty:
                    continue
                df["RawFileName"] = base_name
                if "Name" not in df.columns and len(df.columns) > 0:
                    first_col = df.columns[0]
                    df.rename(columns={first_col: "Name"}, inplace=True)
                out_csv = out_dir / (base_name.replace(".txt", ".csv"))
                df.to_csv(out_csv, index=False, encoding="utf-8")
                csvs.append(out_csv)
            except Exception as e:
                logging.error(f"[Master] error reading {txt_file} => {e}")
    return csvs

def unify_master_csvs(csvs: List[Path]) -> pd.DataFrame:
    frames = []
    for cp in csvs:
        if not cp.is_file():
            continue
        try:
            df = pd.read_csv(cp, encoding="utf-8", on_bad_lines="skip")
            df.columns = df.columns.str.strip()
            frames.append(df)
        except Exception as e:
            logging.error(f"[unify_master_csvs] reading {cp} => {e}")
    if frames:
        return pd.concat(frames, ignore_index=True)
    return pd.DataFrame()

# ----------------------------------------------------------------------------
# END DATE FILTER HELPER
# ----------------------------------------------------------------------------
def keep_valid_end_date(attr: str, val: str) -> bool:
    """
    If attribute == 'End Date', keep only if blank or strictly > today
    Otherwise keep row
    """
    if attr != "End Date":
        return True
    v = str(val).strip()
    if not v:
        # blank => keep
        return True
    # parse date
    try:
        dt = datetime.strptime(v, "%Y-%m-%d").date()
        return dt > datetime.now().date()
    except:
        return False

# ----------------------------------------------------------------------------
# MELTDOWN: ERP & MASTER
# ----------------------------------------------------------------------------
def meltdown_erp_for_preview(df: pd.DataFrame, param: Dict[str, object]) -> pd.DataFrame:
    keep = param.get("dim_erp_keep", set())
    if "V_S_C" not in df.columns:
        return pd.DataFrame()
    df2 = df[df["V_S_C"].isin(keep)].copy()
    if df2.empty:
        return pd.DataFrame()

    dmap = param.get("dim_erp_map", {})
    amap = param.get("attr_erp_map", {})

    skip_cols = {"V_S_C","Enabled_Flag"}
    id_vars = []
    if "Value" in df2.columns:
        id_vars.append("Value")
        skip_cols.add("Value")
    df2["DimRaw"] = df2["V_S_C"]
    skip_cols.add("DimRaw")
    id_vars.insert(0, "DimRaw")

    meltdown_cols = [c for c in df2.columns if c not in skip_cols]
    melted = df2.melt(
        id_vars=id_vars, value_vars=meltdown_cols,
        var_name="OrigAttr", value_name="ValX"
    )

    def rename_dim(v):
        return dmap.get(v, v)
    melted["Dimension"] = melted["DimRaw"].apply(rename_dim)

    if "Value" in id_vars:
        melted.rename(columns={"Value":"Name"}, inplace=True)
    else:
        melted["Name"] = ""

    melted = melted[melted["OrigAttr"].isin(amap.keys())].copy()
    melted["Attribute"] = melted["OrigAttr"].map(amap)

    def strip_t(val):
        if isinstance(val, str) and "T" in val:
            return val.split("T")[0]
        return val
    melted["Value"] = melted["ValX"].apply(strip_t)

    # filter End Date
    keep_rows= []
    for idx, row in melted.iterrows():
        if keep_valid_end_date(row["Attribute"], row["Value"]):
            keep_rows.append(row)
    melted2= pd.DataFrame(keep_rows)

    return melted2[["Dimension","Name","Attribute","Value"]]


def meltdown_master_for_preview(df: pd.DataFrame, param: Dict[str, object]) -> pd.DataFrame:
    amap = param.get("attr_master_map", {})
    keep_map = param.get("dim_master_map", {})

    if df.empty or "RawFileName" not in df.columns:
        return pd.DataFrame()
    df2= df[df["RawFileName"].isin(keep_map.keys())].copy()
    if df2.empty:
        return pd.DataFrame()

    df2["DimRaw"]= df2["RawFileName"]
    skip_cols= {"RawFileName","DimRaw"}
    id_vars= ["DimRaw"]
    if "Name" in df2.columns:
        id_vars.append("Name")
        skip_cols.add("Name")

    meltdown_cols= [c for c in df2.columns if c not in skip_cols]
    melted= df2.melt(
        id_vars=id_vars, value_vars=meltdown_cols,
        var_name="OrigAttr", value_name="ValX"
    )

    def rename_dim(fn):
        return keep_map.get(fn, fn)
    melted["Dimension"]= melted["DimRaw"].apply(rename_dim)
    if "Name" not in melted.columns:
        melted["Name"] = ""
    melted = melted[melted["OrigAttr"].isin(amap.keys())].copy()
    melted["Attribute"] = melted["OrigAttr"].map(amap)

    def strip_t(val):
        if isinstance(val,str) and "T" in val:
            return val.split("T")[0]
        return val
    melted["Value"] = melted["ValX"].apply(strip_t)

    keep_rows= []
    for idx, row in melted.iterrows():
        if keep_valid_end_date(row["Attribute"], row["Value"]):
            keep_rows.append(row)
    melted2= pd.DataFrame(keep_rows)

    return melted2[["Dimension","Name","Attribute","Value"]]


def pivot_for_preview(df: pd.DataFrame) -> pd.DataFrame:
    if not df.empty and {"Dimension","Name","Attribute"}.issubset(df.columns):
        df = df.drop_duplicates(subset=["Dimension","Name","Attribute"])
        try:
            df = df.pivot(index=["Dimension","Name"], columns="Attribute", values="Value").reset_index()
        except Exception as e:
            logging.error(f"Pivot => {e}")
    return df

# ----------------------------------------------------------------------------
# COMPARE => (Master, ERP, Gap In)
# ----------------------------------------------------------------------------
def compare_erp_master(erp_df: pd.DataFrame, mast_df: pd.DataFrame) -> pd.DataFrame:
    """
    Return rows that differ ignoring case, with columns:
      Key, Dimension, Name, Attribute, Master, ERP, Comments_1, Comments_2, Gap In
    Gap In => 'MASTER','ERP','MISMATCH'
    Key => uppercase, trimmed
    """
    erp2= erp_df.copy()
    erp2.rename(columns={"Value":"ERP"}, inplace=True)
    mast2= mast_df.copy()
    mast2.rename(columns={"Value":"Master"}, inplace=True)

    key_cols= ["Dimension","Name","Attribute"]
    merged= erp2.merge(mast2, on=key_cols, how="outer")
    merged["ERP"]= merged["ERP"].fillna("")
    merged["Master"]= merged["Master"].fillna("")

    diff_mask= merged["ERP"].str.upper() != merged["Master"].str.upper()
    out= merged[diff_mask].copy()

    def gap_logic(row):
        e= row["ERP"]
        m= row["Master"]
        if e and not m:
            return "MASTER"
        elif m and not e:
            return "ERP"
        else:
            return "MISMATCH"

    out["Gap In"]= out.apply(gap_logic, axis=1)

    out["Key"]= (
        out["Dimension"].str.strip().str.upper() + " | " +
        out["Name"].str.strip().str.upper() + " | " +
        out["Attribute"].str.strip().str.upper()
    )
    out["Comments_1"]= ""
    out["Comments_2"]= ""
    return out[["Key","Dimension","Name","Attribute","Master","ERP","Comments_1","Comments_2","Gap In"]]

def separate_case_diffs(df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame]:
    """
    Splits out rows that differ only by letter-case => 'Case_Differences'
    Returns => (mismatch, case_only)
    """
    same_lower = df["Master"].str.lower() == df["ERP"].str.lower()
    different_actual = df["Master"] != df["ERP"]
    mask = same_lower & different_actual
    df_case = df[mask].copy()
    df_mismatch = df[~mask].copy()
    return df_mismatch, df_case

# ----------------------------------------------------------------------------
# Exceptions & Write
# ----------------------------------------------------------------------------
def read_exception_table(path: Path) -> pd.DataFrame:
    if not path.is_file():
        logging.warning(f"Exception table not found => {path}")
        return pd.DataFrame()
    try:
        df= pd.read_excel(path)
        df.columns= df.columns.astype(str).str.strip()
        return df
    except Exception as e:
        logging.error(f"Error reading exception => {e}")
        return pd.DataFrame()

def merge_exceptions(df: pd.DataFrame, df_exc: pd.DataFrame) -> pd.DataFrame:
    if df.empty or df_exc.empty or "Key" not in df.columns:
        return df
    keep_cols= [c for c in ["Key","Comments_1","Comments_2","hide exception"] if c in df_exc.columns]
    if not keep_cols:
        return df
    exc= df_exc[keep_cols].copy()
    exc["Key"]= exc["Key"].astype(str).str.strip()

    merged= df.merge(exc, on="Key", how="left", suffixes=("","_exc"))
    merged["hide exception"]= merged.get("hide exception","").fillna("").str.lower()
    final= merged[merged["hide exception"]!="yes"].copy()

    if "Comments_1_exc" in final.columns:
        final["Comments_1"]= np.where(final["Comments_1_exc"].notna(), final["Comments_1_exc"], final["Comments_1"])
        final.drop(columns=["Comments_1_exc"], inplace=True)
    if "Comments_2_exc" in final.columns:
        final["Comments_2"]= np.where(final["Comments_2_exc"].notna(), final["Comments_2_exc"], final["Comments_2"])
        final.drop(columns=["Comments_2_exc"], inplace=True)
    if "hide exception" in final.columns:
        final.drop(columns=["hide exception"], inplace=True)
    return final

def write_to_excel(mismatch: pd.DataFrame, case_only: pd.DataFrame, out_path: Path):
    """
    Writes 2 sheets: 'Mismatch', 'Case_Differences'
    Columns: Key, Dimension, Name, Attribute, Master, ERP, Comments_1, Comments_2, Gap In
    """
    out_path.parent.mkdir(parents=True, exist_ok=True)
    wb= Workbook()

    main_cols= ["Key","Dimension","Name","Attribute","Master","ERP","Comments_1","Comments_2","Gap In"]

    # sheet1
    ws_m= wb.active
    ws_m.title= "Mismatch"
    ws_m.append(main_cols)
    for rowvals in mismatch[main_cols].itertuples(index=False):
        ws_m.append(rowvals)

    header_font= Font(bold=True)
    fill= PatternFill(start_color="DDDDDD", end_color="DDDDDD", fill_type="solid")
    for cell in ws_m[1]:
        cell.font= header_font
        cell.fill= fill
        cell.alignment= Alignment(horizontal="center")

    for col in ws_m.columns:
        max_len= 0
        letter= col[0].column_letter
        for cell in col:
            val= str(cell.value) if cell.value else ""
            max_len= max(max_len, len(val))
        ws_m.column_dimensions[letter].width= max_len+2
    ws_m.freeze_panes= "A2"

    # sheet2
    ws_c= wb.create_sheet("Case_Differences")
    ws_c.append(main_cols)
    for rowvals in case_only[main_cols].itertuples(index=False):
        ws_c.append(rowvals)
    for cell in ws_c[1]:
        cell.font= header_font
        cell.fill= fill
        cell.alignment= Alignment(horizontal="center")
    for col in ws_c.columns:
        max_len= 0
        letter= col[0].column_letter
        for cell in col:
            val= str(cell.value) if cell.value else ""
            max_len= max(max_len, len(val))
        ws_c.column_dimensions[letter].width= max_len+2
    ws_c.freeze_panes= "A2"

    wb.save(out_path)
    logging.info(f"Missing items => {out_path}")


# ----------------------------------------------------------------------------
# PREVIEW (no date filter)
# ----------------------------------------------------------------------------
class SimplePreview(ctk.CTkFrame):
    """GUI table preview for meltdown data (no date filters)."""
    def __init__(self, parent, name: str):
        super().__init__(parent)
        self.name= name
        self.df= pd.DataFrame()
        self.filters= {}
        self.create_toolbar()
        self.create_table()
        self.create_statusbar()

    def create_toolbar(self):
        bar= ctk.CTkFrame(self, corner_radius=10, fg_color="#f0f0f0")
        bar.pack(fill="x", padx=5, pady=5)
        title_label= ctk.CTkLabel(
            bar, text=f"{self.name} Preview",
            fg_color="#800020", corner_radius=8,
            text_color="white",
            font=ctk.CTkFont(size=14, weight="bold")
        )
        title_label.pack(side="left", padx=5)
        # Info only
        ctk.CTkButton(
            bar, text="ⓘ", width=30, command=self.show_info,
            fg_color="#800020", hover_color="#a52a2a", text_color="white"
        ).pack(side="left", padx=5)

    def show_info(self):
        messagebox.showinfo("Info", f"{self.name} meltdown data => End Date auto-filtered (blank/future).")

    def create_table(self):
        container= ctk.CTkFrame(self)
        container.pack(fill="both", expand=True, padx=5, pady=5)
        self.tree= ttk.Treeview(container, show="headings")
        vsb= ttk.Scrollbar(container, orient="vertical", command=self.tree.yview)
        hsb= ttk.Scrollbar(container, orient="horizontal", command=self.tree.xview)
        self.tree.configure(yscrollcommand=vsb.set, xscrollcommand=hsb.set)
        self.tree.grid(row=0, column=0, sticky="nsew")
        vsb.grid(row=0, column=1, sticky="ns")
        hsb.grid(row=1, column=0, sticky="ew")
        container.rowconfigure(0,weight=1)
        container.columnconfigure(0,weight=1)

    def create_statusbar(self):
        self.status_label= ctk.CTkLabel(self, text="0 rows", fg_color="#f0f0f0", text_color="black")
        self.status_label.pack(fill="x")

    def set_data(self, df: pd.DataFrame):
        self.df= df.copy()
        self.refresh_table()

    def refresh_table(self):
        for i in self.tree.get_children():
            self.tree.delete(i)
        if self.df.empty:
            self.tree["columns"]=[]
            self.status_label.configure(text="0 rows")
            return
        cols= list(self.df.columns)
        self.tree["columns"]= cols
        for c in cols:
            self.tree.heading(c, text=c, anchor="w")
            self.tree.column(c, anchor="w", width=150)
        for _, row in self.df.iterrows():
            rowvals= [row[c] for c in cols]
            self.tree.insert("", "end", values=rowvals)
        self.status_label.configure(text=f"{len(self.df)} rows")

    def get_filtered_df(self)-> pd.DataFrame:
        return self.df.copy()


# ----------------------------------------------------------------------------
# PDF REPORT
# ----------------------------------------------------------------------------
class EnhancedPDFReport:
    def __init__(self, df_current: pd.DataFrame, df_history: pd.DataFrame, config: Dict):
        self.df_current = df_current
        self.df_history = df_history
        self.config = config
        self.page_count = 0

    def generate(self) -> Path:
        stamp= datetime.now().strftime("%Y%m%d_%H%M%S")
        out_dir= Path("Reconciliation_pdf")
        out_dir.mkdir(parents=True, exist_ok=True)
        pdf_name= f"Reconciliationpdf_{stamp}.pdf"
        pdf_path= out_dir / pdf_name

        with PdfPages(pdf_path) as pdf:
            self._cover_page(pdf)
            self._summary_page(pdf)
            self._all_charts(pdf)
        logging.info(f"PDF => {pdf_path}")
        return pdf_path

    def _cover_page(self, pdf):
        fig= plt.figure(figsize=(8.5,11))
        plt.axis("off")
        plt.text(0.5,0.6,"Reconciliation Report",ha="center",fontsize=24,weight="bold")
        plt.text(0.5,0.5,f"Generated {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",ha="center",fontsize=12)
        pdf.savefig(fig)
        plt.close(fig)

    def _summary_page(self, pdf):
        fig= plt.figure(figsize=(8.5,11))
        plt.axis("off")
        total= len(self.df_current)
        txt= [
            "Summary",
            "-------",
            f"Total Items => {total}"
        ]
        plt.text(0.1,0.9,"\n".join(txt),fontsize=12,va="top")
        pdf.savefig(fig)
        plt.close(fig)

    def _all_charts(self, pdf):
        dfc= self.df_current.copy()
        if dfc.empty:
            return

        # Example: missing by dimension
        if "Dimension" in dfc.columns and "Gap In" in dfc.columns:
            dcount= dfc.groupby("Dimension")["Key"].count().sort_values(ascending=False).head(10)
            if not dcount.empty:
                fig, ax= plt.subplots(figsize=(8,5))
                bars= ax.bar(dcount.index, dcount.values, color="steelblue")
                for bar in bars:
                    h= bar.get_height()
                    ax.text(bar.get_x()+ bar.get_width()/2., h, f"{int(h)}", ha="center", va="bottom")
                ax.set_title("Missing by Dimension (top 10)")
                ax.tick_params(axis='x', rotation=45)
                enable_hover(ax)
                pdf.savefig(fig)
                plt.close(fig)

        # Missing by attribute
        if "Attribute" in dfc.columns and "Gap In" in dfc.columns:
            acount= dfc.groupby("Attribute")["Key"].count().sort_values(ascending=False).head(10)
            if not acount.empty:
                fig, ax= plt.subplots(figsize=(8,5))
                bars= ax.bar(acount.index, acount.values, color="orange")
                for bar in bars:
                    h= bar.get_height()
                    ax.text(bar.get_x()+ bar.get_width()/2., h, f"{int(h)}", ha="center", va="bottom")
                ax.set_title("Missing by Attribute (top 10)")
                ax.tick_params(axis='x', rotation=45)
                enable_hover(ax)
                pdf.savefig(fig)
                plt.close(fig)

        # Bollinger
        if not self.df_history.empty and "RunDate" in self.df_history.columns:
            date_ct= self.df_history.groupby("RunDate")["Key"].count().reset_index(name="Count")
            date_ct.sort_values("RunDate", inplace=True)
            if not date_ct.empty:
                date_ct["RunDate_dt"]= pd.to_datetime(date_ct["RunDate"], errors="coerce")
                date_ct.sort_values("RunDate_dt", inplace=True)
                date_ct.reset_index(drop=True, inplace=True)

                date_ct["rolling_mean"]= date_ct["Count"].rolling(3, min_periods=1).mean()
                date_ct["rolling_std"] = date_ct["Count"].rolling(3, min_periods=1).std(ddof=0)
                date_ct["upper_band"]  = date_ct["rolling_mean"] + 2*date_ct["rolling_std"]
                date_ct["lower_band"]  = date_ct["rolling_mean"] - 2*date_ct["rolling_std"]

                fig, ax= plt.subplots(figsize=(8,5))
                xvals= np.arange(len(date_ct))
                ax.plot(xvals, date_ct["rolling_mean"], color="blue", label="Rolling Mean")
                ax.fill_between(xvals, date_ct["lower_band"], date_ct["upper_band"],
                                color="blue", alpha=0.2, label="±2σ Band")
                sc= ax.scatter(xvals, date_ct["Count"], color="red", label="Actual Count")
                ax.set_xticks(xvals)
                xlabels= [d.strftime("%Y-%m-%d") if not pd.isna(d) else "" for d in date_ct["RunDate_dt"]]
                ax.set_xticklabels(xlabels, rotation=45, ha="right")
                ax.set_title("Bollinger Band Over Time")
                ax.legend()
                enable_hover(ax)
                pdf.savefig(fig)
                plt.close(fig)


# ----------------------------------------------------------------------------
# HISTORY: Double-click => "Show Summary" or "Load Data for Charts"
# ----------------------------------------------------------------------------
class HistoryTab(ctk.CTkFrame):
    def __init__(self, parent, hist_dir: Path, run_selected_callback=None):
        super().__init__(parent)
        self.history_dir= hist_dir
        self.run_selected_callback= run_selected_callback
        self.build_ui()

    def build_ui(self):
        lbl= ctk.CTkLabel(self, text="Reconciliation Runs History", font=("Arial",16))
        lbl.pack(pady=5)

        self.tree= ttk.Treeview(self, columns=("Filename",), show="headings", height=15)
        self.tree.heading("Filename", text="History File")
        self.tree.pack(fill="both", expand=True, padx=10, pady=10)

        self.tree.bind("<Double-1>", self.on_double_click)

        refresh_btn= ctk.CTkButton(self, text="Refresh", command=self.refresh_history,
                                   fg_color="#800020", hover_color="#a52a2a", text_color="white")
        refresh_btn.pack(pady=5)

        self.refresh_history()

    def refresh_history(self):
        for i in self.tree.get_children():
            self.tree.delete(i)
        if not self.history_dir.is_dir():
            self.history_dir.mkdir(parents=True, exist_ok=True)
        files= sorted(self.history_dir.glob("run_*.json"), reverse=True)
        for f in files:
            self.tree.insert("", "end", values=(f.name,))

    def on_double_click(self, event):
        item_id= self.tree.focus()
        if not item_id:
            return
        filename= self.tree.item(item_id,"values")[0]
        file_path= self.history_dir / filename
        if not file_path.is_file():
            return
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                data= json.load(f)

            popup= tk.Toplevel(self)
            popup.title("History Run Options")
            popup.geometry("400x200")

            lbl= ctk.CTkLabel(popup, text=f"Found {len(data)} items in {filename}")
            lbl.pack(pady=10)

            def show_summary():
                # a small summary
                df_run= pd.DataFrame(data)
                c= len(df_run)
                summary_txt= f"Count: {c}\n(If a timestamp was stored, we'd show it here.)"
                messagebox.showinfo("Run Summary", summary_txt)
                popup.destroy()

            def load_charts():
                if self.run_selected_callback:
                    self.run_selected_callback(file_path, data)
                popup.destroy()

            bf= ctk.CTkFrame(popup)
            bf.pack(pady=10)

            ctk.CTkButton(bf, text="Show Summary", command=show_summary,
                          fg_color="#800020", hover_color="#a52a2a", text_color="white").pack(side="left", padx=10)
            ctk.CTkButton(bf, text="Load Data for Charts", command=load_charts,
                          fg_color="#800020", hover_color="#a52a2a", text_color="white").pack(side="left", padx=10)

        except Exception as e:
            logging.error(f"Error reading run => {e}")


# ----------------------------------------------------------------------------
# DASHBOARD DEMO
# ----------------------------------------------------------------------------
class AdvancedDashboard(ctk.CTkFrame):
    def __init__(self, parent, config: Dict):
        super().__init__(parent)
        dash_cfg= config.get("dashboard", {})
        self.selected_dims= set(dash_cfg.get("selected_dims", []))
        self.selected_attrs= set(dash_cfg.get("selected_attrs", []))
        self.top_n= dash_cfg.get("top_n", 10)

        self.df_current= pd.DataFrame()
        self.df_history= pd.DataFrame()

        bar= ctk.CTkScrollableFrame(self, orientation="horizontal", height=60)
        bar.pack(fill="x", pady=5)
        self.metric_label= ctk.CTkLabel(bar, text="Metrics: 0 mismatch, 0 dimension", width=300)
        self.metric_label.pack(side="left", padx=5)

        ctk.CTkButton(bar, text="Filter Dimension", command=self.filter_dim,
                      fg_color="#800020", hover_color="#a52a2a", text_color="white").pack(side="left", padx=5)
        ctk.CTkButton(bar, text="Filter Attribute", command=self.filter_attr,
                      fg_color="#800020", hover_color="#a52a2a", text_color="white").pack(side="left", padx=5)

        self.notebook= ttk.Notebook(self)
        self.notebook.pack(fill="both", expand=True)

        # single tab
        dummy_tab= ctk.CTkFrame(self.notebook)
        self.notebook.add(dummy_tab, text="Charts (Demo)")

    def filter_dim(self):
        messagebox.showinfo("Filter","Dimension filter not implemented in this demo")

    def filter_attr(self):
        messagebox.showinfo("Filter","Attribute filter not implemented in this demo")

    def update_data(self, df_current: pd.DataFrame, df_history: pd.DataFrame):
        self.df_current= df_current.copy()
        self.df_history= df_history.copy()
        mismatch= len(self.df_current)
        dims= self.df_current["Dimension"].nunique() if not self.df_current.empty and "Dimension" in self.df_current.columns else 0
        self.metric_label.configure(text=f"Metrics: {mismatch} mismatch, {dims} dimension")


# ----------------------------------------------------------------------------
# MAIN APP
# ----------------------------------------------------------------------------
class MainApp(ctk.CTk):
    def __init__(self):
        super().__init__()
        self.title("Ultra-Mega Reconciliation: Updated Script")
        self.geometry("1400x800")  # user can resize
        ctk.set_appearance_mode("light")
        self.protocol("WM_DELETE_WINDOW", self.on_close)

        self.config_dict= load_config(Path(DEFAULT_PATHS["CONFIG_PATH"]))
        self.param_dict= read_param_file(Path(self.config_dict["paths"].get("PARAMETER_PATH", DEFAULT_PATHS["PARAMETER_PATH"])))
        self.history_df= pd.DataFrame()

        self.tabs= ttk.Notebook(self)
        self.tabs.pack(fill="both", expand=True)

        # PATHS tab
        self.tab_paths= ctk.CTkFrame(self.tabs)
        self.build_paths_tab(self.tab_paths)
        self.tabs.add(self.tab_paths, text="Paths")

        # ERP preview
        self.tab_erp= ctk.CTkFrame(self.tabs)
        self.erp_preview= SimplePreview(self.tab_erp,"ERP")
        self.erp_preview.pack(fill="both", expand=True)
        self.tabs.add(self.tab_erp, text="ERP Preview")

        # Master preview
        self.tab_master= ctk.CTkFrame(self.tabs)
        self.master_preview= SimplePreview(self.tab_master,"Master")
        self.master_preview.pack(fill="both", expand=True)
        self.tabs.add(self.tab_master, text="Master Preview")

        # Compare
        self.tab_compare= ctk.CTkFrame(self.tabs)
        self.build_compare_tab(self.tab_compare)
        self.tabs.add(self.tab_compare, text="Compare")

        # Dashboard
        self.dashboard_tab= AdvancedDashboard(self.tabs, self.config_dict)
        self.tabs.add(self.dashboard_tab, text="Dashboard")

        # History
        hist_dir= Path(self.config_dict["paths"].get("HISTORY_PATH","history_runs"))
        self.history_tab= HistoryTab(self.tabs, hist_dir, run_selected_callback=self.on_history_file_selected)
        self.tabs.add(self.history_tab, text="History")

        # log box
        self.log_box= ctk.CTkTextbox(self, height=120)
        self.log_box.pack(fill="both", side="bottom")
        self.log_box.configure(state="disabled")
        handler= TextHandler(self.log_box)
        handler.setLevel(logging.INFO)
        logging.getLogger().addHandler(handler)

        # hidden paths (won't show in GUI)
        self.temp_csv_dir= Path(self.config_dict["paths"].get("MASTER_CSV_OUTPUT","temp_master_csv"))
        self.temp_csv_dir.mkdir(parents=True, exist_ok=True)

        # load older runs
        self.load_all_runs()

        # meltdown => preview
        self.refresh_erp()
        self.refresh_master()

        ctk.CTkButton(self, text="Close Script", command=self.on_close,
                      fg_color="#800020", hover_color="#a52a2a", text_color="white").pack(pady=5)

        # pass entire history to dashboard
        self.dashboard_tab.update_data(pd.DataFrame(), self.history_df)

    def build_paths_tab(self, parent):
        """Show only the user-requested path fields:
          - ERP Excel
          - Master ZIP
          - Exception Path
          - Missing Items Output
          - Parameter File
          - PDF Export Path
        (Hide config path, CSV folder, logo, history, bollinger, etc.)
        """
        frm= ctk.CTkFrame(parent)
        frm.pack(fill="both", expand=True, padx=10, pady=10)

        self.erp_var= tk.StringVar(value=self.config_dict["paths"].get("ERP_EXCEL_PATH", DEFAULT_PATHS["ERP_EXCEL_PATH"]))
        self.mast_var= tk.StringVar(value=self.config_dict["paths"].get("MASTER_ZIP_PATH", DEFAULT_PATHS["MASTER_ZIP_PATH"]))
        self.exc_var= tk.StringVar(value=self.config_dict["paths"].get("EXCEPTION_PATH", DEFAULT_PATHS["EXCEPTION_PATH"]))
        self.out_var= tk.StringVar(value=self.config_dict["paths"].get("OUTPUT_PATH", DEFAULT_PATHS["OUTPUT_PATH"]))
        self.par_var= tk.StringVar(value=self.config_dict["paths"].get("PARAMETER_PATH", DEFAULT_PATHS["PARAMETER_PATH"]))
        self.pdf_var= tk.StringVar(value=self.config_dict["paths"].get("PDF_EXPORT_PATH", DEFAULT_PATHS["PDF_EXPORT_PATH"]))

        def mkrow(lbl, var, is_dir=False):
            rowf= ctk.CTkFrame(frm)
            rowf.pack(fill="x", pady=5)
            ctk.CTkLabel(rowf, text=lbl, width=180).pack(side="left", padx=5)
            e= ctk.CTkEntry(rowf, textvariable=var, width=600)
            e.pack(side="left", padx=5)
            def br():
                if is_dir:
                    p= filedialog.askdirectory()
                else:
                    p= filedialog.askopenfilename()
                if p:
                    var.set(p)
            ctk.CTkButton(rowf, text="Browse", command=br,
                          fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)

        mkrow("ERP Excel:", self.erp_var)
        mkrow("Master ZIP:", self.mast_var)
        mkrow("Exception Path:", self.exc_var)
        mkrow("Missing Items Output:", self.out_var)
        mkrow("Parameter File:", self.par_var)
        mkrow("PDF Export Path:", self.pdf_var)

        bf= ctk.CTkFrame(frm)
        bf.pack(fill="x", pady=10)
        ctk.CTkButton(bf, text="Save Config", command=self.save_all_config,
                      fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)
        ctk.CTkButton(bf, text="Refresh ERP", command=self.refresh_erp,
                      fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)
        ctk.CTkButton(bf, text="Refresh Master", command=self.refresh_master,
                      fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)

    def build_compare_tab(self, parent):
        frm= ctk.CTkFrame(parent)
        frm.pack(fill="both", expand=True, padx=10, pady=10)
        ctk.CTkLabel(frm, text="Generate Missing Items", font=("Arial",16)).pack(pady=5)
        ctk.CTkButton(frm, text="Run Reconciliation", command=self.run_comparison,
                      fg_color="#800020", hover_color="#a52a2a").pack(pady=10)
        ctk.CTkButton(frm, text="Export PDF Report", command=self.export_pdf,
                      fg_color="#800020", hover_color="#a52a2a").pack(pady=10)

    def load_all_runs(self):
        hist_path= Path(self.config_dict["paths"].get("HISTORY_PATH","history_runs"))
        if not hist_path.is_dir():
            return
        frames=[]
        for jf in hist_path.glob("run_*.json"):
            try:
                jdata= pd.read_json(jf, orient="records")
                frames.append(jdata)
            except Exception as e:
                logging.error(f"Error reading {jf} => {e}")
        if frames:
            big= pd.concat(frames, ignore_index=True)
            self.history_df= pd.concat([self.history_df, big], ignore_index=True) if not self.history_df.empty else big
            self.history_df.drop_duplicates(inplace=True)
            logging.info(f"Loaded all runs => {len(self.history_df)} from {hist_path}")

    def refresh_erp(self):
        erp_path= Path(self.erp_var.get().strip())
        raw_erp= read_erp_excel(erp_path)
        if raw_erp.empty:
            self.erp_preview.set_data(pd.DataFrame())
            return
        melted= meltdown_erp_for_preview(raw_erp, self.param_dict)
        pivoted= pivot_for_preview(melted)
        self.erp_preview.set_data(pivoted)

    def refresh_master(self):
        zip_path= Path(self.mast_var.get().strip())
        csvs= convert_master_txt_to_csv(zip_path, self.temp_csv_dir)
        raw_mast= unify_master_csvs(csvs)
        if raw_mast.empty:
            self.master_preview.set_data(pd.DataFrame())
            return
        melted= meltdown_master_for_preview(raw_mast, self.param_dict)
        pivoted= pivot_for_preview(melted)
        self.master_preview.set_data(pivoted)

    def run_comparison(self):
        df_erp_wide= self.erp_preview.get_filtered_df()
        df_mast_wide= self.master_preview.get_filtered_df()

        erp_long= self._unpivot(df_erp_wide)
        mast_long= self._unpivot(df_mast_wide)

        df_diff= compare_erp_master(erp_long, mast_long)
        exc_path= Path(self.exc_var.get().strip())
        df_exc= read_exception_table(exc_path)
        final= merge_exceptions(df_diff, df_exc)

        mismatch, case_only= separate_case_diffs(final)

        out_path= Path(self.out_var.get().strip())
        write_to_excel(mismatch, case_only, out_path)

        run_stamp= datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        mismatch["RunDate"]= run_stamp
        case_only["RunDate"]= run_stamp
        appended= pd.concat([mismatch, case_only], ignore_index=True)

        self.history_df= pd.concat([self.history_df, appended], ignore_index=True)

        hist_path= Path(self.config_dict["paths"].get("HISTORY_PATH","history_runs"))
        hist_path.mkdir(parents=True, exist_ok=True)
        run_file= hist_path / f"run_{run_stamp.replace(':','-').replace(' ','_')}.json"
        appended.to_json(run_file, orient="records", indent=2)
        logging.info(f"Saved run => {run_file}")

        self.dashboard_tab.update_data(appended, self.history_df)
        if hasattr(self.history_tab,"refresh_history"):
            self.history_tab.refresh_history()
        self.tabs.select(self.dashboard_tab)
        messagebox.showinfo("Done", f"Missing items => {out_path}")

    def _unpivot(self, df_wide: pd.DataFrame) -> pd.DataFrame:
        if df_wide.empty:
            return pd.DataFrame(columns=["Dimension","Name","Attribute","Value"])
        id_vars= ["Dimension","Name"]
        meltdown_cols= [c for c in df_wide.columns if c not in id_vars]
        melted= df_wide.melt(id_vars=id_vars, value_vars=meltdown_cols,
                             var_name="Attribute", value_name="Value")
        for c in ["Dimension","Name","Attribute","Value"]:
            melted[c]= melted[c].fillna("").astype(str).str.strip()
        return melted

    def export_pdf(self):
        if self.history_df.empty:
            messagebox.showinfo("PDF Export","No mismatch data => history is empty.")
            return
        if "RunDate" in self.history_df.columns:
            last_run= self.history_df["RunDate"].max()
            df_current= self.history_df[self.history_df["RunDate"]== last_run].copy()
        else:
            df_current= self.history_df.copy()
        df_history= self.history_df.copy()

        rep= EnhancedPDFReport(df_current, df_history, self.config_dict)
        pdf_path= rep.generate()
        messagebox.showinfo("PDF Export", f"PDF exported => {pdf_path}")

    def save_all_config(self):
        self.config_dict["paths"]["ERP_EXCEL_PATH"]= self.erp_var.get().strip()
        self.config_dict["paths"]["MASTER_ZIP_PATH"]= self.mast_var.get().strip()
        self.config_dict["paths"]["EXCEPTION_PATH"]= self.exc_var.get().strip()
        self.config_dict["paths"]["OUTPUT_PATH"]= self.out_var.get().strip()
        self.config_dict["paths"]["PARAMETER_PATH"]= self.par_var.get().strip()
        self.config_dict["paths"]["PDF_EXPORT_PATH"]= self.pdf_var.get().strip()

        self.config_dict.setdefault("erp_grid", {})
        self.config_dict["erp_grid"]["filters"]= self.erp_preview.filters
        self.config_dict.setdefault("master_grid", {})
        self.config_dict["master_grid"]["filters"]= self.master_preview.filters

        dash_cfg= self.config_dict.setdefault("dashboard", {})
        dash_cfg["selected_dims"]= list(self.dashboard_tab.selected_dims)
        dash_cfg["selected_attrs"]= list(self.dashboard_tab.selected_attrs)
        dash_cfg["top_n"]= self.dashboard_tab.top_n

        cfg_path= Path(self.config_dict["paths"].get("CONFIG_PATH","config/ui_config.json"))
        save_config(self.config_dict, cfg_path)
        messagebox.showinfo("Saved","Config saved.")

    def on_history_file_selected(self, file_path, data):
        df_run= pd.DataFrame(data)
        if not df_run.empty and "RunDate" in df_run.columns:
            run_date= df_run["RunDate"].iloc[0]
            self.history_df= self.history_df[self.history_df["RunDate"]!= run_date]
        self.history_df= pd.concat([self.history_df, df_run], ignore_index=True)
        self.dashboard_tab.update_data(df_run, self.history_df)
        self.tabs.select(self.dashboard_tab)

    def on_close(self):
        self.save_all_config()
        # optionally write bollinger data
        band_path= self.config_dict["paths"].get("BAND_CHART_JSON_PATH","")
        if band_path and not self.history_df.empty and "RunDate" in self.history_df.columns:
            try:
                outp= Path(band_path)
                date_ct= self.history_df.groupby("RunDate")["Key"].count().reset_index(name="Count")
                date_ct["RunDate_dt"]= pd.to_datetime(date_ct["RunDate"], errors="coerce")
                date_ct.sort_values("RunDate_dt", inplace=True)
                date_ct.reset_index(drop=True, inplace=True)

                date_ct["rolling_mean"]= date_ct["Count"].rolling(3, min_periods=1).mean()
                date_ct["rolling_std"] = date_ct["Count"].rolling(3, min_periods=1).std(ddof=0)
                date_ct["upper_band"]  = date_ct["rolling_mean"] + 2*date_ct["rolling_std"]
                date_ct["lower_band"]  = date_ct["rolling_mean"] - 2*date_ct["rolling_std"]

                date_ct["RunDate"]= date_ct["RunDate_dt"].dt.strftime("%Y-%m-%d %H:%M:%S")
                date_ct.drop(columns=["RunDate_dt"], inplace=True)

                date_ct.to_json(outp, orient="records", indent=2)
                logging.info(f"Bollinger data => {outp}")
            except Exception as e:
                logging.error(f"Bollinger => {e}")

        self.destroy()


def main():
    app= MainApp()
    app.mainloop()

if __name__=="__main__":
    main()
