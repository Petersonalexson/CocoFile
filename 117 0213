"""
Ultra-Mega Reconciliation: Mode=2, Param-based with "V S C" for ERP dimension, "FileName" for Master dimension
-----------------------------------------------------------------------------------------------
1) ERP:
   - Exclude any row where "Enabled_Flag" != "Enabled"
   - Instead of using Dimension_Name, we look at the column "V S C"
   - The parameter file tells us which "V S C" values we actually keep (where "ERP Values" == 'x')
   - The parameter file also provides the rename of "V S C" => final dimension name
2) Master:
   - For each .txt file in the ZIP, we unify them into one DF
   - The dimension is normally derived from the .txt file name, 
     but if the parameter file has a row with FileName = that .txt, we rename dimension => "Dimension" from param
3) Meltdown => if attribute => "Start Date" or "End Date", we strip T...
4) Compare => Mode=2
5) Dashboard => 8 charts
6) Filtering => only "Start Date"/"End Date" columns have a filter popup
"""

import os
import json
import logging
import zipfile
import shutil
from pathlib import Path
from typing import Dict, List, Set, Tuple
from datetime import datetime

import tkinter as tk
from tkinter import ttk, filedialog, messagebox, simpledialog  # note we import simpledialog
import customtkinter as ctk
import pandas as pd
import numpy as np

try:
    import chardet
except ImportError:
    chardet = None

from openpyxl import Workbook
from openpyxl.styles import PatternFill, Font, Alignment

import matplotlib
matplotlib.use("TkAgg")
import matplotlib.pyplot as plt
from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg

# ---------------- LOGGING ----------------
def setup_logger():
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s [%(levelname)s] %(message)s"
    )
setup_logger()

# ---------------- DEFAULT CONFIG ----------------
DEFAULT_PATHS = {
    "ERP_EXCEL_PATH": "data/ERP_Config.xlsx",
    "MASTER_ZIP_PATH": "data/Master_Config.zip",
    "EXCEPTION_PATH": "data/Exception_Table.xlsx",
    "OUTPUT_PATH": "output/Reconciliation.xlsx",
    "CONFIG_PATH": "config/ui_config.json",
    "PARAMETER_PATH": "data/parameters.xlsx",
    "MASTER_CSV_OUTPUT": "temp_master_csv"
}

def default_config() -> Dict:
    return {
        "paths": {
            "ERP_EXCEL_PATH": DEFAULT_PATHS["ERP_EXCEL_PATH"],
            "MASTER_ZIP_PATH": DEFAULT_PATHS["MASTER_ZIP_PATH"],
            "EXCEPTION_PATH": DEFAULT_PATHS["EXCEPTION_PATH"],
            "OUTPUT_PATH": DEFAULT_PATHS["OUTPUT_PATH"],
            "CONFIG_PATH": DEFAULT_PATHS["CONFIG_PATH"],
            "PARAMETER_PATH": DEFAULT_PATHS["PARAMETER_PATH"],
            "MASTER_CSV_OUTPUT": DEFAULT_PATHS["MASTER_CSV_OUTPUT"]
        },
        "erp_grid": {
            "columns": [],
            "filters": {}
        },
        "master_grid": {
            "columns": [],
            "filters": {}
        },
        "comparison_option": 2
    }

def load_config(path: Path) -> Dict:
    if path.is_file():
        try:
            with open(path, "r", encoding="utf-8") as f:
                return json.load(f)
        except Exception as e:
            logging.warning(f"Could not load config: {e}")
    return default_config()

def save_config(cfg: Dict, path: Path):
    path.parent.mkdir(parents=True, exist_ok=True)
    try:
        with open(path, "w", encoding="utf-8") as f:
            json.dump(cfg, f, indent=2)
        logging.info(f"Saved config to {path}")
    except Exception as e:
        logging.error(f"Error saving config: {e}")

# ---------------- TEXT LOGGER HANDLER ----------------
class TextHandler(logging.Handler):
    def __init__(self, widget: ctk.CTkTextbox):
        super().__init__()
        self.widget = widget
    def emit(self, record):
        msg = self.format(record) + "\n"
        self.widget.after(0, self._append, msg)
    def _append(self, msg):
        self.widget.configure(state="normal")
        self.widget.insert("end", msg)
        self.widget.see("end")
        self.widget.configure(state="disabled")

# ---------------- PARAM FILE READING ----------------
def read_parameter_file(path: Path) -> Dict[str,object]:
    """
    We assume one sheet with columns:
      FileName, Dimension, ERP Values, ERP Hierarchy, V S C, ...
    We'll build:
      'erp_vsc_map': { original_vsc => final_dimension_name }
      'erp_vsc_keep': set of original_vsc we keep (where ERP Values=='x')
      'master_file_map': { 'Dimension_Example.txt' => final_dim_name } from FileName => Dimension
    (We won't use 'ERP Hierarchy' if it's "future usage".)
    """
    import pandas as pd
    param= {
        "erp_vsc_map": {},     # original => rename
        "erp_vsc_keep": set(), # only keep if 'x'
        "master_file_map": {}  # filename => dimension rename
    }
    if not path.is_file():
        logging.warning(f"Param file not found: {path}")
        return param

    try:
        dfp= pd.read_excel(path, sheet_name=0)
        dfp.columns= dfp.columns.astype(str).str.strip()

        # We'll look for columns: "FileName", "Dimension", "ERP Values", "V S C"
        # ignoring others if present
        def s(x):
            return str(x).strip() if pd.notna(x) else ""

        for i, row in dfp.iterrows():
            file_ = s(row.get("FileName",""))
            dim_  = s(row.get("Dimension",""))
            erp_vsc= s(row.get("V S C",""))
            erp_vals= s(row.get("ERP Values",""))

            if file_ and dim_:
                param["master_file_map"][file_] = dim_
            if erp_vsc and dim_:
                param["erp_vsc_map"][erp_vsc] = dim_
            # if ERP Values=='x', we keep that vsc
            if erp_vsc and erp_vals.lower()=="x":
                param["erp_vsc_keep"].add(erp_vsc)
        return param
    except Exception as e:
        logging.error(f"Error reading param file: {e}")
        return param

# ---------------- ERP READING => ONLY 'ENABLED' ----------------
def read_erp_enabled(path: Path)-> pd.DataFrame:
    if not path.is_file():
        logging.warning(f"ERP not found: {path}")
        return pd.DataFrame()
    import pandas as pd
    try:
        df= pd.read_excel(path, skiprows=3)
        df.columns= df.columns.str.strip()
        if "Enabled_Flag" in df.columns:
            df= df[df["Enabled_Flag"]=="Enabled"]
        return df
    except Exception as e:
        logging.error(f"Error reading ERP: {e}")
        return pd.DataFrame()

# ---------------- MASTER .TXT => .CSV => unify (use FileName => rename) ----------------
def read_txt_robust_in_memory(raw: bytes)-> pd.DataFrame:
    import csv
    import io
    import pandas as pd
    encs= [
        'utf-8-sig','utf-8','utf-16','utf-16-le','utf-16-be','utf-32','utf-32-le','utf-32-be',
        'cp1250','cp1251','cp1252','cp1254','cp1256','cp932','cp949','latin1','iso-8859-1','iso-8859-2',
        'windows-1250','windows-1251','windows-1252','windows-1254','windows-1256','shift_jis','euc_jp','euc_kr',
        'big5','big5hkscs','gb2312','gbk','gb18030'
    ]
    for enc in encs:
        try:
            buf= io.BytesIO(raw)
            df= pd.read_csv(
                buf,
                encoding=enc,
                sep=",",
                on_bad_lines="skip",
                quoting=csv.QUOTE_MINIMAL,
                engine="python"
            )
            df.dropna(how="all", axis=0, inplace=True)
            df.dropna(how="all", axis=1, inplace=True)
            return df
        except:
            pass
    logging.error("[Master] Could not parse .txt with known encodings.")
    return pd.DataFrame()

def convert_master_txt_to_csv(zip_path: Path, out_dir: Path)-> List[Path]:
    import pandas as pd
    if out_dir.exists():
        shutil.rmtree(out_dir, ignore_errors=True)
    out_dir.mkdir(parents=True, exist_ok=True)
    csvs=[]
    if not zip_path.is_file():
        logging.warning(f"[Master] ZIP not found: {zip_path}")
        return csvs

    with zipfile.ZipFile(zip_path, "r") as z:
        txt_files= [f for f in z.namelist() if f.lower().endswith(".txt")]
        for txt_file in txt_files:
            base_name= os.path.basename(txt_file)
            if not base_name:
                continue
            try:
                with z.open(txt_file) as fo:
                    raw= fo.read()
                if not raw:
                    continue
                df= read_txt_robust_in_memory(raw)
                df.columns= df.columns.str.strip()

                # dimension from file name (not renamed here, we do final rename after reading param)
                # but let's store an intermediate dimension col
                low= base_name.lower()
                # e.g. "Dimension_example.txt"
                # or maybe param["master_file_map"] can rename it
                # We'll assign the raw dimension for now:
                raw_dim= base_name
                df["RawFileName"]= raw_dim  # store the EXACT file name
                if "Name" not in df.columns and len(df.columns)>0:
                    firstcol= df.columns[0]
                    df.rename(columns={firstcol:"Name"}, inplace=True)

                out_csv= out_dir / base_name.replace(".txt",".csv")
                df.to_csv(out_csv, index=False, encoding="utf-8")
                csvs.append(out_csv)
            except Exception as e:
                logging.error(f"[Master] Error reading {txt_file}: {e}")
    return csvs

def unify_master_csvs(csvs: List[Path])-> pd.DataFrame:
    import pandas as pd
    frames=[]
    for cp in csvs:
        if not cp.is_file():
            continue
        try:
            df= pd.read_csv(cp, encoding="utf-8", on_bad_lines="skip")
            df.columns= df.columns.str.strip()
            frames.append(df)
        except Exception as e:
            logging.error(f"[Master unify] Error reading {cp}: {e}")
    if frames:
        return pd.concat(frames, ignore_index=True)
    return pd.DataFrame()

# ---------------- MELTDOWN: ERP => V S C is dimension, MASTER => file param rename ----------------
def meltdown_erp(df: pd.DataFrame, param: Dict[str,object]) -> pd.DataFrame:
    """
    We no longer use Dimension_Name; we interpret the column "V S C" as the dimension.
    The param has:
      erp_vsc_map => { original_vsc => final_dimension_name }
      erp_vsc_keep => set(original_vsc) that are allowed (ERP Values=='x')
    Steps:
     1) Keep only rows where df["V S C"] in param["erp_vsc_keep"]
     2) Map that value => param["erp_vsc_map"] => final dimension
     3) meltdown the rest columns => attributes
     4) if attribute => 'Start Date'/'End Date', strip T
    """
    import pandas as pd
    vsc_keep= param.get("erp_vsc_keep", set())
    vsc_map= param.get("erp_vsc_map", {})

    if "V S C" not in df.columns:
        logging.warning("[ERP meltdown] 'V S C' column not found => empty meltdown.")
        return pd.DataFrame()

    # filter rows
    df2= df[df["V S C"].isin(vsc_keep)].copy()
    if df2.empty:
        logging.warning("[ERP meltdown] after filtering V S C by param => empty.")
        return pd.DataFrame()

    # define dimension from vsc
    # We'll drop 'Dimension_Name' if present
    drop_cols= [c for c in df2.columns if c.lower()=="dimension_name"]
    if drop_cols:
        df2.drop(columns=drop_cols, inplace=True)

    # skip some columns
    skip_cols= {"Enabled_Flag","V S C"}  # not meltdown as attribute
    keep_cols= [c for c in df2.columns if c not in skip_cols]
    # We'll treat the dimension as final => param rename
    df2["Dimension_OriginalVSC"]= df2["V S C"]

    id_vars= ["Dimension_OriginalVSC"]
    # do we have "Value"? Possibly
    if "Value" in keep_cols:
        id_vars.append("Value")

    value_vars= [c for c in keep_cols if c not in id_vars]

    melted= df2.melt(
        id_vars=id_vars,
        value_vars=value_vars,
        var_name="Attribute",
        value_name="Value"
    )
    # rename dimension with param => dimension
    def dimension_rename(orig):
        return vsc_map.get(orig, orig)

    melted.rename(columns={"Dimension_OriginalVSC":"DimRaw","Value":"RefName"}, inplace=True)
    melted["Dimension"]= melted["DimRaw"].apply(dimension_rename)

    # strip T if attribute => 'Start Date'/'End Date'
    def strip_t(val):
        if isinstance(val,str) and "T" in val:
            return val.split("T")[0]
        return val
    melted["Value"]= melted.apply(
        lambda row: strip_t(row["Value"]) if row["Attribute"] in ["Start Date","End Date"] else row["Value"],
        axis=1
    )

    # final
    return melted[["Dimension","RefName","Attribute","Value"]].copy()

def meltdown_master(df: pd.DataFrame, param: Dict[str,object]) -> pd.DataFrame:
    """
    param["master_file_map"]: { 'Dimension_example.txt' => final_dim_name }
    We read from column "RawFileName" in df => param => dimension rename
    meltdown => skip "RawFileName"
    if attribute => 'Start Date'/'End Date', strip T
    """
    if df.empty:
        return df
    file_map= param.get("master_file_map", {})
    import pandas as pd
    if "RawFileName" not in df.columns:
        # we can't rename dimension from param => fallback dimension col?
        logging.warning("[Master meltdown] 'RawFileName' not found => no dimension rename from param.")
        df["Dimension"]= ""
        # meltdown
        keep= df.columns.tolist()
        id_vars= [c for c in ["Dimension","Name"] if c in keep]
        value_vars= [c for c in keep if c not in id_vars]
        melted= df.melt(id_vars=id_vars, value_vars=value_vars,
                        var_name="Attribute", value_name="Value")
        melted.rename(columns={"Name":"RefName"}, inplace=True)
        # strip T
        def strip_t(val):
            if isinstance(val,str) and "T" in val:
                return val.split("T")[0]
            return val
        melted["Value"]= melted.apply(
            lambda row: strip_t(row["Value"]) if row["Attribute"] in ["Start Date","End Date"] else row["Value"],
            axis=1
        )
        return melted[["Dimension","RefName","Attribute","Value"]].copy()
    else:
        # we rename dimension from param
        def get_dim_from_filename(rawfile):
            # rawfile might be "Dimension_Example.txt", etc
            return file_map.get(rawfile, rawfile)  # fallback to itself if not in param

        df2= df.copy()
        df2["Dimension"]= df2["RawFileName"].apply(get_dim_from_filename)

        # meltdown
        skip_cols= ["RawFileName"]
        keep= [c for c in df2.columns if c not in skip_cols]
        id_vars= [c for c in ["Dimension","Name"] if c in keep]
        value_vars= [c for c in keep if c not in id_vars]
        melted= df2.melt(id_vars=id_vars, value_vars=value_vars,
                         var_name="Attribute", value_name="Value")
        melted.rename(columns={"Name":"RefName"}, inplace=True)
        # strip T if attribute => 'Start Date'/'End Date'
        def strip_t(val):
            if isinstance(val,str) and "T" in val:
                return val.split("T")[0]
            return val

        melted["Value"]= melted.apply(
            lambda row: strip_t(row["Value"]) if row["Attribute"] in ["Start Date","End Date"] else row["Value"],
            axis=1
        )
        return melted[["Dimension","RefName","Attribute","Value"]].copy()

def build_keys(df: pd.DataFrame)-> pd.DataFrame:
    df= df.copy()
    for c in ["Dimension","RefName","Attribute","Value"]:
        if c not in df.columns:
            df[c]=""
        df[c]= df[c].fillna("").astype(str).str.strip()
    df["GroupKey"]= df["Dimension"]+" | "+df["RefName"]
    df["Key"]= df["Dimension"]+" | "+df["RefName"]+" | "+df["Attribute"]+" | "+df["Value"]
    df["Comments_1"]=""
    df["Comments_2"]=""
    df["Action Item"]=""
    df["Missing In"]=""
    return df

def build_lookup_dict(df: pd.DataFrame)-> Dict[str,Dict[str,str]]:
    lookup={}
    for gk, grp in df.groupby("GroupKey"):
        rec={}
        name_= grp["RefName"].iloc[0] if not grp.empty else ""
        rec["Name"]= name_
        for _, row in grp.iterrows():
            rec[row["Attribute"]]= row["Value"]
        lookup[gk]= rec
    return lookup

def compare_mode2(df_erp: pd.DataFrame, df_mst: pd.DataFrame)-> pd.DataFrame:
    # If name missing => entire record missing, else compare attributes
    erp_dict= build_lookup_dict(df_erp)
    mst_dict= build_lookup_dict(df_mst)
    all_keys= set(erp_dict.keys())| set(mst_dict.keys())
    results=[]
    for gk in all_keys:
        dim= gk.split(" | ")[0]
        a_data= erp_dict.get(gk,{})
        b_data= mst_dict.get(gk,{})
        name_a= a_data.get("Name", a_data.get("RefName",""))
        name_b= b_data.get("Name", b_data.get("RefName",""))
        if name_a and name_b and (name_a==name_b):
            # partial
            all_attrs= (set(a_data.keys())| set(b_data.keys()))- {"Name"}
            for attr in all_attrs:
                va= a_data.get(attr,"")
                vb= b_data.get(attr,"")
                if va!= vb:
                    if va and not vb:
                        results.append({"Dimension":dim,"Name":name_a,"Attribute":attr,"Value":va,"Missing In":"MASTER"})
                    elif vb and not va:
                        results.append({"Dimension":dim,"Name":name_a,"Attribute":attr,"Value":vb,"Missing In":"ERP"})
                    else:
                        results.append({"Dimension":dim,"Name":name_a,"Attribute":attr,"Value":va,"Missing In":"MASTER"})
                        results.append({"Dimension":dim,"Name":name_a,"Attribute":attr,"Value":vb,"Missing In":"ERP"})
        else:
            if name_a and not name_b:
                results.append({"Dimension":dim,"Name":name_a,"Attribute":"Name","Value":name_a,"Missing In":"MASTER"})
            elif name_b and not name_a:
                results.append({"Dimension":dim,"Name":name_b,"Attribute":"Name","Value":name_b,"Missing In":"ERP"})
    import pandas as pd
    df_diff= pd.DataFrame(results)
    if not df_diff.empty:
        df_diff["Key"]= (
            df_diff["Dimension"].str.strip()+" | "+
            df_diff["Name"].str.strip()+" | "+
            df_diff["Attribute"].str.strip()+" | "+
            df_diff["Value"].str.strip()
        )
    return df_diff

# ---------------- EXCEPTIONS & WRITE RESULTS ----------------
def read_exception_table(path: Path)-> pd.DataFrame:
    import pandas as pd
    if not path.is_file():
        logging.warning(f"Exception table not found: {path}")
        return pd.DataFrame()
    try:
        df= pd.read_excel(path)
        df.columns= df.columns.astype(str).str.strip()
        return df
    except Exception as e:
        logging.error(f"Error reading exception table: {e}")
        return pd.DataFrame()

def merge_exceptions(df: pd.DataFrame, df_exc: pd.DataFrame)-> pd.DataFrame:
    if df.empty or df_exc.empty or "Key" not in df.columns:
        return df
    keep= [c for c in df_exc.columns if c in ["Key","Comments_1","Comments_2","hide exception"]]
    if not keep:
        return df
    exc= df_exc[keep].copy()
    exc["Key"]= exc["Key"].astype(str).str.strip()

    merged= df.merge(exc, on="Key", how="left", suffixes=("", "_exc"))
    merged["hide exception"]= merged.get("hide exception","").fillna("").str.lower()
    final= merged[merged["hide exception"]!="yes"].copy()

    if "Comments_1_exc" in final.columns:
        final["Comments_1"]= np.where(final["Comments_1_exc"].notna(), final["Comments_1_exc"], final["Comments_1"])
        final.drop(columns=["Comments_1_exc"], inplace=True)
    if "Comments_2_exc" in final.columns:
        final["Comments_2"]= np.where(final["Comments_2_exc"].notna(), final["Comments_2_exc"], final["Comments_2"])
        final.drop(columns=["Comments_2_exc"], inplace=True)
    if "hide exception" in final.columns:
        final.drop(columns=["hide exception"], inplace=True)
    return final

def write_results(df: pd.DataFrame, out_path: Path):
    import pandas as pd
    if df.empty:
        logging.info("No differences => skip writing.")
        return
    out_path.parent.mkdir(parents=True, exist_ok=True)

    final_cols= ["Key","Dimension","Name","Attribute","Value","Comments_1","Comments_2","Action Item","Missing In"]
    for c in final_cols:
        if c not in df.columns:
            df[c]=""
    df= df[final_cols]

    wb= Workbook()
    ws= wb.active
    ws.title= "Results"
    ws.append(final_cols)
    for rowvals in df.itertuples(index=False):
        ws.append(rowvals)

    header_font= Font(bold=True)
    fill= PatternFill(start_color="DDDDDD", end_color="DDDDDD", fill_type="solid")
    for cell in ws[1]:
        cell.font= header_font
        cell.fill= fill
        cell.alignment= Alignment(horizontal="center")

    for col in ws.columns:
        max_len=0
        col_letter= col[0].column_letter
        for cell in col:
            val= str(cell.value) if cell.value else ""
            max_len= max(max_len, len(val))
        ws.column_dimensions[col_letter].width= max_len+2

    ws.freeze_panes= "A2"
    wb.save(out_path)
    logging.info(f"Results => {out_path}")

# ---------------- 8-CHART DASHBOARD ----------------
class Dashboard(ctk.CTkFrame):
    """
    8 chart frames: Heatmap, Lollipop, Circular, Scatter, Radar, Normal Pie, Normal Bar, Band Chart
    """
    def __init__(self, parent):
        super().__init__(parent)
        self.df_current= pd.DataFrame()
        self.df_history= pd.DataFrame()

        self.notebook= ttk.Notebook(self)
        self.notebook.pack(fill="both", expand=True)

        self.frame_heatmap   = ctk.CTkFrame(self.notebook)
        self.frame_lollipop  = ctk.CTkFrame(self.notebook)
        self.frame_circular  = ctk.CTkFrame(self.notebook)
        self.frame_scatter   = ctk.CTkFrame(self.notebook)
        self.frame_radar     = ctk.CTkFrame(self.notebook)
        self.frame_normalpie = ctk.CTkFrame(self.notebook)
        self.frame_normalbar = ctk.CTkFrame(self.notebook)
        self.frame_bandchart = ctk.CTkFrame(self.notebook)

        self.notebook.add(self.frame_heatmap,   text="Heatmap")
        self.notebook.add(self.frame_lollipop,  text="Lollipop Dim")
        self.notebook.add(self.frame_circular,  text="Circular Attr")
        self.notebook.add(self.frame_scatter,   text="Scatter")
        self.notebook.add(self.frame_radar,     text="Radar")
        self.notebook.add(self.frame_normalpie, text="Normal Pie")
        self.notebook.add(self.frame_normalbar, text="Normal Bar")
        self.notebook.add(self.frame_bandchart, text="Band Chart")

    def update_data(self, df_current: pd.DataFrame, df_history: pd.DataFrame):
        self.df_current= df_current.copy()
        self.df_history= df_history.copy()

        self.plot_heatmap()
        self.plot_lollipop()
        self.plot_circular()
        self.plot_scatter()
        self.plot_radar()
        self.plot_normal_pie()
        self.plot_normal_bar()
        self.plot_band_chart()

    def plot_heatmap(self):
        for w in self.frame_heatmap.winfo_children():
            w.destroy()
        df_m= self.df_current[self.df_current["Missing In"]!=""]
        if df_m.empty:
            return
        pivoted= df_m.groupby(["Dimension","Attribute"]).size().unstack(fill_value=0)
        if pivoted.empty:
            return
        fig, ax= plt.subplots(figsize=(6,5))
        cax= ax.imshow(pivoted, aspect="auto", cmap="Reds")
        ax.set_xticks(range(len(pivoted.columns)))
        ax.set_xticklabels(pivoted.columns, rotation=90)
        ax.set_yticks(range(len(pivoted.index)))
        ax.set_yticklabels(pivoted.index)
        fig.colorbar(cax, ax=ax)
        ax.set_title("Heatmap: Missing Items")
        canvas= FigureCanvasTkAgg(fig, master=self.frame_heatmap)
        canvas.draw()
        canvas.get_tk_widget().pack(fill="both", expand=True)

    def plot_lollipop(self):
        for w in self.frame_lollipop.winfo_children():
            w.destroy()
        df_m= self.df_current[self.df_current["Missing In"]!=""]
        if df_m.empty:
            return
        count_dim= df_m.groupby("Dimension")["Key"].count().sort_values(ascending=False).head(10)
        if count_dim.empty:
            return
        fig, ax= plt.subplots(figsize=(6,5))
        ax.hlines(y=count_dim.index, xmin=0, xmax=count_dim.values, color="skyblue")
        ax.plot(count_dim.values, count_dim.index, "o", color="skyblue")
        ax.set_title("Lollipop: Missing Dimensions")
        ax.set_xlabel("Missing Count")
        canvas= FigureCanvasTkAgg(fig, master=self.frame_lollipop)
        canvas.draw()
        canvas.get_tk_widget().pack(fill="both", expand=True)

    def plot_circular(self):
        for w in self.frame_circular.winfo_children():
            w.destroy()
        df_m= self.df_current[self.df_current["Missing In"]!=""]
        if df_m.empty:
            return
        count_attr= df_m.groupby("Attribute")["Key"].count().sort_values(ascending=False).head(10)
        if count_attr.empty:
            return

        categories= count_attr.index.tolist()
        values= count_attr.values
        angles= np.linspace(0, 2*np.pi, len(categories), endpoint=False)

        fig= plt.figure(figsize=(6,6))
        ax= fig.add_subplot(111, polar=True)
        ax.set_theta_offset(np.pi/2)
        ax.set_theta_direction(-1)
        ax.set_xticks(angles)
        ax.set_xticklabels(categories, fontsize=9)
        ax.bar(angles, values, width=0.4, color="orange", alpha=0.6)
        ax.set_title("Circular Barplot: Missing Attributes", y=1.05)
        canvas= FigureCanvasTkAgg(fig, master=self.frame_circular)
        canvas.draw()
        canvas.get_tk_widget().pack(fill="both", expand=True)

    def plot_scatter(self):
        for w in self.frame_scatter.winfo_children():
            w.destroy()
        df_m= self.df_current[self.df_current["Missing In"]!=""]
        if df_m.empty:
            return
        count_dim= df_m.groupby("Dimension")["Key"].count().reset_index(name="Count")
        count_dim.sort_values("Count", ascending=False, inplace=True)
        if count_dim.empty:
            return
        xvals= np.arange(len(count_dim))
        yvals= count_dim["Count"].values
        labels= count_dim["Dimension"].values

        fig, ax= plt.subplots(figsize=(6,5))
        ax.scatter(xvals, yvals, color="green")
        for i, txt in enumerate(labels):
            ax.text(xvals[i], yvals[i], txt, ha="center", va="bottom", rotation=60)
        ax.set_xticks([])
        ax.set_ylabel("Missing Count")
        ax.set_title("Scatter: Missing by Dimension")
        canvas= FigureCanvasTkAgg(fig, master=self.frame_scatter)
        canvas.draw()
        canvas.get_tk_widget().pack(fill="both", expand=True)

    def plot_radar(self):
        for w in self.frame_radar.winfo_children():
            w.destroy()
        df_m= self.df_current[self.df_current["Missing In"]!=""]
        if df_m.empty:
            return
        count_dim= df_m.groupby("Dimension")["Key"].count().sort_values(ascending=False).head(5)
        if count_dim.empty:
            return
        categories= count_dim.index.tolist()
        values= count_dim.values.tolist()
        N= len(categories)
        angles= np.linspace(0,2*np.pi,N,endpoint=False).tolist()
        angles+= angles[:1]
        values+= values[:1]

        fig= plt.figure(figsize=(6,6))
        ax= fig.add_subplot(111, polar=True)
        ax.set_theta_offset(np.pi/2)
        ax.set_theta_direction(-1)
        ax.set_xticks(angles[:-1])
        ax.set_xticklabels(categories, fontsize=9)
        ax.plot(angles, values, color="red", linewidth=2)
        ax.fill(angles, values, color="red", alpha=0.3)
        ax.set_title("Radar: Top 5 Missing Dimensions", y=1.08)
        canvas= FigureCanvasTkAgg(fig, master=self.frame_radar)
        canvas.draw()
        canvas.get_tk_widget().pack(fill="both", expand=True)

    def plot_normal_pie(self):
        for w in self.frame_normalpie.winfo_children():
            w.destroy()
        df_m= self.df_current[self.df_current["Missing In"]!=""]
        if df_m.empty:
            return
        dist= df_m["Missing In"].value_counts()
        fig, ax= plt.subplots(figsize=(5,5))
        ax.pie(dist.values, labels=dist.index, autopct="%.1f%%", startangle=140)
        ax.set_title("Normal Pie: Missing In Distribution")
        canvas= FigureCanvasTkAgg(fig, master=self.frame_normalpie)
        canvas.draw()
        canvas.get_tk_widget().pack(fill="both", expand=True)

    def plot_normal_bar(self):
        for w in self.frame_normalbar.winfo_children():
            w.destroy()
        df_m= self.df_current[self.df_current["Missing In"]!=""]
        if df_m.empty:
            return
        count_attr= df_m.groupby("Attribute")["Key"].count().sort_values(ascending=False).head(10)
        fig, ax= plt.subplots(figsize=(6,4))
        count_attr.plot(kind="bar", ax=ax, color="blue")
        ax.set_ylabel("Missing Count")
        ax.set_title("Normal Bar: Top 10 Missing Attributes")
        canvas= FigureCanvasTkAgg(fig, master=self.frame_normalbar)
        canvas.draw()
        canvas.get_tk_widget().pack(fill="both", expand=True)

    def plot_band_chart(self):
        for w in self.frame_bandchart.winfo_children():
            w.destroy()
        if self.df_history.empty or "RunDate" not in self.df_history.columns:
            return
        df_m= self.df_history[self.df_history["Missing In"]!=""]
        if df_m.empty:
            return
        date_counts= df_m.groupby("RunDate")["Key"].count().reset_index()
        date_counts.sort_values("RunDate", inplace=True)
        date_counts["Count_min"]= date_counts["Key"]*0.9
        date_counts["Count_max"]= date_counts["Key"]*1.1

        fig, ax= plt.subplots(figsize=(6,4))
        ax.plot(date_counts["RunDate"], date_counts["Key"], color="purple", label="Missing Count")
        ax.fill_between(date_counts["RunDate"], date_counts["Count_min"], date_counts["Count_max"],
                        color="purple", alpha=0.2, label="±10% band")
        ax.set_title("Band Chart Over Days")
        ax.set_xlabel("RunDate")
        ax.set_ylabel("Missing Count")
        plt.xticks(rotation=45)
        ax.legend()

        for i, row in date_counts.iterrows():
            ax.text(row["RunDate"], row["Key"], str(row["Key"]), ha="center", va="bottom")

        canvas= FigureCanvasTkAgg(fig, master=self.frame_bandchart)
        canvas.draw()
        canvas.get_tk_widget().pack(fill="both", expand=True)

# ---------------- EXCELGRID => only Start/End Date filterable ----------------
class ExcelGrid(ctk.CTkFrame):
    """
    The user can rename/hide columns, but filter popup only for "Start Date"/"End Date".
    """
    FILTERABLE_COLS= {"Start Date","End Date"}

    def __init__(self, parent, config_block: Dict, name: str):
        super().__init__(parent)
        self.name= name
        self.col_defs= config_block.get("columns", [])
        self.filters: Dict[str,Set]= {k:set(v) for k,v in config_block.get("filters",{}).items()}
        self.df= pd.DataFrame()

        self.create_toolbar()
        self.create_table()
        self.create_statusbar()

    def create_toolbar(self):
        tb= ctk.CTkFrame(self)
        tb.pack(fill="x", padx=5, pady=5)
        ctk.CTkButton(tb, text="Manage Columns", command=self.show_column_manager).pack(side="left", padx=5)
        ctk.CTkButton(tb, text="Clear Filters", command=self.clear_filters).pack(side="left", padx=5)

    def create_table(self):
        container= ctk.CTkFrame(self)
        container.pack(fill="both", expand=True, padx=5, pady=5)

        self.tree= ttk.Treeview(container, show="headings")
        vsb= ttk.Scrollbar(container, orient="vertical", command=self.tree.yview)
        hsb= ttk.Scrollbar(container, orient="horizontal", command=self.tree.xview)
        self.tree.configure(yscrollcommand=vsb.set, xscrollcommand=hsb.set)

        self.tree.grid(row=0, column=0, sticky="nsew")
        vsb.grid(row=0, column=1, sticky="ns")
        hsb.grid(row=1, column=0, sticky="ew")

        container.rowconfigure(0, weight=1)
        container.columnconfigure(0, weight=1)

    def create_statusbar(self):
        self.status_label= ctk.CTkLabel(self, text="Ready")
        self.status_label.pack(fill="x")

    def set_data(self, df: pd.DataFrame):
        self.df= df.copy(deep=True)
        existing_ids= [c["id"] for c in self.col_defs]
        for col in self.df.columns:
            if col not in existing_ids:
                self.col_defs.append({
                    "id": col,
                    "name": col,
                    "locked": False,
                    "visible": True,
                    "renameable": True
                })
        self.refresh_table()

    def get_config_block(self)-> Dict:
        return {
            "columns": self.col_defs,
            "filters": {cid: sorted(list(vals)) for cid, vals in self.filters.items()}
        }

    def get_filtered_df(self)-> pd.DataFrame:
        if self.df.empty:
            return self.df
        df_f= self.df.copy()

        def passes(x, allowed):
            if pd.isna(x):
                return any(pd.isna(a) for a in allowed)
            else:
                return x in allowed

        for col_id, allowed_vals in self.filters.items():
            if col_id in df_f.columns and allowed_vals:
                df_f= df_f[df_f[col_id].apply(lambda z: passes(z, allowed_vals))]

        vis_ids= [c["id"] for c in self.col_defs if c.get("visible",True)]
        vis_ids= [c for c in vis_ids if c in df_f.columns]
        return df_f[vis_ids]

    def refresh_table(self):
        for item in self.tree.get_children():
            self.tree.delete(item)

        visible_cols= [c for c in self.col_defs if c.get("visible",True)]
        self.tree["columns"]= [c["id"] for c in visible_cols]

        for col_def in visible_cols:
            col_txt= col_def["name"]
            if col_def.get("locked",False):
                col_txt+= " \U0001F512"
            self.tree.heading(
                col_def["id"],
                text= col_txt,
                anchor="w",
                command=lambda c=col_def:self.on_heading_click(c)
            )
            self.tree.column(col_def["id"], anchor="w", width=150)

        df_f= self.get_filtered_df()
        for _, row in df_f.iterrows():
            rowvals= [row[c["id"]] if c["id"] in df_f.columns else "" for c in visible_cols]
            self.tree.insert("", "end", values=rowvals)

        self.status_label.configure(text=f"{len(df_f)} rows")

    def on_heading_click(self, col_def: Dict):
        # only open filter if col_def["name"] in FILTERABLE_COLS
        if col_def["name"] in self.FILTERABLE_COLS:
            self.show_filter_popup(col_def)
        else:
            pass

    def show_filter_popup(self, col_def: Dict):
        col_id= col_def["id"]
        if self.df.empty or col_id not in self.df.columns:
            return
        popup= tk.Toplevel(self)
        popup.title(f"Filter: {col_def['name']}")
        popup.geometry("300x400")

        frame= ctk.CTkFrame(popup)
        frame.pack(fill="both", expand=True, padx=5, pady=5)

        unique_vals= self.df[col_id].unique()
        display_map={}
        for v in unique_vals:
            if pd.isna(v):
                dsp= "(NaN)"
            elif isinstance(v,str) and not v.strip():
                dsp= "(blank)"
            else:
                dsp= str(v)
            display_map[v]= dsp

        sorted_vals= sorted(display_map.keys(), key=lambda x: display_map[x].lower())
        curr_filter= self.filters.get(col_id, set())
        if not curr_filter:
            curr_filter= set(unique_vals)

        select_all_var= tk.BooleanVar(value=True)
        def toggle_all():
            check= select_all_var.get()
            for vb in var_dict.values():
                vb.set(check)

        ctk.CTkCheckBox(frame, text="Select All", variable=select_all_var, command=toggle_all).pack(anchor="w", pady=5)

        scroll= ctk.CTkScrollableFrame(frame, width=250, height=250)
        scroll.pack(fill="both", expand=True, padx=5, pady=5)

        var_dict={}
        for rv in sorted_vals:
            if pd.isna(rv):
                in_filter= any(pd.isna(a) for a in curr_filter)
            else:
                in_filter= (rv in curr_filter)
            bvar= tk.BooleanVar(value=in_filter)
            var_dict[rv]= bvar
            ctk.CTkCheckBox(scroll, text=display_map[rv], variable=bvar).pack(anchor="w")

        def apply_():
            sel= set()
            for rv, vb in var_dict.items():
                if vb.get():
                    sel.add(rv)
            self.filters[col_id]= sel
            popup.destroy()
            self.refresh_table()

        bf= ctk.CTkFrame(frame)
        bf.pack(fill="x", pady=5)
        ctk.CTkButton(bf, text="Apply", command=apply_).pack(side="left", padx=5)
        ctk.CTkButton(bf, text="Cancel", command=popup.destroy).pack(side="left", padx=5)

    def show_column_manager(self):
        cm= tk.Toplevel(self)
        cm.title(f"{self.name} Column Manager")
        scrolled= ctk.CTkScrollableFrame(cm, width=600, height=500)
        scrolled.pack(fill="both", expand=True)

        for i, col_def in enumerate(self.col_defs):
            rowf= ctk.CTkFrame(scrolled)
            rowf.pack(fill="x", pady=2)

            if col_def.get("locked",False):
                txt= col_def["name"]+" \U0001F512"
                ctk.CTkLabel(rowf, text=txt).pack(side="left", padx=5)
                continue

            var_vis= tk.BooleanVar(value=col_def.get("visible",True))
            def toggler(c=col_def,v=var_vis):
                c["visible"]= v.get()
                self.refresh_table()

            ctk.CTkCheckBox(rowf, text="", variable=var_vis, command=toggler).pack(side="left")

            if col_def.get("renameable",True):
                ctk.CTkButton(rowf, text=col_def["name"], command=lambda c=col_def: self.rename_column(c)).pack(side="left", padx=5)
            else:
                ctk.CTkLabel(rowf, text=col_def["name"]).pack(side="left", padx=5)

            ctk.CTkButton(rowf, text="↑", width=30, command=lambda idx=i:self.move_column(idx,-1)).pack(side="right", padx=2)
            ctk.CTkButton(rowf, text="↓", width=30, command=lambda idx=i:self.move_column(idx,1)).pack(side="right", padx=2)

    def rename_column(self, col_def: Dict):
        old_name= col_def["name"]
        new_name= simpledialog.askstring("Rename Column", f"New name for {old_name}:", initialvalue= old_name)
        if new_name:
            col_def["name"]= new_name
            self.refresh_table()

    def move_column(self, idx: int, delta: int):
        new_idx= idx+ delta
        if 0 <= new_idx< len(self.col_defs):
            self.col_defs[idx], self.col_defs[new_idx]= self.col_defs[new_idx], self.col_defs[idx]
            self.refresh_table()

    def clear_filters(self):
        self.filters.clear()
        self.refresh_table()

# ---------------- MAIN APP => mode=2 ONLY ----------------
class MainApp(ctk.CTk):
    """
    - We read ERP => Only 'Enabled' => meltdown_erp (via "V S C" column + param)
    - We read Master => unify => meltdown_master (renaming dimension from param's FileName => Dimension)
    - Compare => mode=2 => exceptions => 8-charts
    - Filter popups => only "Start Date"/"End Date"
    """
    def __init__(self):
        super().__init__()
        self.title("Ultra-Mega Reconciliation: Mode=2, V S C for ERP Dimension, Param-based, 8 Charts")
        self.geometry("1600x900")

        self.config_dict= load_config(Path(DEFAULT_PATHS["CONFIG_PATH"]))
        self.history_df= pd.DataFrame()

        # read param => "FileName", "Dimension", "ERP Values", "V S C"
        self.param_dict= read_parameter_file(Path(self.config_dict["paths"].get("PARAMETER_PATH",DEFAULT_PATHS["PARAMETER_PATH"])))

        self.notebook= ttk.Notebook(self)
        self.notebook.pack(fill="both", expand=True)

        # 1) Paths
        self.tab_paths= ctk.CTkFrame(self.notebook)
        self.notebook.add(self.tab_paths, text="Paths")
        self.build_paths_tab(self.tab_paths)

        # 2) ERP
        self.tab_erp= ctk.CTkFrame(self.notebook)
        self.notebook.add(self.tab_erp, text="ERP")
        self.erp_grid= ExcelGrid(self.tab_erp, self.config_dict["erp_grid"], "ERP")
        self.erp_grid.pack(fill="both", expand=True)

        # 3) Master
        self.tab_master= ctk.CTkFrame(self.notebook)
        self.notebook.add(self.tab_master, text="Master")
        self.master_grid= ExcelGrid(self.tab_master, self.config_dict["master_grid"], "Master")
        self.master_grid.pack(fill="both", expand=True)

        # 4) Compare & Exceptions
        self.tab_compare= ctk.CTkFrame(self.notebook)
        self.notebook.add(self.tab_compare, text="Compare & Exceptions")
        self.build_compare_tab(self.tab_compare)

        # 5) Dashboard
        self.tab_dashboard= Dashboard(self.notebook)
        self.notebook.add(self.tab_dashboard, text="Dashboard")

        # Logging
        self.log_box= ctk.CTkTextbox(self, height=120)
        self.log_box.pack(fill="both", expand=False)
        self.log_box.configure(state="disabled")
        handler= TextHandler(self.log_box)
        handler.setLevel(logging.INFO)
        logging.getLogger().addHandler(handler)

        # master CSV folder
        self.temp_csv_dir= Path(self.config_dict["paths"].get("MASTER_CSV_OUTPUT","temp_master_csv"))
        self.temp_csv_dir.mkdir(exist_ok=True)

        # load data
        self.refresh_erp_data()
        self.refresh_master_data()

    def build_paths_tab(self, parent):
        frm= ctk.CTkFrame(parent)
        frm.pack(fill="both", expand=True, padx=10, pady=10)

        self.erp_var= tk.StringVar(value=self.config_dict["paths"].get("ERP_EXCEL_PATH",DEFAULT_PATHS["ERP_EXCEL_PATH"]))
        self.mst_var= tk.StringVar(value=self.config_dict["paths"].get("MASTER_ZIP_PATH",DEFAULT_PATHS["MASTER_ZIP_PATH"]))
        self.exc_var= tk.StringVar(value=self.config_dict["paths"].get("EXCEPTION_PATH",DEFAULT_PATHS["EXCEPTION_PATH"]))
        self.out_var= tk.StringVar(value=self.config_dict["paths"].get("OUTPUT_PATH",DEFAULT_PATHS["OUTPUT_PATH"]))
        self.cfg_var= tk.StringVar(value=self.config_dict["paths"].get("CONFIG_PATH",DEFAULT_PATHS["CONFIG_PATH"]))
        self.par_var= tk.StringVar(value=self.config_dict["paths"].get("PARAMETER_PATH",DEFAULT_PATHS["PARAMETER_PATH"]))
        self.csv_var= tk.StringVar(value=self.config_dict["paths"].get("MASTER_CSV_OUTPUT",DEFAULT_PATHS["MASTER_CSV_OUTPUT"]))

        def mkrow(lbl,var,is_dir=False):
            rowf= ctk.CTkFrame(frm)
            rowf.pack(fill="x", pady=5)
            ctk.CTkLabel(rowf, text=lbl, width=180).pack(side="left", padx=5)
            e= ctk.CTkEntry(rowf, textvariable=var, width=600)
            e.pack(side="left", padx=5)
            def br():
                if is_dir:
                    p= filedialog.askdirectory()
                else:
                    p= filedialog.askopenfilename()
                if p:
                    var.set(p)
            ctk.CTkButton(rowf, text="Browse", command=br).pack(side="left", padx=5)

        mkrow("ERP Excel Path:", self.erp_var)
        mkrow("Master ZIP Path:", self.mst_var)
        mkrow("Exception Path:", self.exc_var)
        mkrow("Output Excel Path:", self.out_var)
        mkrow("JSON Config Path:", self.cfg_var)
        mkrow("Parameter File Path:", self.par_var)
        mkrow("Master CSV Folder:", self.csv_var, is_dir=True)

    def build_compare_tab(self, parent):
        frm= ctk.CTkFrame(parent)
        frm.pack(fill="both", expand=True, padx=10, pady=10)
        ctk.CTkLabel(frm, text="Mode=2 Only").pack(pady=5)

        btnf= ctk.CTkFrame(frm)
        btnf.pack(fill="x", pady=5)
        ctk.CTkButton(btnf, text="Run Comparison", command=self.run_comparison).pack(side="left", padx=5)
        ctk.CTkButton(btnf, text="Save Config", command=self.save_all_config).pack(side="left", padx=5)

    def refresh_erp_data(self):
        df_erp= read_erp_enabled(Path(self.erp_var.get().strip()))
        self.erp_grid.set_data(df_erp)

    def refresh_master_data(self):
        zip_path= Path(self.mst_var.get().strip())
        out_dir= Path(self.csv_var.get().strip())
        csvs= convert_master_txt_to_csv(zip_path, out_dir)
        df_m= unify_master_csvs(csvs)
        self.master_grid.set_data(df_m)

    def run_comparison(self):
        # update config
        self.config_dict["paths"]["ERP_EXCEL_PATH"]= self.erp_var.get().strip()
        self.config_dict["paths"]["MASTER_ZIP_PATH"]= self.mst_var.get().strip()
        self.config_dict["paths"]["EXCEPTION_PATH"]= self.exc_var.get().strip()
        self.config_dict["paths"]["OUTPUT_PATH"]= self.out_var.get().strip()
        self.config_dict["paths"]["CONFIG_PATH"]= self.cfg_var.get().strip()
        self.config_dict["paths"]["PARAMETER_PATH"]= self.par_var.get().strip()
        self.config_dict["paths"]["MASTER_CSV_OUTPUT"]= self.csv_var.get().strip()

        self.config_dict["comparison_option"]= 2

        # re-read param
        newparam= read_parameter_file(Path(self.par_var.get().strip()))

        # meltdown ERP => use meltdown_erp
        df_erp_filt= self.erp_grid.get_filtered_df()
        erp_ready_raw= meltdown_erp(df_erp_filt, newparam)
        erp_ready= build_keys(erp_ready_raw)

        # meltdown Master => meltdown_master
        df_mst_filt= self.master_grid.get_filtered_df()
        mst_ready_raw= meltdown_master(df_mst_filt, newparam)
        mst_ready= build_keys(mst_ready_raw)

        # compare => mode2
        df_diff= compare_mode2(erp_ready, mst_ready)

        # exceptions
        exc_path= Path(self.exc_var.get().strip())
        df_exc= read_exception_table(exc_path)
        final= merge_exceptions(df_diff, df_exc)

        # write
        out_path= Path(self.out_var.get().strip())
        write_results(final, out_path)

        # dash
        run_date= datetime.now().strftime("%Y-%m-%d")
        final["RunDate"]= run_date
        self.history_df= pd.concat([self.history_df, final], ignore_index=True)

        self.notebook.select(self.tab_dashboard)
        self.tab_dashboard.update_data(final, self.history_df)

        messagebox.showinfo("Done", f"Comparison => mode=2 done. Output => {out_path}")

    def save_all_config(self):
        self.config_dict["erp_grid"]= self.erp_grid.get_config_block()
        self.config_dict["master_grid"]= self.master_grid.get_config_block()

        self.config_dict["paths"]["ERP_EXCEL_PATH"]= self.erp_var.get().strip()
        self.config_dict["paths"]["MASTER_ZIP_PATH"]= self.mst_var.get().strip()
        self.config_dict["paths"]["EXCEPTION_PATH"]= self.exc_var.get().strip()
        self.config_dict["paths"]["OUTPUT_PATH"]= self.out_var.get().strip()
        self.config_dict["paths"]["CONFIG_PATH"]= self.cfg_var.get().strip()
        self.config_dict["paths"]["PARAMETER_PATH"]= self.par_var.get().strip()
        self.config_dict["paths"]["MASTER_CSV_OUTPUT"]= self.csv_var.get().strip()

        self.config_dict["comparison_option"]= 2

        save_config(self.config_dict, Path(self.cfg_var.get()))
        messagebox.showinfo("Saved", "All config saved successfully.")

# ---------------- MAIN ----------------
def main():
    app= MainApp()
    app.mainloop()

if __name__=="__main__":
    main()
