#!/usr/bin/env python3
import os
import io
import zipfile
import pandas as pd
from pathlib import Path

def read_txt_2encodings(raw: bytes) -> pd.DataFrame:
    """
    Attempt to parse 'raw' bytes as CSV using two encodings:
    1) utf-8-sig
    2) utf-16-le

    Returns the first non-empty DataFrame encountered.
    If both fail or produce (0,0) shape, returns empty DataFrame.
    """
    for enc in ["utf-8-sig", "utf-16-le"]:
        try:
            # Use engine="python" and on_bad_lines="skip" to handle messy files
            df = pd.read_csv(io.BytesIO(raw), encoding=enc, engine="python", on_bad_lines="skip")
            # Drop columns or rows that are all-NaN, to reduce empty shapes
            df.dropna(how="all", axis=0, inplace=True)
            df.dropna(how="all", axis=1, inplace=True)
            # If this DataFrame is non-empty, return
            if df.shape[0] > 0 and df.shape[1] > 0:
                return df
        except Exception as e:
            pass
    return pd.DataFrame()  # If both fail or produce empty => return empty

def extract_master_zip(zip_path: str, output_excel: str):
    """
    1) Read each .txt inside 'zip_path' with two encodings (utf-8-sig, utf-16-le).
    2) If no 'Name' column is found, rename the *first* column to 'Name' (if any).
    3) Append all columns to a final DataFrame. Also add 'SourceFile' for tracking.
    4) Write a single Excel with data from all text files.
    """
    zip_path = Path(zip_path)
    if not zip_path.is_file():
        print(f"[ERROR] Zip file not found => {zip_path}")
        return

    all_frames = []
    with zipfile.ZipFile(zip_path, 'r') as z:
        # Collect .txt files
        txt_files = [f for f in z.namelist() if f.lower().endswith(".txt")]
        if not txt_files:
            print(f"[WARN] No .txt files found in {zip_path}")
            return

        for txt_file in txt_files:
            file_name = os.path.basename(txt_file)
            try:
                with z.open(txt_file) as fh:
                    raw = fh.read()
            except Exception as e:
                print(f"[WARN] Could not read {txt_file}: {e}")
                continue

            df = read_txt_2encodings(raw)
            if df.empty:
                print(f"[INFO] {txt_file} => empty or failed parsing in both encodings.")
                continue

            # Make sure there's a 'Name' column.
            # If there's no 'Name', rename the first column to 'Name' if possible.
            lower_cols = [c.lower().strip() for c in df.columns]
            if 'name' not in lower_cols:
                if len(df.columns) > 0:
                    old_first = df.columns[0]
                    df.rename(columns={old_first: "Name"}, inplace=True)
                else:
                    # If there's not even a single column, skip
                    print(f"[INFO] {txt_file} => No columns after cleaning.")
                    continue
            # Tag the source file
            df["SourceFile"] = file_name
            all_frames.append(df)

    if not all_frames:
        print("[INFO] No data to write after processing all .txt files.")
        return

    # Combine everything
    final_df = pd.concat(all_frames, ignore_index=True)

    # Write to Excel
    final_df.to_excel(output_excel, index=False)
    print(f"[OK] Wrote {len(final_df)} rows to {output_excel}")

if __name__ == "__main__":
    # Example usage:
    # Adjust paths to your environment
    master_zip_path = "data/Master_Config.zip"
    output_file = "all_master_data.xlsx"

    extract_master_zip(master_zip_path, output_file)
