#!/usr/bin/env python3
"""
Ultra-Mega Reconciliation
- Name-first logic (skip-other-attributes if Name mismatch)
- Red color scheme for both Mismatch + Case sheets
- Dashboard includes mismatch + case
- Future End Date filter includes blank
- Full single-file script
"""

import os
import sys
import json
import logging
import zipfile
import shutil
import io
from pathlib import Path
from datetime import datetime, date
from typing import Dict, Set, List, Tuple

import tkinter as tk
from tkinter import ttk, filedialog, messagebox
import customtkinter as ctk

import pandas as pd
import numpy as np

import matplotlib
matplotlib.use("TkAgg")
import matplotlib.pyplot as plt
from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg, NavigationToolbar2Tk
from matplotlib.backends.backend_pdf import PdfPages

from openpyxl import Workbook
from openpyxl.styles import PatternFill, Font, Alignment
from openpyxl.worksheet.table import Table, TableStyleInfo
from openpyxl.utils import get_column_letter

logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")

# ----------------------------------------------------------------------------
# DEFAULT PATHS & CONFIG
# ----------------------------------------------------------------------------
DEFAULT_PATHS = {
    "ERP_EXCEL_PATH": "data/ERP_Config.xlsx",
    "MASTER_ZIP_PATH": "data/Master_Config.zip",
    "MASTER_TXT_FOLDER": "",  # if user wants to read from a folder of .txt
    "EXCEPTION_PATH": "data/Exception_Table.xlsx",
    "OUTPUT_PATH": "output/missing_items.xlsx",
    "CONFIG_PATH": "config/ui_config.json",
    "PARAMETER_PATH": "data/parameters.xlsx",
    "MASTER_CSV_OUTPUT": "temp_master_csv",
    "PDF_EXPORT_PATH": "output/dashboard_report.pdf",
    "LOGO_PATH": "images/company_logo.png",
    "HISTORY_PATH": "history_runs"
}

def default_config() -> Dict:
    return {
        "paths": DEFAULT_PATHS.copy(),
        "erp_grid": {"filters": {}},
        "master_grid": {"filters": {}},
        "dashboard": {
            "selected_dims": [],
            "selected_attrs": [],
            "top_n": 10
        },
        "trim_key_toggle": False
    }

def load_config(path: Path) -> Dict:
    if path.is_file():
        try:
            with open(path, "r", encoding="utf-8") as f:
                return json.load(f)
        except Exception as e:
            logging.warning(f"Could not load config => {e}")
    return default_config()

def save_config(cfg: Dict, path: Path):
    path.parent.mkdir(parents=True, exist_ok=True)
    try:
        if "erp_grid" in cfg and "filters" in cfg["erp_grid"]:
            newf={}
            for c,v in cfg["erp_grid"]["filters"].items():
                newf[c]= list(v)
            cfg["erp_grid"]["filters"]= newf
        if "master_grid" in cfg and "filters" in cfg["master_grid"]:
            newf={}
            for c,v in cfg["master_grid"]["filters"].items():
                newf[c]= list(v)
            cfg["master_grid"]["filters"]= newf
        with open(path,"w",encoding="utf-8") as f:
            json.dump(cfg,f,indent=2)
        logging.info(f"Saved config => {path}")
    except Exception as e:
        logging.error(f"Error saving config => {e}")


# ----------------------------------------------------------------------------
# TEXT LOGGER
# ----------------------------------------------------------------------------
class TextHandler(logging.Handler):
    def __init__(self, widget: ctk.CTkTextbox):
        super().__init__()
        self.widget= widget

    def emit(self, record):
        msg= self.format(record)+ "\n"
        self.widget.after(0, self._append, msg)

    def _append(self, msg):
        self.widget.configure(state="normal")
        self.widget.insert("end", msg)
        self.widget.see("end")
        self.widget.configure(state="disabled")


# ----------------------------------------------------------------------------
# UTILS
# ----------------------------------------------------------------------------
def read_erp_excel(path: Path)-> pd.DataFrame:
    if not path.is_file():
        logging.warning(f"ERP Excel not found => {path}")
        return pd.DataFrame()
    try:
        df= pd.read_excel(path, skiprows=3)
        df.columns= df.columns.str.strip()
        if "Enabled_Flag" in df.columns:
            df= df[df["Enabled_Flag"]=="Enabled"]
        return df
    except Exception as e:
        logging.error(f"Error reading ERP => {e}")
        return pd.DataFrame()

def try_read_csv_bytes(raw: bytes)-> pd.DataFrame:
    encs= ["utf-8-sig","utf-16-le","utf-16-be","cp1252","latin-1","ascii"]
    import io
    for enc in encs:
        try:
            buf= io.BytesIO(raw)
            df= pd.read_csv(buf, encoding=enc, on_bad_lines="skip", engine="python")
            df.dropna(how="all", axis=0, inplace=True)
            df.dropna(how="all", axis=1, inplace=True)
            df.columns= df.columns.astype(str).str.strip()
            if "Name" not in df.columns and len(df.columns)>0:
                fc= df.columns[0]
                df.rename(columns={fc:"Name"}, inplace=True)
            return df
        except Exception as e:
            logging.debug(f"[try_read_csv_bytes] => {enc} => fail => {e}")
    logging.error("[try_read_csv_bytes] => all encs fail => empty DF")
    return pd.DataFrame()

def convert_master_txt_to_csv(zip_path: Path, out_dir: Path)-> List[Path]:
    if not zip_path.is_file():
        logging.warning(f"Master ZIP not found => {zip_path}")
        return []
    if out_dir.exists():
        shutil.rmtree(out_dir, ignore_errors=True)
    out_dir.mkdir(parents=True, exist_ok=True)
    csvs=[]
    with zipfile.ZipFile(zip_path,"r") as z:
        txt_files= [f for f in z.namelist() if f.lower().endswith(".txt")]
        for txt_file in txt_files:
            bn= os.path.basename(txt_file)
            if not bn:
                continue
            try:
                with z.open(txt_file) as fo:
                    raw= fo.read()
                df= try_read_csv_bytes(raw)
                if df.empty:
                    continue
                df["RawFileName"]= bn
                out_csv= out_dir/(bn.replace(".txt",".csv"))
                df.to_csv(out_csv, index=False, encoding="utf-8")
                csvs.append(out_csv)
            except Exception as e:
                logging.error(f"Master reading {txt_file} => {e}")
    return csvs

def unify_master_csvs(csvs: List[Path])-> pd.DataFrame:
    frames=[]
    for cp in csvs:
        if not cp.is_file():
            continue
        try:
            df= pd.read_csv(cp, encoding="utf-8", on_bad_lines="skip")
            df.columns= df.columns.str.strip()
            frames.append(df)
        except Exception as e:
            logging.error(f"unify_master_csvs => {cp} => {e}")
    if frames:
        return pd.concat(frames, ignore_index=True)
    return pd.DataFrame()

def unify_master_txt_in_folder(folder: Path)-> pd.DataFrame:
    if not folder.is_dir():
        logging.warning(f"Master folder not found => {folder}")
        return pd.DataFrame()
    txt_files= list(folder.glob("*.txt"))
    if not txt_files:
        logging.warning(f"No .txt found => {folder}")
        return pd.DataFrame()
    frames=[]
    for f in txt_files:
        try:
            raw= f.read_bytes()
            df= try_read_csv_bytes(raw)
            if not df.empty:
                df["RawFileName"]= f.name
                frames.append(df)
        except Exception as e:
            logging.error(f"Reading unzipped {f} => {e}")
    if frames:
        return pd.concat(frames, ignore_index=True)
    return pd.DataFrame()


# ----------------------------------------------------------------------------
# PARAM READING
# ----------------------------------------------------------------------------
def read_param_file(path: Path)-> Dict[str,object]:
    param= {
        "dim_erp_keep": set(),
        "dim_erp_map": {},
        "dim_master_map": {},
        "attr_erp_map": {},
        "attr_master_map": {}
    }
    if not path.is_file():
        logging.warning(f"Param file not found => {path}")
        return param
    try:
        dim_df= pd.read_excel(path, sheet_name="Dimension Parameters")
        dim_df.columns= dim_df.columns.astype(str).str.strip()

        def s(x): return str(x).strip() if pd.notna(x) else ""
        for _, row in dim_df.iterrows():
            fn= s(row.get("FileName",""))
            vsc= s(row.get("V S C",""))
            dim= s(row.get("Dimension",""))
            ev= s(row.get("ERP Values",""))
            if ev.lower()=="x" and vsc and dim:
                param["dim_erp_keep"].add(vsc)
            if vsc and dim:
                param["dim_erp_map"][vsc]= dim
            if fn and dim and ev.lower()=="x":
                param["dim_master_map"][fn]= dim

        attr_df= pd.read_excel(path, sheet_name="Attribute Parameters")
        attr_df.columns= attr_df.columns.astype(str).str.strip()
        for _, row in attr_df.iterrows():
            e_orig= s(row.get("ERP Original Attributes",""))
            m_orig= s(row.get("Master Original Attributes",""))
            final_= s(row.get("Attribute",""))
            onoff= s(row.get("On/Off",""))
            if onoff.lower()=="x" and final_:
                if e_orig:
                    param["attr_erp_map"][e_orig]= final_
                if m_orig:
                    param["attr_master_map"][m_orig]= final_
        return param
    except Exception as e:
        logging.error(f"Error reading param => {e}")
        return param


# ----------------------------------------------------------------------------
# MELTDOWN
# ----------------------------------------------------------------------------
def meltdown_erp_for_preview(df: pd.DataFrame, param: Dict[str,object])-> pd.DataFrame:
    if "V_S_C" not in df.columns:
        return pd.DataFrame()
    keep= param["dim_erp_keep"]
    dmap= param["dim_erp_map"]
    amap= param["attr_erp_map"]

    df2= df[df["V_S_C"].isin(keep)].copy()
    if df2.empty:
        return pd.DataFrame()

    skip_cols= {"V_S_C","Enabled_Flag"}
    id_vars=[]
    if "Value" in df2.columns:
        id_vars.append("Value")
        skip_cols.add("Value")
    df2["DimRaw"]= df2["V_S_C"]
    skip_cols.add("DimRaw")
    id_vars.insert(0,"DimRaw")

    meltdown_cols= [c for c in df2.columns if c not in skip_cols]
    melted= df2.melt(
        id_vars=id_vars,
        value_vars=meltdown_cols,
        var_name="OrigAttr",
        value_name="ValX"
    )

    def rename_dim(x):
        return dmap.get(x,x)
    melted["Dimension"]= melted["DimRaw"].apply(rename_dim)

    if "Value" in id_vars:
        melted.rename(columns={"Value":"Name"}, inplace=True)
    else:
        melted["Name"]= ""

    # only keep mapped attributes
    melted= melted[melted["OrigAttr"].isin(amap.keys())].copy()
    melted["Attribute"]= melted["OrigAttr"].map(amap)

    def strip_t(val):
        if isinstance(val,str) and "T" in val:
            return val.split("T")[0]
        return val
    melted["Value"]= np.where(
        melted["Attribute"].isin(["Start Date","End Date"]),
        melted["ValX"].apply(strip_t),
        melted["ValX"]
    )
    return melted[["Dimension","Name","Attribute","Value"]]

def meltdown_master_for_preview(df: pd.DataFrame, param: Dict[str,object])-> pd.DataFrame:
    if df.empty or "RawFileName" not in df.columns:
        return pd.DataFrame()
    keep_map= param["dim_master_map"]
    amap= param["attr_master_map"]

    df2= df[df["RawFileName"].isin(keep_map.keys())].copy()
    if df2.empty:
        return pd.DataFrame()

    df2["DimRaw"]= df2["RawFileName"]
    skip_cols= {"RawFileName","DimRaw"}
    id_vars= ["DimRaw"]
    if "Name" in df2.columns:
        id_vars.append("Name")
        skip_cols.add("Name")

    meltdown_cols= [c for c in df2.columns if c not in skip_cols]
    melted= df2.melt(
        id_vars=id_vars,
        value_vars=meltdown_cols,
        var_name="OrigAttr",
        value_name="ValX"
    )

    def rename_dim(x):
        return keep_map.get(x,x)
    melted["Dimension"]= melted["DimRaw"].apply(rename_dim)

    if "Name" in id_vars:
        melted.rename(columns={"Name":"Name"}, inplace=True)
    else:
        melted["Name"]= ""

    def strip_t(val):
        if isinstance(val,str) and "T" in val:
            return val.split("T")[0]
        return val

    # only keep mapped attributes
    amap_keys= set(amap.keys())
    melted= melted[melted["OrigAttr"].isin(amap_keys)].copy()
    melted["Attribute"]= melted["OrigAttr"].map(amap)
    melted["Value"]= np.where(
        melted["Attribute"].isin(["Start Date","End Date"]),
        melted["ValX"].apply(strip_t),
        melted["ValX"]
    )
    return melted[["Dimension","Name","Attribute","Value"]]

def pivot_for_preview(df: pd.DataFrame)-> pd.DataFrame:
    if df.empty or not {"Dimension","Name","Attribute"}.issubset(df.columns):
        return pd.DataFrame()
    df2= df.drop_duplicates(subset=["Dimension","Name","Attribute"])
    try:
        out= df2.pivot(index=["Dimension","Name"], columns="Attribute", values="Value").reset_index()
        return out
    except Exception as e:
        logging.error(f"pivot_for_preview => {e}")
        return pd.DataFrame()

def meltdown_to_long(df_wide: pd.DataFrame)-> pd.DataFrame:
    if df_wide.empty or {"Dimension","Name"}.difference(df_wide.columns):
        return pd.DataFrame()
    meltdown_cols= [c for c in df_wide.columns if c not in ("Dimension","Name")]
    melted= df_wide.melt(
        id_vars=["Dimension","Name"],
        value_vars= meltdown_cols,
        var_name="Attribute",
        value_name="Value"
    )
    melted["Value"]= melted["Value"].fillna("")
    return melted

# ----------------------------------------------------------------------------
# NAME-FIRST LOGIC
# ----------------------------------------------------------------------------
def compare_name_attribute(
    erp_long: pd.DataFrame,
    mast_long: pd.DataFrame,
    trim_key=False
)-> Tuple[pd.DataFrame, pd.DataFrame]:
    """
    Name-first logic:
     - If Name missing or differs => single row => skip other attributes
     - If Name matches => compare all other attributes
     - case-only mismatch => case_df
    """
    def build_dict(d: pd.DataFrame):
        out={}
        for (dim,nm), grp in d.groupby(["Dimension","Name"]):
            dd={}
            for _, row in grp.iterrows():
                dd[row["Attribute"]]= row["Value"]
            out[(dim,nm)] = dd
        return out

    e_dict= build_dict(erp_long)
    m_dict= build_dict(mast_long)
    mismatch_rows=[]
    case_rows=[]
    all_dnm= set(e_dict.keys())| set(m_dict.keys())

    for dnm in all_dnm:
        dim, nm= dnm
        e_map= e_dict.get(dnm,{})
        m_map= m_dict.get(dnm,{})
        e_name= e_map.get("Name","")
        m_name= m_map.get("Name","")
        name_issue=False

        # Missing in ERP
        if dnm not in e_dict and dnm in m_dict:
            row= {
                "Dimension": dim,
                "Name": nm,
                "Attribute": "Name",
                "Master": m_name,
                "ERP": "",
                "Comments_1": "",
                "Comments_2": "",
                "Status": "Missing in ERP"
            }
            raw= f"{dim}|{nm}|Name|{m_name}|".upper()
            if trim_key: raw= raw.replace(" ","")
            row["Key"]= raw
            mismatch_rows.append(row)
            name_issue=True
        # Missing in Master
        elif dnm in e_dict and dnm not in m_dict:
            row= {
                "Dimension": dim,
                "Name": nm,
                "Attribute": "Name",
                "Master": "",
                "ERP": e_name,
                "Comments_1": "",
                "Comments_2": "",
                "Status": "Missing in Master"
            }
            raw= f"{dim}|{nm}|Name||{e_name}".upper()
            if trim_key: raw= raw.replace(" ","")
            row["Key"]= raw
            mismatch_rows.append(row)
            name_issue=True
        # Both exist but differ
        elif e_name and m_name and e_name!= m_name:
            if e_name.lower()== m_name.lower():
                # case
                row= {
                    "Dimension": dim,
                    "Name": nm,
                    "Attribute": "Name",
                    "Master": m_name,
                    "ERP": e_name,
                    "Comments_1": "",
                    "Comments_2": "",
                    "Status": "CASE"
                }
            else:
                # difference in both
                row= {
                    "Dimension": dim,
                    "Name": nm,
                    "Attribute": "Name",
                    "Master": m_name,
                    "ERP": e_name,
                    "Comments_1": "",
                    "Comments_2": "",
                    "Status": "Difference in both"
                }
            raw= f"{dim}|{nm}|Name|{m_name}|{e_name}".upper()
            if trim_key: raw= raw.replace(" ","")
            row["Key"]= raw
            if row["Status"]=="CASE":
                case_rows.append(row)
            else:
                mismatch_rows.append(row)
            name_issue=True

        if name_issue:
            # skip other attributes
            continue

        # If here => name matches or both blank => compare all other attributes
        all_atts= set(e_map.keys())| set(m_map.keys())
        all_atts.discard("Name")
        for att in all_atts:
            ev= e_map.get(att,"")
            mv= m_map.get(att,"")
            if ev.lower()== mv.lower() and ev!=mv and ev and mv:
                # case
                row= {
                    "Dimension": dim,
                    "Name": nm,
                    "Attribute": att,
                    "Master": mv,
                    "ERP": ev,
                    "Comments_1": "",
                    "Comments_2": "",
                    "Status": "CASE"
                }
                raw= f"{dim}|{nm}|{att}|{mv}|{ev}".upper()
                if trim_key: raw= raw.replace(" ","")
                row["Key"]= raw
                case_rows.append(row)
            elif ev!= mv:
                if ev and not mv:
                    status= "Missing in Master"
                elif mv and not ev:
                    status= "Missing in ERP"
                else:
                    status= "Difference in both"
                row= {
                    "Dimension": dim,
                    "Name": nm,
                    "Attribute": att,
                    "Master": mv,
                    "ERP": ev,
                    "Comments_1": "",
                    "Comments_2": "",
                    "Status": status
                }
                raw= f"{dim}|{nm}|{att}|{mv}|{ev}".upper()
                if trim_key: raw= raw.replace(" ","")
                row["Key"]= raw
                mismatch_rows.append(row)

    mismatch_cols= ["Key","Dimension","Name","Attribute","Master","ERP","Comments_1","Comments_2","Status"]
    mismatch_df= pd.DataFrame(mismatch_rows) if mismatch_rows else pd.DataFrame(columns=mismatch_cols)
    case_df= pd.DataFrame(case_rows) if case_rows else pd.DataFrame(columns=mismatch_cols)
    return mismatch_df, case_df

# ----------------------------------------------------------------------------
# EXCEPTION + MERGE
# ----------------------------------------------------------------------------
def read_exception_table(path: Path)-> pd.DataFrame:
    if not path.is_file():
        logging.warning(f"Exception table not found => {path}")
        return pd.DataFrame()
    try:
        df= pd.read_excel(path)
        df.columns= df.columns.astype(str).str.strip()
        return df
    except Exception as e:
        logging.error(f"Exception => {e}")
        return pd.DataFrame()

def merge_exceptions(df: pd.DataFrame, df_exc: pd.DataFrame)-> pd.DataFrame:
    if df.empty or df_exc.empty or "Key" not in df.columns:
        return df
    keep= [c for c in ["Key","Comments_1","Comments_2","hide exception"] if c in df_exc.columns]
    if not keep:
        return df
    exc= df_exc[keep].copy()
    exc["Key"]= exc["Key"].astype(str).str.strip()
    merged= df.merge(exc, on="Key", how="left", suffixes=("","_exc"))
    merged["hide exception"]= merged.get("hide exception","").fillna("").str.lower()
    final= merged[merged["hide exception"]!="yes"].copy()
    if "Comments_1_exc" in final.columns:
        final["Comments_1"]= np.where(final["Comments_1_exc"].notna(),
                                      final["Comments_1_exc"],
                                      final["Comments_1"])
        final.drop(columns=["Comments_1_exc"], inplace=True)
    if "Comments_2_exc" in final.columns:
        final["Comments_2"]= np.where(final["Comments_2_exc"].notna(),
                                      final["Comments_2_exc"],
                                      final["Comments_2"])
        final.drop(columns=["Comments_2_exc"], inplace=True)
    if "hide exception" in final.columns:
        final.drop(columns=["hide exception"], inplace=True)
    return final

# ----------------------------------------------------------------------------
# WRITE 2-SHEET => RED THEME, BOTH SHEETS
# ----------------------------------------------------------------------------
def write_2sheet_excel(mismatch_df: pd.DataFrame, case_df: pd.DataFrame, out_path: Path):
    """
    Red color theme for both sheets:
      - Header fill: #B30000 (dark red) w/ white text
      - Data row fill => based on 'Status':
        * Missing in Master => #FFD2D2 (very light red)
        * Missing in ERP => #FF9999 (light red)
        * Difference in both => #FF6666 (medium red)
        * CASE => #FF4D4D (slightly deeper red)
        * default => #FFCCCC (pinkish/red)
    """
    out_path.parent.mkdir(parents=True, exist_ok=True)
    columns = ["Key","Dimension","Name","Attribute","Master","ERP","Comments_1","Comments_2","Status"]

    wb= Workbook()
    ws_m= wb.active
    ws_m.title= "Mismatch"
    ws_c= wb.create_sheet("Case_Differences")

    # fill mismatch
    for col in columns:
        if col not in mismatch_df.columns:
            mismatch_df[col]= ""
    ws_m.append(columns)
    for rowvals in mismatch_df[columns].itertuples(index=False):
        ws_m.append(rowvals)

    # fill case
    for col in columns:
        if col not in case_df.columns:
            case_df[col]= ""
    ws_c.append(columns)
    for rowvals in case_df[columns].itertuples(index=False):
        ws_c.append(rowvals)

    # Red header
    header_font= Font(bold=True, color="FFFFFF")
    header_fill= PatternFill(start_color="B30000", end_color="B30000", fill_type="solid")

    for cell in ws_m[1]:
        cell.font= header_font
        cell.fill= header_fill
        cell.alignment= Alignment(horizontal="center")
    for cell in ws_c[1]:
        cell.font= header_font
        cell.fill= header_fill
        cell.alignment= Alignment(horizontal="center")

    # define data color fill
    c_missing_master = PatternFill(start_color="FFD2D2", end_color="FFD2D2", fill_type="solid")  # very light red
    c_missing_erp    = PatternFill(start_color="FF9999", end_color="FF9999", fill_type="solid")  # light red
    c_diff_both      = PatternFill(start_color="FF6666", end_color="FF6666", fill_type="solid")  # medium red
    c_case           = PatternFill(start_color="FF4D4D", end_color="FF4D4D", fill_type="solid")  # deeper red
    c_default        = PatternFill(start_color="FFCCCC", end_color="FFCCCC", fill_type="solid")  # pinkish red

    def color_rows(sheet):
        if sheet.max_row<=1:
            return
        status_idx= columns.index("Status")+1
        for r in range(2, sheet.max_row+1):
            st_val= sheet.cell(r, status_idx).value
            if st_val=="Missing in Master":
                fillc= c_missing_master
            elif st_val=="Missing in ERP":
                fillc= c_missing_erp
            elif st_val=="Difference in both":
                fillc= c_diff_both
            elif st_val=="CASE":
                fillc= c_case
            else:
                fillc= c_default

            for c_ in range(1, sheet.max_column+1):
                cell_= sheet.cell(r,c_)
                cell_.fill= fillc
                cell_.font= Font(color="000000")  # black text

    color_rows(ws_m)
    color_rows(ws_c)

    # auto-size + freeze
    for sheet in [ws_m, ws_c]:
        for col in sheet.columns:
            max_len=0
            letter= col[0].column_letter
            for cell in col:
                val= str(cell.value) if cell.value else ""
                max_len= max(max_len, len(val))
            sheet.column_dimensions[letter].width= max_len+2
        sheet.freeze_panes= "A2"

    # add table
    def add_table(ws, name_):
        if ws.max_row>1:
            last_r= ws.max_row
            last_c= ws.max_column
            ref= f"A1:{get_column_letter(last_c)}{last_r}"
            tb= Table(displayName=name_, ref=ref)
            style= TableStyleInfo(name="TableStyleMedium9", showRowStripes=True,
                                  showColumnStripes=False, showFirstColumn=True)
            tb.tableStyleInfo= style
            ws.add_table(tb)

    add_table(ws_m,"MismatchTable")
    add_table(ws_c,"CaseTable")

    wb.save(out_path)
    logging.info(f"Missing items => {out_path}")

    stamp= datetime.now().strftime("%Y%m%d_%H%M%S")
    stamped= out_path.parent / f"{out_path.stem}_{stamp}{out_path.suffix}"
    wb.save(stamped)
    logging.info(f"Timestamped => {stamped}")

# ----------------------------------------------------------------------------
# PDF => partial
# ----------------------------------------------------------------------------
class EnhancedPDFReport:
    def __init__(self, df_current: pd.DataFrame, df_history: pd.DataFrame, config: Dict):
        self.df_current= df_current
        self.df_history= df_history
        self.config= config
        self.page_count=0
        self.colors= {
            "primary":"#800020",
            "text":"#2C1810",
            "background":"#FFFFFF"
        }
        self.logo_path= self.config["paths"].get("LOGO_PATH","images/company_logo.png")

        self.PAGE_WIDTH= 8.5
        self.PAGE_HEIGHT= 11
        self.CHART_SCALE= 0.7

    def generate(self)-> Path:
        stamp= datetime.now().strftime("%Y%m%d_%H%M%S")
        out_dir= Path("Reconciliation_pdf")
        out_dir.mkdir(parents=True, exist_ok=True)
        pdf_name= f"Reconciliation_{stamp}.pdf"
        pdf_path= out_dir/pdf_name
        with PdfPages(pdf_path) as pdf:
            self._cover_page(pdf)
            self._summary_page(pdf)
            self._topdimsattrs_page(pdf)
        logging.info(f"PDF => {pdf_path}")
        return pdf_path

    def _new_page(self)-> plt.Figure:
        fig= plt.figure(figsize=(self.PAGE_WIDTH,self.PAGE_HEIGHT))
        fig.patch.set_facecolor(self.colors["background"])
        plt.axis("off")
        self.page_count+=1
        if self.logo_path and os.path.exists(self.logo_path):
            try:
                import matplotlib.image as mpimg
                img= mpimg.imread(self.logo_path)
                ax_img= fig.add_axes([0.65,0.75,0.3,0.2])
                ax_img.imshow(img, alpha=0.2)
                ax_img.axis("off")
            except Exception as e:
                logging.error(f"Logo => {e}")
        fig.text(0.5, 0.98, "Reconciliation Report", ha="center", fontsize=10, color="gray")
        fig.text(0.9, 0.03, f"Page {self.page_count}", ha="right", fontsize=8, color="gray")
        fig.text(0.5, 0.02, "© Ultra-Mega Reconciliation", ha="center", fontsize=8, color="gray")
        return fig

    def _cover_page(self, pdf: PdfPages):
        fig= self._new_page()
        plt.text(0.5,0.7,"Reconciliation Analysis Report",
                 ha="center",fontsize=24,fontweight="bold",color=self.colors["primary"],
                 transform=fig.transFigure)
        plt.text(0.5,0.6,f"Generated on {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
                 ha="center",fontsize=12,color=self.colors["text"],
                 transform=fig.transFigure)
        plt.text(0.5,0.15,"CONFIDENTIAL",
                 ha="center",fontsize=9,color=self.colors["text"],
                 transform=fig.transFigure)
        pdf.savefig(fig)
        plt.close(fig)

    def _summary_page(self, pdf: PdfPages):
        fig= self._new_page()
        plt.text(0.5,0.92,"Reconciliation Summary",
                 ha="center",fontsize=18,fontweight="bold",color=self.colors["primary"],
                 transform=fig.transFigure)
        y=0.75
        if self.df_current.empty:
            plt.text(0.5,y,"No mismatches found this run.",
                     ha="center",fontsize=14,color=self.colors["text"],
                     transform=fig.transFigure)
        else:
            total= len(self.df_current)
            c_erp= (self.df_current["Status"]=="Missing in ERP").sum()
            c_mas= (self.df_current["Status"]=="Missing in Master").sum()
            c_both= (self.df_current["Status"]=="Difference in both").sum()
            c_case= (self.df_current["Status"]=="CASE").sum()
            summ= f"Total: {total}\nMissing in ERP: {c_erp}\nMissing in Master: {c_mas}\nDifference in both: {c_both}\nCASE: {c_case}"
            plt.text(0.5,y, summ, ha="center",fontsize=14,color=self.colors["text"],
                     transform=fig.transFigure)
        pdf.savefig(fig)
        plt.close(fig)

    def _topdimsattrs_page(self, pdf: PdfPages):
        fig= self._new_page()
        plt.text(0.5,0.92,"Top Dimensions & Attributes",
                 ha="center",fontsize=18,fontweight="bold",color=self.colors["primary"],
                 transform=fig.transFigure)
        if self.df_current.empty:
            plt.text(0.5,0.7,"No data available.",
                     ha="center",fontsize=12,color=self.colors["text"],
                     transform=fig.transFigure)
        else:
            if "Dimension" in self.df_current.columns:
                topdims= self.df_current["Dimension"].value_counts().head(5)
                lines= [f"- {k} ({v})" for k,v in topdims.items()]
                textdim= "Top Dimensions:\n"+ "\n".join(lines)
                plt.text(0.25,0.7,textdim,fontsize=12,color=self.colors["text"], transform=fig.transFigure)
            if "Attribute" in self.df_current.columns:
                topatts= self.df_current["Attribute"].value_counts().head(5)
                lines= [f"- {k} ({v})" for k,v in topatts.items()]
                textatt= "Top Attributes:\n"+ "\n".join(lines)
                plt.text(0.65,0.7,textatt,fontsize=12,color=self.colors["text"], transform=fig.transFigure)
        pdf.savefig(fig)
        plt.close(fig)


# ----------------------------------------------------------------------------
# ADV DASHBOARD
# ----------------------------------------------------------------------------
class AdvancedDashboard(ctk.CTkFrame):
    def __init__(self, parent, config: Dict):
        super().__init__(parent)
        dash_cfg= config.get("dashboard",{})
        self.config= config
        self.selected_dims: Set[str]= set(dash_cfg.get("selected_dims",[]))
        self.selected_attrs: Set[str]= set(dash_cfg.get("selected_attrs",[]))
        self.top_n= dash_cfg.get("top_n",10)

        self.df_current= pd.DataFrame()
        self.df_history= pd.DataFrame()

        self.topbar= ctk.CTkScrollableFrame(self, orientation="horizontal", height=60)
        self.topbar.pack(fill="x", pady=5)
        self.metric_label= ctk.CTkLabel(self.topbar, text="Metrics: 0 mismatch, 0 dimension", width=300)
        self.metric_label.pack(side="left", padx=5)

        ctk.CTkButton(
            self.topbar, text="Filter Dimension", command=self.show_dimension_filter,
            fg_color="#800020", hover_color="#a52a2a", text_color="white"
        ).pack(side="left", padx=5)
        ctk.CTkButton(
            self.topbar, text="Filter Attribute", command=self.show_attribute_filter,
            fg_color="#800020", hover_color="#a52a2a", text_color="white"
        ).pack(side="left", padx=5)
        ctk.CTkButton(
            self.topbar, text="Toggle Top 10 / All", command=self.toggle_top_n,
            fg_color="#800020", hover_color="#a52a2a", text_color="white"
        ).pack(side="left", padx=5)

        self.notebook= ttk.Notebook(self)
        self.notebook.pack(fill="both", expand=True)

    def toggle_top_n(self):
        if self.top_n==10:
            self.top_n=None
        else:
            self.top_n=10
        self.update_data_filters()

    def show_dimension_filter(self):
        self.show_filter_popup("Dimension")

    def show_attribute_filter(self):
        self.show_filter_popup("Attribute")

    def show_filter_popup(self, col:str):
        base_df= self.df_history if not self.df_history.empty else self.df_current
        if base_df.empty or col not in base_df.columns:
            return
        popup= tk.Toplevel(self)
        popup.title(f"Filter: {col}")
        popup.geometry("300x400")

        fr= ctk.CTkFrame(popup)
        fr.pack(fill="both", expand=True, padx=5, pady=5)

        unique_vals= base_df[col].dropna().unique()
        display_map={}
        for v in unique_vals:
            dsp= str(v) if (isinstance(v,str) and v.strip()) else "(blank)"
            display_map[v]= dsp
        sorted_vals= sorted(display_map.keys(), key=lambda x: display_map[x].lower())
        if col=="Dimension":
            curr= self.selected_dims
        else:
            curr= self.selected_attrs
        if not curr:
            curr= set(sorted_vals)
        all_vals= set(sorted_vals)
        selall_var= tk.BooleanVar(value=(curr==all_vals or not curr))

        def toggle_all():
            check= selall_var.get()
            for vb in var_dict.values():
                vb.set(check)

        ctk.CTkCheckBox(
            fr, text="Select All", variable=selall_var, command=toggle_all,
            fg_color="#800020", hover_color="#a52a2a", text_color="black"
        ).pack(anchor="w", pady=5)

        scroll= ctk.CTkScrollableFrame(fr, width=250, height=250)
        scroll.pack(fill="both", expand=True, padx=5, pady=5)
        var_dict={}
        for rv in sorted_vals:
            in_filter= (rv in curr) or (not curr)
            bvar= tk.BooleanVar(value=in_filter)
            var_dict[rv]= bvar
            ctk.CTkCheckBox(
                scroll, text= display_map[rv], variable=bvar,
                fg_color="#800020", hover_color="#a52a2a", text_color="black"
            ).pack(anchor="w")

        def apply_():
            sel= {rv for rv,bv in var_dict.items() if bv.get()}
            if col=="Dimension":
                self.selected_dims= sel
            else:
                self.selected_attrs= sel
            popup.destroy()
            self.update_data_filters()

        bf= ctk.CTkFrame(fr)
        bf.pack(fill="x", pady=5)
        ctk.CTkButton(
            bf, text="Apply", command=apply_,
            fg_color="#800020", hover_color="#a52a2a", text_color="white"
        ).pack(side="left", padx=5)
        ctk.CTkButton(
            bf, text="Cancel", command=popup.destroy,
            fg_color="#800020", hover_color="#a52a2a", text_color="white"
        ).pack(side="left", padx=5)

    def update_data(self, df_current: pd.DataFrame, df_history: pd.DataFrame):
        self.df_current= df_current.copy()
        self.df_history= df_history.copy()
        self.update_data_filters()

    def update_data_filters(self):
        dfc= self.df_current.copy()
        if not dfc.empty:
            if self.selected_dims:
                dfc= dfc[dfc["Dimension"].isin(self.selected_dims)]
            if self.selected_attrs:
                dfc= dfc[dfc["Attribute"].isin(self.selected_attrs)]
        mism= len(dfc)
        dims= dfc["Dimension"].nunique() if not dfc.empty and "Dimension" in dfc.columns else 0
        self.metric_label.configure(text=f"Mismatches: {mism}, Dims: {dims}")


# ----------------------------------------------------------------------------
# HISTORY
# ----------------------------------------------------------------------------
class HistoryTab(ctk.CTkFrame):
    def __init__(self, parent, hist_dir: Path):
        super().__init__(parent)
        self.history_dir= hist_dir
        self.tree= None
        self.build_ui()

    def build_ui(self):
        lbl= ctk.CTkLabel(self, text="Reconciliation Runs History", font=("Arial",16))
        lbl.pack(pady=5)
        self.tree= ttk.Treeview(self, columns=("Filename",), show="headings", height=15)
        self.tree.heading("Filename", text="History File")
        self.tree.pack(fill="both", expand=True, padx=10, pady=10)

        self.tree.bind("<Double-1>", self.on_double_click)

        btn= ctk.CTkButton(
            self, text="Refresh", command=self.refresh_history,
            fg_color="#800020", hover_color="#a52a2a", text_color="white"
        )
        btn.pack(pady=5)
        self.refresh_history()

    def refresh_history(self):
        for i in self.tree.get_children():
            self.tree.delete(i)
        if not self.history_dir.is_dir():
            self.history_dir.mkdir(parents=True, exist_ok=True)
        files= sorted(self.history_dir.glob("run_*.json"), reverse=True)
        for f in files:
            self.tree.insert("", "end", values=(f.name,))

    def on_double_click(self, event):
        item_id= self.tree.focus()
        if not item_id:
            return
        fn= self.tree.item(item_id,"values")[0]
        path= self.history_dir/fn
        if not path.is_file():
            return
        try:
            with open(path, "r", encoding="utf-8") as ff:
                content= ff.read()
            popup= tk.Toplevel(self)
            popup.title(f"Viewing {fn}")
            txt= ctk.CTkTextbox(popup, width=800, height=600)
            txt.pack(fill="both", expand=True)
            txt.insert("end", content)
            txt.configure(state="disabled")
        except Exception as e:
            logging.error(f"Error opening {path} => {e}")


# ----------------------------------------------------------------------------
# MAIN APP
# ----------------------------------------------------------------------------
class MainApp(ctk.CTk):
    def __init__(self):
        super().__init__()
        self.title("Ultra-Mega Reconciliation: Name-first, Red Sheets, Full Dashboard")
        self.geometry("1600x900")
        ctk.set_appearance_mode("light")

        self.config_dict= load_config(Path(DEFAULT_PATHS["CONFIG_PATH"]))
        self.param_dict= read_param_file(Path(self.config_dict["paths"].get("PARAMETER_PATH", DEFAULT_PATHS["PARAMETER_PATH"])))
        self.history_df= pd.DataFrame()

        self.tabs= ttk.Notebook(self)
        self.tabs.pack(fill="both", expand=True)

        # 1) Paths
        self.tab_paths= ctk.CTkFrame(self.tabs)
        self.build_paths_tab(self.tab_paths)
        self.tabs.add(self.tab_paths, text="Paths")

        # 2) ERP preview
        self.tab_erp= ctk.CTkFrame(self.tabs)
        erp_filters= self.config_dict.get("erp_grid",{}).get("filters",{})
        self.erp_preview= SimplePreview(self.tab_erp,"ERP", erp_filters)
        self.erp_preview.pack(fill="both", expand=True)
        self.tabs.add(self.tab_erp, text="ERP Preview")

        # 3) Master preview
        self.tab_master= ctk.CTkFrame(self.tabs)
        mast_filters= self.config_dict.get("master_grid",{}).get("filters",{})
        self.master_preview= SimplePreview(self.tab_master,"Master", mast_filters)
        self.master_preview.pack(fill="both", expand=True)
        self.tabs.add(self.tab_master, text="Master Preview")

        # 4) Compare
        self.tab_compare= ctk.CTkFrame(self.tabs)
        self.build_compare_tab(self.tab_compare)
        self.tabs.add(self.tab_compare, text="Compare")

        # 5) Dashboard
        self.dashboard_tab= AdvancedDashboard(self.tabs, self.config_dict)
        self.tabs.add(self.dashboard_tab, text="Dashboard")

        # 6) History
        histp= Path(self.config_dict["paths"].get("HISTORY_PATH","history_runs"))
        self.history_tab= HistoryTab(self.tabs, histp)
        self.tabs.add(self.history_tab, text="History")

        # Logging area
        self.log_box= ctk.CTkTextbox(self, height=120)
        self.log_box.pack(fill="both", side="bottom")
        self.log_box.configure(state="disabled")
        handler= TextHandler(self.log_box)
        handler.setLevel(logging.INFO)
        logging.getLogger().addHandler(handler)

        self.temp_csv_dir= Path(self.config_dict["paths"].get("MASTER_CSV_OUTPUT","temp_master_csv"))
        self.temp_csv_dir.mkdir(parents=True, exist_ok=True)

        self.load_all_runs()

        # meltdown => show previews
        self.refresh_erp()
        self.refresh_master()
        # empty current => pass entire history => see Bollinger
        self.dashboard_tab.update_data(pd.DataFrame(), self.history_df)

    def build_paths_tab(self, parent):
        frm= ctk.CTkFrame(parent)
        frm.pack(fill="both", expand=True, padx=10, pady=10)

        self.erp_var= tk.StringVar(value=self.config_dict["paths"].get("ERP_EXCEL_PATH", DEFAULT_PATHS["ERP_EXCEL_PATH"]))
        self.mast_var= tk.StringVar(value=self.config_dict["paths"].get("MASTER_ZIP_PATH", DEFAULT_PATHS["MASTER_ZIP_PATH"]))
        self.mast_folder_var= tk.StringVar(value=self.config_dict["paths"].get("MASTER_TXT_FOLDER",""))
        self.exc_var= tk.StringVar(value=self.config_dict["paths"].get("EXCEPTION_PATH", DEFAULT_PATHS["EXCEPTION_PATH"]))
        self.out_var= tk.StringVar(value=self.config_dict["paths"].get("OUTPUT_PATH", DEFAULT_PATHS["OUTPUT_PATH"]))
        self.par_var= tk.StringVar(value=self.config_dict["paths"].get("PARAMETER_PATH", DEFAULT_PATHS["PARAMETER_PATH"]))
        self.pdf_var= tk.StringVar(value=self.config_dict["paths"].get("PDF_EXPORT_PATH", DEFAULT_PATHS["PDF_EXPORT_PATH"]))

        def mkrow(lbl,var,is_dir=False):
            rowf= ctk.CTkFrame(frm)
            rowf.pack(fill="x", pady=5)
            ctk.CTkLabel(rowf, text=lbl, width=200).pack(side="left", padx=5)
            e= ctk.CTkEntry(rowf, textvariable=var, width=600)
            e.pack(side="left", padx=5)
            def br():
                if is_dir:
                    p= filedialog.askdirectory()
                else:
                    p= filedialog.askopenfilename()
                if p:
                    var.set(p)
            ctk.CTkButton(rowf, text="Browse", command=br,
                          fg_color="#800020", hover_color="#a52a2a", text_color="white").pack(side="left", padx=5)

        mkrow("ERP Excel:", self.erp_var)
        mkrow("Master ZIP:", self.mast_var)
        mkrow("Master TXT Folder:", self.mast_folder_var, is_dir=True)
        mkrow("Exception Path:", self.exc_var)
        mkrow("Missing Items Output:", self.out_var)
        mkrow("Parameter File:", self.par_var)
        mkrow("PDF Export Path:", self.pdf_var)

        bf= ctk.CTkFrame(frm)
        bf.pack(fill="x", pady=10)
        ctk.CTkButton(bf, text="Save Config", command=self.save_all_config,
                      fg_color="#800020", hover_color="#a52a2a", text_color="white").pack(side="left", padx=5)
        ctk.CTkButton(bf, text="Refresh ERP", command=self.refresh_erp,
                      fg_color="#800020", hover_color="#a52a2a", text_color="white").pack(side="left", padx=5)
        ctk.CTkButton(bf, text="Refresh Master", command=self.refresh_master,
                      fg_color="#800020", hover_color="#a52a2a", text_color="white").pack(side="left", padx=5)

    def build_compare_tab(self, parent):
        frm= ctk.CTkFrame(parent)
        frm.pack(fill="both", expand=True, padx=10, pady=10)
        ctk.CTkLabel(frm, text="Generate Missing Items", font=("Arial",16)).pack(pady=5)

        self.trim_key_var= tk.BooleanVar(value=self.config_dict.get("trim_key_toggle",False))
        ctk.CTkCheckBox(
            frm, text="Trim Key? (remove spaces)",
            variable=self.trim_key_var,
            fg_color="#800020", hover_color="#a52a2a", text_color="black"
        ).pack(pady=5)

        ctk.CTkButton(
            frm, text="Run Reconciliation", command=self.run_comparison,
            fg_color="#800020", hover_color="#a52a2a", text_color="white"
        ).pack(pady=10)

        ctk.CTkButton(
            frm, text="Export PDF Report",
            command=self.export_pdf,
            fg_color="#800020", hover_color="#a52a2a", text_color="white"
        ).pack(pady=10)

    def load_all_runs(self):
        histp= Path(self.config_dict["paths"].get("HISTORY_PATH","history_runs"))
        if not histp.is_dir():
            return
        frames=[]
        for jf in histp.glob("run_*.json"):
            try:
                jdf= pd.read_json(jf, orient="records")
                frames.append(jdf)
            except Exception as e:
                logging.error(f"History read => {jf} => {e}")
        if frames:
            big= pd.concat(frames, ignore_index=True).drop_duplicates()
            self.history_df= big if self.history_df.empty else pd.concat([self.history_df, big], ignore_index=True).drop_duplicates()
            logging.info(f"Loaded runs => total {len(self.history_df)} records in history")

    def refresh_erp(self):
        p= Path(self.erp_var.get().strip())
        df= read_erp_excel(p)
        if df.empty:
            self.erp_preview.set_data(pd.DataFrame())
            return
        meltdowned= meltdown_erp_for_preview(df, self.param_dict)
        pivoted= pivot_for_preview(meltdowned)
        self.erp_preview.set_data(pivoted)

    def refresh_master(self):
        folder= self.mast_folder_var.get().strip()
        if folder:
            dfm= unify_master_txt_in_folder(Path(folder))
        else:
            zf= Path(self.mast_var.get().strip())
            outd= self.temp_csv_dir
            csvs= convert_master_txt_to_csv(zf,outd)
            dfm= unify_master_csvs(csvs)
        if dfm.empty:
            self.master_preview.set_data(pd.DataFrame())
            return
        meltdowned= meltdown_master_for_preview(dfm, self.param_dict)
        pivoted= pivot_for_preview(meltdowned)
        self.master_preview.set_data(pivoted)

    def run_comparison(self):
        df_erp_w= self.erp_preview.get_filtered_df()
        df_mast_w= self.master_preview.get_filtered_df()
        e_long= meltdown_to_long(df_erp_w)
        m_long= meltdown_to_long(df_mast_w)

        trim_flag= bool(self.trim_key_var.get())
        mismatch_df, case_df= compare_name_attribute(e_long, m_long, trim_key=trim_flag)

        exc_path= Path(self.config_dict["paths"].get("EXCEPTION_PATH",""))
        df_exc= read_exception_table(exc_path)
        mismatch_df= merge_exceptions(mismatch_df, df_exc)
        case_df= merge_exceptions(case_df, df_exc)

        outp= Path(self.out_var.get().strip())
        write_2sheet_excel(mismatch_df, case_df, outp)

        # unify for the dashboard + history
        run_ts= datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        all_run= pd.concat([mismatch_df, case_df], ignore_index=True).drop_duplicates()
        all_run["RunDate"]= run_ts

        # update history
        if self.history_df.empty:
            self.history_df= all_run
        else:
            self.history_df= pd.concat([self.history_df, all_run], ignore_index=True).drop_duplicates()

        histp= Path(self.config_dict["paths"].get("HISTORY_PATH","history_runs"))
        histp.mkdir(parents=True, exist_ok=True)
        run_file= histp / f"run_{run_ts.replace(':','-').replace(' ','_')}.json"
        try:
            all_run.to_json(run_file, orient="records", indent=2)
            logging.info(f"Saved run => {run_file}")
        except Exception as e:
            logging.error(f"Error saving JSON => {e}")

        # dashboard => pass all rows
        self.dashboard_tab.update_data(all_run, self.history_df)
        self.history_tab.refresh_history()

        self.tabs.select(self.dashboard_tab)
        messagebox.showinfo("Done", f"Missing items => {outp}")

    def export_pdf(self):
        if self.history_df.empty:
            messagebox.showinfo("PDF Export","No mismatch => history empty.")
            return
        # let's pick the last run
        if "RunDate" in self.history_df.columns:
            last_run= self.history_df["RunDate"].max()
            df_curr= self.history_df[self.history_df["RunDate"]== last_run].copy()
        else:
            df_curr= self.history_df.copy()

        rep= EnhancedPDFReport(df_curr, self.history_df, self.config_dict)
        pdfp= rep.generate()
        messagebox.showinfo("PDF Export", f"PDF => {pdfp}")

    def save_all_config(self):
        self.config_dict["paths"]["ERP_EXCEL_PATH"]= self.erp_var.get().strip()
        self.config_dict["paths"]["MASTER_ZIP_PATH"]= self.mast_var.get().strip()
        self.config_dict["paths"]["MASTER_TXT_FOLDER"]= self.mast_folder_var.get().strip()
        self.config_dict["paths"]["EXCEPTION_PATH"]= self.exc_var.get().strip()
        self.config_dict["paths"]["OUTPUT_PATH"]= self.out_var.get().strip()
        self.config_dict["paths"]["PARAMETER_PATH"]= self.par_var.get().strip()
        self.config_dict["paths"]["PDF_EXPORT_PATH"]= self.pdf_var.get().strip()

        self.config_dict["trim_key_toggle"]= bool(self.trim_key_var.get())

        self.config_dict.setdefault("erp_grid",{})
        self.config_dict["erp_grid"]["filters"]= self.erp_preview.filters

        self.config_dict.setdefault("master_grid",{})
        self.config_dict["master_grid"]["filters"]= self.master_preview.filters

        dash_cfg= self.config_dict.setdefault("dashboard",{})
        dash_cfg["selected_dims"]= list(self.dashboard_tab.selected_dims)
        dash_cfg["selected_attrs"]= list(self.dashboard_tab.selected_attrs)
        dash_cfg["top_n"]= self.dashboard_tab.top_n

        cfgp= Path(self.config_dict["paths"].get("CONFIG_PATH","config/ui_config.json"))
        save_config(self.config_dict, cfgp)


def main():
    app= MainApp()
    app.mainloop()

if __name__=="__main__":
    main()
