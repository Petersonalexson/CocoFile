#!/usr/bin/env python3
"""
Ultra-Mega Reconciliation
 - Mismatch & CASE stored in separate JSON
 - 2-Sheet XLSX (Mismatch + Case) with burgundy/beige formatting + single "Charts" sheet
 - SHIFTED PDF with 8 charts
 - Two Bollinger JSONs (one for mismatch, one for case)
 - 'Include CASE in Dashboard/PDF?' toggle to unify or exclude case
 - 'Missing Name' logic in compare_name_first
 - 'Trim Key' logic
"""

import os
import sys
import json
import logging
import zipfile
import shutil
import io
from pathlib import Path
from datetime import datetime, date
from typing import Dict, Set, List, Tuple

import tkinter as tk
from tkinter import ttk, filedialog, messagebox
import customtkinter as ctk

import pandas as pd
import numpy as np

import matplotlib
matplotlib.use("TkAgg")
import matplotlib.pyplot as plt
from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg, NavigationToolbar2Tk
from matplotlib.backends.backend_pdf import PdfPages

from openpyxl import Workbook
from openpyxl.styles import PatternFill, Font, Alignment, Border, Side
from openpyxl.utils import get_column_letter
from openpyxl.worksheet.table import Table, TableStyleInfo
from openpyxl.chart import BarChart, Reference

logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")


# ----------------------------------------------------------------------------
# DEFAULT CONFIG - Updated with new paths for CASE JSONs
# ----------------------------------------------------------------------------
DEFAULT_PATHS = {
    "ERP_EXCEL_PATH": "data/ERP_Config.xlsx",
    "MASTER_ZIP_PATH": "data/Master_Config.zip",
    "MASTER_TXT_FOLDER": "",
    "EXCEPTION_PATH": "data/Exception_Table.xlsx",
    "OUTPUT_PATH": "output/missing_items.xlsx",
    "CONFIG_PATH": "config/ui_config.json",
    "PARAMETER_PATH": "data/parameters.xlsx",
    "MASTER_CSV_OUTPUT": "temp_master_csv",
    "PDF_EXPORT_PATH": "output/dashboard_report.pdf",
    "LOGO_PATH": "images/company_logo.png",
    "HISTORY_PATH": "history_runs",
    "CASE_HISTORY_PATH": "case_history_runs",  # NEW: Separate folder for CASE history
    "BOLLINGER_JSON_PATH": "data/bollinger_data.json",
    "CASE_BOLLINGER_JSON_PATH": "data/case_bollinger_data.json"  # NEW: Separate JSON for CASE bollinger
}


def default_config() -> Dict:
    return {
        "paths": DEFAULT_PATHS.copy(),
        "erp_grid": {"filters": {}, "future_end_toggle": False},
        "master_grid": {"filters": {}, "future_end_toggle": False},
        "dashboard": {
            "selected_dims": [],
            "selected_attrs": [],
            "top_n": 10
        },
        "trim_key_toggle": False,
        "include_case_in_report": False  # NEW toggle for including CASE in Dashboard/PDF
    }


def load_config(path: Path) -> Dict:
    if path.is_file():
        try:
            with open(path, "r", encoding="utf-8") as f:
                return json.load(f)
        except Exception as e:
            logging.warning(f"Could not load config => {e}")
    return default_config()


def save_config(cfg: Dict, path: Path):
    path.parent.mkdir(parents=True, exist_ok=True)
    try:
        # Convert sets->lists in erp_grid
        if "erp_grid" in cfg and "filters" in cfg["erp_grid"]:
            new_erp = {}
            for c, svals in cfg["erp_grid"]["filters"].items():
                new_erp[c] = list(svals)
            cfg["erp_grid"]["filters"] = new_erp

        # Convert sets->lists in master_grid
        if "master_grid" in cfg and "filters" in cfg["master_grid"]:
            new_m = {}
            for c, svals in cfg["master_grid"]["filters"].items():
                new_m[c] = list(svals)
            cfg["master_grid"]["filters"] = new_m

        with open(path, "w", encoding="utf-8") as f:
            json.dump(cfg, f, indent=2)
        logging.info(f"Saved config => {path}")
    except Exception as e:
        logging.error(f"Error saving config => {e}")


# ----------------------------------------------------------------------------
# LOGGER => to UI text box
# ----------------------------------------------------------------------------
class TextHandler(logging.Handler):
    def __init__(self, widget: ctk.CTkTextbox):
        super().__init__()
        self.widget = widget

    def emit(self, record):
        msg = self.format(record) + "\n"
        self.widget.after(0, self._append, msg)

    def _append(self, msg):
        self.widget.configure(state="normal")
        self.widget.insert("end", msg)
        self.widget.see("end")
        self.widget.configure(state="disabled")


# ----------------------------------------------------------------------------
# READ PARAM, ERP, MASTER, meltdown, etc.
# (Fill in meltdown logic exactly as your environment requires.)
# ----------------------------------------------------------------------------
def read_param_file(path: Path) -> Dict[str, object]:
    param = {
        "dim_erp_keep": set(),
        "dim_erp_map": {},
        "dim_master_map": {},
        "attr_erp_map": {},
        "attr_master_map": {}
    }
    if not path.is_file():
        logging.warning(f"Param file => {path} not found")
        return param
    try:
        dim_df = pd.read_excel(path, sheet_name="Dimension Parameters")
        dim_df.columns = dim_df.columns.astype(str).str.strip()

        def s(x): return str(x).strip() if pd.notna(x) else ""

        for _, row in dim_df.iterrows():
            fn = s(row.get("FileName", ""))
            vsc = s(row.get("V S C", ""))
            dim = s(row.get("Dimension", ""))
            ev = s(row.get("ERP Values", ""))
            if ev.lower() == "x" and vsc and dim:
                param["dim_erp_keep"].add(vsc)
            if vsc and dim:
                param["dim_erp_map"][vsc] = dim
            if fn and dim and ev.lower() == "x":
                param["dim_master_map"][fn] = dim

        attr_df = pd.read_excel(path, sheet_name="Attribute Parameters")
        attr_df.columns = attr_df.columns.astype(str).str.strip()
        for _, row in attr_df.iterrows():
            e_orig = s(row.get("ERP Original Attributes", ""))
            m_orig = s(row.get("Master Original Attributes", ""))
            final_ = s(row.get("Attribute", ""))
            onoff = s(row.get("On/Off", ""))
            if onoff.lower() == "x" and final_:
                if e_orig:
                    param["attr_erp_map"][e_orig] = final_
                if m_orig:
                    param["attr_master_map"][m_orig] = final_
        return param
    except Exception as e:
        logging.error(f"read_param_file => {e}")
        return param


def read_erp_excel(path: Path) -> pd.DataFrame:
    if not path.is_file():
        logging.warning(f"ERP Excel => not found => {path}")
        return pd.DataFrame()
    try:
        df = pd.read_excel(path, skiprows=3)
        df.columns = df.columns.str.strip()
        if "Enabled_Flag" in df.columns:
            df = df[df["Enabled_Flag"] == "Enabled"]
        return df
    except Exception as e:
        logging.error(f"read_erp_excel => {e}")
        return pd.DataFrame()


def try_read_csv_bytes(raw: bytes) -> pd.DataFrame:
    encodings = ["utf-8-sig", "utf-16-le", "utf-16-be", "cp1252", "latin-1", "ascii"]
    import io
    for enc in encodings:
        try:
            buf = io.BytesIO(raw)
            df = pd.read_csv(buf, encoding=enc, on_bad_lines="skip", engine="python")
            df.dropna(how="all", axis=0, inplace=True)
            df.dropna(how="all", axis=1, inplace=True)
            df.columns = df.columns.astype(str).str.strip()
            if "Name" not in df.columns and len(df.columns) > 0:
                first_col = df.columns[0]
                df.rename(columns={first_col: "Name"}, inplace=True)
            return df
        except:
            pass
    logging.error("All encodings failed => returning empty DF.")
    return pd.DataFrame()


def unify_master_txt_in_folder(folder: Path) -> pd.DataFrame:
    if not folder.is_dir():
        logging.warning(f"Master folder => not exist => {folder}")
        return pd.DataFrame()
    txt_files = list(folder.glob("*.txt"))
    frames = []
    for f in txt_files:
        try:
            raw = f.read_bytes()
            df = try_read_csv_bytes(raw)
            if not df.empty:
                df["RawFileName"] = f.name
                frames.append(df)
        except Exception as e:
            logging.error(f"unify_master_txt_in_folder => {f} => {e}")
    if frames:
        return pd.concat(frames, ignore_index=True)
    return pd.DataFrame()


def convert_master_txt_to_csv(zip_path: Path, out_dir: Path) -> List[Path]:
    if not zip_path.is_file():
        logging.warning(f"Master ZIP => not found => {zip_path}")
        return []
    if out_dir.exists():
        shutil.rmtree(out_dir, ignore_errors=True)
    out_dir.mkdir(parents=True, exist_ok=True)
    csvs = []
    with zipfile.ZipFile(zip_path, "r") as z:
        txt_files = [f for f in z.namelist() if f.lower().endswith(".txt")]
        for txtf in txt_files:
            bn = os.path.basename(txtf)
            if not bn:
                continue
            try:
                with z.open(txtf) as fo:
                    raw = fo.read()
                df = try_read_csv_bytes(raw)
                if df.empty:
                    continue
                df["RawFileName"] = bn
                out_csv = out_dir / bn.replace(".txt", ".csv")
                df.to_csv(out_csv, index=False, encoding="utf-8")
                csvs.append(out_csv)
            except Exception as e:
                logging.error(f"Reading {txtf} => {e}")
    return csvs


def unify_master_csvs(csvs: List[Path]) -> pd.DataFrame:
    frames = []
    for cp in csvs:
        if not cp.is_file():
            continue
        try:
            df = pd.read_csv(cp, encoding="utf-8", on_bad_lines="skip")
            df.columns = df.columns.str.strip()
            frames.append(df)
        except Exception as e:
            logging.error(f"unify_master_csvs => {cp} => {e}")
    if frames:
        return pd.concat(frames, ignore_index=True)
    return pd.DataFrame()


def meltdown_erp_for_preview(df: pd.DataFrame, param: Dict[str, object]) -> pd.DataFrame:
    """
    Example meltdown for ERP.  
    In your real code, fill in the logic the same way you had it before.
    """
    if "V_S_C" not in df.columns:
        return pd.DataFrame()
    keep_vsc = param["dim_erp_keep"]
    dim_map = param["dim_erp_map"]
    attr_map = param["attr_erp_map"]

    df2 = df[df["V_S_C"].isin(keep_vsc)].copy()
    if df2.empty:
        return pd.DataFrame()

    skip_cols = {"V_S_C", "Enabled_Flag"}
    idv = []
    if "Value" in df2.columns:
        idv.append("Value")
        skip_cols.add("Value")

    df2["DimRaw"] = df2["V_S_C"]
    skip_cols.add("DimRaw")
    idv.insert(0, "DimRaw")

    meltdown_cols = [c for c in df2.columns if c not in skip_cols]
    melted = df2.melt(id_vars=idv, value_vars=meltdown_cols, var_name="OrigAttr", value_name="ValX")

    def rename_dim(x):
        return dim_map.get(x, x)
    melted["DimRaw"] = melted["DimRaw"].astype(str)  # ensure no weirdness
    melted["Dimension"] = melted["DimRaw"].apply(rename_dim)

    if "Value" in idv:
        melted.rename(columns={"Value": "Name"}, inplace=True)
    else:
        melted["Name"] = ""

    def strip_t(v):
        if isinstance(v, str) and "T" in v:
            return v.split("T")[0]
        return v

    melted = melted[melted["OrigAttr"].isin(attr_map.keys())].copy()
    melted["Attribute"] = melted["OrigAttr"].map(attr_map)
    melted["Value"] = np.where(
        melted["Attribute"].isin(["Start Date", "End Date"]),
        melted["ValX"].apply(strip_t),
        melted["ValX"]
    )
    return melted[["Dimension", "Name", "Attribute", "Value"]]


def meltdown_master_for_preview(df: pd.DataFrame, param: Dict[str, object]) -> pd.DataFrame:
    """
    Example meltdown for Master.  
    In your real code, fill in the logic the same way you had it before.
    """
    if df.empty or "RawFileName" not in df.columns:
        return pd.DataFrame()

    keep_dim_map = param["dim_master_map"]
    attr_map = param["attr_master_map"]

    df2 = df[df["RawFileName"].isin(keep_dim_map.keys())].copy()
    if df2.empty:
        return pd.DataFrame()

    df2["DimRaw"] = df2["RawFileName"]
    skip_cols = {"RawFileName", "DimRaw"}
    idv = ["DimRaw"]
    if "Name" in df2.columns:
        idv.append("Name")
        skip_cols.add("Name")

    meltdown_cols = [c for c in df2.columns if c not in skip_cols]
    melted = df2.melt(id_vars=idv, value_vars=meltdown_cols, var_name="OrigAttr", value_name="ValX")

    def rename_dim(x):
        return keep_dim_map.get(x, x)
    melted["DimRaw"] = melted["DimRaw"].astype(str)  # ensure no weirdness
    melted["Dimension"] = melted["DimRaw"].apply(rename_dim)

    if "Name" in idv:
        melted.rename(columns={"Name": "Name"}, inplace=True)
    else:
        melted["Name"] = ""

    def strip_t(v):
        if isinstance(v, str) and "T" in v:
            return v.split("T")[0]
        return v

    melted = melted[melted["OrigAttr"].isin(attr_map.keys())].copy()
    melted["Attribute"] = melted["OrigAttr"].map(attr_map)
    melted["Value"] = np.where(
        melted["Attribute"].isin(["Start Date", "End Date"]),
        melted["ValX"].apply(strip_t),
        melted["ValX"]
    )
    return melted[["Dimension", "Name", "Attribute", "Value"]]


def pivot_for_preview(df: pd.DataFrame) -> pd.DataFrame:
    """
    Pivot meltdown => wide for preview in the UI
    """
    if df.empty or not {"Dimension", "Name", "Attribute"}.issubset(df.columns):
        return pd.DataFrame()
    df2 = df.drop_duplicates(subset=["Dimension", "Name", "Attribute"])
    try:
        return df2.pivot(index=["Dimension", "Name"], columns="Attribute", values="Value").reset_index()
    except:
        return pd.DataFrame()


def meltdown_to_long(df_wide: pd.DataFrame) -> pd.DataFrame:
    """
    Convert pivoted to long for final comparison
    """
    if df_wide.empty or {"Dimension", "Name"}.difference(df_wide.columns):
        return pd.DataFrame()
    meltdown_cols = [c for c in df_wide.columns if c not in ("Dimension", "Name")]
    melted = df_wide.melt(id_vars=["Dimension", "Name"], value_vars=meltdown_cols,
                          var_name="Attribute", value_name="Value")
    melted["Value"] = melted["Value"].fillna("")
    return melted


# ----------------------------------------------------------------------------
# EXCEPTIONS
# ----------------------------------------------------------------------------
def read_exception_table(path: Path) -> pd.DataFrame:
    if not path.is_file():
        logging.warning(f"Exception => {path} not found")
        return pd.DataFrame()
    try:
        df = pd.read_excel(path)
        df.columns = df.columns.astype(str).str.strip()
        return df
    except Exception as e:
        logging.error(f"Exception => {e}")
        return pd.DataFrame()


def merge_exceptions(df: pd.DataFrame, df_exc: pd.DataFrame) -> pd.DataFrame:
    if df.empty or df_exc.empty or "Key" not in df.columns:
        return df
    keep = [c for c in df_exc.columns if c in ("Key", "Comments_1", "Comments_2", "hide exception")]
    if not keep:
        return df
    exc_ = df_exc[keep].copy()
    exc_["Key"] = exc_["Key"].astype(str).str.strip()

    merged = df.merge(exc_, on="Key", how="left", suffixes=("", "_exc"))
    merged["hide exception"] = merged.get("hide exception", "").fillna("").str.lower()

    final = merged[merged["hide exception"] != "yes"].copy()

    if "Comments_1_exc" in final.columns:
        final["Comments_1"] = np.where(final["Comments_1_exc"].notna(),
                                       final["Comments_1_exc"],
                                       final["Comments_1"])
        final.drop(columns=["Comments_1_exc"], inplace=True)

    if "Comments_2_exc" in final.columns:
        final["Comments_2"] = np.where(final["Comments_2_exc"].notna(),
                                       final["Comments_2_exc"],
                                       final["Comments_2"])
        final.drop(columns=["Comments_2_exc"], inplace=True)

    if "hide exception" in final.columns:
        final.drop(columns=["hide exception"], inplace=True)

    return final


# ----------------------------------------------------------------------------
# NAME-FIRST COMPARISON => mismatch + case => with Missing Name logic
# ----------------------------------------------------------------------------
def compare_name_first(erp_long: pd.DataFrame, mast_long: pd.DataFrame, trim_key=False)\
        -> Tuple[pd.DataFrame, pd.DataFrame]:
    """
    EXACT logic from your snippet:
    - If (Dimension,Name) missing => single row => skip other attributes
    - If Name differs => single row => skip other attributes
    - If Name matches => compare other attributes
    - 'CASE' if only differs in letter-case
    - 'Missing in Master' / 'Missing in ERP' / 'Difference in both'

    *** UPDATED: If 'Name' is missing on one side, auto-populate from the other side:
      - If missing in ERP and attribute is 'Name', fill row["ERP"] with Master name.
      - If missing in Master and attribute is 'Name', fill row["Master"] with ERP name.
    """

    mismatch_rows = []
    case_rows = []

    def build_dict(d):
        out = {}
        for (dim, nm), grp in d.groupby(["Dimension", "Name"]):
            rec = {}
            for _, row in grp.iterrows():
                rec[row["Attribute"]] = row["Value"]
            out[(dim, nm)] = rec
        return out

    e_dict = build_dict(erp_long)
    m_dict = build_dict(mast_long)
    all_dn = set(e_dict.keys()) | set(m_dict.keys())

    for dn in all_dn:
        dim, nm = dn
        e_map = e_dict.get(dn, {})
        m_map = m_dict.get(dn, {})

        e_name = e_map.get("Name", "")
        m_name = m_map.get("Name", "")

        name_issue = False

        # missing in ERP
        if dn not in e_dict and dn in m_dict:
            # This row's attribute is 'Name'
            # ADDED => If attribute is 'Name', copy Master name into ERP
            row = {
                "Dimension": dim, "Name": nm, "Attribute": "Name",
                # We'll show that we 'filled' ERP with Master's value
                "Master": m_name,
                "ERP": m_name,  # auto-populate from Master
                "Comments_1": "",
                "Comments_2": "",
                "Status": "Missing in ERP"
            }
            raw_key = f"{dim}|{nm}|Name|{m_name}|".upper()
            if trim_key:
                raw_key = raw_key.replace(" ", "")
            row["Key"] = raw_key
            mismatch_rows.append(row)
            name_issue = True

        # missing in Master
        elif dn in e_dict and dn not in m_dict:
            # ADDED => If attribute is 'Name', copy ERP name into Master
            row = {
                "Dimension": dim, "Name": nm, "Attribute": "Name",
                # We'll show that we 'filled' Master with ERP's value
                "Master": e_name,   # auto-populate from ERP
                "ERP": e_name,
                "Comments_1": "",
                "Comments_2": "",
                "Status": "Missing in Master"
            }
            raw_key = f"{dim}|{nm}|Name||{e_name}".upper()
            if trim_key:
                raw_key = raw_key.replace(" ", "")
            row["Key"] = raw_key
            mismatch_rows.append(row)
            name_issue = True

        # both => but name differs?
        elif e_name and m_name and e_name != m_name:
            # only differs by letter case
            if e_name.lower() == m_name.lower():
                row = {
                    "Dimension": dim, "Name": nm, "Attribute": "Name",
                    "Master": m_name, "ERP": e_name,
                    "Comments_1": "", "Comments_2": "",
                    "Status": "CASE"
                }
                raw_key = f"{dim}|{nm}|Name|{m_name}|{e_name}".upper()
                if trim_key:
                    raw_key = raw_key.replace(" ", "")
                row["Key"] = raw_key
                case_rows.append(row)
            else:
                # truly different
                row = {
                    "Dimension": dim, "Name": nm, "Attribute": "Name",
                    "Master": m_name, "ERP": e_name,
                    "Comments_1": "", "Comments_2": "",
                    "Status": "Difference in both"
                }
                raw_key = f"{dim}|{nm}|Name|{m_name}|{e_name}".upper()
                if trim_key:
                    raw_key = raw_key.replace(" ", "")
                row["Key"] = raw_key
                mismatch_rows.append(row)
            name_issue = True

        if name_issue:
            continue

        # name matched => compare other attributes
        all_atts = set(e_map.keys()) | set(m_map.keys())
        all_atts.discard("Name")
        for at in all_atts:
            ev = e_map.get(at, "")
            mv = m_map.get(at, "")
            if ev.lower() == mv.lower() and ev != mv and ev and mv:
                # differs only by letter-case
                row = {
                    "Dimension": dim, "Name": nm, "Attribute": at,
                    "Master": mv, "ERP": ev,
                    "Comments_1": "", "Comments_2": "",
                    "Status": "CASE"
                }
                raw_key = f"{dim}|{nm}|{at}|{mv}|{ev}".upper()
                if trim_key:
                    raw_key = raw_key.replace(" ", "")
                row["Key"] = raw_key
                case_rows.append(row)
            else:
                if ev == mv:
                    continue
                if ev and not mv:
                    st = "Missing in Master"
                    ms = ""
                    es = ev
                elif mv and not ev:
                    st = "Missing in ERP"
                    ms = mv
                    es = ""
                else:
                    st = "Difference in both"
                    ms = mv
                    es = ev
                row = {
                    "Dimension": dim, "Name": nm, "Attribute": at,
                    "Master": ms, "ERP": es,
                    "Comments_1": "", "Comments_2": "",
                    "Status": st
                }
                raw_key = f"{dim}|{nm}|{at}|{ms}|{es}".upper()
                if trim_key:
                    raw_key = raw_key.replace(" ", "")
                row["Key"] = raw_key
                mismatch_rows.append(row)

    cols = ["Key", "Dimension", "Name", "Attribute", "Master", "ERP", "Comments_1", "Comments_2", "Status"]
    mismatch_df = pd.DataFrame(mismatch_rows, columns=cols) if mismatch_rows else pd.DataFrame(columns=cols)
    case_df = pd.DataFrame(case_rows, columns=cols) if case_rows else pd.DataFrame(columns=cols)
    return mismatch_df, case_df


# ----------------------------------------------------------------------------
# 2-SHEET XLSX => mismatch + case => plus single "Charts" sheet
# ----------------------------------------------------------------------------
def write_2sheet_excel(mismatch_df: pd.DataFrame,
                       case_df: pd.DataFrame,
                       out_path: Path):
    """
    Create an Excel with:
      1) "Mismatch" sheet => burgundy header + 'human-skin beige' data rows
      2) "Case_Differences" sheet => same styling
      3) "Charts" sheet => dimension/attribute/status counts in one table + improved chart spacing
    """
    if mismatch_df.empty and case_df.empty:
        logging.info("No mismatches => skip writing xlsx.")
        return
    out_path.parent.mkdir(parents=True, exist_ok=True)

    cols = ["Key", "Dimension", "Name", "Attribute", "Master", "ERP", "Comments_1", "Comments_2", "Status"]
    for c in cols:
        if c not in mismatch_df.columns:
            mismatch_df[c] = ""
        if c not in case_df.columns:
            case_df[c] = ""

    wb = Workbook()
    ws_m = wb.active
    ws_m.title = "Mismatch"
    ws_m.append(cols)
    for rv in mismatch_df[cols].itertuples(index=False):
        ws_m.append(rv)

    ws_c = wb.create_sheet("Case_Differences")
    ws_c.append(cols)
    for rv in case_df[cols].itertuples(index=False):
        ws_c.append(rv)

    # Third sheet => single table for dimension/attribute/status
    ws_ch = wb.create_sheet("Charts")

    # dimension/attribute/status counts
    dcounts = mismatch_df["Dimension"].value_counts().reset_index()
    dcounts.columns = ["Category", "Count"]
    acounts = mismatch_df["Attribute"].value_counts().reset_index()
    acounts.columns = ["Category", "Count"]
    scounts = mismatch_df["Status"].value_counts().reset_index()
    scounts.columns = ["Category", "Count"]

    ws_ch["A1"] = "Type"
    ws_ch["B1"] = "Category"
    ws_ch["C1"] = "Count"

    row_i = 2

    def append_block(rows_df: pd.DataFrame, block_type: str, start_row: int) -> int:
        r = start_row
        for _, rowv in rows_df.iterrows():
            ws_ch.cell(row=r, column=1, value=block_type)
            ws_ch.cell(row=r, column=2, value=rowv["Category"])
            ws_ch.cell(row=r, column=3, value=rowv["Count"])
            r += 1
        return r

    row_i = append_block(dcounts, "Dimension", row_i)
    row_i += 1
    row_i = append_block(acounts, "Attribute", row_i)
    row_i += 1
    row_i = append_block(scounts, "Status", row_i)
    last_data_row = row_i - 1

    burgundy = PatternFill(start_color="800020", end_color="800020", fill_type="solid")
    beige = PatternFill(start_color="F5DEB3", end_color="F5DEB3", fill_type="solid")
    white_font = Font(color="FFFFFF", bold=True)
    dark_font = Font(color="2C1810", bold=False)
    thin_border = Border(
        left=Side(style='thin', color='2C1810'),
        right=Side(style='thin', color='2C1810'),
        top=Side(style='thin', color='2C1810'),
        bottom=Side(style='thin', color='2C1810')
    )

    def style_data_sheet(ws):
        max_r = ws.max_row
        max_c = ws.max_column
        # header => burgundy
        for cell in ws[1]:
            cell.fill = burgundy
            cell.font = white_font
            cell.alignment = Alignment(horizontal="center", vertical="center")
            cell.border = thin_border
        # data => beige
        for rr in range(2, max_r + 1):
            for cc in range(1, max_c + 1):
                c_ = ws.cell(rr, cc)
                c_.fill = beige
                c_.font = dark_font
                c_.border = thin_border
                if cc > 1:
                    c_.alignment = Alignment(horizontal="left", vertical="center")
        # auto-width, freeze
        for col in ws.columns:
            max_len = 0
            let = col[0].column_letter
            for cell_ in col:
                val = str(cell_.value) if cell_.value else ""
                max_len = max(max_len, len(val))
            ws.column_dimensions[let].width = max_len + 4
        ws.freeze_panes = "A2"

        if max_r > 1:
            ref = f"A1:{get_column_letter(max_c)}{max_r}"
            tbl = Table(displayName=f"{ws.title}Table", ref=ref)
            st = TableStyleInfo(
                name="TableStyleMedium9",
                showRowStripes=True, showColumnStripes=False,
                showFirstColumn=True
            )
            tbl.tableStyleInfo = st
            ws.add_table(tbl)

    style_data_sheet(ws_m)
    style_data_sheet(ws_c)

    # style charts sheet
    if last_data_row >= 1:
        for cell in ws_ch[1]:
            cell.fill = burgundy
            cell.font = white_font
            cell.alignment = Alignment(horizontal="center", vertical="center")
            cell.border = thin_border
        for rr in range(2, last_data_row + 1):
            for cc in range(1, 4):
                c_ = ws_ch.cell(rr, cc)
                c_.fill = beige
                c_.font = dark_font
                c_.border = thin_border
                c_.alignment = Alignment(horizontal="left", vertical="center")
        for col in range(1, 4):
            let = get_column_letter(col)
            max_len = 0
            for row_ in range(1, last_data_row + 1):
                vv = ws_ch.cell(row_, col).value
                vs = str(vv) if vv else ""
                max_len = max(max_len, len(vs))
            ws_ch.column_dimensions[let].width = max_len + 6
        ws_ch.freeze_panes = "A2"

        ref = f"A1:C{last_data_row}"
        chart_table = Table(displayName="ChartsTable", ref=ref)
        st_info = TableStyleInfo(
            name="TableStyleMedium9",
            showRowStripes=True, showColumnStripes=False,
            showFirstColumn=True
        )
        chart_table.tableStyleInfo = st_info
        ws_ch.add_table(chart_table)

    # create bar charts
    dim_cnt = len(dcounts)
    dim_start = 2
    dim_end = dim_start + dim_cnt - 1
    attr_start = dim_end + 2
    attr_cnt = len(acounts)
    attr_end = attr_start + attr_cnt - 1
    stat_start = attr_end + 2
    stat_cnt = len(scounts)
    stat_end = stat_start + stat_cnt - 1

    def make_barchart(sheet, start_row, end_row, title, anchor):
        if end_row < start_row:
            return
        chart = BarChart()
        chart.title = title
        chart.style = 11
        cat_ref = Reference(sheet, min_col=2, min_row=start_row, max_row=end_row)
        val_ref = Reference(sheet, min_col=3, min_row=start_row, max_row=end_row)
        chart.add_data(val_ref, titles_from_data=False)
        chart.set_categories(cat_ref)
        chart.height = 12
        chart.width = 18
        sheet.add_chart(chart, anchor)

    make_barchart(ws_ch, dim_start, dim_end, "Mismatch by Dimension", "E2")
    make_barchart(ws_ch, attr_start, attr_end, "Mismatch by Attribute", "E20")
    make_barchart(ws_ch, stat_start, stat_end, "Mismatch by Status", "E38")

    wb.save(out_path)
    logging.info(f"Missing items => {out_path}")

    stamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    stamped = out_path.parent / f"{out_path.stem}_{stamp}{out_path.suffix}"
    wb.save(stamped)
    logging.info(f"Timestamped => {stamped}")


# ----------------------------------------------------------------------------
# PDF => SHIFTED => 8 charts => “CASE only: X” in summary
# ----------------------------------------------------------------------------
class EnhancedPDFReport:
    def __init__(self, df_current: pd.DataFrame, df_history: pd.DataFrame, config: Dict):
        self.df_current = df_current
        self.df_history = df_history
        self.config = config
        self.page_count = 0
        self.colors = {
            "primary": "#800020",
            "text": "#2C1810",
            "background": "#FFFFFF"
        }
        self.logo_path = self.config["paths"].get("LOGO_PATH", "images/company_logo.png")

        self.PAGE_WIDTH = 8.5
        self.PAGE_HEIGHT = 11

    def generate(self) -> Path:
        pdf_path = self._get_pdf_path()
        with PdfPages(pdf_path) as pdf:
            self._cover_page(pdf)
            self._summary_page(pdf)
            self._all_charts(pdf)
        logging.info(f"PDF => {pdf_path}")
        return pdf_path

    def _get_pdf_path(self) -> Path:
        stamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        out_dir = Path("Reconciliation_pdf")
        out_dir.mkdir(parents=True, exist_ok=True)
        pdf_name = f"Reconciliation_{stamp}.pdf"
        return out_dir/pdf_name

    def _new_page(self) -> plt.Figure:
        self.page_count += 1
        fig = plt.figure(figsize=(self.PAGE_WIDTH, self.PAGE_HEIGHT))
        fig.patch.set_facecolor(self.colors["background"])
        plt.axis("off")

        if self.logo_path and os.path.exists(self.logo_path):
            try:
                import matplotlib.image as mpimg
                img = mpimg.imread(self.logo_path)
                ax_img = fig.add_axes([0.65, 0.75, 0.3, 0.2])
                ax_img.imshow(img, alpha=0.2)
                ax_img.axis("off")
            except Exception as e:
                logging.error(f"Logo => {e}")

        fig.text(0.5, 0.98, "Reconciliation Report", ha="center", fontsize=10, color="gray")
        fig.text(0.9, 0.03, f"Page {self.page_count}", ha="right", fontsize=8, color="gray")
        fig.text(0.5, 0.02, "© Ultra-Mega Reconciliation", ha="center", fontsize=8, color="gray")
        return fig

    def _cover_page(self, pdf: PdfPages):
        fig = self._new_page()
        plt.text(0.5, 0.7, "Reconciliation Analysis Report",
                 ha="center", fontsize=24, fontweight="bold", color=self.colors["primary"],
                 transform=fig.transFigure)
        plt.text(0.5, 0.6, f"Generated on {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
                 ha="center", fontsize=12, color=self.colors["text"], transform=fig.transFigure)
        plt.text(0.5, 0.15, "CONFIDENTIAL",
                 ha="center", fontsize=9, color=self.colors["text"], transform=fig.transFigure)
        pdf.savefig(fig)
        plt.close(fig)

    def _summary_page(self, pdf: PdfPages):
        fig = self._new_page()
        plt.text(0.5, 0.92, "Reconciliation Summary",
                 ha="center", fontsize=18, fontweight="bold", color=self.colors["primary"],
                 transform=fig.transFigure)
        y = 0.75

        if self.df_current.empty:
            plt.text(0.5, y, "No mismatches/case found this run.",
                     ha="center", fontsize=14, color=self.colors["text"],
                     transform=fig.transFigure)
        else:
            total = len(self.df_current)
            c_erp = (self.df_current["Status"] == "Missing in ERP").sum()
            c_mas = (self.df_current["Status"] == "Missing in Master").sum()
            c_both = (self.df_current["Status"] == "Difference in both").sum()
            c_case = (self.df_current["Status"] == "CASE").sum()
            lines = [
                f"Total Issues: {total}",
                f"Missing in ERP: {c_erp}",
                f"Missing in Master: {c_mas}",
                f"Difference in both: {c_both}",
                f"CASE only: {c_case}"
            ]
            summary = "\n".join(lines)
            plt.text(0.5, y, summary, ha="center", fontsize=14, color=self.colors["text"],
                     transform=fig.transFigure)

        pdf.savefig(fig)
        plt.close(fig)

    def _chart_page(self, pdf: PdfPages, title: str, plot_func, **kwargs):
        fig = self._new_page()
        fig.suptitle(title, fontsize=14, fontweight="bold", color=self.colors["primary"], y=0.93)
        ax = fig.add_axes([0.30, 0.2, 0.65, 0.55])  # SHIFT ~1 inch left
        try:
            plot_func(ax, **kwargs)
            pdf.savefig(fig)
        except Exception as e:
            logging.error(f"{title} => {e}")
        plt.close(fig)

    def _all_charts(self, pdf: PdfPages):
        dfc = self.df_current.copy()
        if dfc.empty:
            return
        df_m = dfc[dfc["Status"] != ""]

        # Heatmap
        if not df_m.empty and {"Dimension", "Attribute"}.issubset(df_m.columns):
            pivot = df_m.groupby(["Dimension", "Attribute"]).size().unstack(fill_value=0)
            if not pivot.empty:
                self._chart_page(pdf, "Heatmap", self._plot_heatmap, pivot=pivot)

        # Lollipop
        cdim = df_m.groupby("Dimension")["Key"].count().sort_values(ascending=False).head(10)
        if not cdim.empty:
            self._chart_page(pdf, "Lollipop", self._plot_lollipop, cdim=cdim)

        # Circular
        cattr = df_m.groupby("Attribute")["Key"].count().sort_values(ascending=False).head(10)
        if not cattr.empty:
            self._chart_page(pdf, "Circular", self._plot_circular, cattr=cattr)

        # Scatter
        cdim_sc = df_m.groupby("Dimension")["Key"].count().reset_index(name="Count")
        cdim_sc.sort_values("Count", ascending=False, inplace=True)
        cdim_sc = cdim_sc.head(10)
        if not cdim_sc.empty:
            self._chart_page(pdf, "Scatter", self._plot_scatter, cdim=cdim_sc)

        # Radar
        cdim_ra = df_m.groupby("Dimension")["Key"].count().sort_values(ascending=False).head(10)
        if not cdim_ra.empty and len(cdim_ra) > 1:
            self._chart_page(pdf, "Radar", self._plot_radar, cdim=cdim_ra)

        # Pie
        dist = df_m["Status"].value_counts()
        if not dist.empty:
            self._chart_page(pdf, "Pie: Status distribution", self._plot_pie, dist=dist)

        # Bar
        cattr_b = df_m.groupby("Attribute")["Key"].count().sort_values(ascending=False).head(10)
        if not cattr_b.empty:
            self._chart_page(pdf, "Bar: Missing attributes", self._plot_bar, cattr=cattr_b)

        # Bollinger
        if not self.df_history.empty and "RunDate" in self.df_history.columns:
            date_ct = self.df_history.groupby("RunDate")["Key"].count().reset_index(name="Count")
            date_ct.sort_values("RunDate", inplace=True)
            if not date_ct.empty:
                self._chart_page(pdf, "Bollinger Over Time", self._plot_bollinger, date_ct=date_ct)

    # chart helpers
    def _plot_heatmap(self, ax, pivot):
        im = ax.imshow(pivot, aspect="auto", cmap="Reds")
        ax.set_xticks(range(len(pivot.columns)))
        ax.set_xticklabels(pivot.columns, rotation=45, ha="right")
        ax.set_yticks(range(len(pivot.index)))
        ax.set_yticklabels(pivot.index)
        ax.set_title("Heatmap (Shifted Left)")
        plt.colorbar(im, ax=ax)

    def _plot_lollipop(self, ax, cdim):
        ax.hlines(y=cdim.index, xmin=0, xmax=cdim.values, color="skyblue")
        ax.plot(cdim.values, cdim.index, "o", color="skyblue")
        ax.set_xlabel("Count")
        ax.set_title("Lollipop Chart")

    def _plot_circular(self, ax, cattr):
        angles = np.linspace(0, 2*np.pi, len(cattr), endpoint=False)
        ax.set_theta_offset(np.pi/2)
        ax.set_theta_direction(-1)
        ax.set_xticks(angles)
        ax.set_xticklabels(cattr.index, fontsize=8)
        ax.bar(angles, cattr.values, width=0.4, alpha=0.6)
        ax.set_title("Circular Chart")

    def _plot_scatter(self, ax, cdim):
        xvals = np.arange(len(cdim))
        yvals = cdim["Count"].values
        labs = cdim["Dimension"].values
        ax.scatter(xvals, yvals, color="green")
        for i, d in enumerate(labs):
            ax.text(xvals[i], yvals[i], d, ha="center", va="bottom", rotation=60, fontsize=8)
        ax.set_xticks([])
        ax.set_ylabel("Count")
        ax.set_title("Scatter Chart")

    def _plot_radar(self, ax, cdim):
        cat = cdim.index.tolist()
        val = cdim.values.tolist()
        angles = np.linspace(0, 2*np.pi, len(cat), endpoint=False).tolist()
        angles += angles[:1]
        val += val[:1]
        ax.set_theta_offset(np.pi/2)
        ax.set_theta_direction(-1)
        ax.set_xticks(angles[:-1])
        ax.set_xticklabels(cat, fontsize=8)
        ax.plot(angles, val, color="red", linewidth=2)
        ax.fill(angles, val, color="red", alpha=0.3)
        ax.set_title("Radar Chart")

    def _plot_pie(self, ax, dist):
        ax.pie(dist.values, labels=dist.index, autopct="%.1f%%", startangle=140)
        ax.set_title("Pie Chart")

    def _plot_bar(self, ax, cattr):
        bars = ax.bar(range(len(cattr)), cattr.values, color="blue")
        ax.set_xticks(range(len(cattr)))
        ax.set_xticklabels(cattr.index, rotation=45, ha="right", fontsize=8)
        ax.set_ylabel("Count")
        ax.set_title("Bar Chart")
        for b in bars:
            h = b.get_height()
            ax.text(b.get_x() + b.get_width()/2., h, str(int(h)), ha="center", va="bottom")

    def _plot_bollinger(self, ax, date_ct):
        date_ct["RunDate_dt"] = pd.to_datetime(date_ct["RunDate"], errors="coerce")
        date_ct.sort_values("RunDate_dt", inplace=True)
        date_ct.reset_index(drop=True, inplace=True)
        date_ct["rolling_mean"] = date_ct["Count"].rolling(3, min_periods=1).mean()
        date_ct["rolling_std"] = date_ct["Count"].rolling(3, min_periods=1).std(ddof=0)
        date_ct["upper_band"] = date_ct["rolling_mean"] + 2*date_ct["rolling_std"]
        date_ct["lower_band"] = date_ct["rolling_mean"] - 2*date_ct["rolling_std"]
        xvals = np.arange(len(date_ct))
        ax.plot(xvals, date_ct["rolling_mean"], color="blue", label="Mean")
        ax.fill_between(xvals, date_ct["lower_band"], date_ct["upper_band"], color="blue", alpha=0.2)
        ax.scatter(xvals, date_ct["Count"], color="red", label="Count")
        ax.set_xticks(xvals)
        xlabels = [d.strftime("%Y-%m-%d") if not pd.isna(d) else "" for d in date_ct["RunDate_dt"]]
        ax.set_xticklabels(xlabels, rotation=45, ha="right")
        ax.set_xlabel("RunDate")
        ax.set_ylabel("Mismatch Count")
        ax.set_title("Bollinger Chart")
        ax.legend()


# ----------------------------------------------------------------------------
# SIMPLE PREVIEW => future end date toggle
# ----------------------------------------------------------------------------
class SimplePreview(ctk.CTkFrame):
    FILTERABLE = {"Start Date", "End Date"}

    def __init__(self, parent, name: str, cfg_sub: Dict):
        super().__init__(parent)
        self.name = name
        self.df = pd.DataFrame()

        self.filters: Dict[str, Set[str]] = {}
        self.future_var = tk.BooleanVar(value=False)

        if "filters" in cfg_sub:
            for col, arr in cfg_sub["filters"].items():
                if isinstance(arr, list):
                    self.filters[col] = set(arr)
        if "future_end_toggle" in cfg_sub:
            self.future_var.set(bool(cfg_sub["future_end_toggle"]))

        self.build_ui()

    def build_ui(self):
        top = ctk.CTkFrame(self, fg_color="#f0f0f0")
        top.pack(fill="x", padx=5, pady=5)

        ctk.CTkLabel(
            top, text=f"{self.name} Preview",
            fg_color="#800020", corner_radius=8,
            text_color="white",
            font=ctk.CTkFont(size=14, weight="bold")
        ).pack(side="left", padx=5)

        ctk.CTkCheckBox(
            top, text="Future End Date?",
            variable=self.future_var,
            command=self.refresh_table,
            fg_color="#800020", hover_color="#a52a2a",
            text_color="black"
        ).pack(side="left", padx=5)

        ctk.CTkButton(
            top, text="Clear Date Filters",
            command=self.clear_filters,
            fg_color="#800020", hover_color="#a52a2a",
            text_color="white"
        ).pack(side="left", padx=5)

        container = ctk.CTkFrame(self)
        container.pack(fill="both", expand=True)

        self.tree = ttk.Treeview(container, show="headings")
        vsb = ttk.Scrollbar(container, orient="vertical", command=self.tree.yview)
        hsb = ttk.Scrollbar(container, orient="horizontal", command=self.tree.xview)
        self.tree.configure(yscrollcommand=vsb.set, xscrollcommand=hsb.set)

        self.tree.grid(row=0, column=0, sticky="nsew")
        vsb.grid(row=0, column=1, sticky="ns")
        hsb.grid(row=1, column=0, sticky="ew")
        container.rowconfigure(0, weight=1)
        container.columnconfigure(0, weight=1)

        self.stat_lab = ctk.CTkLabel(self, text="0 rows", fg_color="#f0f0f0", text_color="black")
        self.stat_lab.pack(fill="x")

    def set_data(self, df: pd.DataFrame):
        self.df = df.copy()
        self.refresh_table()

    def get_filters(self) -> Dict[str, Set[str]]:
        return self.filters

    def get_future_toggle(self) -> bool:
        return bool(self.future_var.get())

    def get_filtered_df(self) -> pd.DataFrame:
        return self.apply_filters()

    def refresh_table(self):
        for i in self.tree.get_children():
            self.tree.delete(i)
        if self.df.empty:
            self.tree["columns"] = []
            self.stat_lab.configure(text="0 rows")
            return

        cols = list(self.df.columns)
        self.tree["columns"] = cols
        for c in cols:
            self.tree.heading(c, text=c, anchor="w", command=lambda cc=c: self.on_col_click(cc))
            self.tree.column(c, anchor="w", width=150)

        df_f = self.apply_filters()
        for _, row in df_f.iterrows():
            rowvals = [row.get(col, "") for col in cols]
            self.tree.insert("", "end", values=rowvals)
        self.stat_lab.configure(text=f"{len(df_f)} rows")

    def apply_filters(self) -> pd.DataFrame:
        df_f = self.df.copy()
        for col, allowed in self.filters.items():
            if col not in df_f.columns:
                continue
            if not allowed:
                return df_f.iloc[0:0]

            def keeper(x):
                if pd.isna(x):
                    return ("<<NaN>>" in allowed)
                elif isinstance(x, str) and not x.strip():
                    return ("<<BLANK>>" in allowed)
                else:
                    return str(x) in allowed

            df_f = df_f[df_f[col].apply(keeper)]

        if self.future_var.get() and "End Date" in df_f.columns:
            today_ = date.today()
            keep_set = set()
            for v in df_f["End Date"].unique():
                if pd.isna(v) or (isinstance(v, str) and not v.strip()):
                    keep_set.add(v)
                    continue
                sval = str(v).strip()
                keep = False
                try:
                    dtp = datetime.strptime(sval, "%Y-%m-%d")
                    if dtp.date() >= today_ or dtp.year > 2200:
                        keep = True
                except:
                    if "9999" in sval:
                        keep = True
                    else:
                        import re
                        yrs = re.findall(r"\d{4}", sval)
                        for y_ in yrs:
                            try:
                                if int(y_) > 2200:
                                    keep = True
                                    break
                            except:
                                pass
                if keep:
                    keep_set.add(v)
            df_f = df_f[df_f["End Date"].isin(keep_set)]

        return df_f

    def on_col_click(self, col_name: str):
        if col_name in self.FILTERABLE:
            self.show_filter_popup(col_name)

    def show_filter_popup(self, col_name: str):
        if self.df.empty or col_name not in self.df.columns:
            return
        pop = tk.Toplevel(self)
        pop.title(f"Filter: {col_name}")
        pop.geometry("300x400")

        fr = ctk.CTkFrame(pop)
        fr.pack(fill="both", expand=True, padx=5, pady=5)

        unq = self.df[col_name].unique()
        dsp_map = {}
        rev_map = {}
        for v in unq:
            if pd.isna(v):
                dsp = "(NaN)"
                sen = "<<NaN>>"
            elif isinstance(v, str) and not v.strip():
                dsp = "(blank)"
                sen = "<<BLANK>>"
            else:
                dsp = str(v)
                sen = dsp
            dsp_map[v] = dsp
            rev_map[dsp] = sen
        sortd = sorted(dsp_map.values(), key=lambda x: x.lower())

        curr = self.filters.get(col_name, set())
        all_sens = set(rev_map.values())
        selall_var = tk.BooleanVar(value=(curr == all_sens or not curr))

        def toggle_all():
            c = selall_var.get()
            for vb in var_dict.values():
                vb.set(c)

        ctk.CTkCheckBox(
            fr, text="Select All", variable=selall_var, command=toggle_all,
            fg_color="#800020", hover_color="#a52a2a", text_color="black"
        ).pack(anchor="w", pady=5)

        scr = ctk.CTkScrollableFrame(fr, width=250, height=250)
        scr.pack(fill="both", expand=True, padx=5, pady=5)

        var_dict = {}
        for dsp in sortd:
            sen = rev_map[dsp]
            in_f = (sen in curr) or (not curr)
            bvar = tk.BooleanVar(value=in_f)
            var_dict[dsp] = bvar
            ctk.CTkCheckBox(
                scr, text=dsp, variable=bvar,
                fg_color="#800020", hover_color="#a52a2a", text_color="black"
            ).pack(anchor="w")

        def apply_():
            sel = {rev_map[d] for d, bv in var_dict.items() if bv.get()}
            if sel == all_sens or not sel:
                if col_name in self.filters:
                    del self.filters[col_name]
            else:
                self.filters[col_name] = sel
            pop.destroy()
            self.refresh_table()

        bf = ctk.CTkFrame(fr)
        bf.pack(fill="x", pady=5)
        ctk.CTkButton(
            bf, text="Apply", command=apply_,
            fg_color="#800020", hover_color="#a52a2a", text_color="white"
        ).pack(side="left", padx=5)
        ctk.CTkButton(
            bf, text="Cancel", command=pop.destroy,
            fg_color="#800020", hover_color="#a52a2a", text_color="white"
        ).pack(side="left", padx=5)

    def clear_filters(self):
        to_del = []
        for c in self.filters:
            if c in self.FILTERABLE:
                to_del.append(c)
        for d in to_del:
            del self.filters[d]
        self.future_var.set(False)
        self.refresh_table()


# ----------------------------------------------------------------------------
# ADV DASHBOARD => 8 chart tabs
# ----------------------------------------------------------------------------
class AdvancedDashboard(ctk.CTkFrame):
    def __init__(self, parent, config: Dict):
        super().__init__(parent)
        dash_cfg = config.get("dashboard", {})
        self.config = config

        self.selected_dims = set(dash_cfg.get("selected_dims", []))
        self.selected_attrs = set(dash_cfg.get("selected_attrs", []))
        self.top_n = dash_cfg.get("top_n", 10)

        self.df_current = pd.DataFrame()
        self.df_history = pd.DataFrame()

        topbar = ctk.CTkScrollableFrame(self, orientation="horizontal", height=60)
        topbar.pack(fill="x", pady=5)

        self.metric_label = ctk.CTkLabel(topbar, text="Metrics: 0 mismatch, 0 dimension", width=300)
        self.metric_label.pack(side="left", padx=5)

        ctk.CTkButton(
            topbar, text="Filter Dimension", command=self.show_dim_filter,
            fg_color="#800020", hover_color="#a52a2a", text_color="white"
        ).pack(side="left", padx=5)
        ctk.CTkButton(
            topbar, text="Filter Attribute", command=self.show_attr_filter,
            fg_color="#800020", hover_color="#a52a2a", text_color="white"
        ).pack(side="left", padx=5)
        ctk.CTkButton(
            topbar, text="Toggle Top 10 / All", command=self.toggle_top_n,
            fg_color="#800020", hover_color="#a52a2a", text_color="white"
        ).pack(side="left", padx=5)

        self.notebook = ttk.Notebook(self)
        self.notebook.pack(fill="both", expand=True)

        chart_names = ["Heatmap", "Lollipop", "Circular", "Scatter", "Radar",
                       "Normal Pie", "Normal Bar", "Bollinger Chart"]
        self.frames = {}
        for nm in chart_names:
            fr = ctk.CTkFrame(self.notebook)
            fr.pack(fill="both", expand=True)
            self.notebook.add(fr, text=nm)
            self.frames[nm] = fr

    def toggle_top_n(self):
        if self.top_n == 10:
            self.top_n = None
        else:
            self.top_n = 10
        self.update_data_filters()

    def show_dim_filter(self):
        self.show_filter_popup("Dimension")

    def show_attr_filter(self):
        self.show_filter_popup("Attribute")

    def show_filter_popup(self, col: str):
        base = self.df_history if not self.df_history.empty else self.df_current
        if base.empty or col not in base.columns:
            return
        pop = tk.Toplevel(self)
        pop.title(f"Filter: {col}")
        pop.geometry("300x400")

        fr = ctk.CTkFrame(pop)
        fr.pack(fill="both", expand=True, padx=5, pady=5)

        unq = base[col].dropna().unique()
        dsp_map = {}
        for v in unq:
            if isinstance(v, str) and v.strip():
                dsp = v
            else:
                dsp = "(blank)"
            dsp_map[v] = dsp

        svals = sorted(dsp_map.keys(), key=lambda x: dsp_map[x].lower())
        if col == "Dimension":
            curr = self.selected_dims
        else:
            curr = self.selected_attrs

        if not curr:
            curr = set(svals)
        all_vals = set(svals)
        selall_var = tk.BooleanVar(value=(curr == all_vals or not curr))

        def toggle_all():
            c = selall_var.get()
            for vb in var_dict.values():
                vb.set(c)

        ctk.CTkCheckBox(
            fr, text="Select All", variable=selall_var, command=toggle_all,
            fg_color="#800020", hover_color="#a52a2a", text_color="black"
        ).pack(anchor="w", pady=5)

        scr = ctk.CTkScrollableFrame(fr, width=250, height=250)
        scr.pack(fill="both", expand=True, padx=5, pady=5)

        var_dict = {}
        for rv in svals:
            in_f = (rv in curr) or (not curr)
            bvar = tk.BooleanVar(value=in_f)
            var_dict[rv] = bvar
            ctk.CTkCheckBox(
                scr, text=dsp_map[rv], variable=bvar,
                fg_color="#800020", hover_color="#a52a2a", text_color="black"
            ).pack(anchor="w")

        def apply_():
            sel = {k for k, bv in var_dict.items() if bv.get()}
            if col == "Dimension":
                self.selected_dims = sel
            else:
                self.selected_attrs = sel
            pop.destroy()
            self.update_data_filters()

        bf = ctk.CTkFrame(fr)
        bf.pack(fill="x", pady=5)
        ctk.CTkButton(
            bf, text="Apply", command=apply_,
            fg_color="#800020", hover_color="#a52a2a", text_color="white"
        ).pack(side="left", padx=5)
        ctk.CTkButton(
            bf, text="Cancel", command=pop.destroy,
            fg_color="#800020", hover_color="#a52a2a", text_color="white"
        ).pack(side="left", padx=5)

    def update_data(self, df_current: pd.DataFrame, df_history: pd.DataFrame):
        self.df_current = df_current.copy()
        self.df_history = df_history.copy()
        self.update_data_filters()

    def update_data_filters(self):
        dfc = self.df_current.copy()
        if not dfc.empty:
            if self.selected_dims:
                dfc = dfc[dfc["Dimension"].isin(self.selected_dims)]
            if self.selected_attrs:
                dfc = dfc[dfc["Attribute"].isin(self.selected_attrs)]
        mism = len(dfc)
        dims = dfc["Dimension"].nunique() if not dfc.empty and "Dimension" in dfc.columns else 0
        self.metric_label.configure(text=f"Mismatches: {mism}, Dims: {dims}")

        self.build_heatmap(dfc, self.frames["Heatmap"])
        self.build_lollipop(dfc, self.frames["Lollipop"])
        self.build_circular(dfc, self.frames["Circular"])
        self.build_scatter(dfc, self.frames["Scatter"])
        self.build_radar(dfc, self.frames["Radar"])
        self.build_pie(dfc, self.frames["Normal Pie"])
        self.build_bar(dfc, self.frames["Normal Bar"])
        self.build_bollinger(self.frames["Bollinger Chart"])

    def build_heatmap(self, df: pd.DataFrame, frame: ctk.CTkFrame):
        self.clear_frame(frame)
        if df.empty or "Status" not in df.columns:
            return
        df_m = df[df["Status"] != ""]
        if df_m.empty or not {"Dimension", "Attribute"}.issubset(df_m.columns):
            return
        pivot = df_m.groupby(["Dimension", "Attribute"]).size().unstack(fill_value=0)
        if pivot.empty:
            return
        fig, ax = plt.subplots(figsize=(5,4))
        im = ax.imshow(pivot, aspect="auto", cmap="Reds")
        ax.set_xticks(range(len(pivot.columns)))
        ax.set_xticklabels(pivot.columns, rotation=45, ha="right")
        ax.set_yticks(range(len(pivot.index)))
        ax.set_yticklabels(pivot.index)
        ax.set_title("Heatmap")
        plt.colorbar(im, ax=ax)
        self.plot_chart(frame, fig)

    def build_lollipop(self, df: pd.DataFrame, frame: ctk.CTkFrame):
        self.clear_frame(frame)
        if df.empty:
            return
        df_m = df[df["Status"] != ""]
        if df_m.empty:
            return
        cdim = df_m.groupby("Dimension")["Key"].count().sort_values(ascending=False)
        if self.top_n == 10:
            cdim = cdim.head(10)
        if cdim.empty:
            return
        fig, ax = plt.subplots(figsize=(5,4))
        ax.hlines(y=cdim.index, xmin=0, xmax=cdim.values, color="skyblue")
        ax.plot(cdim.values, cdim.index, "o", color="skyblue")
        ax.set_title("Lollipop")
        ax.set_xlabel("Count")
        self.plot_chart(frame, fig)

    def build_circular(self, df: pd.DataFrame, frame: ctk.CTkFrame):
        self.clear_frame(frame)
        if df.empty:
            return
        df_m = df[df["Status"] != ""]
        if df_m.empty:
            return
        cattr = df_m.groupby("Attribute")["Key"].count().sort_values(ascending=False)
        if self.top_n == 10:
            cattr = cattr.head(10)
        if cattr.empty:
            return
        fig = plt.figure(figsize=(5,5))
        ax = fig.add_subplot(111, polar=True)
        angles = np.linspace(0, 2*np.pi, len(cattr), endpoint=False)
        ax.set_theta_offset(np.pi/2)
        ax.set_theta_direction(-1)
        ax.set_xticks(angles)
        ax.set_xticklabels(cattr.index, fontsize=8)
        ax.bar(angles, cattr.values, width=0.4, alpha=0.6)
        ax.set_title("Circular")
        self.plot_chart(frame, fig)

    def build_scatter(self, df: pd.DataFrame, frame: ctk.CTkFrame):
        self.clear_frame(frame)
        if df.empty:
            return
        df_m = df[df["Status"] != ""]
        if df_m.empty:
            return
        cdim = df_m.groupby("Dimension")["Key"].count().reset_index(name="Count")
        cdim.sort_values("Count", ascending=False, inplace=True)
        if self.top_n == 10:
            cdim = cdim.head(10)
        if cdim.empty:
            return
        fig, ax = plt.subplots(figsize=(5,4))
        xvals = np.arange(len(cdim))
        yvals = cdim["Count"].values
        labs = cdim["Dimension"].values
        ax.scatter(xvals, yvals, color="green")
        for i, la in enumerate(labs):
            ax.text(xvals[i], yvals[i], la, ha="center", va="bottom", rotation=60, fontsize=8)
        ax.set_xticks([])
        ax.set_ylabel("Count")
        ax.set_title("Scatter")
        self.plot_chart(frame, fig)

    def build_radar(self, df: pd.DataFrame, frame: ctk.CTkFrame):
        self.clear_frame(frame)
        if df.empty:
            return
        df_m = df[df["Status"] != ""]
        if df_m.empty:
            return
        cdim = df_m.groupby("Dimension")["Key"].count().sort_values(ascending=False)
        if self.top_n == 10:
            cdim = cdim.head(10)
        if cdim.empty or len(cdim) < 2:
            return
        cat = cdim.index.tolist()
        val = cdim.values.tolist()
        angles = np.linspace(0, 2*np.pi, len(cat), endpoint=False).tolist()
        angles += angles[:1]
        val += val[:1]
        fig = plt.figure(figsize=(5,5))
        ax = fig.add_subplot(111, polar=True)
        ax.set_theta_offset(np.pi/2)
        ax.set_theta_direction(-1)
        ax.set_xticks(angles[:-1])
        ax.set_xticklabels(cat, fontsize=8)
        ax.plot(angles, val, color="red", linewidth=2)
        ax.fill(angles, val, color="red", alpha=0.3)
        ax.set_title("Radar")
        self.plot_chart(frame, fig)

    def build_pie(self, df: pd.DataFrame, frame: ctk.CTkFrame):
        self.clear_frame(frame)
        if df.empty:
            return
        df_m = df[df["Status"] != ""]
        if df_m.empty:
            return
        dist = df_m["Status"].value_counts()
        if dist.empty:
            return
        fig, ax = plt.subplots(figsize=(5,4))
        ax.pie(dist.values, labels=dist.index, autopct="%.1f%%", startangle=140)
        ax.set_title("Pie: Status")
        self.plot_chart(frame, fig)

    def build_bar(self, df: pd.DataFrame, frame: ctk.CTkFrame):
        self.clear_frame(frame)
        if df.empty:
            return
        df_m = df[df["Status"] != ""]
        if df_m.empty:
            return
        cattr = df_m["Attribute"].value_counts().sort_values(ascending=False)
        if self.top_n == 10:
            cattr = cattr.head(10)
        if cattr.empty:
            return
        fig, ax = plt.subplots(figsize=(5,3))
        bars = ax.bar(range(len(cattr)), cattr.values, color="blue")
        ax.set_xticks(range(len(cattr)))
        ax.set_xticklabels(cattr.index, rotation=45, ha="right")
        ax.set_ylabel("Count")
        ax.set_title("Bar: Attributes")
        for bar in bars:
            h = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2., h, str(int(h)), ha="center", va="bottom")
        plt.tight_layout()
        self.plot_chart(frame, fig)

    def build_bollinger(self, frame: ctk.CTkFrame):
        self.clear_frame(frame)
        if self.df_history.empty or "RunDate" not in self.df_history.columns:
            return
        date_ct = self.df_history.groupby("RunDate")["Key"].count().reset_index(name="Count")
        date_ct.sort_values("RunDate", inplace=True)
        if date_ct.empty:
            return
        fig, ax = plt.subplots(figsize=(6,3))
        date_ct["RunDate_dt"] = pd.to_datetime(date_ct["RunDate"], errors="coerce")
        date_ct.sort_values("RunDate_dt", inplace=True)
        date_ct.reset_index(drop=True, inplace=True)
        date_ct["rolling_mean"] = date_ct["Count"].rolling(3, min_periods=1).mean()
        date_ct["rolling_std"] = date_ct["Count"].rolling(3, min_periods=1).std(ddof=0)
        date_ct["upper_band"] = date_ct["rolling_mean"] + 2*date_ct["rolling_std"]
        date_ct["lower_band"] = date_ct["rolling_mean"] - 2*date_ct["rolling_std"]
        xvals = np.arange(len(date_ct))
        ax.plot(xvals, date_ct["rolling_mean"], color="blue", label="Mean")
        ax.fill_between(xvals, date_ct["lower_band"], date_ct["upper_band"], color="blue", alpha=0.2)
        ax.scatter(xvals, date_ct["Count"], color="red", label="Count")
        ax.set_xticks(xvals)
        xlabels = [d.strftime("%Y-%m-%d") if not pd.isna(d) else "" for d in date_ct["RunDate_dt"]]
        ax.set_xticklabels(xlabels, rotation=45, ha="right")
        ax.set_xlabel("RunDate")
        ax.set_ylabel("Mismatch Count")
        ax.set_title("Bollinger Chart")
        ax.legend()
        self.plot_chart(frame, fig)

    def plot_chart(self, frame: ctk.CTkFrame, fig: plt.Figure):
        for w in frame.winfo_children():
            w.destroy()
        canvas = FigureCanvasTkAgg(fig, master=frame)
        canvas.draw()
        toolbar_frame = ctk.CTkFrame(frame)
        toolbar_frame.pack(side="top", fill="x")
        tb = NavigationToolbar2Tk(canvas, toolbar_frame)
        tb.update()
        canvas.get_tk_widget().pack(fill="both", expand=True)
        plt.close(fig)

    def clear_frame(self, frame: ctk.CTkFrame):
        for w in frame.winfo_children():
            w.destroy()


# ----------------------------------------------------------------------------
# HISTORY TAB
# ----------------------------------------------------------------------------
class HistoryTab(ctk.CTkFrame):
    def __init__(self, parent, hist_dir: Path):
        super().__init__(parent)
        self.history_dir = hist_dir
        self.tree = None
        self.build_ui()

    def build_ui(self):
        lbl = ctk.CTkLabel(self, text="Reconciliation Runs History", font=("Arial", 16))
        lbl.pack(pady=5)
        self.tree = ttk.Treeview(self, columns=("Filename",), show="headings", height=15)
        self.tree.heading("Filename", text="History File")
        self.tree.pack(fill="both", expand=True, padx=10, pady=10)

        self.tree.bind("<Double-1>", self.on_double_click)

        ctk.CTkButton(
            self, text="Refresh", command=self.refresh_history,
            fg_color="#800020", hover_color="#a52a2a", text_color="white"
        ).pack(pady=5)

        self.refresh_history()

    def refresh_history(self):
        for i in self.tree.get_children():
            self.tree.delete(i)
        if not self.history_dir.is_dir():
            self.history_dir.mkdir(parents=True, exist_ok=True)
        files = sorted(self.history_dir.glob("run_*.json"), reverse=True)
        for f in files:
            self.tree.insert("", "end", values=(f.name,))

    def on_double_click(self, event):
        it = self.tree.focus()
        if not it:
            return
        fn = self.tree.item(it, "values")[0]
        path = self.history_dir / fn
        if not path.is_file():
            return
        try:
            with open(path, "r", encoding="utf-8") as ff:
                content = ff.read()
            pop = tk.Toplevel(self)
            pop.title(f"Viewing {fn}")
            txt = ctk.CTkTextbox(pop, width=800, height=600)
            txt.pack(fill="both", expand=True)
            txt.insert("end", content)
            txt.configure(state="disabled")
        except Exception as e:
            logging.error(f"Error opening {path} => {e}")


# ----------------------------------------------------------------------------
# MAIN APP => mismatch history + case history => separate JSON => two bollinger
# ----------------------------------------------------------------------------
class MainApp(ctk.CTk):
    def __init__(self):
        super().__init__()
        self.title("Ultra-Mega Reconciliation => SHIFTED PDF, 2-sheets (burgundy+beige)")
        self.geometry("1600x900")
        ctk.set_appearance_mode("light")

        self.protocol("WM_DELETE_WINDOW", self.on_close)

        self.config_dict = load_config(Path(DEFAULT_PATHS["CONFIG_PATH"]))
        self.param_dict = read_param_file(
            Path(self.config_dict["paths"].get("PARAMETER_PATH", DEFAULT_PATHS["PARAMETER_PATH"]))
        )

        # Mismatch vs. Case dataframes
        self.history_df = pd.DataFrame()
        self.case_history_df = pd.DataFrame()

        self.tabs = ttk.Notebook(self)
        self.tabs.pack(fill="both", expand=True)

        # 1) Paths
        self.tab_paths = ctk.CTkFrame(self.tabs)
        self.build_paths_tab(self.tab_paths)
        self.tabs.add(self.tab_paths, text="Paths")

        # 2) ERP preview
        e_cfg = self.config_dict.get("erp_grid", {})
        self.tab_erp = ctk.CTkFrame(self.tabs)
        self.erp_preview = SimplePreview(self.tab_erp, "ERP", e_cfg)
        self.erp_preview.pack(fill="both", expand=True)
        self.tabs.add(self.tab_erp, text="ERP Preview")

        # 3) Master preview
        m_cfg = self.config_dict.get("master_grid", {})
        self.tab_master = ctk.CTkFrame(self.tabs)
        self.master_preview = SimplePreview(self.tab_master, "Master", m_cfg)
        self.master_preview.pack(fill="both", expand=True)
        self.tabs.add(self.tab_master, text="Master Preview")

        # 4) Compare
        self.tab_compare = ctk.CTkFrame(self.tabs)
        self.build_compare_tab(self.tab_compare)
        self.tabs.add(self.tab_compare, text="Compare")

        # 5) Dashboard
        self.dashboard_tab = AdvancedDashboard(self.tabs, self.config_dict)
        self.tabs.add(self.dashboard_tab, text="Dashboard")

        # 6) History
        hist_path = Path(self.config_dict["paths"].get("HISTORY_PATH", "history_runs"))
        self.history_tab = HistoryTab(self.tabs, hist_path)
        self.tabs.add(self.history_tab, text="History")

        # LOG area
        self.log_box = ctk.CTkTextbox(self, height=120)
        self.log_box.pack(fill="both", side="bottom")
        self.log_box.configure(state="disabled")
        handler = TextHandler(self.log_box)
        handler.setLevel(logging.INFO)
        logging.getLogger().addHandler(handler)

        self.temp_csv_dir = Path(self.config_dict["paths"].get("MASTER_CSV_OUTPUT", "temp_master_csv"))
        self.temp_csv_dir.mkdir(parents=True, exist_ok=True)

        # load mismatch & case
        self.load_history_runs()
        self.load_case_history_runs()

        self.refresh_erp()
        self.refresh_master()

        # Show empty => Bollinger sees entire hist
        self.dashboard_tab.update_data(pd.DataFrame(), self.history_df)

        ctk.CTkButton(self, text="Close", command=self.on_close,
                      fg_color="#800020", hover_color="#a52a2a", text_color="white").pack(pady=5)

    def build_paths_tab(self, parent):
        frm = ctk.CTkFrame(parent)
        frm.pack(fill="both", expand=True, padx=10, pady=10)

        self.erp_var = tk.StringVar(value=self.config_dict["paths"].get("ERP_EXCEL_PATH", DEFAULT_PATHS["ERP_EXCEL_PATH"]))
        self.mast_zip_var = tk.StringVar(value=self.config_dict["paths"].get("MASTER_ZIP_PATH", DEFAULT_PATHS["MASTER_ZIP_PATH"]))
        self.mast_folder_var = tk.StringVar(value=self.config_dict["paths"].get("MASTER_TXT_FOLDER", ""))
        self.exc_var = tk.StringVar(value=self.config_dict["paths"].get("EXCEPTION_PATH", DEFAULT_PATHS["EXCEPTION_PATH"]))
        self.out_var = tk.StringVar(value=self.config_dict["paths"].get("OUTPUT_PATH", DEFAULT_PATHS["OUTPUT_PATH"]))
        self.par_var = tk.StringVar(value=self.config_dict["paths"].get("PARAMETER_PATH", DEFAULT_PATHS["PARAMETER_PATH"]))
        self.pdf_var = tk.StringVar(value=self.config_dict["paths"].get("PDF_EXPORT_PATH", DEFAULT_PATHS["PDF_EXPORT_PATH"]))

        def mkrow(lbl, var, is_dir=False):
            rowf = ctk.CTkFrame(frm)
            rowf.pack(fill="x", pady=5)
            ctk.CTkLabel(rowf, text=lbl, width=200).pack(side="left", padx=5)
            e = ctk.CTkEntry(rowf, textvariable=var, width=600)
            e.pack(side="left", padx=5)

            def br():
                if is_dir:
                    p = filedialog.askdirectory()
                else:
                    p = filedialog.askopenfilename()
                if p:
                    var.set(p)

            ctk.CTkButton(
                rowf, text="Browse", command=br,
                fg_color="#800020", hover_color="#a52a2a", text_color="white"
            ).pack(side="left", padx=5)

        mkrow("ERP Excel:", self.erp_var)
        mkrow("Master ZIP:", self.mast_zip_var)
        mkrow("Master Folder:", self.mast_folder_var, True)
        mkrow("Exception Path:", self.exc_var)
        mkrow("Missing Items Output:", self.out_var)
        mkrow("Parameter File:", self.par_var)
        mkrow("PDF Export Path:", self.pdf_var)

        bf = ctk.CTkFrame(frm)
        bf.pack(fill="x", pady=10)
        ctk.CTkButton(bf, text="Save Config", command=self.save_all_config,
                      fg_color="#800020", hover_color="#a52a2a", text_color="white").pack(side="left", padx=5)
        ctk.CTkButton(bf, text="Refresh ERP", command=self.refresh_erp,
                      fg_color="#800020", hover_color="#a52a2a", text_color="white").pack(side="left", padx=5)
        ctk.CTkButton(bf, text="Refresh Master", command=self.refresh_master,
                      fg_color="#800020", hover_color="#a52a2a", text_color="white").pack(side="left", padx=5)

    def build_compare_tab(self, parent):
        frm = ctk.CTkFrame(parent)
        frm.pack(fill="both", expand=True, padx=10, pady=10)

        ctk.CTkLabel(
            frm, text="Generate Missing Items => 2-sheets + SHIFTED PDF",
            font=ctk.CTkFont(size=14, weight="bold")
        ).pack(pady=5)

        self.trim_key_var = tk.BooleanVar(value=self.config_dict.get("trim_key_toggle", False))
        ctk.CTkCheckBox(
            frm, text="Trim Key?", variable=self.trim_key_var,
            fg_color="#800020", hover_color="#a52a2a", text_color="black"
        ).pack(pady=5)

        self.include_case_var = tk.BooleanVar(value=self.config_dict.get("include_case_in_report", False))
        ctk.CTkCheckBox(
            frm, text="Include CASE in Dashboard/PDF?", variable=self.include_case_var,
            fg_color="#800020", hover_color="#a52a2a", text_color="black"
        ).pack(pady=5)

        ctk.CTkButton(
            frm, text="Run Reconciliation", command=self.run_comparison,
            fg_color="#800020", hover_color="#a52a2a", text_color="white"
        ).pack(pady=10)

        ctk.CTkButton(
            frm, text="Export PDF Report", command=self.export_pdf,
            fg_color="#800020", hover_color="#a52a2a", text_color="white"
        ).pack(pady=10)

    def load_history_runs(self):
        histp = Path(self.config_dict["paths"].get("HISTORY_PATH", "history_runs"))
        if not histp.is_dir():
            return
        frames = []
        for jf in histp.glob("run_*.json"):
            try:
                df_ = pd.read_json(jf, orient="records")
                frames.append(df_)
            except Exception as e:
                logging.error(f"History => {jf} => {e}")
        if frames:
            big = pd.concat(frames, ignore_index=True).drop_duplicates()
            if self.history_df.empty:
                self.history_df = big
            else:
                self.history_df = pd.concat([self.history_df, big], ignore_index=True).drop_duplicates()
            logging.info(f"Loaded mismatch runs => total {len(self.history_df)} records")

    def load_case_history_runs(self):
        case_histp = Path(self.config_dict["paths"].get("CASE_HISTORY_PATH", "case_history_runs"))
        if not case_histp.is_dir():
            return
        frames = []
        for jf in case_histp.glob("case_run_*.json"):
            try:
                df_ = pd.read_json(jf, orient="records")
                frames.append(df_)
            except Exception as e:
                logging.error(f"CASE History => {jf} => {e}")
        if frames:
            big = pd.concat(frames, ignore_index=True).drop_duplicates()
            if self.case_history_df.empty:
                self.case_history_df = big
            else:
                self.case_history_df = pd.concat([self.case_history_df, big], ignore_index=True).drop_duplicates()
            logging.info(f"Loaded CASE runs => total {len(self.case_history_df)} records")

    def refresh_erp(self):
        path_ = Path(self.erp_var.get().strip())
        df = read_erp_excel(path_)
        if df.empty:
            self.erp_preview.set_data(pd.DataFrame())
            return
        meltdown_ = meltdown_erp_for_preview(df, self.param_dict)
        pivoted = pivot_for_preview(meltdown_)
        self.erp_preview.set_data(pivoted)

    def refresh_master(self):
        folder_ = self.mast_folder_var.get().strip()
        zpath_ = self.mast_zip_var.get().strip()

        if folder_:
            dfm = unify_master_txt_in_folder(Path(folder_))
        else:
            cfiles = convert_master_txt_to_csv(Path(zpath_), self.temp_csv_dir)
            dfm = unify_master_csvs(cfiles)

        if dfm.empty:
            self.master_preview.set_data(pd.DataFrame())
            return
        meltdown_ = meltdown_master_for_preview(dfm, self.param_dict)
        pivoted = pivot_for_preview(meltdown_)
        self.master_preview.set_data(pivoted)

    # RUN COMPARISON => updated with mismatch + case => separate JSON => bollinger
    def run_comparison(self):
        df_erp_w = self.erp_preview.get_filtered_df()
        df_mast_w = self.master_preview.get_filtered_df()

        erp_long = meltdown_to_long(df_erp_w)
        mast_long = meltdown_to_long(df_mast_w)

        trim_flag = bool(self.trim_key_var.get())
        mismatch_df, case_df = compare_name_first(erp_long, mast_long, trim_key=trim_flag)

        exc_path = Path(self.config_dict["paths"].get("EXCEPTION_PATH", ""))
        df_exc = read_exception_table(exc_path)
        mismatch_df = merge_exceptions(mismatch_df, df_exc)
        case_df = merge_exceptions(case_df, df_exc)

        outp = Path(self.config_dict["paths"].get("OUTPUT_PATH", "output/missing_items.xlsx"))
        write_2sheet_excel(mismatch_df, case_df, outp)

        run_ts = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        mismatch_df["RunDate"] = run_ts
        case_df["RunDate"] = run_ts

        # store mismatch in self.history_df
        if self.history_df.empty:
            self.history_df = mismatch_df.copy()
        else:
            self.history_df = pd.concat([self.history_df, mismatch_df], ignore_index=True).drop_duplicates()

        # store case in self.case_history_df
        if self.case_history_df.empty:
            self.case_history_df = case_df.copy()
        else:
            self.case_history_df = pd.concat([self.case_history_df, case_df], ignore_index=True).drop_duplicates()

        # mismatch JSON
        hist_path = Path(self.config_dict["paths"].get("HISTORY_PATH", "history_runs"))
        hist_path.mkdir(parents=True, exist_ok=True)
        run_file = hist_path / f"run_{run_ts.replace(':','-').replace(' ','_')}.json"
        try:
            mismatch_df.to_json(run_file, orient="records", indent=2)
            logging.info(f"Saved mismatch run => {run_file}")
        except Exception as e:
            logging.error(f"Error saving mismatch run => {e}")

        # case JSON
        case_hist_path = Path(self.config_dict["paths"].get("CASE_HISTORY_PATH", "case_history_runs"))
        case_hist_path.mkdir(parents=True, exist_ok=True)
        case_run_file = case_hist_path / f"case_run_{run_ts.replace(':','-').replace(' ','_')}.json"
        try:
            case_df.to_json(case_run_file, orient="records", indent=2)
            logging.info(f"Saved case run => {case_run_file}")
        except Exception as e:
            logging.error(f"Error saving case run => {e}")

        # create bollinger data => mismatch vs. case
        self._save_bollinger_data(self.history_df, "BOLLINGER_JSON_PATH")
        self._save_bollinger_data(self.case_history_df, "CASE_BOLLINGER_JSON_PATH")

        # update dashboard => mismatch only or mismatch+case
        if self.include_case_var.get():
            combined_df = pd.concat([mismatch_df, case_df], ignore_index=True)
            combined_hist = pd.concat([self.history_df, self.case_history_df], ignore_index=True).drop_duplicates()
        else:
            combined_df = mismatch_df.copy()
            combined_hist = self.history_df

        self.dashboard_tab.update_data(combined_df, combined_hist)
        self.history_tab.refresh_history()
        self.tabs.select(self.dashboard_tab)

        messagebox.showinfo("Done", f"Missing items => {outp}")

    def _save_bollinger_data(self, df: pd.DataFrame, path_key: str):
        """Helper method to save mismatch or case Bollinger data to separate JSON."""
        if df.empty or "RunDate" not in df.columns:
            return
        try:
            path_str = self.config_dict["paths"].get(path_key, "")
            if not path_str:
                return
            outp = Path(path_str)
            outp.parent.mkdir(parents=True, exist_ok=True)

            date_ct = df.groupby("RunDate")["Key"].count().reset_index(name="Count")
            date_ct["RunDate_dt"] = pd.to_datetime(date_ct["RunDate"], errors="coerce")
            date_ct.sort_values("RunDate_dt", inplace=True)
            date_ct.reset_index(drop=True, inplace=True)
            date_ct["rolling_mean"] = date_ct["Count"].rolling(3, min_periods=1).mean()
            date_ct["rolling_std"] = date_ct["Count"].rolling(3, min_periods=1).std(ddof=0)
            date_ct["upper_band"] = date_ct["rolling_mean"] + 2 * date_ct["rolling_std"]
            date_ct["lower_band"] = date_ct["rolling_mean"] - 2 * date_ct["rolling_std"]
            date_ct["RunDate"] = date_ct["RunDate_dt"].dt.strftime("%Y-%m-%d %H:%M:%S")
            date_ct.drop(columns=["RunDate_dt"], inplace=True)

            date_ct.to_json(outp, orient="records", indent=2)
            logging.info(f"Bollinger => {outp}")
        except Exception as e:
            logging.error(f"Bollinger => {e}")

    def export_pdf(self):
        # unify mismatch+case if toggled
        if self.history_df.empty and self.case_history_df.empty:
            messagebox.showinfo("PDF Export", "No data => empty history.")
            return

        last_run = None
        if not self.history_df.empty and "RunDate" in self.history_df.columns:
            last_run = self.history_df["RunDate"].max()

        if last_run:
            df_curr = self.history_df[self.history_df["RunDate"] == last_run].copy()
        else:
            df_curr = self.history_df.copy()

        if self.include_case_var.get() and not self.case_history_df.empty:
            case_last_run = self.case_history_df["RunDate"].max()
            if case_last_run and case_last_run == last_run:
                case_curr = self.case_history_df[self.case_history_df["RunDate"] == case_last_run].copy()
                df_curr = pd.concat([df_curr, case_curr], ignore_index=True)

        if self.include_case_var.get():
            big_hist = pd.concat([self.history_df, self.case_history_df], ignore_index=True).drop_duplicates()
        else:
            big_hist = self.history_df

        rep = EnhancedPDFReport(df_curr, big_hist, self.config_dict)
        pdf_path = rep.generate()
        messagebox.showinfo("PDF Export", f"PDF => {pdf_path}")

    def save_all_config(self):
        self.config_dict["paths"]["ERP_EXCEL_PATH"] = self.erp_var.get().strip()
        self.config_dict["paths"]["MASTER_ZIP_PATH"] = self.mast_zip_var.get().strip()
        self.config_dict["paths"]["MASTER_TXT_FOLDER"] = self.mast_folder_var.get().strip()
        self.config_dict["paths"]["EXCEPTION_PATH"] = self.exc_var.get().strip()
        self.config_dict["paths"]["OUTPUT_PATH"] = self.out_var.get().strip()
        self.config_dict["paths"]["PARAMETER_PATH"] = self.par_var.get().strip()
        self.config_dict["paths"]["PDF_EXPORT_PATH"] = self.pdf_var.get().strip()

        self.config_dict["paths"]["CASE_HISTORY_PATH"] = self.config_dict["paths"].get("CASE_HISTORY_PATH", "case_history_runs")
        self.config_dict["paths"]["BOLLINGER_JSON_PATH"] = self.config_dict["paths"].get("BOLLINGER_JSON_PATH", "data/bollinger_data.json")
        self.config_dict["paths"]["CASE_BOLLINGER_JSON_PATH"] = self.config_dict["paths"].get("CASE_BOLLINGER_JSON_PATH", "data/case_bollinger_data.json")

        self.config_dict["trim_key_toggle"] = bool(self.trim_key_var.get())
        self.config_dict["include_case_in_report"] = bool(self.include_case_var.get())

        e_cfg = self.config_dict.setdefault("erp_grid", {})
        e_cfg["filters"] = self.erp_preview.get_filters()
        e_cfg["future_end_toggle"] = self.erp_preview.get_future_toggle()

        m_cfg = self.config_dict.setdefault("master_grid", {})
        m_cfg["filters"] = self.master_preview.get_filters()
        m_cfg["future_end_toggle"] = self.master_preview.get_future_toggle()

        dash_cfg = self.config_dict.setdefault("dashboard", {})
        dash_cfg["selected_dims"] = list(self.dashboard_tab.selected_dims)
        dash_cfg["selected_attrs"] = list(self.dashboard_tab.selected_attrs)
        dash_cfg["top_n"] = self.dashboard_tab.top_n

        cfgp = Path(self.config_dict["paths"].get("CONFIG_PATH", "config/ui_config.json"))
        save_config(self.config_dict, cfgp)

    def on_close(self):
        self.save_all_config()
        self._save_bollinger_data(self.history_df, "BOLLINGER_JSON_PATH")
        self._save_bollinger_data(self.case_history_df, "CASE_BOLLINGER_JSON_PATH")
        self.destroy()


def main():
    app = MainApp()
    app.mainloop()


if __name__ == "__main__":
    main()
