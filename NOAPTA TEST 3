
"""
Demo: Convert Master .txt -> .csv (with robust multi-encoding attempts), then load into an Excel-like UI for Reconciliation
----------------------------------------------------------------------------------
Steps:
1) Extract all .txt from a ZIP, convert each to .csv in a local folder (trying multiple encodings).
2) Read each .csv, combine them into a single 'Master' DataFrame, deduce 'Dimension' from filename.
3) Present ERP & Master data in a UI for column renaming/hiding, row filtering, etc.
4) On Compare: meltdown, merge exceptions, output Excel with mismatches.

Requires:
  - pandas
  - openpyxl
  - customtkinter
  - chardet (optional but recommended for advanced detection)
  - tkinter (part of standard Python on most platforms)

Author: ChatGPT
Date: 2025
"""

import os
import json
import logging
import zipfile
import shutil
from pathlib import Path
from typing import Dict, List, Set, Tuple
from datetime import datetime

import tkinter as tk
from tkinter import ttk, filedialog, messagebox, simpledialog

import customtkinter as ctk
import pandas as pd
import numpy as np

# For Excel output formatting
from openpyxl import Workbook
from openpyxl.styles import PatternFill, Font, Alignment

# Optional encoding detection
try:
    import chardet
except ImportError:
    chardet = None

# ------------------------------------------------------------------------------
# 1) LOGGING
# ------------------------------------------------------------------------------
def setup_logger():
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s [%(levelname)s] %(message)s"
    )
setup_logger()

# ------------------------------------------------------------------------------
# 2) DEFAULT PATHS AND CONFIG
# ------------------------------------------------------------------------------
DEFAULT_PATHS = {
    "ERP_EXCEL_PATH": "data/ERP_Config.xlsx",
    "MASTER_ZIP_PATH": "data/Master_Config.zip",
    "EXCEPTION_PATH": "data/Exception_Table.xlsx",
    "OUTPUT_PATH": "output/Reconciliation.xlsx",
    "CONFIG_PATH": "config/ui_config.json",

    # Directory for writing intermediate CSVs from Master .txt
    "MASTER_CSV_OUTPUT": "converted_master"
}

def default_config() -> Dict:
    return {
        "paths": {
            "ERP_EXCEL_PATH": DEFAULT_PATHS["ERP_EXCEL_PATH"],
            "MASTER_ZIP_PATH": DEFAULT_PATHS["MASTER_ZIP_PATH"],
            "EXCEPTION_PATH": DEFAULT_PATHS["EXCEPTION_PATH"],
            "OUTPUT_PATH": DEFAULT_PATHS["OUTPUT_PATH"],
            "MASTER_CSV_OUTPUT": DEFAULT_PATHS["MASTER_CSV_OUTPUT"],
            "CONFIG_PATH": DEFAULT_PATHS["CONFIG_PATH"]
        },
        "erp_grid": {
            "columns": [
                {
                    "id": "Col1", "name": "Col1",
                    "locked": False, "visible": True, "renameable": True
                },
                {
                    "id": "Col2", "name": "Col2",
                    "locked": False, "visible": True, "renameable": True
                },
                {
                    "id": "Enabled_Flag", "name": "Enabled_Flag",
                    "locked": False, "visible": True, "renameable": True
                },
                {
                    "id": "Dimension_Name", "name": "Dimension_Name",
                    "locked": True, "visible": True, "renameable": False
                },
                {
                    "id": "Value", "name": "Value",
                    "locked": True, "visible": True, "renameable": False
                }
            ],
            "filters": {}
        },
        "master_grid": {
            "columns": [
                {
                    "id": "Name", "name": "Name",
                    "locked": True, "visible": True, "renameable": False
                },
                {
                    "id": "Dimension", "name": "Dimension",
                    "locked": True, "visible": True, "renameable": False
                }
            ],
            "filters": {}
        },
        "comparison_option": 1
    }

def load_config(path: Path) -> Dict:
    if path.is_file():
        try:
            with open(path, "r", encoding="utf-8") as f:
                return json.load(f)
        except Exception as e:
            logging.warning(f"Could not load config from {path}: {e}")
    return default_config()

def save_config(config: Dict, path: Path):
    path.parent.mkdir(parents=True, exist_ok=True)
    try:
        with open(path, "w", encoding="utf-8") as f:
            json.dump(config, f, indent=2)
        logging.info(f"Config saved to {path}")
    except Exception as e:
        logging.error(f"Error saving config to {path}: {e}")

# ------------------------------------------------------------------------------
# 3) TEXT LOGGER HANDLER
# ------------------------------------------------------------------------------
class TextHandler(logging.Handler):
    """
    A handler to show log messages in a customtkinter CTkTextbox (or any text widget).
    """
    def __init__(self, widget: ctk.CTkTextbox):
        super().__init__()
        self.widget = widget

    def emit(self, record):
        msg = self.format(record) + "\n"
        self.widget.after(0, self._append, msg)

    def _append(self, msg):
        self.widget.configure(state="normal")
        self.widget.insert("end", msg)
        self.widget.see("end")
        self.widget.configure(state="disabled")

# ------------------------------------------------------------------------------
# 4) EXCEL-LIKE GRID
# ------------------------------------------------------------------------------
class ExcelGrid(ctk.CTkFrame):
    """
    An Excel-like grid with:
      - column definitions (id, name, visible, locked, renameable)
      - a Treeview for rows
      - row filtering by each column
      - column manager for rename/hide/reorder
    """

    def __init__(self, parent, config_block: Dict, name: str):
        super().__init__(parent)
        self.name = name
        self.col_defs = config_block.get("columns", [])
        self.filters: Dict[str, Set] = {}
        for k, v in config_block.get("filters", {}).items():
            self.filters[k] = set(v)

        self.df = pd.DataFrame()
        self.create_toolbar()
        self.create_table()
        self.create_statusbar()

    def create_toolbar(self):
        bar = ctk.CTkFrame(self)
        bar.pack(fill="x", padx=5, pady=5)
        ctk.CTkButton(bar, text="Manage Columns", command=self.show_column_manager).pack(side="left", padx=5)
        ctk.CTkButton(bar, text="Clear Filters", command=self.clear_filters).pack(side="left", padx=5)

    def create_table(self):
        container = ctk.CTkFrame(self)
        container.pack(fill="both", expand=True)

        self.tree = ttk.Treeview(container, show="headings")
        vsb = ttk.Scrollbar(container, orient="vertical", command=self.tree.yview)
        hsb = ttk.Scrollbar(container, orient="horizontal", command=self.tree.xview)
        self.tree.configure(yscrollcommand=vsb.set, xscrollcommand=hsb.set)

        self.tree.grid(row=0, column=0, sticky="nsew")
        vsb.grid(row=0, column=1, sticky="ns")
        hsb.grid(row=1, column=0, sticky="ew")
        container.rowconfigure(0, weight=1)
        container.columnconfigure(0, weight=1)

    def create_statusbar(self):
        self.status_label = ctk.CTkLabel(self, text="Ready")
        self.status_label.pack(fill="x")

    def set_data(self, df: pd.DataFrame):
        """
        Load the DataFrame into the grid, merging with existing col_defs
        so newly seen columns get added automatically.
        """
        self.df = df.copy()
        existing_ids = [c["id"] for c in self.col_defs]
        for col in df.columns:
            if col not in existing_ids:
                self.col_defs.append({
                    "id": col,
                    "name": col,
                    "locked": False,
                    "visible": True,
                    "renameable": True
                })
        self.refresh_table()

    def refresh_table(self):
        # Clear existing rows
        for item in self.tree.get_children():
            self.tree.delete(item)

        # Columns
        visible_cols = [c for c in self.col_defs if c.get("visible", True)]
        self.tree["columns"] = [c["id"] for c in visible_cols]
        for col_def in visible_cols:
            self.tree.heading(
                col_def["id"],
                text=col_def["name"],
                anchor="w",
                command=lambda c=col_def: self.show_filter_popup(c)
            )
            self.tree.column(col_def["id"], anchor="w", width=col_def.get("width", 150))

        # Insert data
        df_f = self.get_filtered_df()
        for _, row in df_f.iterrows():
            vals = [row[col["id"]] for col in visible_cols]
            self.tree.insert("", "end", values=vals)

        self.status_label.configure(text=f"{len(df_f)} rows")

    def get_filtered_df(self) -> pd.DataFrame:
        if self.df.empty:
            return self.df
        df_f = self.df.copy()
        for col_id, allowed in self.filters.items():
            if col_id in df_f.columns and allowed:
                df_f = df_f[df_f[col_id].isin(allowed)]
        visible_cols = [c["id"] for c in self.col_defs if c.get("visible", True)]
        visible_cols = [c for c in visible_cols if c in df_f.columns]
        return df_f[visible_cols]

    def show_column_manager(self):
        cm = tk.Toplevel(self)
        cm.title(f"{self.name} - Column Manager")
        frm = ctk.CTkScrollableFrame(cm, width=500, height=400)
        frm.pack(fill="both", expand=True)

        for i, col_def in enumerate(self.col_defs):
            rowf = ctk.CTkFrame(frm)
            rowf.pack(fill="x", pady=2)

            var_vis = tk.BooleanVar(value=col_def.get("visible", True))
            ctk.CTkCheckBox(rowf, text="", variable=var_vis,
                            command=lambda c=col_def, v=var_vis: self.on_toggle_visibility(c, v.get())).pack(side="left")

            if col_def.get("renameable", True):
                ctk.CTkButton(rowf, text=col_def["name"], command=lambda c=col_def: self.rename_column(c)).pack(side="left", padx=5)
            else:
                ctk.CTkLabel(rowf, text=col_def["name"]).pack(side="left", padx=5)

            if not col_def.get("locked", False):
                ctk.CTkButton(rowf, text="↑", width=30, command=lambda idx=i: self.move_column(idx, -1)).pack(side="right", padx=2)
                ctk.CTkButton(rowf, text="↓", width=30, command=lambda idx=i: self.move_column(idx, 1)).pack(side="right", padx=2)

    def on_toggle_visibility(self, col_def: Dict, visible: bool):
        col_def["visible"] = visible
        self.refresh_table()

    def rename_column(self, col_def: Dict):
        new_name = simpledialog.askstring("Rename Column", f"New name for {col_def['name']}:", initialvalue=col_def['name'])
        if new_name:
            col_def["name"] = new_name
            self.refresh_table()

    def move_column(self, index: int, delta: int):
        new_idx = index + delta
        if 0 <= new_idx < len(self.col_defs):
            self.col_defs[index], self.col_defs[new_idx] = self.col_defs[new_idx], self.col_defs[index]
            self.refresh_table()

    def show_filter_popup(self, col_def: Dict):
        """Open a Toplevel with checkboxes for unique column values to filter by."""
        col_id = col_def["id"]
        if self.df.empty or col_id not in self.df.columns:
            return

        popup = tk.Toplevel(self)
        popup.title(f"Filter: {col_def['name']}")
        popup.geometry("300x400")

        frame = ctk.CTkFrame(popup)
        frame.pack(fill="both", expand=True, padx=5, pady=5)

        unique_vals = sorted(self.df[col_id].dropna().unique(), key=lambda x: str(x))
        current_filter = self.filters.get(col_id, set())
        if not current_filter:
            current_filter = set(unique_vals)

        select_all_var = tk.BooleanVar(value=True)

        def toggle_all():
            check = select_all_var.get()
            for vb in var_dict.values():
                vb.set(check)

        ctk.CTkCheckBox(frame, text="Select All", variable=select_all_var, command=toggle_all).pack(anchor="w", pady=5)

        scroll = ctk.CTkScrollableFrame(frame, width=250, height=250)
        scroll.pack(fill="both", expand=True, padx=5, pady=5)

        var_dict = {}
        for val in unique_vals:
            v = tk.BooleanVar(value=(val in current_filter))
            var_dict[val] = v
            ctk.CTkCheckBox(scroll, text=str(val), variable=v).pack(anchor="w")

        btnf = ctk.CTkFrame(frame)
        btnf.pack(fill="x", pady=5)

        def apply_filter():
            selected = {k for k, v in var_dict.items() if v.get()}
            self.filters[col_id] = selected
            popup.destroy()
            self.refresh_table()

        ctk.CTkButton(btnf, text="Apply", command=apply_filter).pack(side="left", padx=5)
        ctk.CTkButton(btnf, text="Cancel", command=popup.destroy).pack(side="left", padx=5)

    def clear_filters(self):
        self.filters.clear()
        self.refresh_table()

    def get_config_block(self) -> Dict:
        return {
            "columns": self.col_defs,
            "filters": {k: sorted(list(v)) for k, v in self.filters.items()}
        }

# ------------------------------------------------------------------------------
# 5) CSV READING HELPERS WITH ROBUST ENCODING
# ------------------------------------------------------------------------------
def read_csv_robust(path: Path) -> pd.DataFrame:
    """
    Attempts to read a CSV file by trying a wide range of encodings in sequence.
    Returns the DataFrame on the first success; otherwise returns an empty DataFrame.
    """
    import csv

    # A broad list of encodings to try (Oracle systems, Windows code pages, etc.)
    encoding_candidates = [
        'utf-8-sig', 'utf-8', 'utf-16', 'utf-16-le', 'utf-16-be',
        'utf-32', 'utf-32-le', 'utf-32-be',
        'cp1250', 'cp1251', 'cp1252', 'cp1254', 'cp1256', 'cp932', 'cp949',
        'latin1', 'iso-8859-1', 'iso-8859-2', 'windows-1250', 'windows-1251',
        'windows-1252', 'windows-1254', 'windows-1256', 'shift_jis',
        'euc_jp', 'euc_kr', 'big5', 'big5hkscs', 'gb2312', 'gbk', 'gb18030',
        # Add more if needed...
    ]

    for enc in encoding_candidates:
        try:
            df = pd.read_csv(
                path,
                encoding=enc,
                sep=",",               # or None if you want pandas to infer
                on_bad_lines="skip",
                quoting=csv.QUOTE_MINIMAL,
                engine="python",
            )
            # Optional: drop fully-empty rows/cols
            df.dropna(axis=0, how="all", inplace=True)
            df.dropna(axis=1, how="all", inplace=True)

            logging.info(f"[read_csv_robust] Success with encoding='{enc}' => shape={df.shape}")
            return df
        except Exception as e:
            logging.debug(f"[read_csv_robust] Fail with '{enc}': {e}")

    logging.error(f"[read_csv_robust] Could not read '{path}' with any known encoding.")
    return pd.DataFrame()

# ------------------------------------------------------------------------------
# 6) MASTER TXT -> CSV CONVERSION
# ------------------------------------------------------------------------------
def convert_master_txt_to_csv(zip_path: Path, out_dir: Path) -> List[Path]:
    """
    Step 1: Extract all .txt from the ZIP, convert each to .csv in out_dir using read_csv_robust.
    Returns a list of created CSV paths.
    """
    if not zip_path.is_file():
        logging.warning(f"Master ZIP not found: {zip_path}")
        return []

    if out_dir.exists():
        # Clear out existing
        shutil.rmtree(out_dir, ignore_errors=True)
    out_dir.mkdir(parents=True, exist_ok=True)

    created_csvs = []
    with zipfile.ZipFile(zip_path, "r") as z:
        txt_files = [f for f in z.namelist() if f.lower().endswith(".txt")]
        for txt_file in txt_files:
            basename = os.path.basename(txt_file)
            if not basename:
                continue

            # We'll extract the .txt to a temp location
            try:
                with z.open(txt_file) as fo:
                    raw_data = fo.read()
            except Exception as e:
                logging.error(f"Error reading {txt_file} from ZIP: {e}")
                continue

            temp_txt_path = out_dir / basename
            try:
                with temp_txt_path.open("wb") as f:
                    f.write(raw_data)
            except Exception as e2:
                logging.error(f"Failed to write temp TXT {temp_txt_path}: {e2}")
                continue

            # Now read the newly created .txt using read_csv_robust => get df
            df_tmp = read_csv_robust(temp_txt_path)
            # Write a .csv version
            csv_name = basename.rsplit(".", 1)[0] + ".csv"
            csv_path = out_dir / csv_name
            try:
                df_tmp.to_csv(csv_path, index=False)
                created_csvs.append(csv_path)
                logging.info(f"Converted {txt_file} -> {csv_name}")
            except Exception as e3:
                logging.error(f"Error writing CSV {csv_name}: {e3}")

            # Optionally remove the intermediate .txt
            try:
                temp_txt_path.unlink()
            except:
                pass

    return created_csvs

def read_all_master_csvs(csv_paths: List[Path]) -> pd.DataFrame:
    """
    Step 2: Read all created CSVs, combine them into one DataFrame.
    We also insert 'Dimension' from the filename (like old logic).
    """
    dfs = []
    for csvf in csv_paths:
        df = read_csv_robust(csvf)
        if df.empty:
            continue
        # Derive dimension from filename
        base = csvf.stem
        if "_ceaster" in base.lower():
            base_dim = base.lower().replace("_ceaster", "")
        else:
            base_dim = base
        dimension = base_dim.replace("_", " ").title()

        # If no "Name" col, rename first col => "Name"
        if "Name" not in df.columns and len(df.columns) > 0:
            first_col = df.columns[0]
            df.rename(columns={first_col: "Name"}, inplace=True)

        df["Dimension"] = dimension
        dfs.append(df)
    if dfs:
        return pd.concat(dfs, ignore_index=True)
    else:
        return pd.DataFrame()

# ------------------------------------------------------------------------------
# 7) READING ERP
# ------------------------------------------------------------------------------
def read_erp_data(xlsx_path: Path) -> pd.DataFrame:
    if not xlsx_path.is_file():
        logging.warning(f"ERP Excel not found at {xlsx_path}")
        return pd.DataFrame()
    try:
        df = pd.read_excel(xlsx_path, skiprows=3)
        df.columns = df.columns.str.strip()
        return df
    except Exception as e:
        logging.error(f"Error reading ERP Excel: {e}")
        return pd.DataFrame()

# ------------------------------------------------------------------------------
# 8) MELTDOWN & COMPARISON
# ------------------------------------------------------------------------------
def meltdown_erp(df: pd.DataFrame) -> pd.DataFrame:
    if df.empty:
        return df
    keep_cols = [c for c in df.columns if c not in ["Col1", "Col2", "Enabled_Flag"]]
    id_vars = []
    for c in ["Dimension_Name", "Value"]:
        if c in keep_cols:
            id_vars.append(c)
    value_vars = [c for c in keep_cols if c not in id_vars]
    melted = df.melt(id_vars=id_vars, value_vars=value_vars, var_name="Attribute", value_name="Value_melted")
    melted.rename(columns={
        "Dimension_Name": "Dimension",
        "Value": "RefName",
        "Value_melted": "Value"
    }, inplace=True)
    return melted[["Dimension", "RefName", "Attribute", "Value"]].copy()

def meltdown_master(df: pd.DataFrame) -> pd.DataFrame:
    if df.empty:
        return df
    keep_cols = df.columns.tolist()
    id_vars = [c for c in ["Dimension","Name"] if c in keep_cols]
    value_vars = [c for c in keep_cols if c not in id_vars]
    melted = df.melt(id_vars=id_vars, value_vars=value_vars, var_name="Attribute", value_name="Value")
    melted.rename(columns={"Name": "RefName"}, inplace=True)
    return melted[["Dimension","RefName","Attribute","Value"]].copy()

def build_keys(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    for col in ["Dimension","RefName","Attribute","Value"]:
        if col not in df.columns:
            df[col] = ""
        df[col] = df[col].fillna("").astype(str).str.strip()
    df["GroupKey"] = df["Dimension"] + " | " + df["RefName"]
    df["Key"] = df["Dimension"] + " | " + df["RefName"] + " | " + df["Attribute"] + " | " + df["Value"]
    df["Comments_1"] = ""
    df["Comments_2"] = ""
    df["Action Item"] = ""
    df["Missing In"] = ""
    return df

def build_lookup_dict(df: pd.DataFrame) -> Dict[str,Dict[str,str]]:
    lookup = {}
    for gk, grp in df.groupby("GroupKey"):
        rec = {}
        if not grp.empty:
            ref = grp["RefName"].iloc[0]
        else:
            ref = ""
        rec["Name"] = ref
        for _, row in grp.iterrows():
            rec[row["Attribute"]] = row["Value"]
        lookup[gk] = rec
    return lookup

def compare_data(df_erp: pd.DataFrame, df_master: pd.DataFrame, mode: int) -> pd.DataFrame:
    erp_dict = build_lookup_dict(df_erp)
    mst_dict = build_lookup_dict(df_master)
    all_keys = set(erp_dict.keys()) | set(mst_dict.keys())
    results = []
    for gk in all_keys:
        dimension = gk.split(" | ")[0]
        a_data = erp_dict.get(gk, {})
        b_data = mst_dict.get(gk, {})
        name_a = a_data.get("Name","")
        name_b = b_data.get("Name","")

        if mode == 1:
            results.extend(compare_mode_1(dimension, name_a, name_b, a_data, b_data))
        elif mode == 2:
            results.extend(compare_mode_2(dimension, name_a, name_b, a_data, b_data))
        else:
            results.extend(compare_mode_3(dimension, name_a, name_b, a_data, b_data))

    df_diff = pd.DataFrame(results)
    if not df_diff.empty:
        df_diff["Key"] = (
            df_diff["Dimension"].str.strip() + " | " +
            df_diff["Name"].str.strip() + " | " +
            df_diff["Attribute"].str.strip() + " | " +
            df_diff["Value"].str.strip()
        )
    return df_diff

def compare_mode_1(dimension, name_a, name_b, a_data, b_data):
    results = []
    all_attrs = set(a_data.keys()) | set(b_data.keys())
    for attr in all_attrs:
        va = a_data.get(attr, "")
        vb = b_data.get(attr, "")
        if va != vb:
            if va and not vb:
                results.append({"Dimension": dimension, "Name": name_a, "Attribute": attr, "Value": va, "Missing In": "MASTER"})
            elif vb and not va:
                results.append({"Dimension": dimension, "Name": name_b, "Attribute": attr, "Value": vb, "Missing In": "ERP"})
            else:
                results.append({"Dimension": dimension, "Name": name_a, "Attribute": attr, "Value": va, "Missing In": "MASTER"})
                results.append({"Dimension": dimension, "Name": name_b, "Attribute": attr, "Value": vb, "Missing In": "ERP"})
    return results

def compare_mode_2(dimension, name_a, name_b, a_data, b_data):
    results = []
    if name_a and name_b and (name_a == name_b):
        all_attrs = (set(a_data.keys()) | set(b_data.keys())) - {"Name"}
        for attr in all_attrs:
            va = a_data.get(attr, "")
            vb = b_data.get(attr, "")
            if va != vb:
                if va and not vb:
                    results.append({"Dimension": dimension, "Name": name_a, "Attribute": attr, "Value": va, "Missing In": "MASTER"})
                elif vb and not va:
                    results.append({"Dimension": dimension, "Name": name_a, "Attribute": attr, "Value": vb, "Missing In": "ERP"})
                else:
                    results.append({"Dimension": dimension, "Name": name_a, "Attribute": attr, "Value": va, "Missing In": "MASTER"})
                    results.append({"Dimension": dimension, "Name": name_a, "Attribute": attr, "Value": vb, "Missing In": "ERP"})
    else:
        if name_a and not name_b:
            results.append({"Dimension": dimension, "Name": name_a, "Attribute": "Name", "Value": name_a, "Missing In": "MASTER"})
        elif name_b and not name_a:
            results.append({"Dimension": dimension, "Name": name_b, "Attribute": "Name", "Value": name_b, "Missing In": "ERP"})
    return results

def compare_mode_3(dimension, name_a, name_b, a_data, b_data):
    results = []
    all_attrs = set(a_data.keys()) | set(b_data.keys())
    for attr in all_attrs:
        va = a_data.get(attr, "")
        vb = b_data.get(attr, "")
        if va == vb:
            results.append({"Dimension": dimension, "Name": name_a if name_a else name_b, "Attribute": attr, "Value": va, "Missing In": ""})
        else:
            if va and not vb:
                results.append({"Dimension": dimension, "Name": name_a, "Attribute": attr, "Value": va, "Missing In": "MASTER"})
            elif vb and not va:
                results.append({"Dimension": dimension, "Name": name_b, "Attribute": attr, "Value": vb, "Missing In": "ERP"})
            else:
                results.append({"Dimension": dimension, "Name": name_a, "Attribute": attr, "Value": va, "Missing In": "MASTER"})
                results.append({"Dimension": dimension, "Name": name_b if name_b else name_a, "Attribute": attr, "Value": vb, "Missing In": "ERP"})
    return results

# ------------------------------------------------------------------------------
# 9) EXCEPTIONS
# ------------------------------------------------------------------------------
def read_exception_table(exc_path: Path) -> pd.DataFrame:
    if exc_path.is_file():
        try:
            return pd.read_excel(exc_path)
        except Exception as e:
            logging.error(f"Error reading exception table: {e}")
    return pd.DataFrame()

def merge_exceptions(df: pd.DataFrame, df_exc: pd.DataFrame) -> pd.DataFrame:
    if df.empty or df_exc.empty or "Key" not in df.columns:
        return df
    keep = [c for c in df_exc.columns if c in ["Key","Comments_1","Comments_2","hide exception"]]
    if not keep:
        return df
    exc = df_exc[keep].copy()
    exc["Key"] = exc["Key"].astype(str).str.strip()
    merged = df.merge(exc, on="Key", how="left", suffixes=("", "_exc"))
    merged["hide exception"] = merged.get("hide exception", "").fillna("").str.lower()
    final = merged[merged["hide exception"]!="yes"].copy()
    if "Comments_1_exc" in final.columns:
        final["Comments_1"] = np.where(final["Comments_1_exc"].notna(), final["Comments_1_exc"], final["Comments_1"])
        final.drop(columns=["Comments_1_exc"], inplace=True)
    if "Comments_2_exc" in final.columns:
        final["Comments_2"] = np.where(final["Comments_2_exc"].notna(), final["Comments_2_exc"], final["Comments_2"])
        final.drop(columns=["Comments_2_exc"], inplace=True)
    if "hide exception" in final.columns:
        final.drop(columns=["hide exception"], inplace=True)
    return final

# ------------------------------------------------------------------------------
# 10) WRITE RESULTS
# ------------------------------------------------------------------------------
def write_results(df: pd.DataFrame, out_path: Path, mode: int):
    if df.empty:
        logging.info("No differences to write => skipping file output.")
        return
    out_path.parent.mkdir(parents=True, exist_ok=True)
    final_cols = ["Key","Dimension","Name","Attribute","Value","Comments_1","Comments_2","Action Item","Missing In"]
    for c in final_cols:
        if c not in df.columns:
            df[c] = ""
    df = df[final_cols]

    wb = Workbook()
    max_rows_per_sheet = 30000 if mode == 3 else 999999
    sheet_count = 1
    start = 0
    while start < len(df):
        end = min(start + max_rows_per_sheet, len(df))
        chunk = df.iloc[start:end]
        if sheet_count == 1:
            ws = wb.active
            ws.title = f"Results{sheet_count}"
        else:
            ws = wb.create_sheet(title=f"Results{sheet_count}")
        ws.append(final_cols)
        for row in chunk.itertuples(index=False):
            ws.append(row)
        header_font = Font(bold=True)
        fill = PatternFill(start_color="DDDDDD", end_color="DDDDDD", fill_type="solid")
        for cell in ws[1]:
            cell.font = header_font
            cell.fill = fill
            cell.alignment = Alignment(horizontal="center")

        # Auto-col width
        for col in ws.columns:
            max_len = 0
            col_letter = col[0].column_letter
            for cell in col:
                val = str(cell.value) if cell.value is not None else ""
                max_len = max(max_len, len(val))
            ws.column_dimensions[col_letter].width = max_len + 2
        ws.freeze_panes = "A2"

        sheet_count += 1
        start = end

    wb.save(out_path)
    logging.info(f"Results saved to {out_path}")

# ------------------------------------------------------------------------------
# 11) MAIN APP
# ------------------------------------------------------------------------------
class MainApp(ctk.CTk):
    """
    The main GUI:
     - A tab for ERP (ExcelGrid)
     - A tab for Master (ExcelGrid) after .txt->.csv->DataFrame
     - A Compare & Exceptions tab
    """
    def __init__(self):
        super().__init__()
        self.title("TXT -> CSV (Robust), Then Reconciliation UI")
        self.geometry("1500x900")

        # Load config
        self.config_dict = load_config(Path(DEFAULT_PATHS["CONFIG_PATH"]))

        # Create Notebook
        self.notebook = ttk.Notebook(self)
        self.notebook.pack(fill="both", expand=True)

        # Tab 1: ERP
        self.tab_erp = ctk.CTkFrame(self.notebook)
        self.notebook.add(self.tab_erp, text="ERP (ALFA)")
        self.erp_grid = ExcelGrid(self.tab_erp, self.config_dict.get("erp_grid", {}), "ERP")
        self.erp_grid.pack(fill="both", expand=True)

        # Tab 2: MASTER
        self.tab_master = ctk.CTkFrame(self.notebook)
        self.notebook.add(self.tab_master, text="Master (GAMMA)")
        self.master_grid = ExcelGrid(self.tab_master, self.config_dict.get("master_grid", {}), "Master")
        self.master_grid.pack(fill="both", expand=True)

        # Tab 3: Compare & Exceptions
        self.tab_compare = ctk.CTkFrame(self.notebook)
        self.notebook.add(self.tab_compare, text="Compare & Exceptions")
        self.build_compare_tab(self.tab_compare)

        # Logging box
        self.log_box = ctk.CTkTextbox(self, height=120)
        self.log_box.pack(fill="both", expand=False)
        self.log_box.configure(state="disabled")
        handler = TextHandler(self.log_box)
        handler.setLevel(logging.INFO)
        logging.getLogger().addHandler(handler)

        # Load initial data
        self.refresh_erp_data()
        self.refresh_master_data()

    def build_compare_tab(self, parent):
        frame = ctk.CTkFrame(parent)
        frame.pack(fill="both", expand=True, padx=10, pady=10)

        # Row for Exceptions
        row1 = ctk.CTkFrame(frame)
        row1.pack(fill="x", pady=5)
        ctk.CTkLabel(row1, text="Exception Table:").pack(side="left", padx=5)
        self.exc_var = tk.StringVar(value=self.config_dict["paths"].get("EXCEPTION_PATH", DEFAULT_PATHS["EXCEPTION_PATH"]))
        ctk.CTkEntry(row1, textvariable=self.exc_var, width=600).pack(side="left", padx=5)
        ctk.CTkButton(row1, text="Browse", command=lambda: self.browse_file(self.exc_var)).pack(side="left", padx=5)

        # Row for Output
        row2 = ctk.CTkFrame(frame)
        row2.pack(fill="x", pady=5)
        ctk.CTkLabel(row2, text="Output Path:").pack(side="left", padx=5)
        self.out_var = tk.StringVar(value=self.config_dict["paths"].get("OUTPUT_PATH", DEFAULT_PATHS["OUTPUT_PATH"]))
        ctk.CTkEntry(row2, textvariable=self.out_var, width=600).pack(side="left", padx=5)
        ctk.CTkButton(row2, text="Browse", command=lambda: self.browse_file(self.out_var)).pack(side="left", padx=5)

        # Comparison modes
        self.mode_var = tk.IntVar(value=self.config_dict.get("comparison_option", 1))
        for i, label in enumerate([
            "Option 1: Show everything missing in ERP or MASTER",
            "Option 2: If Name missing, skip attributes; else show missing attributes",
            "Option 3: Show missing + matching"
        ], start=1):
            ctk.CTkRadioButton(frame, text=label, variable=self.mode_var, value=i).pack(anchor="w", padx=15, pady=2)

        # Buttons
        btnf = ctk.CTkFrame(frame)
        btnf.pack(fill="x", pady=10)
        ctk.CTkButton(btnf, text="Run Comparison", command=self.run_comparison).pack(side="left", padx=5)
        ctk.CTkButton(btnf, text="Save Config", command=self.save_all_config).pack(side="left", padx=5)

    def browse_file(self, var: tk.StringVar):
        p = filedialog.askopenfilename()
        if p:
            var.set(p)

    def refresh_erp_data(self):
        erp_path = Path(self.config_dict["paths"].get("ERP_EXCEL_PATH", DEFAULT_PATHS["ERP_EXCEL_PATH"]))
        df_erp = read_erp_data(erp_path)
        self.erp_grid.set_data(df_erp)

    def refresh_master_data(self):
        """
        Step 1: Convert all .txt from Master ZIP => .csv with robust encoding tries
        Step 2: Read .csv => single DataFrame
        Step 3: Display in master_grid
        """
        zip_path = Path(self.config_dict["paths"].get("MASTER_ZIP_PATH", DEFAULT_PATHS["MASTER_ZIP_PATH"]))
        out_dir = Path(self.config_dict["paths"].get("MASTER_CSV_OUTPUT", DEFAULT_PATHS["MASTER_CSV_OUTPUT"]))

        created_csvs = convert_master_txt_to_csv(zip_path, out_dir)
        if not created_csvs:
            logging.warning("No CSVs created from Master .txt => empty DataFrame.")
            df_master = pd.DataFrame()
        else:
            df_master = read_all_master_csvs(created_csvs)

        self.master_grid.set_data(df_master)

    def run_comparison(self):
        self.config_dict["paths"]["EXCEPTION_PATH"] = self.exc_var.get().strip()
        self.config_dict["paths"]["OUTPUT_PATH"] = self.out_var.get().strip()
        self.config_dict["comparison_option"] = self.mode_var.get()

        df_erp_filtered = self.erp_grid.get_filtered_df()
        df_master_filtered = self.master_grid.get_filtered_df()

        # meltdown
        erp_m = meltdown_erp(df_erp_filtered)
        erp_m = build_keys(erp_m)
        mst_m = meltdown_master(df_master_filtered)
        mst_m = build_keys(mst_m)

        # compare
        mode = self.mode_var.get()
        df_diff = compare_data(erp_m, mst_m, mode)

        # exceptions
        exc_path = Path(self.exc_var.get().strip())
        df_exc = read_exception_table(exc_path)
        final = merge_exceptions(df_diff, df_exc)

        # write results
        out_path = Path(self.out_var.get().strip())
        write_results(final, out_path, mode)
        messagebox.showinfo("Done", f"Comparison complete! Results => {out_path}")

    def save_all_config(self):
        # store erp_grid + master_grid config
        self.config_dict["erp_grid"] = self.erp_grid.get_config_block()
        self.config_dict["master_grid"] = self.master_grid.get_config_block()

        self.config_dict["paths"]["EXCEPTION_PATH"] = self.exc_var.get().strip()
        self.config_dict["paths"]["OUTPUT_PATH"] = self.out_var.get().strip()
        self.config_dict["comparison_option"] = self.mode_var.get()

        save_config(self.config_dict, Path(self.config_dict["paths"].get("CONFIG_PATH", DEFAULT_PATHS["CONFIG_PATH"])))

# ------------------------------------------------------------------------------
# 12) MAIN
# ------------------------------------------------------------------------------
def main():
    app = MainApp()
    app.mainloop()

if __name__ == "__main__":
    main()
