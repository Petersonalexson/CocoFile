#!/usr/bin/env python3
"""
ULTRA-MEGA Data Reconciliation Script with customtkinter GUI
-------------------------------------------------------------
Features:
  - Modern-looking GUI using customtkinter (Light mode).
  - Multi-tab interface using CTkTabview.
  - Scrollable frames for tabs that may contain many widgets.
  - Centered treeviews (for exclusions/renames and keep rules).
  - Data reconciliation: reading Alfa Excel, Gamma ZIP, and optional Exception Table;
    transformation (filtering, melting, renaming, key building) and Excel output with color coding.
  - Interactive charts:
      • Matplotlib bar charts with mplcursors (sized 12x8 inches).
      • Plotly pie charts embedded in an HTMLLabel.
  
Customize the default paths and filtering/renaming rules as needed.
"""

import customtkinter as ctk
import tkinter as tk
from tkinter import ttk, filedialog, simpledialog, scrolledtext
import logging
import os
import zipfile
from pathlib import Path
from typing import List, Dict, Tuple, Optional

import pandas as pd

# Use TkAgg so that mplcursors works properly
import matplotlib
matplotlib.use("TkAgg")
import matplotlib.pyplot as plt
import mplcursors  # for interactive tooltips on bar charts

import plotly.express as px
from tkhtmlview import HTMLLabel

from openpyxl import load_workbook
from openpyxl.styles import PatternFill, Font

# -------------------------
# Appearance settings for customtkinter
# -------------------------
ctk.set_appearance_mode("Light")  # options: "Light", "Dark", "System"
ctk.set_default_color_theme("blue")

# =============================================================================
# DEFAULT PARAMETERS (EDIT AS NEEDED)
# =============================================================================

#: Default file paths
DEFAULT_ALFA_PATH     = "AlfaData.xlsx"
DEFAULT_GAMMA_PATH    = "GammaData.zip"
DEFAULT_EXC_PATH      = "Exception_Table.xlsx"
DEFAULT_OUTPUT_PATH   = "Missing_Items.xlsx"

#: Default "Bad Dims" and "Bad Attrs" for Alfa & Gamma
DEFAULT_ALFA_BAD_DIMS  = ["AlfaDimX"]
DEFAULT_ALFA_BAD_ATTRS = ["AlfaAttrY"]
DEFAULT_GAMMA_BAD_DIMS = ["GammaDimX"]
DEFAULT_GAMMA_BAD_ATTRS = ["GammaAttrY"]

#: Default dimension/attribute renames (as (old, new) pairs)
DEFAULT_ALFA_DIM_RENAMES  = [("DimOldA", "DimNewA")]
DEFAULT_ALFA_ATTR_RENAMES = [("AttrOldA", "AttrNewA")]
DEFAULT_GAMMA_DIM_RENAMES = [("DimOldG", "DimNewG")]
DEFAULT_GAMMA_ATTR_RENAMES = [("AttrOldG", "AttrNewG")]

#: Default Keep & Disallow rules
DEFAULT_ALFA_KEEP_AND   = [("AlfaKeepCol1", "ValA,ValB")]
DEFAULT_ALFA_DISALLOW   = [("AlfaNegCol", "Bad1")]
DEFAULT_GAMMA_KEEP_OR   = [("GammaKeepCol1", "X,Y")]
DEFAULT_GAMMA_DISALLOW  = [("GammaNegCol", "Z")]

#: Log file
LOG_FILE = Path("script.log")

# =============================================================================
# LOGGING SETUP
# =============================================================================
def setup_logging() -> None:
    """Sets up logging to console (INFO) and file (DEBUG)."""
    logger = logging.getLogger()
    logger.setLevel(logging.DEBUG)
    logger.handlers.clear()

    ch = logging.StreamHandler()
    ch.setLevel(logging.INFO)
    ch_fmt = logging.Formatter("%(levelname)s: %(message)s")
    ch.setFormatter(ch_fmt)
    logger.addHandler(ch)

    fh = logging.FileHandler(LOG_FILE, mode="w", encoding="utf-8")
    fh.setLevel(logging.DEBUG)
    fh_fmt = logging.Formatter("%(asctime)s - %(levelname)s - %(message)s")
    fh.setFormatter(fh_fmt)
    logger.addHandler(fh)

    logging.debug("Logging Initialized.")

# =============================================================================
# DATA TRANSFORMATION FUNCTIONS
# =============================================================================
def filter_pre_melt(df: pd.DataFrame,
                    exclude_rules: Optional[List[Tuple[str, List[str]]]] = None) -> pd.DataFrame:
    """Exclude rows if a given column contains any bad values, before melting."""
    df = df.copy(deep=True)
    if not exclude_rules:
        return df

    combined_mask = pd.Series(False, index=df.index)
    for col, badvals in exclude_rules:
        if col in df.columns:
            mask = df[col].isin(badvals)
            combined_mask |= mask
        else:
            logging.warning(f"[Pre-Melt] Column '{col}' not found; skipping rule {badvals}")
    return df[~combined_mask].copy(deep=True)

def exclude_dimension_attribute(df: pd.DataFrame,
                                bad_dimensions: Optional[List[str]] = None,
                                bad_attributes: Optional[List[str]] = None) -> pd.DataFrame:
    """Exclude rows whose Dimension or Attribute are in the provided bad lists."""
    df = df.copy(deep=True)
    if bad_dimensions:
        init = len(df)
        df = df[~df["Dimension"].isin(bad_dimensions)]
        logging.debug(f"[ExcludeDimAttr] Removed {init - len(df)} rows by dims {bad_dimensions}")
    if bad_attributes:
        init = len(df)
        df = df[~df["Attribute"].isin(bad_attributes)]
        logging.debug(f"[ExcludeDimAttr] Removed {init - len(df)} rows by attrs {bad_attributes}")
    return df

def filter_alfa_keep_and_disallow(df: pd.DataFrame,
                                  keep_rules: List[Tuple[str, str]],
                                  disallow_rules: List[Tuple[str, str]]) -> pd.DataFrame:
    """
    For Alfa:
      - Keep rows only if ALL allowed values (AND) are satisfied.
      - Exclude rows if ANY disallowed value (OR) is present.
    """
    df = df.copy(deep=True)
    if keep_rules:
        combined_keep = pd.Series(True, index=df.index)
        for col, val_str in keep_rules:
            if col not in df.columns:
                logging.warning(f"[AlfaKeep] Column '{col}' missing; skipping rule {val_str}")
                continue
            allowed = {v.strip() for v in val_str.split(",") if v.strip()}
            combined_keep &= df[col].isin(allowed)
        df = df[combined_keep].copy(deep=True)
    if disallow_rules:
        combined_neg = pd.Series(False, index=df.index)
        for col, val_str in disallow_rules:
            if col not in df.columns:
                logging.warning(f"[AlfaDisallow] Column '{col}' missing; skipping rule {val_str}")
                continue
            not_allowed = {v.strip() for v in val_str.split(",") if v.strip()}
            combined_neg |= df[col].isin(not_allowed)
        df = df[~combined_neg].copy(deep=True)
    return df

def filter_gamma_keep_and_disallow(df: pd.DataFrame,
                                   keep_rules: List[Tuple[str, str]],
                                   disallow_rules: List[Tuple[str, str]]) -> pd.DataFrame:
    """
    For Gamma:
      - Keep rows if ANY allowed value (OR) is present.
      - Exclude rows if ANY disallowed value (OR) is present.
    """
    df = df.copy(deep=True)
    if keep_rules:
        combined_keep = pd.Series(False, index=df.index)
        for col, val_str in keep_rules:
            if col not in df.columns:
                logging.warning(f"[GammaKeep] Column '{col}' missing; skipping rule {val_str}")
                continue
            allowed = {v.strip() for v in val_str.split(",") if v.strip()}
            combined_keep |= df[col].isin(allowed)
        df = df[combined_keep].copy(deep=True)
    if disallow_rules:
        combined_neg = pd.Series(False, index=df.index)
        for col, val_str in disallow_rules:
            if col not in df.columns:
                logging.warning(f"[GammaDisallow] Column '{col}' missing; skipping rule {val_str}")
                continue
            not_allowed = {v.strip() for v in val_str.split(",") if v.strip()}
            combined_neg |= df[col].isin(not_allowed)
        df = df[~combined_neg].copy(deep=True)
    return df

def transform_alfa(file_path: Path,
                   alfa_keep_and: List[Tuple[str, str]],
                   alfa_disallow: List[Tuple[str, str]],
                   pre_melt_exclude_rules: List[Tuple[str, List[str]]],
                   bad_dimensions: List[str],
                   bad_attributes: List[str],
                   dimension_rename: Dict[str, str],
                   attribute_rename: Dict[str, str],
                   sheet_name: str = "Sheet1",
                   skip_rows: int = 3) -> pd.DataFrame:
    """
    Reads Alfa Excel file, applies rules, melts the DataFrame, renames columns,
    excludes bad dimensions/attributes, and creates keys.
    """
    if not file_path.is_file():
        logging.error(f"[Alfa] File not found: {file_path}")
        return pd.DataFrame()
    try:
        df = pd.read_excel(file_path, sheet_name=sheet_name, skiprows=skip_rows).copy(deep=True)
        logging.info(f"[Alfa] Loaded {len(df)} rows from '{file_path.name}'")
        if "Dimension_Name" in df.columns:
            df.rename(columns={"Dimension_Name": "Dimension"}, inplace=True)
        else:
            third_col = df.columns[2]
            df.rename(columns={third_col: "Dimension"}, inplace=True)
        if "Name" not in df.columns:
            fourth_col = df.columns[3]
            df.rename(columns={fourth_col: "Name"}, inplace=True)
        df["RecordID"] = df.index.astype(str)
        df = filter_alfa_keep_and_disallow(df, alfa_keep_and, alfa_disallow)
        df = filter_pre_melt(df, pre_melt_exclude_rules)
        id_vars = ["Dimension", "RecordID"]
        value_vars = [c for c in df.columns if c not in id_vars]
        melted = df.melt(id_vars=id_vars, value_vars=value_vars,
                         var_name="Attribute", value_name="Value")
        if dimension_rename:
            melted["Dimension"] = melted["Dimension"].replace(dimension_rename)
        if attribute_rename:
            melted["Attribute"] = melted["Attribute"].replace(attribute_rename)
        melted = exclude_dimension_attribute(melted, bad_dimensions, bad_attributes)
        ref_df = melted[melted["Attribute"] == "Name"][["RecordID", "Value"]].drop_duplicates("RecordID")
        ref_df.rename(columns={"Value": "RefName"}, inplace=True)
        melted = melted.merge(ref_df, on="RecordID", how="left")
        for col in ("Dimension", "Attribute", "Value", "RefName"):
            melted[col] = melted[col].fillna("").astype(str)
        melted["GroupKey"] = melted["Dimension"].str.strip() + " | " + melted["RefName"].str.strip()
        melted["Key"] = (melted["Dimension"].str.strip() + " | " +
                         melted["RefName"].str.strip() + " | " +
                         melted["Attribute"].str.strip() + " | " +
                         melted["Value"].str.strip())
        melted.drop_duplicates(inplace=True)
        logging.info(f"[Alfa] Final data has {len(melted)} rows.")
        return melted
    except Exception as e:
        logging.exception(f"[Alfa] Error during transformation: {e}")
        return pd.DataFrame()

def transform_gamma(zip_file_path: Path,
                    gamma_keep_or: List[Tuple[str, str]],
                    gamma_disallow: List[Tuple[str, str]],
                    pre_melt_exclude_rules: List[Tuple[str, List[str]]],
                    bad_dimensions: List[str],
                    bad_attributes: List[str],
                    dimension_rename: Dict[str, str],
                    attribute_rename: Dict[str, str],
                    delimiter: str = ",",
                    remove_substring: str = "_ceaster.txt",
                    encoding: str = "utf-8") -> pd.DataFrame:
    """
    Reads Gamma data from a ZIP file (of .txt files) and processes it similarly to Alfa.
    """
    if not zip_file_path.is_file():
        logging.error(f"[Gamma] ZIP file not found: {zip_file_path}")
        return pd.DataFrame()
    all_dfs = []
    try:
        with zipfile.ZipFile(zip_file_path, "r") as z:
            txt_files = [f for f in z.namelist() if f.lower().endswith(".txt")]
            if not txt_files:
                logging.warning("[Gamma] No .txt files found; returning empty DataFrame.")
                return pd.DataFrame()
            for txt_file in txt_files:
                try:
                    base_name = os.path.basename(txt_file)
                    if remove_substring in base_name:
                        base_name = base_name.replace(remove_substring, "")
                    else:
                        base_name, _ = os.path.splitext(base_name)
                    dimension = base_name.replace("_", " ").strip()
                    with z.open(txt_file) as fo:
                        df = pd.read_csv(fo, delimiter=delimiter, encoding=encoding).copy(deep=True)
                    if df.empty:
                        logging.warning(f"[Gamma] '{txt_file}' is empty; skipping.")
                        continue
                    first_col = df.columns[0]
                    df.rename(columns={first_col: "Name"}, inplace=True)
                    df["Name"] = df["Name"].fillna("Unknown").astype(str)
                    df = filter_gamma_keep_and_disallow(df, gamma_keep_or, gamma_disallow)
                    df = filter_pre_melt(df, pre_melt_exclude_rules)
                    df["Dimension"] = dimension
                    df["RecordID"] = df.index.astype(str)
                    id_vars = ["Dimension", "RecordID"]
                    value_vars = [c for c in df.columns if c not in id_vars]
                    melted = df.melt(id_vars=id_vars, value_vars=value_vars,
                                     var_name="Attribute", value_name="Value")
                    if dimension_rename:
                        melted["Dimension"] = melted["Dimension"].replace(dimension_rename)
                    if attribute_rename:
                        melted["Attribute"] = melted["Attribute"].replace(attribute_rename)
                    melted = exclude_dimension_attribute(melted, bad_dimensions, bad_attributes)
                    ref_df = melted[melted["Attribute"] == "Name"][["RecordID", "Value"]].drop_duplicates("RecordID")
                    ref_df.rename(columns={"Value": "RefName"}, inplace=True)
                    melted = melted.merge(ref_df, on="RecordID", how="left")
                    for col in ("Dimension", "Attribute", "Value", "RefName"):
                        melted[col] = melted[col].fillna("").astype(str)
                    melted["GroupKey"] = melted["Dimension"].str.strip() + " | " + melted["RefName"].str.strip()
                    melted["Key"] = (melted["Dimension"].str.strip() + " | " +
                                     melted["RefName"].str.strip() + " | " +
                                     melted["Attribute"].str.strip() + " | " +
                                     melted["Value"].str.strip())
                    melted.drop_duplicates(inplace=True)
                    logging.info(f"[Gamma] Processed '{txt_file}' with {len(melted)} rows.")
                    all_dfs.append(melted.copy(deep=True))
                except Exception as e2:
                    logging.error(f"[Gamma] Error processing '{txt_file}': {e2}")
                    continue
        if all_dfs:
            df_gamma = pd.concat(all_dfs, ignore_index=True)
            logging.info(f"[Gamma] Combined data has {len(df_gamma)} rows.")
            return df_gamma
        else:
            logging.warning("[Gamma] No valid data found; returning empty DataFrame.")
            return pd.DataFrame()
    except Exception as e:
        logging.exception(f"[Gamma] Error reading ZIP file: {e}")
        return pd.DataFrame()

def create_missing_items_excel(df_alfa: pd.DataFrame,
                               df_gamma: pd.DataFrame,
                               df_exceptions: pd.DataFrame,
                               output_path: Path) -> pd.DataFrame:
    """
    Compares Alfa and Gamma data, builds a DataFrame of mismatches,
    writes an Excel file with color coding, and returns the missing items DataFrame.
    """
    def build_map(df: pd.DataFrame) -> Dict[str, Dict[str, str]]:
        out = {}
        for gk, s_df in df.groupby("GroupKey"):
            row_map = {}
            for attr, sub_sub in s_df.groupby("Attribute"):
                row_map[attr] = str(sub_sub["Value"].iloc[0])
            out[gk] = row_map
        return out

    df_missing = pd.DataFrame()
    if "GroupKey" not in df_alfa.columns or "GroupKey" not in df_gamma.columns:
        logging.error("[Missing Items] 'GroupKey' column missing; returning empty DataFrame.")
        return df_missing

    alfa_map = build_map(df_alfa)
    gamma_map = build_map(df_gamma)
    all_keys = set(alfa_map.keys()).union(set(gamma_map.keys()))
    items = []

    for group_key in all_keys:
        a_dict = alfa_map.get(group_key)
        g_dict = gamma_map.get(group_key)
        parts = group_key.split(" | ", maxsplit=1)
        dimension = parts[0] if len(parts) > 0 else ""
        ref_name = parts[1] if len(parts) > 1 else ""
        if a_dict is None and g_dict is not None:
            if "Name" in g_dict:
                items.append({
                    "Dimension": dimension, "Name": g_dict["Name"],
                    "Attribute": "Name", "Value": g_dict["Name"],
                    "Missing In": "Alfa"
                })
            continue
        if g_dict is None and a_dict is not None:
            if "Name" in a_dict:
                items.append({
                    "Dimension": dimension, "Name": a_dict["Name"],
                    "Attribute": "Name", "Value": a_dict["Name"],
                    "Missing In": "Gamma"
                })
            continue
        if a_dict and g_dict:
            has_name_a = ("Name" in a_dict)
            has_name_g = ("Name" in g_dict)
            if not has_name_a and has_name_g:
                items.append({
                    "Dimension": dimension, "Name": g_dict["Name"],
                    "Attribute": "Name", "Value": g_dict["Name"],
                    "Missing In": "Alfa"
                })
                continue
            if not has_name_g and has_name_a:
                items.append({
                    "Dimension": dimension, "Name": a_dict["Name"],
                    "Attribute": "Name", "Value": a_dict["Name"],
                    "Missing In": "Gamma"
                })
                continue
            all_attrs = set(a_dict.keys()).union(set(g_dict.keys()))
            if "Name" in all_attrs:
                all_attrs.remove("Name")
            for attr in all_attrs:
                a_val = a_dict.get(attr)
                g_val = g_dict.get(attr)
                if a_val is None and g_val is not None:
                    items.append({
                        "Dimension": dimension, "Name": g_dict["Name"],
                        "Attribute": attr, "Value": g_val,
                        "Missing In": "Alfa"
                    })
                elif g_val is None and a_val is not None:
                    items.append({
                        "Dimension": dimension, "Name": a_dict["Name"],
                        "Attribute": attr, "Value": a_val,
                        "Missing In": "Gamma"
                    })
                elif a_val != g_val:
                    items.append({
                        "Dimension": dimension, "Name": a_dict["Name"],
                        "Attribute": attr, "Value": a_val,
                        "Missing In": "Gamma"
                    })
                    items.append({
                        "Dimension": dimension, "Name": a_dict["Name"],
                        "Attribute": attr, "Value": g_val,
                        "Missing In": "Alfa"
                    })

    df_missing = pd.DataFrame(items)
    logging.info(f"[Missing Items] Found {len(df_missing)} mismatched rows.")

    if df_missing.empty:
        logging.info("[Missing Items] No differences found; writing empty Excel.")
        empty_cols = ["Key", "Dimension", "Name", "Attribute", "Value",
                      "Comments_1", "Comments_2", "Action Item", "Missing In"]
        pd.DataFrame(columns=empty_cols).to_excel(output_path, sheet_name="Missing_Items", index=False)
        return df_missing

    for c in ("Dimension", "Name", "Attribute", "Value"):
        df_missing[c] = df_missing[c].fillna("")

    df_missing["Key"] = (df_missing["Dimension"].str.strip() + " | " +
                         df_missing["Name"].str.strip() + " | " +
                         df_missing["Attribute"].str.strip() + " | " +
                         df_missing["Value"].str.strip())

    df_exceptions = df_exceptions.copy(deep=True)
    if not df_exceptions.empty:
        val_cols = {"Key", "Comments_1", "Comments_2", "hide exception"}
        exc = df_exceptions[[x for x in df_exceptions.columns if x in val_cols]].copy()
        exc["Key"] = exc["Key"].astype(str).str.strip()
        df_missing = df_missing.merge(exc, on="Key", how="left", suffixes=("", "_exc"))
        df_missing["hide exception"] = df_missing["hide exception"].fillna("no").str.lower()
        before_len = len(df_missing)
        df_missing = df_missing[df_missing["hide exception"] != "yes"]
        logging.debug(f"[Missing Items] Excluded {before_len - len(df_missing)} hidden exception rows")

    if "Action Item" not in df_missing.columns:
        df_missing["Action Item"] = ""
    final_cols = ["Key", "Dimension", "Name", "Attribute", "Value",
                  "Comments_1", "Comments_2", "Action Item", "Missing In"]
    df_missing = df_missing.reindex(columns=final_cols)

    df_missing.to_excel(output_path, sheet_name="Missing_Items", index=False)
    logging.info(f"[Missing Items] Wrote {len(df_missing)} rows to {output_path}")

    try:
        wb = load_workbook(output_path)
        ws = wb["Missing_Items"]
        header_font = Font(bold=True)
        fill_header = PatternFill(start_color="E0E0E0", end_color="E0E0E0", fill_type="solid")
        fill_gamma = PatternFill(start_color="A6D96A", end_color="A6D96A", fill_type="solid")
        fill_alfa = PatternFill(start_color="67A9CF", end_color="67A9CF", fill_type="solid")

        header_row = next(ws.iter_rows(min_row=1, max_row=1))
        headers = {cell.value: cell.column for cell in header_row}
        for cell in header_row:
            cell.font = header_font
            cell.fill = fill_header

        missing_col = headers.get("Missing In")
        if missing_col is None:
            logging.warning("[Missing Items] 'Missing In' column not found; skipping color shading.")
        else:
            max_col = ws.max_column
            for row_idx in range(2, ws.max_row + 1):
                val = str(ws.cell(row=row_idx, column=missing_col).value).strip().lower()
                if val == "gamma":
                    fill = fill_gamma
                elif val == "alfa":
                    fill = fill_alfa
                else:
                    fill = None
                if fill:
                    for col_idx in range(1, max_col + 1):
                        ws.cell(row=row_idx, column=col_idx).fill = fill

        ws.freeze_panes = "A2"
        wb.save(output_path)
        logging.info("[Missing Items] Excel formatting completed.")
    except Exception as e:
        logging.exception(f"[Missing Items] Error during Excel formatting: {e}")

    return df_missing

def read_exception_table(exc_path: Path) -> pd.DataFrame:
    """Reads an Exception Table from an Excel file; returns empty DataFrame if not found."""
    if not exc_path or not exc_path.is_file():
        logging.warning(f"[Exception] Exception file not found: {exc_path}")
        return pd.DataFrame()
    try:
        df = pd.read_excel(exc_path, sheet_name="Sheet1")
        return df.copy(deep=True)
    except Exception as e:
        logging.exception(f"[Exception] Error reading exception table: {e}")
        return pd.DataFrame()

def run_reconciliation(
    alfa_path: Path,
    gamma_path: Path,
    exc_path: Optional[Path],
    alfa_keep_and: List[Tuple[str, str]],
    alfa_disallow: List[Tuple[str, str]],
    gamma_keep_or: List[Tuple[str, str]],
    gamma_disallow: List[Tuple[str, str]],
    alfa_exclude: List[Tuple[str, List[str]]],
    gamma_exclude: List[Tuple[str, List[str]]],
    alfa_bad_dims: List[str],
    alfa_bad_attrs: List[str],
    gamma_bad_dims: List[str],
    gamma_bad_attrs: List[str],
    alfa_dim_renames: Dict[str, str],
    alfa_attr_renames: Dict[str, str],
    gamma_dim_renames: Dict[str, str],
    gamma_attr_renames: Dict[str, str],
    output_path: Path
) -> pd.DataFrame:
    """Orchestrates the reconciliation process and returns the missing items DataFrame."""
    df_exceptions = read_exception_table(exc_path) if exc_path and exc_path.is_file() else pd.DataFrame()
    df_alfa = transform_alfa(
        file_path=alfa_path,
        alfa_keep_and=alfa_keep_and,
        alfa_disallow=alfa_disallow,
        pre_melt_exclude_rules=alfa_exclude,
        bad_dimensions=alfa_bad_dims,
        bad_attributes=alfa_bad_attrs,
        dimension_rename=alfa_dim_renames,
        attribute_rename=alfa_attr_renames
    )
    df_gamma = transform_gamma(
        zip_file_path=gamma_path,
        gamma_keep_or=gamma_keep_or,
        gamma_disallow=gamma_disallow,
        pre_melt_exclude_rules=gamma_exclude,
        bad_dimensions=gamma_bad_dims,
        bad_attributes=gamma_bad_attrs,
        dimension_rename=gamma_dim_renames,
        attribute_rename=gamma_attr_renames
    )
    df_missing = create_missing_items_excel(df_alfa, df_gamma, df_exceptions, output_path)
    return df_missing

# =============================================================================
# CUSTOM SCROLLABLE FRAME (for use within customtkinter)
# =============================================================================
class ScrollableFrame(ctk.CTkFrame):
    """
    A scrollable frame that uses an internal Canvas and vertical scrollbar.
    """
    def __init__(self, master, **kwargs):
        super().__init__(master, **kwargs)
        self.canvas = tk.Canvas(self, borderwidth=0, bg="white")
        self.v_scrollbar = ctk.CTkScrollbar(self, orientation="vertical", command=self.canvas.yview)
        self.canvas.configure(yscrollcommand=self.v_scrollbar.set)
        self.inner_frame = ctk.CTkFrame(self.canvas)
        self.inner_frame.bind(
            "<Configure>",
            lambda e: self.canvas.configure(scrollregion=self.canvas.bbox("all"))
        )
        self.canvas.create_window((0, 0), window=self.inner_frame, anchor="nw")
        self.canvas.pack(side="left", fill="both", expand=True)
        self.v_scrollbar.pack(side="right", fill="y")
        # Bind mouse wheel events for scrolling
        self.canvas.bind("<Enter>", lambda event: self._bind_mousewheel())
        self.canvas.bind("<Leave>", lambda event: self._unbind_mousewheel())

    def _bind_mousewheel(self):
        self.canvas.bind_all("<MouseWheel>", self._on_mousewheel)
        self.canvas.bind_all("<Button-4>", self._on_mousewheel)
        self.canvas.bind_all("<Button-5>", self._on_mousewheel)

    def _unbind_mousewheel(self):
        self.canvas.unbind_all("<MouseWheel>")
        self.canvas.unbind_all("<Button-4>")
        self.canvas.unbind_all("<Button-5>")

    def _on_mousewheel(self, event):
        if event.delta:
            self.canvas.yview_scroll(int(-1*(event.delta/120)), "units")
        elif event.num == 4:
            self.canvas.yview_scroll(-1, "units")
        elif event.num == 5:
            self.canvas.yview_scroll(1, "units")

# =============================================================================
# MAIN GUI APPLICATION (using customtkinter)
# =============================================================================
class ReconciliationApp(ctk.CTk):
    """
    The main application window using customtkinter.
    Contains a CTkTabview with tabs for Paths, Exclusions & Renames, Keep/DoNotKeep, Run & Progress, and Charts.
    """
    def __init__(self):
        super().__init__()
        self.title("ULTRA-MEGA Data Reconciliation (CustomTkinter GUI)")
        self.geometry("1400x1000")
        # Create a CTkTabview (modern tab widget from customtkinter)
        self.tabview = ctk.CTkTabview(self, width=1300, height=900)
        self.tabview.pack(expand=True, fill="both", padx=10, pady=10)
        # Add tabs
        self.tabview.add("Paths")
        self.tabview.add("Exclusions & Renames")
        self.tabview.add("Keep/DoNotKeep")
        self.tabview.add("Run & Progress")
        self.tabview.add("Charts & Analysis")
        # Build content in each tab
        self.build_tab_paths(self.tabview.tab("Paths"))
        self.build_tab_exclusions(self.tabview.tab("Exclusions & Renames"))
        self.build_tab_keep(self.tabview.tab("Keep/DoNotKeep"))
        self.build_tab_run(self.tabview.tab("Run & Progress"))
        self.build_tab_charts(self.tabview.tab("Charts & Analysis"))
        # Logging area at the bottom
        self.log_text = ctk.CTkTextbox(self, height=150)
        self.log_text.configure(state="disabled")
        self.log_text.pack(fill="both", padx=10, pady=(0,10))
        setup_logging()
        logging.info("[GUI] CustomTkinter app started.")
        self.df_missing = pd.DataFrame()
        # Populate defaults into treeviews
        self.populate_defaults()

    # -------------------------
    # Build Tab: Paths
    # -------------------------
    def build_tab_paths(self, parent: ctk.CTkFrame):
        for i in range(3):
            parent.grid_columnconfigure(i, weight=1)
        row = 0
        ctk.CTkLabel(parent, text="Alfa Excel (.xlsx):").grid(row=row, column=0, padx=5, pady=5, sticky="e")
        self.entry_alfa = ctk.CTkEntry(parent, width=400)
        self.entry_alfa.insert(0, DEFAULT_ALFA_PATH)
        self.entry_alfa.grid(row=row, column=1, padx=5, pady=5)
        ctk.CTkButton(parent, text="Browse", command=self.on_browse_alfa).grid(row=row, column=2, padx=5, pady=5)
        row += 1
        ctk.CTkLabel(parent, text="Gamma ZIP (.zip):").grid(row=row, column=0, padx=5, pady=5, sticky="e")
        self.entry_gamma = ctk.CTkEntry(parent, width=400)
        self.entry_gamma.insert(0, DEFAULT_GAMMA_PATH)
        self.entry_gamma.grid(row=row, column=1, padx=5, pady=5)
        ctk.CTkButton(parent, text="Browse", command=self.on_browse_gamma).grid(row=row, column=2, padx=5, pady=5)
        row += 1
        ctk.CTkLabel(parent, text="Exception Table (optional):").grid(row=row, column=0, padx=5, pady=5, sticky="e")
        self.entry_exc = ctk.CTkEntry(parent, width=400)
        self.entry_exc.insert(0, DEFAULT_EXC_PATH)
        self.entry_exc.grid(row=row, column=1, padx=5, pady=5)
        ctk.CTkButton(parent, text="Browse", command=self.on_browse_exc).grid(row=row, column=2, padx=5, pady=5)
        row += 1
        ctk.CTkLabel(parent, text="Output Missing Items (.xlsx):").grid(row=row, column=0, padx=5, pady=5, sticky="e")
        self.entry_out = ctk.CTkEntry(parent, width=400)
        self.entry_out.insert(0, DEFAULT_OUTPUT_PATH)
        self.entry_out.grid(row=row, column=1, padx=5, pady=5)
        ctk.CTkButton(parent, text="Browse", command=self.on_browse_out).grid(row=row, column=2, padx=5, pady=5)

    # -------------------------
    # Build Tab: Exclusions & Renames
    # -------------------------
    def build_tab_exclusions(self, parent: ctk.CTkFrame):
        # Use a scrollable frame for content that may overflow vertically
        sf = ScrollableFrame(parent)
        sf.pack(expand=True, fill="both", padx=5, pady=5)
        inner = sf.inner_frame
        # Configure three columns for label, treeview, and buttons
        for i in range(3):
            inner.grid_columnconfigure(i, weight=1)
        # Single-column treeviews for Bad Dims/Attrs
        self.tv_alfa_bad_dims  = self.create_singlecol_tree(inner, "Alfa Bad Dims", 0)
        self.tv_alfa_bad_attrs = self.create_singlecol_tree(inner, "Alfa Bad Attrs", 1)
        self.tv_gamma_bad_dims = self.create_singlecol_tree(inner, "Gamma Bad Dims", 2)
        self.tv_gamma_bad_attrs= self.create_singlecol_tree(inner, "Gamma Bad Attrs", 3)
        # Two-column treeviews for Renames
        self.tv_alfa_dim_ren = self.create_twocol_tree(inner, "Alfa Dim Renames", 4)
        self.tv_alfa_attr_ren= self.create_twocol_tree(inner, "Alfa Attr Renames", 5)
        self.tv_gamma_dim_ren= self.create_twocol_tree(inner, "Gamma Dim Renames", 6)
        self.tv_gamma_attr_ren= self.create_twocol_tree(inner, "Gamma Attr Renames", 7)

    # -------------------------
    # Build Tab: Keep/DoNotKeep
    # -------------------------
    def build_tab_keep(self, parent: ctk.CTkFrame):
        sf = ScrollableFrame(parent)
        sf.pack(expand=True, fill="both", padx=5, pady=5)
        inner = sf.inner_frame
        for i in range(3):
            inner.grid_columnconfigure(i, weight=1)
        self.tv_alfa_keep = self.create_keep_tree(inner, "Alfa Keep (AND)", 0)
        self.tv_alfa_neg  = self.create_keep_tree(inner, "Alfa DoNotKeep (OR)", 1)
        self.tv_gamma_keep= self.create_keep_tree(inner, "Gamma Keep (OR)", 2)
        self.tv_gamma_neg = self.create_keep_tree(inner, "Gamma DoNotKeep (OR)", 3)

    # -------------------------
    # Build Tab: Run & Progress
    # -------------------------
    def build_tab_run(self, parent: ctk.CTkFrame):
        ctk.CTkLabel(parent, text="Click 'Run' to start the reconciliation.").pack(padx=5, pady=5, anchor="w")
        self.progress_bar = ctk.CTkProgressBar(parent, width=600)
        self.progress_bar.set(0)
        self.progress_bar.pack(pady=5)
        btn_frame = ctk.CTkFrame(parent)
        btn_frame.pack(pady=5)
        ctk.CTkButton(btn_frame, text="Run", command=self.on_run_clicked).pack(side="left", padx=5)
        ctk.CTkButton(btn_frame, text="Exit", command=self.destroy).pack(side="left", padx=5)
        self.label_status = ctk.CTkLabel(parent, text="")
        self.label_status.pack(padx=5, pady=5, anchor="w")

    # -------------------------
    # Build Tab: Charts & Analysis
    # -------------------------
    def build_tab_charts(self, parent: ctk.CTkFrame):
        # Use a scrollable frame for charts if needed
        sf = ScrollableFrame(parent)
        sf.pack(expand=True, fill="both", padx=5, pady=5)
        inner = sf.inner_frame
        # Bar charts (matplotlib)
        ctk.CTkLabel(inner, text="Interactive Bar Charts (Matplotlib + mplcursors)", font=("Arial", 16)).pack(pady=5)
        self.canvas_bar_dim = ctk.CTkFrame(inner)
        self.canvas_bar_dim.pack(pady=5)
        self.canvas_bar_missing = ctk.CTkFrame(inner)
        self.canvas_bar_missing.pack(pady=5)
        self.canvas_bar_attr = ctk.CTkFrame(inner)
        self.canvas_bar_attr.pack(pady=5)
        # Pie charts (Plotly embedded in HTMLLabel)
        ctk.CTkLabel(inner, text="Interactive Pie Charts (Plotly)", font=("Arial", 16)).pack(pady=5)
        self.html_dim_pie = HTMLLabel(inner, width=800, background="white")
        self.html_dim_pie.pack(pady=5)
        self.html_missing_pie = HTMLLabel(inner, width=800, background="white")
        self.html_missing_pie.pack(pady=5)
        self.html_attr_pie = HTMLLabel(inner, width=800, background="white")
        self.html_attr_pie.pack(pady=5)

    # -------------------------
    # Helper methods to create treeviews
    # -------------------------
    def create_singlecol_tree(self, parent: tk.Widget, label_text: str, row: int) -> ttk.Treeview:
        # Create a frame for label, treeview, and buttons
        frame = ctk.CTkFrame(parent)
        frame.grid(row=row, column=0, columnspan=3, pady=5, padx=5, sticky="ew")
        frame.grid_columnconfigure(0, weight=1)
        ctk.CTkLabel(frame, text=label_text, font=("Arial", 12, "bold")).grid(row=0, column=0, sticky="w")
        tree_frame = ctk.CTkFrame(frame)
        tree_frame.grid(row=1, column=0, sticky="ew", padx=5)
        tv = ttk.Treeview(tree_frame, columns=("Value",), show="headings", height=4)
        tv.heading("Value", text="Value")
        tv.column("Value", width=200, anchor="center")
        scroll_y = ttk.Scrollbar(tree_frame, orient="vertical", command=tv.yview)
        tv.configure(yscrollcommand=scroll_y.set)
        scroll_y.pack(side="right", fill="y")
        tv.pack(side="left", fill="both", expand=True)
        btn_frame = ctk.CTkFrame(frame)
        btn_frame.grid(row=1, column=1, padx=5)
        ctk.CTkButton(btn_frame, text="Add", command=lambda: self.on_add_singlecol(tv)).pack(pady=2)
        ctk.CTkButton(btn_frame, text="Remove", command=lambda: self.on_remove_item(tv)).pack(pady=2)
        return tv

    def create_twocol_tree(self, parent: tk.Widget, label_text: str, row: int) -> ttk.Treeview:
        frame = ctk.CTkFrame(parent)
        frame.grid(row=row, column=0, columnspan=3, pady=5, padx=5, sticky="ew")
        frame.grid_columnconfigure(0, weight=1)
        ctk.CTkLabel(frame, text=label_text, font=("Arial", 12, "bold")).grid(row=0, column=0, sticky="w")
        tree_frame = ctk.CTkFrame(frame)
        tree_frame.grid(row=1, column=0, sticky="ew", padx=5)
        tv = ttk.Treeview(tree_frame, columns=("Old", "New"), show="headings", height=4)
        tv.heading("Old", text="Old")
        tv.heading("New", text="New")
        tv.column("Old", width=100, anchor="center")
        tv.column("New", width=100, anchor="center")
        scroll_y = ttk.Scrollbar(tree_frame, orient="vertical", command=tv.yview)
        tv.configure(yscrollcommand=scroll_y.set)
        scroll_y.pack(side="right", fill="y")
        tv.pack(side="left", fill="both", expand=True)
        btn_frame = ctk.CTkFrame(frame)
        btn_frame.grid(row=1, column=1, padx=5)
        ctk.CTkButton(btn_frame, text="Add", command=lambda: self.on_add_rename(tv)).pack(pady=2)
        ctk.CTkButton(btn_frame, text="Remove", command=lambda: self.on_remove_item(tv)).pack(pady=2)
        return tv

    def create_keep_tree(self, parent: tk.Widget, label_text: str, row: int) -> ttk.Treeview:
        frame = ctk.CTkFrame(parent)
        frame.grid(row=row, column=0, columnspan=3, pady=5, padx=5, sticky="ew")
        frame.grid_columnconfigure(0, weight=1)
        ctk.CTkLabel(frame, text=label_text, font=("Arial", 12, "bold")).grid(row=0, column=0, sticky="w")
        tree_frame = ctk.CTkFrame(frame)
        tree_frame.grid(row=1, column=0, sticky="ew", padx=5)
        tv = ttk.Treeview(tree_frame, columns=("Column", "Values"), show="headings", height=4)
        tv.heading("Column", text="Column")
        tv.heading("Values", text="Allowed Values (comma-sep)")
        tv.column("Column", width=120, anchor="center")
        tv.column("Values", width=200, anchor="center")
        scroll_y = ttk.Scrollbar(tree_frame, orient="vertical", command=tv.yview)
        tv.configure(yscrollcommand=scroll_y.set)
        scroll_y.pack(side="right", fill="y")
        tv.pack(side="left", fill="both", expand=True)
        btn_frame = ctk.CTkFrame(frame)
        btn_frame.grid(row=1, column=1, padx=5)
        ctk.CTkButton(btn_frame, text="Add", command=lambda: self.on_add_keep(tv)).pack(pady=2)
        ctk.CTkButton(btn_frame, text="Remove", command=lambda: self.on_remove_item(tv)).pack(pady=2)
        return tv

    # -------------------------
    # Callbacks for Treeview operations
    # -------------------------
    def on_add_singlecol(self, tv: ttk.Treeview):
        val = simpledialog.askstring("Add Value", "Enter new value:")
        if val and val.strip():
            tv.insert("", "end", values=(val.strip(),))

    def on_add_rename(self, tv: ttk.Treeview):
        oldval = simpledialog.askstring("Add Rename", "Enter OLD name:")
        if not oldval or not oldval.strip():
            return
        newval = simpledialog.askstring("Add Rename", f"Enter NEW name for '{oldval}':")
        if not newval or not newval.strip():
            return
        tv.insert("", "end", values=(oldval.strip(), newval.strip()))

    def on_add_keep(self, tv: ttk.Treeview):
        colname = simpledialog.askstring("Keep Rule", "Enter column name:")
        if not colname or not colname.strip():
            return
        valstr = simpledialog.askstring("Keep Rule", f"Enter comma-separated values for '{colname}':")
        if valstr is None:
            return
        tv.insert("", "end", values=(colname.strip(), valstr.strip()))

    def on_remove_item(self, tv: ttk.Treeview):
        for sel in tv.selection():
            tv.delete(sel)

    # -------------------------
    # Populate defaults into treeviews
    # -------------------------
    def populate_defaults(self):
        for val in DEFAULT_ALFA_BAD_DIMS:
            self.tv_alfa_bad_dims.insert("", "end", values=(val,))
        for val in DEFAULT_ALFA_BAD_ATTRS:
            self.tv_alfa_bad_attrs.insert("", "end", values=(val,))
        for val in DEFAULT_GAMMA_BAD_DIMS:
            self.tv_gamma_bad_dims.insert("", "end", values=(val,))
        for val in DEFAULT_GAMMA_BAD_ATTRS:
            self.tv_gamma_bad_attrs.insert("", "end", values=(val,))
        for oldv, newv in DEFAULT_ALFA_DIM_RENAMES:
            self.tv_alfa_dim_ren.insert("", "end", values=(oldv, newv))
        for oldv, newv in DEFAULT_ALFA_ATTR_RENAMES:
            self.tv_alfa_attr_ren.insert("", "end", values=(oldv, newv))
        for oldv, newv in DEFAULT_GAMMA_DIM_RENAMES:
            self.tv_gamma_dim_ren.insert("", "end", values=(oldv, newv))
        for oldv, newv in DEFAULT_GAMMA_ATTR_RENAMES:
            self.tv_gamma_attr_ren.insert("", "end", values=(oldv, newv))
        for c, v in DEFAULT_ALFA_KEEP_AND:
            self.tv_alfa_keep.insert("", "end", values=(c, v))
        for c, v in DEFAULT_ALFA_DISALLOW:
            self.tv_alfa_neg.insert("", "end", values=(c, v))
        for c, v in DEFAULT_GAMMA_KEEP_OR:
            self.tv_gamma_keep.insert("", "end", values=(c, v))
        for c, v in DEFAULT_GAMMA_DISALLOW:
            self.tv_gamma_neg.insert("", "end", values=(c, v))

    # -------------------------
    # Browse callbacks for file selection
    # -------------------------
    def on_browse_alfa(self):
        path = filedialog.askopenfilename(filetypes=[("Excel Files", "*.xlsx"), ("All Files", "*.*")])
        if path:
            self.entry_alfa.delete(0, "end")
            self.entry_alfa.insert(0, path)

    def on_browse_gamma(self):
        path = filedialog.askopenfilename(filetypes=[("ZIP Files", "*.zip"), ("All Files", "*.*")])
        if path:
            self.entry_gamma.delete(0, "end")
            self.entry_gamma.insert(0, path)

    def on_browse_exc(self):
        path = filedialog.askopenfilename(filetypes=[("Excel Files", "*.xlsx"), ("All Files", "*.*")])
        if path:
            self.entry_exc.delete(0, "end")
            self.entry_exc.insert(0, path)

    def on_browse_out(self):
        path = filedialog.asksaveasfilename(defaultextension=".xlsx",
                                            filetypes=[("Excel Files", "*.xlsx"), ("All Files", "*.*")])
        if path:
            self.entry_out.delete(0, "end")
            self.entry_out.insert(0, path)

    # -------------------------
    # Run the reconciliation process
    # -------------------------
    def on_run_clicked(self):
        logging.info("[GUI] 'Run' clicked.")
        self.progress_bar.set(0)
        self.label_status.configure(text="Processing... please wait")
        self.update()
        alfa_path_str = self.entry_alfa.get().strip()
        gamma_path_str = self.entry_gamma.get().strip()
        exc_path_str = self.entry_exc.get().strip()
        out_path_str = self.entry_out.get().strip()
        if not alfa_path_str or not os.path.isfile(alfa_path_str):
            self.label_status.configure(text="Error: invalid Alfa path")
            return
        if not gamma_path_str or not os.path.isfile(gamma_path_str):
            self.label_status.configure(text="Error: invalid Gamma path")
            return
        if not out_path_str.lower().endswith(".xlsx"):
            out_path_str += ".xlsx"
        # Gather values from treeviews
        alfa_bd = self.gather_singlecol(self.tv_alfa_bad_dims)
        alfa_ba = self.gather_singlecol(self.tv_alfa_bad_attrs)
        gamma_bd = self.gather_singlecol(self.tv_gamma_bad_dims)
        gamma_ba = self.gather_singlecol(self.tv_gamma_bad_attrs)
        alfa_dim_ren = self.gather_rename_pairs(self.tv_alfa_dim_ren)
        alfa_attr_ren = self.gather_rename_pairs(self.tv_alfa_attr_ren)
        gamma_dim_ren = self.gather_rename_pairs(self.tv_gamma_dim_ren)
        gamma_attr_ren = self.gather_rename_pairs(self.tv_gamma_attr_ren)
        alfa_keep = self.gather_keep_rules(self.tv_alfa_keep)
        alfa_neg = self.gather_keep_rules(self.tv_alfa_neg)
        gamma_keep = self.gather_keep_rules(self.tv_gamma_keep)
        gamma_neg = self.gather_keep_rules(self.tv_gamma_neg)
        try:
            df_missing = run_reconciliation(
                alfa_path=Path(alfa_path_str),
                gamma_path=Path(gamma_path_str),
                exc_path=Path(exc_path_str) if exc_path_str and os.path.isfile(exc_path_str) else None,
                alfa_keep_and=alfa_keep,
                alfa_disallow=alfa_neg,
                gamma_keep_or=gamma_keep,
                gamma_disallow=gamma_neg,
                alfa_exclude=[],  # add exclusion rules if needed
                gamma_exclude=[],
                alfa_bad_dims=alfa_bd,
                alfa_bad_attrs=alfa_ba,
                gamma_bad_dims=gamma_bd,
                gamma_bad_attrs=gamma_ba,
                alfa_dim_renames=alfa_dim_ren,
                alfa_attr_renames=alfa_attr_ren,
                gamma_dim_renames=gamma_dim_ren,
                gamma_attr_renames=gamma_attr_ren,
                output_path=Path(out_path_str)
            )
            self.df_missing = df_missing
            self.label_status.configure(text=f"Done! Missing items written to '{out_path_str}'.")
            self.generate_bar_charts()
            self.generate_pie_charts()
        except Exception as e:
            logging.exception(f"[GUI] Run error: {e}")
            self.label_status.configure(text=f"Error: {e}")

    def gather_singlecol(self, tv: ttk.Treeview) -> List[str]:
        out = []
        for child in tv.get_children():
            row = tv.item(child, "values")
            if row and len(row) == 1:
                out.append(row[0])
        return out

    def gather_rename_pairs(self, tv: ttk.Treeview) -> Dict[str, str]:
        out = {}
        for child in tv.get_children():
            row = tv.item(child, "values")
            if row and len(row) == 2:
                out[row[0].strip()] = row[1].strip()
        return out

    def gather_keep_rules(self, tv: ttk.Treeview) -> List[Tuple[str, str]]:
        out = []
        for child in tv.get_children():
            row = tv.item(child, "values")
            if row and len(row) == 2:
                out.append((row[0].strip(), row[1].strip()))
        return out

    # -------------------------
    # Generate Matplotlib Bar Charts (with mplcursors) in the Charts Tab
    # -------------------------
    def generate_bar_charts(self):
        # Clear previous content in the chart frames
        for container in (self.canvas_bar_dim, self.canvas_bar_missing, self.canvas_bar_attr):
            for widget in container.winfo_children():
                widget.destroy()
        if self.df_missing.empty:
            logging.info("[Charts] No missing items data for bar charts.")
            return
        from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg
        # Chart 1: Missing by Dimension
        by_dim = self.df_missing.groupby("Dimension").size().reset_index(name="Count")
        fig1, ax1 = plt.subplots(figsize=(12, 8))
        bars1 = ax1.bar(by_dim["Dimension"], by_dim["Count"], color="#5698c4")
        ax1.set_title("Missing by Dimension", fontsize=16)
        ax1.tick_params(axis='x', rotation=45)
        for i, v in enumerate(by_dim["Count"]):
            ax1.text(i, v + 0.05, str(v), ha="center", va="bottom")
        mplcursors.cursor(bars1, hover=True)
        fig1.tight_layout()
        canvas1 = FigureCanvasTkAgg(fig1, master=self.canvas_bar_dim)
        canvas1.draw()
        canvas1.get_tk_widget().pack(fill="both", expand=True)
        # Chart 2: Missing In
        by_miss = self.df_missing.groupby("Missing In").size().reset_index(name="Count")
        fig2, ax2 = plt.subplots(figsize=(12, 8))
        bars2 = ax2.bar(by_miss["Missing In"], by_miss["Count"], color="#a6d96a")
        ax2.set_title("Missing In", fontsize=16)
        for i, v in enumerate(by_miss["Count"]):
            ax2.text(i, v + 0.05, str(v), ha="center", va="bottom")
        mplcursors.cursor(bars2, hover=True)
        fig2.tight_layout()
        canvas2 = FigureCanvasTkAgg(fig2, master=self.canvas_bar_missing)
        canvas2.draw()
        canvas2.get_tk_widget().pack(fill="both", expand=True)
        # Chart 3: Missing by Attribute
        by_attr = self.df_missing.groupby("Attribute").size().reset_index(name="Count")
        fig3, ax3 = plt.subplots(figsize=(12, 8))
        bars3 = ax3.bar(by_attr["Attribute"], by_attr["Count"], color="#fdb863")
        ax3.set_title("Missing by Attribute", fontsize=16)
        ax3.tick_params(axis='x', rotation=45)
        for i, v in enumerate(by_attr["Count"]):
            ax3.text(i, v + 0.05, str(v), ha="center", va="bottom")
        mplcursors.cursor(bars3, hover=True)
        fig3.tight_layout()
        canvas3 = FigureCanvasTkAgg(fig3, master=self.canvas_bar_attr)
        canvas3.draw()
        canvas3.get_tk_widget().pack(fill="both", expand=True)

    # -------------------------
    # Generate Plotly Pie Charts in the Charts Tab
    # -------------------------
    def generate_pie_charts(self):
        if self.df_missing.empty:
            logging.info("[Charts] No missing items data for pie charts.")
            return
        # Pie chart for Dimension
        fig_dim = px.pie(self.df_missing, names="Dimension", title="Dimension Distribution (Missing)",
                         color_discrete_sequence=px.colors.sequential.Blues)
        fig_dim.update_layout(autosize=True)
        html_dim = fig_dim.to_html(full_html=True, include_plotlyjs="cdn", config={'responsive': True})
        self.html_dim_pie.set_html(html_dim)
        # Pie chart for Missing In
        fig_miss = px.pie(self.df_missing, names="Missing In", title="'Missing In' Distribution",
                          color_discrete_sequence=px.colors.sequential.Greens)
        fig_miss.update_layout(autosize=True)
        html_miss = fig_miss.to_html(full_html=True, include_plotlyjs="cdn", config={'responsive': True})
        self.html_missing_pie.set_html(html_miss)
        # Pie chart for Attribute
        fig_attr = px.pie(self.df_missing, names="Attribute", title="Attribute Distribution (Missing)",
                          color_discrete_sequence=px.colors.sequential.OrRd)
        fig_attr.update_layout(autosize=True)
        html_attr = fig_attr.to_html(full_html=True, include_plotlyjs="cdn", config={'responsive': True})
        self.html_attr_pie.set_html(html_attr)

def main():
    app = ReconciliationApp()
    app.mainloop()

if __name__ == "__main__":
    main()
