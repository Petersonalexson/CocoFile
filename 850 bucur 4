#!/usr/bin/env python3
"""
Ultra-Mega Reconciliation with:
- Name-as-attribute => If Name missing/diff => single row => skip other attributes
- 2-sheet (Mismatch + Case) + "Charts" sheet (openpyxl bar chart)
- SHIFTED PDF with 8 charts (Heatmap, Lollipop, Circular, Scatter, Radar, Normal Pie, Normal Bar, Bollinger)
- Future End Date toggle in SimplePreview => stored in config
- Trim Key toggle in Compare
- White data rows (only burgundy header) in missing_items.xlsx
- AdvancedDashboard with the 8 chart tabs
- HistoryTab loading older runs from JSON
"""

import os
import sys
import json
import logging
import zipfile
import shutil
import io
from pathlib import Path
from datetime import datetime, date
from typing import Dict, Set, List, Tuple

import tkinter as tk
from tkinter import ttk, filedialog, messagebox
import customtkinter as ctk

import pandas as pd
import numpy as np

import matplotlib
matplotlib.use("TkAgg")
import matplotlib.pyplot as plt
from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg, NavigationToolbar2Tk
from matplotlib.backends.backend_pdf import PdfPages

from openpyxl import Workbook
from openpyxl.styles import PatternFill, Font, Alignment
from openpyxl.utils import get_column_letter
from openpyxl.worksheet.table import Table, TableStyleInfo
from openpyxl.chart import BarChart, Reference

logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")


# ----------------------------------------------------------------------------
# DEFAULT CONFIG
# ----------------------------------------------------------------------------
DEFAULT_PATHS = {
    "ERP_EXCEL_PATH": "data/ERP_Config.xlsx",
    "MASTER_ZIP_PATH": "data/Master_Config.zip",
    "MASTER_TXT_FOLDER": "",
    "EXCEPTION_PATH": "data/Exception_Table.xlsx",
    "OUTPUT_PATH": "output/missing_items.xlsx",
    "CONFIG_PATH": "config/ui_config.json",
    "PARAMETER_PATH": "data/parameters.xlsx",
    "MASTER_CSV_OUTPUT": "temp_master_csv",
    "PDF_EXPORT_PATH": "output/dashboard_report.pdf",
    "LOGO_PATH": "images/company_logo.png",
    "HISTORY_PATH": "history_runs",
    "BAND_CHART_JSON_PATH": "data/bollinger_data.json"
}

def default_config() -> Dict:
    return {
        "paths": DEFAULT_PATHS.copy(),
        "erp_grid": {"filters": {}, "future_end_toggle": False},
        "master_grid": {"filters": {}, "future_end_toggle": False},
        "dashboard": {
            "selected_dims": [],
            "selected_attrs": [],
            "top_n": 10
        },
        "trim_key_toggle": False
    }

def load_config(path: Path)-> Dict:
    if path.is_file():
        try:
            with open(path,"r",encoding="utf-8") as f:
                return json.load(f)
        except Exception as e:
            logging.warning(f"Could not load config => {e}")
    return default_config()

def save_config(cfg: Dict, path: Path):
    path.parent.mkdir(parents=True, exist_ok=True)
    try:
        if "erp_grid" in cfg and "filters" in cfg["erp_grid"]:
            new_erp={}
            for c, svals in cfg["erp_grid"]["filters"].items():
                new_erp[c]= list(svals)
            cfg["erp_grid"]["filters"]= new_erp
        if "master_grid" in cfg and "filters" in cfg["master_grid"]:
            new_m={}
            for c, svals in cfg["master_grid"]["filters"].items():
                new_m[c]= list(svals)
            cfg["master_grid"]["filters"]= new_m

        with open(path,"w",encoding="utf-8") as f:
            json.dump(cfg,f,indent=2)
        logging.info(f"Saved config => {path}")
    except Exception as e:
        logging.error(f"Error saving config => {e}")


# ----------------------------------------------------------------------------
# TEXT LOGGER
# ----------------------------------------------------------------------------
class TextHandler(logging.Handler):
    def __init__(self, widget: ctk.CTkTextbox):
        super().__init__()
        self.widget= widget
    def emit(self, record):
        msg= self.format(record)+ "\n"
        self.widget.after(0, self._append, msg)
    def _append(self, msg):
        self.widget.configure(state="normal")
        self.widget.insert("end", msg)
        self.widget.see("end")
        self.widget.configure(state="disabled")


# ----------------------------------------------------------------------------
# READ PARAM
# ----------------------------------------------------------------------------
def read_param_file(path: Path)-> Dict[str, object]:
    param= {
        "dim_erp_keep": set(),
        "dim_erp_map": {},
        "dim_master_map": {},
        "attr_erp_map": {},
        "attr_master_map": {}
    }
    if not path.is_file():
        logging.warning(f"Param file => {path} not found")
        return param
    try:
        dim_df= pd.read_excel(path, sheet_name="Dimension Parameters")
        dim_df.columns= dim_df.columns.astype(str).str.strip()

        def s(x)-> str: return str(x).strip() if pd.notna(x) else ""
        for _, row in dim_df.iterrows():
            fn= s(row.get("FileName",""))
            vsc= s(row.get("V S C",""))
            dim= s(row.get("Dimension",""))
            ev= s(row.get("ERP Values",""))
            if ev.lower()=="x" and vsc and dim:
                param["dim_erp_keep"].add(vsc)
            if vsc and dim:
                param["dim_erp_map"][vsc]= dim
            if fn and dim and ev.lower()=="x":
                param["dim_master_map"][fn]= dim

        attr_df= pd.read_excel(path, sheet_name="Attribute Parameters")
        attr_df.columns= attr_df.columns.astype(str).str.strip()
        for _, row in attr_df.iterrows():
            e_orig= s(row.get("ERP Original Attributes",""))
            m_orig= s(row.get("Master Original Attributes",""))
            final_= s(row.get("Attribute",""))
            onoff= s(row.get("On/Off",""))
            if onoff.lower()=="x" and final_:
                if e_orig:
                    param["attr_erp_map"][e_orig]= final_
                if m_orig:
                    param["attr_master_map"][m_orig]= final_
        return param
    except Exception as e:
        logging.error(f"read_param_file => {e}")
        return param


# ----------------------------------------------------------------------------
# ERP
# ----------------------------------------------------------------------------
def read_erp_excel(path: Path)-> pd.DataFrame:
    if not path.is_file():
        logging.warning(f"ERP Excel => not found => {path}")
        return pd.DataFrame()
    try:
        df= pd.read_excel(path, skiprows=3)
        df.columns= df.columns.str.strip()
        if "Enabled_Flag" in df.columns:
            df= df[df["Enabled_Flag"]=="Enabled"]
        return df
    except Exception as e:
        logging.error(f"read_erp_excel => {e}")
        return pd.DataFrame()


# ----------------------------------------------------------------------------
# MASTER => local folder or zip
# ----------------------------------------------------------------------------
def try_read_csv_bytes(raw: bytes)-> pd.DataFrame:
    encs= ["utf-8-sig","utf-16-le","utf-16-be","cp1252","latin-1","ascii"]
    import io
    for e in encs:
        try:
            buf= io.BytesIO(raw)
            df= pd.read_csv(buf, encoding=e, on_bad_lines="skip", engine="python")
            df.dropna(how="all", axis=0, inplace=True)
            df.dropna(how="all", axis=1, inplace=True)
            df.columns= df.columns.astype(str).str.strip()
            if "Name" not in df.columns and len(df.columns)>0:
                fc= df.columns[0]
                df.rename(columns={fc:"Name"}, inplace=True)
            return df
        except:
            pass
    logging.error("All enc fail => empty DF")
    return pd.DataFrame()

def unify_master_txt_in_folder(folder: Path)-> pd.DataFrame:
    if not folder.is_dir():
        logging.warning(f"Master folder => not exist => {folder}")
        return pd.DataFrame()
    txts= list(folder.glob("*.txt"))
    frames=[]
    for f in txts:
        try:
            raw= f.read_bytes()
            df= try_read_csv_bytes(raw)
            if not df.empty:
                df["RawFileName"]= f.name
                frames.append(df)
        except Exception as e:
            logging.error(f"unify_master_txt_in_folder => {f} => {e}")
    if frames:
        return pd.concat(frames, ignore_index=True)
    return pd.DataFrame()

def convert_master_txt_to_csv(zip_path: Path, out_dir: Path)-> List[Path]:
    if not zip_path.is_file():
        logging.warning(f"Master ZIP => not found => {zip_path}")
        return []
    if out_dir.exists():
        shutil.rmtree(out_dir, ignore_errors=True)
    out_dir.mkdir(parents=True, exist_ok=True)
    csvs=[]
    with zipfile.ZipFile(zip_path,"r") as z:
        txt_files= [f for f in z.namelist() if f.lower().endswith(".txt")]
        for txtf in txt_files:
            bn= os.path.basename(txtf)
            if not bn:
                continue
            try:
                with z.open(txtf) as fo:
                    raw= fo.read()
                df= try_read_csv_bytes(raw)
                if df.empty:
                    continue
                df["RawFileName"]= bn
                out_csv= out_dir/(bn.replace(".txt",".csv"))
                df.to_csv(out_csv, index=False, encoding="utf-8")
                csvs.append(out_csv)
            except Exception as e:
                logging.error(f"Reading {txtf} => {e}")
    return csvs

def unify_master_csvs(csvs: List[Path])-> pd.DataFrame:
    frames=[]
    for cp in csvs:
        if not cp.is_file():
            continue
        try:
            df= pd.read_csv(cp, encoding="utf-8", on_bad_lines="skip")
            df.columns= df.columns.str.strip()
            frames.append(df)
        except Exception as e:
            logging.error(f"unify_master_csvs => {cp} => {e}")
    if frames:
        return pd.concat(frames, ignore_index=True)
    return pd.DataFrame()


# ----------------------------------------------------------------------------
# meltdown => meltdown_erp_for_preview, meltdown_master_for_preview
# ----------------------------------------------------------------------------
def meltdown_erp_for_preview(df: pd.DataFrame, param: Dict[str,object])-> pd.DataFrame:
    if "V_S_C" not in df.columns:
        return pd.DataFrame()
    keep= param["dim_erp_keep"]
    dmap= param["dim_erp_map"]
    amap= param["attr_erp_map"]

    df2= df[df["V_S_C"].isin(keep)].copy()
    if df2.empty:
        return pd.DataFrame()

    skip= {"V_S_C","Enabled_Flag"}
    idv=[]
    if "Value" in df2.columns:
        idv.append("Value")
        skip.add("Value")
    df2["DimRaw"]= df2["V_S_C"]
    skip.add("DimRaw")
    idv.insert(0,"DimRaw")

    meltdown_cols= [c for c in df2.columns if c not in skip]
    melted= df2.melt(
        id_vars=idv,
        value_vars= meltdown_cols,
        var_name="OrigAttr",
        value_name="ValX"
    )

    def rename_dim(x):
        return dmap.get(x,x)
    melted["Dimension"]= melted["DimRaw"].apply(rename_dim)

    if "Value" in idv:
        melted.rename(columns={"Value":"Name"}, inplace=True)
    else:
        melted["Name"]= ""

    def strip_t(v):
        if isinstance(v,str) and "T" in v:
            return v.split("T")[0]
        return v

    melted= melted[melted["OrigAttr"].isin(amap.keys())].copy()
    melted["Attribute"]= melted["OrigAttr"].map(amap)
    melted["Value"]= np.where(
        melted["Attribute"].isin(["Start Date","End Date"]),
        melted["ValX"].apply(strip_t),
        melted["ValX"]
    )
    return melted[["Dimension","Name","Attribute","Value"]]

def meltdown_master_for_preview(df: pd.DataFrame, param: Dict[str,object])-> pd.DataFrame:
    if df.empty or "RawFileName" not in df.columns:
        return pd.DataFrame()
    keep_map= param["dim_master_map"]
    amap= param["attr_master_map"]

    df2= df[df["RawFileName"].isin(keep_map.keys())].copy()
    if df2.empty:
        return pd.DataFrame()

    df2["DimRaw"]= df2["RawFileName"]
    skip= {"RawFileName","DimRaw"}
    idv= ["DimRaw"]
    if "Name" in df2.columns:
        idv.append("Name")
        skip.add("Name")

    meltdown_cols= [c for c in df2.columns if c not in skip]
    melted= df2.melt(
        id_vars=idv,
        value_vars= meltdown_cols,
        var_name="OrigAttr",
        value_name="ValX"
    )

    def rename_dim(x):
        return keep_map.get(x,x)
    melted["Dimension"]= melted["DimRaw"].apply(rename_dim)

    if "Name" in idv:
        melted.rename(columns={"Name":"Name"}, inplace=True)
    else:
        melted["Name"]= ""

    def strip_t(v):
        if isinstance(v,str) and "T" in v:
            return v.split("T")[0]
        return v

    melted= melted[melted["OrigAttr"].isin(amap.keys())].copy()
    melted["Attribute"]= melted["OrigAttr"].map(amap)
    melted["Value"]= np.where(
        melted["Attribute"].isin(["Start Date","End Date"]),
        melted["ValX"].apply(strip_t),
        melted["ValX"]
    )
    return melted[["Dimension","Name","Attribute","Value"]]


def pivot_for_preview(df: pd.DataFrame)-> pd.DataFrame:
    if df.empty or not {"Dimension","Name","Attribute"}.issubset(df.columns):
        return pd.DataFrame()
    df2= df.drop_duplicates(subset=["Dimension","Name","Attribute"])
    try:
        return df2.pivot(index=["Dimension","Name"], columns="Attribute", values="Value").reset_index()
    except:
        return pd.DataFrame()


# ----------------------------------------------------------------------------
# meltdown => wide->long
# ----------------------------------------------------------------------------
def meltdown_to_long(df_wide: pd.DataFrame)-> pd.DataFrame:
    if df_wide.empty or {"Dimension","Name"}.difference(df_wide.columns):
        return pd.DataFrame()
    meltdown_cols= [c for c in df_wide.columns if c not in ("Dimension","Name")]
    melted= df_wide.melt(
        id_vars=["Dimension","Name"],
        value_vars= meltdown_cols,
        var_name="Attribute",
        value_name="Value"
    )
    melted["Value"]= melted["Value"].fillna("")
    return melted


# ----------------------------------------------------------------------------
# NAME-FIRST => mismatch + case => "Status"
# ----------------------------------------------------------------------------
def compare_name_first(erp_long: pd.DataFrame, mast_long: pd.DataFrame, trim_key=False)\
    -> Tuple[pd.DataFrame,pd.DataFrame]:
    """
    Name-first logic:
      - If (Dimension,Name) missing => single row => skip others
      - If Name differs => single row => skip others
      - If Name matches => compare other attributes
      - CASE => second sheet
    "Status" => Missing in Master / Missing in ERP / Difference in both
    """

    def build_dict(d):
        out={}
        for (dim,nm), grp in d.groupby(["Dimension","Name"]):
            rec={}
            for _, row in grp.iterrows():
                rec[row["Attribute"]]= row["Value"]
            out[(dim,nm)]= rec
        return out

    mismatch_rows=[]
    case_rows=[]
    e_dict= build_dict(erp_long)
    m_dict= build_dict(mast_long)
    all_dn= set(e_dict.keys())| set(m_dict.keys())

    for dn in all_dn:
        dim,nm= dn
        e_map= e_dict.get(dn,{})
        m_map= m_dict.get(dn,{})

        e_name= e_map.get("Name","")
        m_name= m_map.get("Name","")

        name_issue= False
        # missing in ERP
        if dn not in e_dict and dn in m_dict:
            row= {
                "Dimension":dim,"Name":nm,"Attribute":"Name",
                "Master":m_name,"ERP":"",
                "Comments_1":"","Comments_2":"",
                "Status":"Missing in ERP"
            }
            raw= f"{dim}|{nm}|Name|{m_name}|".upper()
            if trim_key:
                raw= raw.replace(" ","")
            row["Key"]= raw
            mismatch_rows.append(row)
            name_issue= True
        # missing in Master
        elif dn in e_dict and dn not in m_dict:
            row= {
                "Dimension":dim,"Name":nm,"Attribute":"Name",
                "Master":"",
                "ERP": e_name,
                "Comments_1":"","Comments_2":"",
                "Status":"Missing in Master"
            }
            raw= f"{dim}|{nm}|Name||{e_name}".upper()
            if trim_key:
                raw= raw.replace(" ","")
            row["Key"]= raw
            mismatch_rows.append(row)
            name_issue= True
        # both => name differ
        elif e_name and m_name and e_name!= m_name:
            if e_name.lower()== m_name.lower():
                # case
                row= {
                    "Dimension":dim,"Name":nm,"Attribute":"Name",
                    "Master":m_name,"ERP":e_name,
                    "Comments_1":"","Comments_2":"",
                    "Status":"CASE"
                }
                raw= f"{dim}|{nm}|Name|{m_name}|{e_name}".upper()
                if trim_key:
                    raw= raw.replace(" ","")
                row["Key"]= raw
                case_rows.append(row)
            else:
                # difference in both
                row= {
                    "Dimension":dim,"Name":nm,"Attribute":"Name",
                    "Master":m_name,"ERP":e_name,
                    "Comments_1":"","Comments_2":"",
                    "Status":"Difference in both"
                }
                raw= f"{dim}|{nm}|Name|{m_name}|{e_name}".upper()
                if trim_key:
                    raw= raw.replace(" ","")
                row["Key"]= raw
                mismatch_rows.append(row)
            name_issue= True

        if name_issue:
            continue

        # name matched => compare other attributes
        all_atts= set(e_map.keys())| set(m_map.keys())
        all_atts.discard("Name")
        for at in all_atts:
            ev= e_map.get(at,"")
            mv= m_map.get(at,"")
            if ev.lower()== mv.lower() and ev!= mv and ev and mv:
                row= {
                    "Dimension":dim,"Name":nm,"Attribute":at,
                    "Master":mv,"ERP":ev,
                    "Comments_1":"","Comments_2":"",
                    "Status":"CASE"
                }
                raw= f"{dim}|{nm}|{at}|{mv}|{ev}".upper()
                if trim_key:
                    raw= raw.replace(" ","")
                row["Key"]= raw
                case_rows.append(row)
            else:
                if ev== mv:
                    continue
                if ev and not mv:
                    st= "Missing in Master"
                    ms= ""
                    es= ev
                elif mv and not ev:
                    st= "Missing in ERP"
                    ms= mv
                    es= ""
                else:
                    st= "Difference in both"
                    ms= mv
                    es= ev
                row= {
                    "Dimension":dim,"Name":nm,"Attribute":at,
                    "Master":ms,"ERP":es,
                    "Comments_1":"","Comments_2":"",
                    "Status": st
                }
                raw= f"{dim}|{nm}|{at}|{ms}|{es}".upper()
                if trim_key:
                    raw= raw.replace(" ","")
                row["Key"]= raw
                mismatch_rows.append(row)

    c= ["Key","Dimension","Name","Attribute","Master","ERP","Comments_1","Comments_2","Status"]
    mismatch_df= pd.DataFrame(mismatch_rows, columns=c) if mismatch_rows else pd.DataFrame(columns=c)
    case_df= pd.DataFrame(case_rows, columns=c) if case_rows else pd.DataFrame(columns=c)
    return mismatch_df, case_df


# ----------------------------------------------------------------------------
# EXCEPTIONS
# ----------------------------------------------------------------------------
def read_exception_table(path: Path)-> pd.DataFrame:
    if not path.is_file():
        logging.warning(f"Exception => {path} not found")
        return pd.DataFrame()
    try:
        df= pd.read_excel(path)
        df.columns= df.columns.astype(str).str.strip()
        return df
    except:
        return pd.DataFrame()

def merge_exceptions(df: pd.DataFrame, df_exc: pd.DataFrame)-> pd.DataFrame:
    if df.empty or df_exc.empty or "Key" not in df.columns:
        return df
    keep= [c for c in df_exc.columns if c in ("Key","Comments_1","Comments_2","hide exception")]
    if not keep:
        return df
    exc_= df_exc[keep].copy()
    exc_["Key"]= exc_["Key"].astype(str).str.strip()

    merged= df.merge(exc_, on="Key", how="left", suffixes=("","_exc"))
    merged["hide exception"]= merged.get("hide exception","").fillna("").str.lower()

    final= merged[merged["hide exception"]!="yes"].copy()
    if "Comments_1_exc" in final.columns:
        final["Comments_1"]= np.where(final["Comments_1_exc"].notna(),
                                      final["Comments_1_exc"],
                                      final["Comments_1"])
        final.drop(columns=["Comments_1_exc"], inplace=True)
    if "Comments_2_exc" in final.columns:
        final["Comments_2"]= np.where(final["Comments_2_exc"].notna(),
                                      final["Comments_2_exc"],
                                      final["Comments_2"])
        final.drop(columns=["Comments_2_exc"], inplace=True)
    if "hide exception" in final.columns:
        final.drop(columns=["hide exception"], inplace=True)
    return final


# ----------------------------------------------------------------------------
# 2-SHEET XLSX => plus "Charts" sheet with burgundy header + WHITE rows
# ----------------------------------------------------------------------------
def write_2sheet_excel(mismatch_df: pd.DataFrame,
                       case_df: pd.DataFrame,
                       out_path: Path):
    if mismatch_df.empty and case_df.empty:
        logging.info("No mismatches => skip writing xlsx.")
        return
    out_path.parent.mkdir(parents=True,exist_ok=True)

    cols= ["Key","Dimension","Name","Attribute","Master","ERP","Comments_1","Comments_2","Status"]
    for c in cols:
        if c not in mismatch_df.columns:
            mismatch_df[c]= ""
        if c not in case_df.columns:
            case_df[c]= ""

    wb= Workbook()
    ws_m= wb.active
    ws_m.title= "Mismatch"
    ws_m.append(cols)
    for rv in mismatch_df[cols].itertuples(index=False):
        ws_m.append(rv)

    ws_c= wb.create_sheet("Case_Differences")
    ws_c.append(cols)
    for rv in case_df[cols].itertuples(index=False):
        ws_c.append(rv)

    # "Charts" sheet => bar chart from mismatch dimension counts
    ws_ch= wb.create_sheet("Charts")

    # burgundy header
    head_font= Font(bold=True,color="FFFFFF")
    head_fill= PatternFill(start_color="800020",end_color="800020",fill_type="solid")

    # We'll style the Mismatch, Case, and Charts
    def style_sheet(sheet, tab_name:str):
        # style header row => burgundy
        if sheet.max_row>0:
            for cell in sheet[1]:
                cell.font= head_font
                cell.fill= head_fill
                cell.alignment= Alignment(horizontal="center")
        # auto-size columns, freeze
        for col in sheet.columns:
            max_len=0
            letter= col[0].column_letter
            for cell_ in col:
                val= str(cell_.value) if cell_.value else ""
                max_len= max(max_len,len(val))
            sheet.column_dimensions[letter].width= max_len+2
        sheet.freeze_panes= "A2"
        # add table if any data
        last_r= sheet.max_row
        last_c= sheet.max_column
        if last_r>1:
            ref= f"A1:{get_column_letter(last_c)}{last_r}"
            tb= Table(displayName=tab_name, ref=ref)
            style= TableStyleInfo(name="TableStyleMedium9", showRowStripes=True,
                                  showColumnStripes=False, showFirstColumn=True)
            tb.tableStyleInfo= style
            sheet.add_table(tb)

    style_sheet(ws_m, "MismatchTable")
    style_sheet(ws_c, "CaseTable")

    # "Charts" => fill with dimension counts from mismatch
    ws_ch["A1"]= "Dimension"
    ws_ch["B1"]= "Count"
    dcounts= mismatch_df["Dimension"].value_counts().reset_index()
    dcounts.columns= ["Dimension","Count"]
    row_i=2
    for _, rowv in dcounts.iterrows():
        ws_ch.cell(row=row_i, column=1, value=rowv["Dimension"])
        ws_ch.cell(row=row_i, column=2, value=rowv["Count"])
        row_i+=1

    style_sheet(ws_ch,"ChartsTable")

    # create bar chart if not empty
    if not dcounts.empty:
        chart= BarChart()
        chart.title= "Mismatch by Dimension"
        cat_ref= Reference(ws_ch, min_col=1, min_row=2, max_row=1+len(dcounts))
        val_ref= Reference(ws_ch, min_col=2, min_row=2, max_row=1+len(dcounts))
        chart.add_data(val_ref, titles_from_data=False)
        chart.set_categories(cat_ref)
        ws_ch.add_chart(chart,"D2")

    wb.save(out_path)
    logging.info(f"Missing items => {out_path}")

    # also a timestamped copy
    stamp= datetime.now().strftime("%Y%m%d_%H%M%S")
    stamped= out_path.parent/f"{out_path.stem}_{stamp}{out_path.suffix}"
    wb.save(stamped)
    logging.info(f"Timestamped => {stamped}")


# ----------------------------------------------------------------------------
# SHIFTED PDF => 8 chart tabs + Bollinger => referencing "Status"
# ----------------------------------------------------------------------------
class EnhancedPDFReport:
    def __init__(self, df_current: pd.DataFrame, df_history: pd.DataFrame, config: Dict):
        self.df_current= df_current
        self.df_history= df_history
        self.config= config
        self.page_count=0
        self.colors= {
            "primary":"#800020",
            "text":"#2C1810",
            "background":"#FFFFFF"
        }
        self.logo_path= self.config["paths"].get("LOGO_PATH","images/company_logo.png")
        self.PAGE_WIDTH= 8.5
        self.PAGE_HEIGHT= 11

    def generate(self)-> Path:
        stamp= datetime.now().strftime("%Y%m%d_%H%M%S")
        out_dir= Path("Reconciliation_pdf")
        out_dir.mkdir(parents=True,exist_ok=True)
        pdf_name= f"Reconciliation_{stamp}.pdf"
        pdf_path= out_dir/pdf_name
        with PdfPages(pdf_path) as pdf:
            self._cover_page(pdf)
            self._summary_page(pdf)
            self._all_charts(pdf)
        logging.info(f"PDF => {pdf_path}")
        return pdf_path

    def _new_page(self)-> plt.Figure:
        fig= plt.figure(figsize=(self.PAGE_WIDTH,self.PAGE_HEIGHT))
        fig.patch.set_facecolor(self.colors["background"])
        plt.axis("off")
        self.page_count+=1

        if self.logo_path and os.path.exists(self.logo_path):
            try:
                import matplotlib.image as mpimg
                img= mpimg.imread(self.logo_path)
                ax_img= fig.add_axes([0.65,0.75,0.3,0.2])
                ax_img.imshow(img, alpha=0.2)
                ax_img.axis("off")
            except:
                pass

        fig.text(0.5,0.98,"Reconciliation Report",ha="center",fontsize=10,color="gray")
        fig.text(0.9,0.03,f"Page {self.page_count}",ha="right",fontsize=8,color="gray")
        fig.text(0.5,0.02,"© Ultra-Mega Reconciliation",ha="center",fontsize=8,color="gray")
        return fig

    def _cover_page(self, pdf: PdfPages):
        fig= self._new_page()
        plt.text(0.5,0.7,"Reconciliation Analysis Report",
                 ha="center",fontsize=24,fontweight="bold",color=self.colors["primary"],
                 transform=fig.transFigure)
        plt.text(0.5,0.6,f"Generated on {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
                 ha="center",fontsize=12,color=self.colors["text"],
                 transform=fig.transFigure)
        plt.text(0.5,0.15,"CONFIDENTIAL",
                 ha="center",fontsize=9,color=self.colors["text"],
                 transform=fig.transFigure)
        pdf.savefig(fig)
        plt.close(fig)

    def _summary_page(self, pdf: PdfPages):
        fig= self._new_page()
        plt.text(0.5,0.92,"Reconciliation Summary",
                 ha="center",fontsize=18,fontweight="bold",color=self.colors["primary"],
                 transform=fig.transFigure)
        if self.df_current.empty:
            plt.text(0.5,0.75,"No mismatches found.",
                     ha="center",fontsize=14,color=self.colors["text"],
                     transform=fig.transFigure)
        else:
            tot= len(self.df_current)
            c_erp= (self.df_current["Status"]=="Missing in ERP").sum()
            c_mas= (self.df_current["Status"]=="Missing in Master").sum()
            c_both= (self.df_current["Status"]=="Difference in both").sum()
            text= f"Total Mismatch: {tot}\nMissing in ERP: {c_erp}\nMissing in Master: {c_mas}\nDiff in Both: {c_both}"
            plt.text(0.5,0.75,text,ha="center",fontsize=14,color=self.colors["text"],
                     transform=fig.transFigure)
        pdf.savefig(fig)
        plt.close(fig)

    def _chart_page(self, pdf: PdfPages, title:str, plot_func, **kwargs):
        fig= self._new_page()
        fig.suptitle(title, fontsize=14, fontweight="bold", color=self.colors["primary"], y=0.93)
        ax= fig.add_axes([0.30, 0.2, 0.65, 0.55])  # SHIFT ~1" left
        try:
            plot_func(ax, **kwargs)
            pdf.savefig(fig)
        except Exception as e:
            logging.error(f"{title} => {e}")
        plt.close(fig)

    def _all_charts(self, pdf: PdfPages):
        dfc= self.df_current.copy()
        if dfc.empty:
            return
        df_m= dfc[dfc["Status"]!=""]

        # Heatmap
        if not df_m.empty and {"Dimension","Attribute"}.issubset(df_m.columns):
            pivot= df_m.groupby(["Dimension","Attribute"]).size().unstack(fill_value=0)
            if not pivot.empty:
                self._chart_page(pdf,"Heatmap",self._plot_heatmap,pivot=pivot)

        # Lollipop
        cdim= df_m.groupby("Dimension")["Key"].count().sort_values(ascending=False).head(10)
        if not cdim.empty:
            self._chart_page(pdf,"Lollipop", self._plot_lollipop, cdim=cdim)

        # Circular
        cattr= df_m.groupby("Attribute")["Key"].count().sort_values(ascending=False).head(10)
        if not cattr.empty:
            self._chart_page(pdf,"Circular", self._plot_circular, cattr=cattr)

        # Scatter
        cdim_sc= df_m.groupby("Dimension")["Key"].count().reset_index(name="Count")
        cdim_sc.sort_values("Count", ascending=False, inplace=True)
        cdim_sc= cdim_sc.head(10)
        if not cdim_sc.empty:
            self._chart_page(pdf,"Scatter", self._plot_scatter, cdim=cdim_sc)

        # Radar
        cdim_ra= df_m.groupby("Dimension")["Key"].count().sort_values(ascending=False).head(10)
        if not cdim_ra.empty and len(cdim_ra)>1:
            self._chart_page(pdf,"Radar", self._plot_radar, cdim=cdim_ra)

        # Normal Pie
        dist= df_m["Status"].value_counts()
        if not dist.empty:
            self._chart_page(pdf,"Pie: Status distribution", self._plot_pie, dist=dist)

        # Normal Bar
        cattr_b= df_m.groupby("Attribute")["Key"].count().sort_values(ascending=False).head(10)
        if not cattr_b.empty:
            self._chart_page(pdf,"Bar: Missing Attributes", self._plot_bar, cattr=cattr_b)

        # Bollinger
        if not self.df_history.empty and "RunDate" in self.df_history.columns:
            date_ct= self.df_history.groupby("RunDate")["Key"].count().reset_index(name="Count")
            date_ct.sort_values("RunDate", inplace=True)
            if not date_ct.empty:
                self._chart_page(pdf,"Bollinger Over Time", self._plot_bollinger, date_ct=date_ct)

    # chart helpers
    def _plot_heatmap(self, ax, pivot):
        im= ax.imshow(pivot,aspect="auto",cmap="Reds")
        ax.set_xticks(range(len(pivot.columns)))
        ax.set_xticklabels(pivot.columns,rotation=45,ha="right")
        ax.set_yticks(range(len(pivot.index)))
        ax.set_yticklabels(pivot.index)
        ax.set_title("Heatmap (Shifted Left)")
        plt.colorbar(im, ax=ax)

    def _plot_lollipop(self, ax, cdim):
        ax.hlines(y= cdim.index, xmin=0, xmax= cdim.values, color="skyblue")
        ax.plot(cdim.values, cdim.index, "o", color="skyblue")
        ax.set_xlabel("Count")
        ax.set_title("Lollipop Chart")

    def _plot_circular(self, ax, cattr):
        angles= np.linspace(0,2*np.pi,len(cattr),endpoint=False)
        ax.set_theta_offset(np.pi/2)
        ax.set_theta_direction(-1)
        ax.set_xticks(angles)
        ax.set_xticklabels(cattr.index,fontsize=8)
        ax.bar(angles, cattr.values, width=0.4, color="orange", alpha=0.6)
        ax.set_title("Circular Chart")

    def _plot_scatter(self, ax, cdim):
        xvals= np.arange(len(cdim))
        yvals= cdim["Count"].values
        labs= cdim["Dimension"].values
        ax.scatter(xvals,yvals,color="green")
        for i,d in enumerate(labs):
            ax.text(xvals[i], yvals[i], d, ha="center", va="bottom", rotation=60, fontsize=8)
        ax.set_xticks([])
        ax.set_ylabel("Count")
        ax.set_title("Scatter Chart")

    def _plot_radar(self, ax, cdim):
        cat= cdim.index.tolist()
        val= cdim.values.tolist()
        angles= np.linspace(0,2*np.pi,len(cat),endpoint=False).tolist()
        angles+= angles[:1]
        val+= val[:1]
        ax.set_theta_offset(np.pi/2)
        ax.set_theta_direction(-1)
        ax.set_xticks(angles[:-1])
        ax.set_xticklabels(cat, fontsize=8)
        ax.plot(angles, val, color="red", linewidth=2)
        ax.fill(angles, val, color="red", alpha=0.3)
        ax.set_title("Radar Chart")

    def _plot_pie(self, ax, dist):
        ax.pie(dist.values, labels=dist.index, autopct="%.1f%%", startangle=140)
        ax.set_title("Pie Chart")

    def _plot_bar(self, ax, cattr):
        bars= ax.bar(range(len(cattr)), cattr.values, color="blue")
        ax.set_xticks(range(len(cattr)))
        ax.set_xticklabels(cattr.index, rotation=45, ha="right", fontsize=8)
        ax.set_ylabel("Count")
        ax.set_title("Bar Chart")
        for b in bars:
            h= b.get_height()
            ax.text(b.get_x()+ b.get_width()/2., h, str(int(h)), ha="center", va="bottom")

    def _plot_bollinger(self, ax, date_ct):
        date_ct["RunDate_dt"]= pd.to_datetime(date_ct["RunDate"],errors="coerce")
        date_ct.sort_values("RunDate_dt", inplace=True)
        date_ct.reset_index(drop=True,inplace=True)
        date_ct["rolling_mean"]= date_ct["Count"].rolling(3,min_periods=1).mean()
        date_ct["rolling_std"]= date_ct["Count"].rolling(3,min_periods=1).std(ddof=0)
        date_ct["upper_band"]= date_ct["rolling_mean"]+2*date_ct["rolling_std"]
        date_ct["lower_band"]= date_ct["rolling_mean"]-2*date_ct["rolling_std"]
        xvals= np.arange(len(date_ct))
        ax.plot(xvals, date_ct["rolling_mean"], color="blue", label="Mean")
        ax.fill_between(xvals, date_ct["lower_band"], date_ct["upper_band"], color="blue", alpha=0.2)
        ax.scatter(xvals, date_ct["Count"], color="red", label="Count")
        ax.set_xticks(xvals)
        xlabels= [d.strftime("%Y-%m-%d") if not pd.isna(d) else "" for d in date_ct["RunDate_dt"]]
        ax.set_xticklabels(xlabels, rotation=45, ha="right")
        ax.set_xlabel("RunDate")
        ax.set_ylabel("Mismatch Count")
        ax.set_title("Bollinger Chart")
        ax.legend()


# ----------------------------------------------------------------------------
# SIMPLE PREVIEW => future end date toggle
# ----------------------------------------------------------------------------
class SimplePreview(ctk.CTkFrame):
    FILTERABLE= {"Start Date","End Date"}

    def __init__(self, parent, name:str, cfg_sub:Dict):
        super().__init__(parent)
        self.name= name
        self.df= pd.DataFrame()

        self.filters: Dict[str,Set[str]]= {}
        self.future_var= tk.BooleanVar(value=False)
        if "filters" in cfg_sub:
            for col, arr in cfg_sub["filters"].items():
                if isinstance(arr, list):
                    self.filters[col]= set(arr)
        if "future_end_toggle" in cfg_sub:
            self.future_var.set(bool(cfg_sub["future_end_toggle"]))

        self.build_ui()

    def build_ui(self):
        top= ctk.CTkFrame(self, fg_color="#f0f0f0")
        top.pack(fill="x", padx=5, pady=5)

        ctk.CTkLabel(top, text=f"{self.name} Preview",
                     fg_color="#800020", corner_radius=8,
                     text_color="white",
                     font=ctk.CTkFont(size=14, weight="bold"))\
            .pack(side="left",padx=5)

        ctk.CTkCheckBox(top, text="Future End Date?",
                        variable=self.future_var,
                        command=self.refresh_table,
                        fg_color="#800020", hover_color="#a52a2a",
                        text_color="black")\
            .pack(side="left",padx=5)

        ctk.CTkButton(top, text="Clear Date Filters",
                      command=self.clear_filters,
                      fg_color="#800020", hover_color="#a52a2a",
                      text_color="white")\
            .pack(side="left",padx=5)

        container= ctk.CTkFrame(self)
        container.pack(fill="both", expand=True)

        self.tree= ttk.Treeview(container, show="headings")
        vsb= ttk.Scrollbar(container, orient="vertical", command=self.tree.yview)
        hsb= ttk.Scrollbar(container, orient="horizontal", command=self.tree.xview)
        self.tree.configure(yscrollcommand=vsb.set, xscrollcommand=hsb.set)

        self.tree.grid(row=0,column=0,sticky="nsew")
        vsb.grid(row=0,column=1,sticky="ns")
        hsb.grid(row=1,column=0,sticky="ew")
        container.rowconfigure(0,weight=1)
        container.columnconfigure(0,weight=1)

        self.stat_lab= ctk.CTkLabel(self, text="0 rows", fg_color="#f0f0f0", text_color="black")
        self.stat_lab.pack(fill="x")

    def set_data(self, df: pd.DataFrame):
        self.df= df.copy()
        self.refresh_table()

    def get_filters(self)-> Dict[str,Set[str]]:
        return self.filters

    def get_future_toggle(self)-> bool:
        return bool(self.future_var.get())

    def get_filtered_df(self)-> pd.DataFrame:
        return self.apply_filters()

    def refresh_table(self):
        for i in self.tree.get_children():
            self.tree.delete(i)
        if self.df.empty:
            self.tree["columns"]=[]
            self.stat_lab.configure(text="0 rows")
            return

        cols= list(self.df.columns)
        self.tree["columns"]= cols
        for c in cols:
            self.tree.heading(c,text=c,anchor="w",command=lambda cc=c:self.on_col_click(cc))
            self.tree.column(c,anchor="w",width=150)

        df_f= self.apply_filters()
        for _, row in df_f.iterrows():
            rowvals= [row.get(col,"") for col in cols]
            self.tree.insert("", "end", values=rowvals)
        self.stat_lab.configure(text=f"{len(df_f)} rows")

    def apply_filters(self)-> pd.DataFrame:
        df_f= self.df.copy()
        # normal filters
        for col, allowed in self.filters.items():
            if col not in df_f.columns:
                continue
            if not allowed:
                return df_f.iloc[0:0]
            def keeper(x):
                if pd.isna(x):
                    return ("<<NaN>>" in allowed)
                elif isinstance(x,str) and not x.strip():
                    return ("<<BLANK>>" in allowed)
                else:
                    return str(x) in allowed
            df_f= df_f[df_f[col].apply(keeper)]
        # future end toggle
        if self.future_var.get() and "End Date" in df_f.columns:
            today_= date.today()
            keep_set= set()
            for v in df_f["End Date"].unique():
                if pd.isna(v) or (isinstance(v,str) and not v.strip()):
                    keep_set.add(v)
                    continue
                sval= str(v).strip()
                keep=False
                try:
                    dtp= datetime.strptime(sval,"%Y-%m-%d")
                    if dtp.date()>= today_ or dtp.year>2200:
                        keep= True
                except:
                    if "9999" in sval:
                        keep= True
                    else:
                        import re
                        yrs= re.findall(r"\d{4}", sval)
                        for y_ in yrs:
                            try:
                                if int(y_)>2200:
                                    keep= True
                                    break
                            except:
                                pass
                if keep:
                    keep_set.add(v)
            df_f= df_f[df_f["End Date"].isin(keep_set)]
        return df_f

    def on_col_click(self,col_name:str):
        if col_name in self.FILTERABLE:
            self.show_filter_popup(col_name)

    def show_filter_popup(self,col_name:str):
        if self.df.empty or col_name not in self.df.columns:
            return
        pop= tk.Toplevel(self)
        pop.title(f"Filter: {col_name}")
        pop.geometry("300x400")

        fr= ctk.CTkFrame(pop)
        fr.pack(fill="both", expand=True, padx=5, pady=5)

        unq= self.df[col_name].unique()
        dsp_map={}
        rev_map={}
        for v in unq:
            if pd.isna(v):
                dsp= "(NaN)"
                sen= "<<NaN>>"
            elif isinstance(v,str) and not v.strip():
                dsp= "(blank)"
                sen= "<<BLANK>>"
            else:
                dsp= str(v)
                sen= dsp
            dsp_map[v]= dsp
            rev_map[dsp]= sen
        sortd= sorted(dsp_map.values(), key=lambda x:x.lower())

        curr= self.filters.get(col_name,set())
        all_sens= set(rev_map.values())
        selall_var= tk.BooleanVar(value=(curr==all_sens or not curr))

        def toggle_all():
            c= selall_var.get()
            for vb in var_dict.values():
                vb.set(c)

        ctk.CTkCheckBox(fr,text="Select All",variable=selall_var,command=toggle_all,
                        fg_color="#800020",hover_color="#a52a2a",text_color="black")\
            .pack(anchor="w",pady=5)

        scr= ctk.CTkScrollableFrame(fr,width=250,height=250)
        scr.pack(fill="both", expand=True, padx=5, pady=5)

        var_dict={}
        for dsp in sortd:
            sen= rev_map[dsp]
            in_f= (sen in curr) or (not curr)
            bvar= tk.BooleanVar(value=in_f)
            var_dict[dsp]= bvar
            ctk.CTkCheckBox(scr,text=dsp,variable=bvar,
                            fg_color="#800020",hover_color="#a52a2a",text_color="black")\
                .pack(anchor="w")

        def apply_():
            sel= {rev_map[d] for d,bv in var_dict.items() if bv.get()}
            if sel==all_sens or not sel:
                if col_name in self.filters:
                    del self.filters[col_name]
            else:
                self.filters[col_name]= sel
            pop.destroy()
            self.refresh_table()

        bf= ctk.CTkFrame(fr)
        bf.pack(fill="x", pady=5)
        ctk.CTkButton(bf,text="Apply",command=apply_,
                      fg_color="#800020",hover_color="#a52a2a",text_color="white")\
            .pack(side="left",padx=5)
        ctk.CTkButton(bf,text="Cancel",command=pop.destroy,
                      fg_color="#800020",hover_color="#a52a2a",text_color="white")\
            .pack(side="left",padx=5)

    def clear_filters(self):
        to_del= []
        for c in self.filters:
            if c in self.FILTERABLE:
                to_del.append(c)
        for d in to_del:
            del self.filters[d]
        self.future_var.set(False)
        self.refresh_table()


# ----------------------------------------------------------------------------
# ADV DASHBOARD => 8 chart tabs
# ----------------------------------------------------------------------------
class AdvancedDashboard(ctk.CTkFrame):
    def __init__(self, parent, config: Dict):
        super().__init__(parent)
        dash= config.get("dashboard",{})
        self.config= config
        self.selected_dims= set(dash.get("selected_dims",[]))
        self.selected_attrs= set(dash.get("selected_attrs",[]))
        self.top_n= dash.get("top_n",10)

        self.df_current= pd.DataFrame()
        self.df_history= pd.DataFrame()

        topbar= ctk.CTkScrollableFrame(self, orientation="horizontal", height=60)
        topbar.pack(fill="x", pady=5)

        self.metric_label= ctk.CTkLabel(topbar, text="Metrics: 0 mismatch, 0 dimension", width=300)
        self.metric_label.pack(side="left", padx=5)

        ctk.CTkButton(
            topbar, text="Filter Dimension", command=self.show_dim_filter,
            fg_color="#800020", hover_color="#a52a2a", text_color="white"
        ).pack(side="left", padx=5)
        ctk.CTkButton(
            topbar, text="Filter Attribute", command=self.show_attr_filter,
            fg_color="#800020", hover_color="#a52a2a", text_color="white"
        ).pack(side="left", padx=5)
        ctk.CTkButton(
            topbar, text="Toggle Top 10 / All", command=self.toggle_top_n,
            fg_color="#800020", hover_color="#a52a2a", text_color="white"
        ).pack(side="left", padx=5)

        # 8 charts => each in its own tab
        self.notebook= ttk.Notebook(self)
        self.notebook.pack(fill="both", expand=True)

        chart_names= ["Heatmap","Lollipop","Circular","Scatter","Radar","Normal Pie","Normal Bar","Bollinger Chart"]
        self.frames={}
        for nm in chart_names:
            fr= ctk.CTkFrame(self.notebook)
            fr.pack(fill="both",expand=True)
            self.notebook.add(fr, text=nm)
            self.frames[nm]= fr

    def toggle_top_n(self):
        if self.top_n==10:
            self.top_n=None
        else:
            self.top_n=10
        self.update_data_filters()

    def show_dim_filter(self):
        self.show_filter_popup("Dimension")

    def show_attr_filter(self):
        self.show_filter_popup("Attribute")

    def show_filter_popup(self, col:str):
        base= self.df_history if not self.df_history.empty else self.df_current
        if base.empty or col not in base.columns:
            return
        pop= tk.Toplevel(self)
        pop.title(f"Filter: {col}")
        pop.geometry("300x400")

        fr= ctk.CTkFrame(pop)
        fr.pack(fill="both", expand=True, padx=5, pady=5)

        unq= base[col].dropna().unique()
        dsp_map={}
        for v in unq:
            if pd.isna(v):
                dsp= "(NaN)"
            elif isinstance(v,str) and not v.strip():
                dsp= "(blank)"
            else:
                dsp= str(v)
            dsp_map[v]= dsp
        svals= sorted(dsp_map.keys(), key=lambda x:dsp_map[x].lower())

        if col=="Dimension":
            curr= self.selected_dims
        else:
            curr= self.selected_attrs
        if not curr:
            curr= set(svals)
        all_vals= set(svals)

        selall_var= tk.BooleanVar(value=(curr==all_vals or not curr))
        def toggle_all():
            c= selall_var.get()
            for vb in var_dict.values():
                vb.set(c)

        ctk.CTkCheckBox(
            fr, text="Select All", variable=selall_var, command=toggle_all,
            fg_color="#800020",hover_color="#a52a2a",text_color="black"
        ).pack(anchor="w",pady=5)

        scr= ctk.CTkScrollableFrame(fr, width=250, height=250)
        scr.pack(fill="both", expand=True, padx=5, pady=5)
        var_dict={}
        for rv in svals:
            in_f= (rv in curr) or (not curr)
            bvar= tk.BooleanVar(value=in_f)
            var_dict[rv]= bvar
            ctk.CTkCheckBox(
                scr, text=dsp_map[rv], variable=bvar,
                fg_color="#800020",hover_color="#a52a2a",text_color="black"
            ).pack(anchor="w")

        def apply_():
            sel= {k for k,bv in var_dict.items() if bv.get()}
            if col=="Dimension":
                self.selected_dims= sel
            else:
                self.selected_attrs= sel
            pop.destroy()
            self.update_data_filters()

        bf= ctk.CTkFrame(fr)
        bf.pack(fill="x", pady=5)
        ctk.CTkButton(
            bf,text="Apply",command=apply_,
            fg_color="#800020",hover_color="#a52a2a",text_color="white"
        ).pack(side="left",padx=5)
        ctk.CTkButton(
            bf,text="Cancel",command=pop.destroy,
            fg_color="#800020",hover_color="#a52a2a",text_color="white"
        ).pack(side="left",padx=5)

    def update_data(self, df_current: pd.DataFrame, df_history: pd.DataFrame):
        self.df_current= df_current.copy()
        self.df_history= df_history.copy()
        self.update_data_filters()

    def update_data_filters(self):
        dfc= self.df_current.copy()
        if not dfc.empty:
            if self.selected_dims:
                dfc= dfc[dfc["Dimension"].isin(self.selected_dims)]
            if self.selected_attrs:
                dfc= dfc[dfc["Attribute"].isin(self.selected_attrs)]

        mism= len(dfc)
        dims= dfc["Dimension"].nunique() if not dfc.empty and "Dimension" in dfc.columns else 0
        self.metric_label.configure(text=f"Mismatches: {mism}, Dims: {dims}")

        # We'll produce 8 separate chart plots
        # subset => Status != ""
        dsub= dfc[dfc["Status"]!=""].copy()

        # create each chart in self.frames
        # 1) Heatmap
        self.build_heatmap(dsub, self.frames["Heatmap"])
        # 2) Lollipop
        self.build_lollipop(dsub, self.frames["Lollipop"])
        # 3) Circular
        self.build_circular(dsub, self.frames["Circular"])
        # 4) Scatter
        self.build_scatter(dsub, self.frames["Scatter"])
        # 5) Radar
        self.build_radar(dsub, self.frames["Radar"])
        # 6) Normal Pie
        self.build_pie(dsub, self.frames["Normal Pie"])
        # 7) Normal Bar
        self.build_bar(dsub, self.frames["Normal Bar"])
        # 8) Bollinger
        self.build_bollinger(self.frames["Bollinger Chart"])

    def build_heatmap(self, df: pd.DataFrame, frame: ctk.CTkFrame):
        for w in frame.winfo_children():
            w.destroy()
        if df.empty or not {"Dimension","Attribute"}.issubset(df.columns):
            return
        pivot= df.groupby(["Dimension","Attribute"]).size().unstack(fill_value=0)
        if pivot.empty:
            return
        fig, ax= plt.subplots(figsize=(5,4))
        im= ax.imshow(pivot,aspect="auto",cmap="Reds")
        ax.set_xticks(range(len(pivot.columns)))
        ax.set_xticklabels(pivot.columns,rotation=45,ha="right")
        ax.set_yticks(range(len(pivot.index)))
        ax.set_yticklabels(pivot.index)
        ax.set_title("Heatmap")
        plt.colorbar(im, ax=ax)
        self.plot_chart(frame, fig)

    def build_lollipop(self, df: pd.DataFrame, frame: ctk.CTkFrame):
        for w in frame.winfo_children():
            w.destroy()
        if df.empty:
            return
        cdim= df.groupby("Dimension")["Key"].count().sort_values(ascending=False)
        if self.top_n==10:
            cdim= cdim.head(10)
        if cdim.empty:
            return
        fig, ax= plt.subplots(figsize=(5,4))
        ax.hlines(y= cdim.index, xmin=0, xmax= cdim.values, color="skyblue")
        ax.plot(cdim.values, cdim.index, "o", color="skyblue")
        ax.set_title("Lollipop")
        ax.set_xlabel("Count")
        self.plot_chart(frame, fig)

    def build_circular(self, df: pd.DataFrame, frame: ctk.CTkFrame):
        for w in frame.winfo_children():
            w.destroy()
        if df.empty:
            return
        cattr= df.groupby("Attribute")["Key"].count().sort_values(ascending=False)
        if self.top_n==10:
            cattr= cattr.head(10)
        if cattr.empty:
            return
        fig= plt.figure(figsize=(5,5))
        ax= fig.add_subplot(111, polar=True)
        angles= np.linspace(0,2*np.pi,len(cattr),endpoint=False)
        ax.set_theta_offset(np.pi/2)
        ax.set_theta_direction(-1)
        ax.set_xticks(angles)
        ax.set_xticklabels(cattr.index,fontsize=8)
        ax.bar(angles, cattr.values, width=0.4, color="orange", alpha=0.6)
        ax.set_title("Circular")
        self.plot_chart(frame, fig)

    def build_scatter(self, df: pd.DataFrame, frame: ctk.CTkFrame):
        for w in frame.winfo_children():
            w.destroy()
        if df.empty:
            return
        cdim= df.groupby("Dimension")["Key"].count().reset_index(name="Count")
        cdim.sort_values("Count", ascending=False, inplace=True)
        if self.top_n==10:
            cdim= cdim.head(10)
        if cdim.empty:
            return
        fig, ax= plt.subplots(figsize=(5,4))
        xvals= np.arange(len(cdim))
        yvals= cdim["Count"].values
        labs= cdim["Dimension"].values
        ax.scatter(xvals,yvals,color="green")
        for i, la in enumerate(labs):
            ax.text(xvals[i], yvals[i], la, ha="center", va="bottom", rotation=60, fontsize=8)
        ax.set_xticks([])
        ax.set_ylabel("Count")
        ax.set_title("Scatter")
        self.plot_chart(frame, fig)

    def build_radar(self, df: pd.DataFrame, frame: ctk.CTkFrame):
        for w in frame.winfo_children():
            w.destroy()
        if df.empty:
            return
        cdim= df.groupby("Dimension")["Key"].count().sort_values(ascending=False)
        if self.top_n==10:
            cdim= cdim.head(10)
        if cdim.empty or len(cdim)<2:
            return
        cat= cdim.index.tolist()
        val= cdim.values.tolist()
        angles= np.linspace(0,2*np.pi,len(cat),endpoint=False).tolist()
        angles+= angles[:1]
        val+= val[:1]
        fig= plt.figure(figsize=(5,5))
        ax= fig.add_subplot(111, polar=True)
        ax.set_theta_offset(np.pi/2)
        ax.set_theta_direction(-1)
        ax.set_xticks(angles[:-1])
        ax.set_xticklabels(cat, fontsize=8)
        ax.plot(angles, val, color="red", linewidth=2)
        ax.fill(angles, val, color="red", alpha=0.3)
        ax.set_title("Radar")
        self.plot_chart(frame, fig)

    def build_pie(self, df: pd.DataFrame, frame: ctk.CTkFrame):
        for w in frame.winfo_children():
            w.destroy()
        if df.empty:
            return
        dist= df["Status"].value_counts()
        if dist.empty:
            return
        fig, ax= plt.subplots(figsize=(5,4))
        ax.pie(dist.values, labels=dist.index, autopct="%.1f%%", startangle=140)
        ax.set_title("Pie: Status")
        self.plot_chart(frame, fig)

    def build_bar(self, df: pd.DataFrame, frame: ctk.CTkFrame):
        for w in frame.winfo_children():
            w.destroy()
        if df.empty:
            return
        cattr= df["Attribute"].value_counts().sort_values(ascending=False)
        if self.top_n==10:
            cattr= cattr.head(10)
        if cattr.empty:
            return
        fig, ax= plt.subplots(figsize=(5,3))
        bars= ax.bar(range(len(cattr)), cattr.values, color="blue")
        ax.set_xticks(range(len(cattr)))
        ax.set_xticklabels(cattr.index, rotation=45, ha="right")
        ax.set_ylabel("Count")
        ax.set_title("Bar: Attributes")
        for bar in bars:
            h= bar.get_height()
            ax.text(bar.get_x()+ bar.get_width()/2., h, str(int(h)), ha="center", va="bottom")
        plt.tight_layout()
        self.plot_chart(frame, fig)

    def build_bollinger(self, frame: ctk.CTkFrame):
        for w in frame.winfo_children():
            w.destroy()
        if self.df_history.empty or "RunDate" not in self.df_history.columns:
            return
        date_ct= self.df_history.groupby("RunDate")["Key"].count().reset_index(name="Count")
        date_ct.sort_values("RunDate", inplace=True)
        if date_ct.empty:
            return
        fig, ax= plt.subplots(figsize=(6,3))
        date_ct["RunDate_dt"]= pd.to_datetime(date_ct["RunDate"], errors="coerce")
        date_ct.sort_values("RunDate_dt", inplace=True)
        date_ct.reset_index(drop=True, inplace=True)
        date_ct["rolling_mean"]= date_ct["Count"].rolling(3,min_periods=1).mean()
        date_ct["rolling_std"]= date_ct["Count"].rolling(3,min_periods=1).std(ddof=0)
        date_ct["upper_band"]= date_ct["rolling_mean"]+2*date_ct["rolling_std"]
        date_ct["lower_band"]= date_ct["rolling_mean"]-2*date_ct["rolling_std"]
        xvals= np.arange(len(date_ct))
        ax.plot(xvals, date_ct["rolling_mean"], color="blue", label="Mean")
        ax.fill_between(xvals, date_ct["lower_band"], date_ct["upper_band"], color="blue", alpha=0.2)
        ax.scatter(xvals, date_ct["Count"], color="red", label="Count")
        ax.set_xticks(xvals)
        xlabels= [d.strftime("%Y-%m-%d") if not pd.isna(d) else "" for d in date_ct["RunDate_dt"]]
        ax.set_xticklabels(xlabels, rotation=45, ha="right")
        ax.set_xlabel("RunDate")
        ax.set_ylabel("Mismatch Count")
        ax.set_title("Bollinger Chart")
        ax.legend()
        self.plot_chart(frame, fig)

    def plot_chart(self, frame: ctk.CTkFrame, fig: plt.Figure):
        for w in frame.winfo_children():
            w.destroy()
        canvas= FigureCanvasTkAgg(fig, master=frame)
        canvas.draw()
        toolbar_frame= ctk.CTkFrame(frame)
        toolbar_frame.pack(side="top", fill="x")
        tb= NavigationToolbar2Tk(canvas, toolbar_frame)
        tb.update()
        canvas.get_tk_widget().pack(fill="both", expand=True)
        plt.close(fig)


# ----------------------------------------------------------------------------
# HISTORY TAB
# ----------------------------------------------------------------------------
class HistoryTab(ctk.CTkFrame):
    def __init__(self, parent, hist_dir: Path):
        super().__init__(parent)
        self.history_dir= hist_dir
        self.tree= None
        self.build_ui()

    def build_ui(self):
        lbl= ctk.CTkLabel(self, text="Reconciliation Runs History", font=("Arial",16))
        lbl.pack(pady=5)
        self.tree= ttk.Treeview(self, columns=("Filename",), show="headings", height=15)
        self.tree.heading("Filename", text="History File")
        self.tree.pack(fill="both", expand=True, padx=10, pady=10)

        self.tree.bind("<Double-1>", self.on_double_click)

        ctk.CTkButton(
            self, text="Refresh", command=self.refresh_history,
            fg_color="#800020", hover_color="#a52a2a", text_color="white"
        ).pack(pady=5)
        self.refresh_history()

    def refresh_history(self):
        for i in self.tree.get_children():
            self.tree.delete(i)
        if not self.history_dir.is_dir():
            self.history_dir.mkdir(parents=True, exist_ok=True)
        files= sorted(self.history_dir.glob("run_*.json"), reverse=True)
        for f in files:
            self.tree.insert("", "end", values=(f.name,))

    def on_double_click(self,event):
        it= self.tree.focus()
        if not it:
            return
        fn= self.tree.item(it,"values")[0]
        path= self.history_dir/fn
        if not path.is_file():
            return
        try:
            with open(path,"r",encoding="utf-8") as ff:
                content= ff.read()
            pop= tk.Toplevel(self)
            pop.title(f"Viewing {fn}")
            txt= ctk.CTkTextbox(pop, width=800, height=600)
            txt.pack(fill="both", expand=True)
            txt.insert("end", content)
            txt.configure(state="disabled")
        except Exception as e:
            logging.error(f"Error opening {path} => {e}")


# ----------------------------------------------------------------------------
# MAIN APP
# ----------------------------------------------------------------------------
class MainApp(ctk.CTk):
    def __init__(self):
        super().__init__()
        self.title("Ultra-Mega Reconciliation => SHIFTED PDF, 2-sheets (white rows), FutureEnd Toggle, TrimKey, Name-First")
        self.geometry("1600x900")
        ctk.set_appearance_mode("light")

        self.config_dict= load_config(Path(DEFAULT_PATHS["CONFIG_PATH"]))
        self.param_dict= read_param_file(Path(self.config_dict["paths"].get("PARAMETER_PATH",DEFAULT_PATHS["PARAMETER_PATH"])))
        self.history_df= pd.DataFrame()

        self.tabs= ttk.Notebook(self)
        self.tabs.pack(fill="both", expand=True)

        # 1) Paths
        self.tab_paths= ctk.CTkFrame(self.tabs)
        self.build_paths_tab(self.tab_paths)
        self.tabs.add(self.tab_paths, text="Paths")

        # 2) ERP
        e_cfg= self.config_dict.get("erp_grid",{"filters":{},"future_end_toggle":False})
        self.tab_erp= ctk.CTkFrame(self.tabs)
        self.erp_preview= SimplePreview(self.tab_erp,"ERP", e_cfg)
        self.erp_preview.pack(fill="both",expand=True)
        self.tabs.add(self.tab_erp, text="ERP Preview")

        # 3) Master
        m_cfg= self.config_dict.get("master_grid",{"filters":{},"future_end_toggle":False})
        self.tab_master= ctk.CTkFrame(self.tabs)
        self.master_preview= SimplePreview(self.tab_master,"Master", m_cfg)
        self.master_preview.pack(fill="both",expand=True)
        self.tabs.add(self.tab_master, text="Master Preview")

        # 4) Compare => name-first
        self.tab_compare= ctk.CTkFrame(self.tabs)
        self.build_compare_tab(self.tab_compare)
        self.tabs.add(self.tab_compare, text="Compare")

        # 5) Dashboard => mismatch only => 8 chart tabs
        self.dashboard_tab= AdvancedDashboard(self.tabs, self.config_dict)
        self.tabs.add(self.dashboard_tab, text="Dashboard")

        # 6) History
        histp= Path(self.config_dict["paths"].get("HISTORY_PATH","history_runs"))
        self.history_tab= HistoryTab(self.tabs, histp)
        self.tabs.add(self.history_tab, text="History")

        # Logging area
        self.log_box= ctk.CTkTextbox(self, height=120)
        self.log_box.pack(fill="both", side="bottom")
        self.log_box.configure(state="disabled")
        handler= TextHandler(self.log_box)
        handler.setLevel(logging.INFO)
        logging.getLogger().addHandler(handler)

        # ephemeral CSV dir
        self.temp_csv_dir= Path(self.config_dict["paths"].get("MASTER_CSV_OUTPUT","temp_master_csv"))
        self.temp_csv_dir.mkdir(parents=True,exist_ok=True)

        # load old runs
        self.load_runs()

        # meltdown => show
        self.refresh_erp()
        self.refresh_master()

        # pass empty => dash sees entire hist => for Bollinger
        self.dashboard_tab.update_data(pd.DataFrame(), self.history_df)

        # close button
        ctk.CTkButton(
            self, text="Close", command=self.on_close,
            fg_color="#800020", hover_color="#a52a2a", text_color="white"
        ).pack(pady=5)

    def build_paths_tab(self, parent):
        frm= ctk.CTkFrame(parent)
        frm.pack(fill="both",expand=True,padx=10,pady=10)

        self.erp_var= tk.StringVar(value=self.config_dict["paths"].get("ERP_EXCEL_PATH", DEFAULT_PATHS["ERP_EXCEL_PATH"]))
        self.mast_zip_var= tk.StringVar(value=self.config_dict["paths"].get("MASTER_ZIP_PATH", DEFAULT_PATHS["MASTER_ZIP_PATH"]))
        self.mast_folder_var= tk.StringVar(value=self.config_dict["paths"].get("MASTER_TXT_FOLDER",""))
        self.exc_var= tk.StringVar(value=self.config_dict["paths"].get("EXCEPTION_PATH", DEFAULT_PATHS["EXCEPTION_PATH"]))
        self.out_var= tk.StringVar(value=self.config_dict["paths"].get("OUTPUT_PATH", DEFAULT_PATHS["OUTPUT_PATH"]))
        self.par_var= tk.StringVar(value=self.config_dict["paths"].get("PARAMETER_PATH", DEFAULT_PATHS["PARAMETER_PATH"]))
        self.pdf_var= tk.StringVar(value=self.config_dict["paths"].get("PDF_EXPORT_PATH", DEFAULT_PATHS["PDF_EXPORT_PATH"]))

        def mkrow(lbl,var,is_dir=False):
            rowf= ctk.CTkFrame(frm)
            rowf.pack(fill="x", pady=5)
            ctk.CTkLabel(rowf,text=lbl,width=200).pack(side="left",padx=5)
            e= ctk.CTkEntry(rowf,textvariable=var,width=600)
            e.pack(side="left",padx=5)
            def br():
                if is_dir:
                    p= filedialog.askdirectory()
                else:
                    p= filedialog.askopenfilename()
                if p:
                    var.set(p)
            ctk.CTkButton(
                rowf,text="Browse",command=br,
                fg_color="#800020",hover_color="#a52a2a",text_color="white"
            ).pack(side="left",padx=5)

        mkrow("ERP Excel:", self.erp_var)
        mkrow("Master ZIP:", self.mast_zip_var)
        mkrow("Master Folder:", self.mast_folder_var, True)
        mkrow("Exception Path:", self.exc_var)
        mkrow("Missing Items Output:", self.out_var)
        mkrow("Parameter File:", self.par_var)
        mkrow("PDF Export Path:", self.pdf_var)

        bf= ctk.CTkFrame(frm)
        bf.pack(fill="x", pady=10)
        ctk.CTkButton(
            bf,text="Save Config",command=self.save_all_config,
            fg_color="#800020",hover_color="#a52a2a",text_color="white"
        ).pack(side="left",padx=5)
        ctk.CTkButton(
            bf,text="Refresh ERP",command=self.refresh_erp,
            fg_color="#800020",hover_color="#a52a2a",text_color="white"
        ).pack(side="left",padx=5)
        ctk.CTkButton(
            bf,text="Refresh Master",command=self.refresh_master,
            fg_color="#800020",hover_color="#a52a2a",text_color="white"
        ).pack(side="left",padx=5)

    def build_compare_tab(self, parent):
        frm= ctk.CTkFrame(parent)
        frm.pack(fill="both",expand=True,padx=10,pady=10)

        ctk.CTkLabel(frm, text="Generate Missing Items => 2-sheets + chart, SHIFTED PDF, etc.", font=("Arial",16))\
            .pack(pady=5)

        self.trim_key_var= tk.BooleanVar(value=self.config_dict.get("trim_key_toggle",False))
        ctk.CTkCheckBox(
            frm, text="Trim Key?", variable=self.trim_key_var,
            fg_color="#800020",hover_color="#a52a2a",text_color="black"
        ).pack(pady=5)

        ctk.CTkButton(
            frm, text="Run Reconciliation", command=self.run_comparison,
            fg_color="#800020",hover_color="#a52a2a",text_color="white"
        ).pack(pady=10)

        ctk.CTkButton(
            frm, text="Export PDF Report", command=self.export_pdf,
            fg_color="#800020",hover_color="#a52a2a",text_color="white"
        ).pack(pady=10)

    def load_runs(self):
        histp= Path(self.config_dict["paths"].get("HISTORY_PATH","history_runs"))
        if not histp.is_dir():
            return
        frames=[]
        for jf in histp.glob("run_*.json"):
            try:
                df_= pd.read_json(jf, orient="records")
                frames.append(df_)
            except Exception as e:
                logging.error(f"History => {jf} => {e}")
        if frames:
            big= pd.concat(frames, ignore_index=True).drop_duplicates()
            if self.history_df.empty:
                self.history_df= big
            else:
                self.history_df= pd.concat([self.history_df,big],ignore_index=True).drop_duplicates()
            logging.info(f"Loaded runs => total {len(self.history_df)} records")

    def refresh_erp(self):
        path_= Path(self.erp_var.get().strip())
        df= read_erp_excel(path_)
        if df.empty:
            self.erp_preview.set_data(pd.DataFrame())
            return
        meltdown_= meltdown_erp_for_preview(df,self.param_dict)
        pivoted= pivot_for_preview(meltdown_)
        self.erp_preview.set_data(pivoted)

    def refresh_master(self):
        folder_= self.mast_folder_var.get().strip()
        zpath_= self.mast_zip_var.get().strip()
        if folder_:
            dfm= unify_master_txt_in_folder(Path(folder_))
        else:
            cfiles= convert_master_txt_to_csv(Path(zpath_), self.temp_csv_dir)
            dfm= unify_master_csvs(cfiles)
        if dfm.empty:
            self.master_preview.set_data(pd.DataFrame())
            return
        meltdown_= meltdown_master_for_preview(dfm,self.param_dict)
        pivoted= pivot_for_preview(meltdown_)
        self.master_preview.set_data(pivoted)

    def run_comparison(self):
        df_erp_w= self.erp_preview.get_filtered_df()
        df_mast_w= self.master_preview.get_filtered_df()

        erp_long= meltdown_to_long(df_erp_w)
        mast_long= meltdown_to_long(df_mast_w)

        trim_flag= bool(self.trim_key_var.get())
        mismatch_df, case_df= compare_name_first(erp_long,mast_long,trim_key=trim_flag)

        exc_path= Path(self.config_dict["paths"].get("EXCEPTION_PATH",""))
        df_exc= read_exception_table(exc_path)
        mismatch_df= merge_exceptions(mismatch_df, df_exc)
        case_df= merge_exceptions(case_df, df_exc)

        outp= Path(self.config_dict["paths"].get("OUTPUT_PATH","output/missing_items.xlsx"))
        write_2sheet_excel(mismatch_df, case_df, outp)

        run_ts= datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        mismatch_df["RunDate"]= run_ts
        if self.history_df.empty:
            self.history_df= mismatch_df.copy()
        else:
            self.history_df= pd.concat([self.history_df,mismatch_df],ignore_index=True).drop_duplicates()

        hist_path= Path(self.config_dict["paths"].get("HISTORY_PATH","history_runs"))
        hist_path.mkdir(parents=True, exist_ok=True)
        run_file= hist_path / f"run_{run_ts.replace(':','-').replace(' ','_')}.json"
        try:
            mismatch_df.to_json(run_file, orient="records", indent=2)
            logging.info(f"Saved run => {run_file}")
        except Exception as e:
            logging.error(f"Error saving => {e}")

        # update dash => mismatch only
        self.dashboard_tab.update_data(mismatch_df,self.history_df)
        self.history_tab.refresh_history()
        self.tabs.select(self.dashboard_tab)

        messagebox.showinfo("Done", f"Missing items => {outp}")

    def export_pdf(self):
        if self.history_df.empty:
            messagebox.showinfo("PDF Export","No mismatch => empty history.")
            return
        if "RunDate" in self.history_df.columns:
            last_run= self.history_df["RunDate"].max()
            df_curr= self.history_df[self.history_df["RunDate"]== last_run].copy()
        else:
            df_curr= self.history_df.copy()

        rep= EnhancedPDFReport(df_curr, self.history_df, self.config_dict)
        pdfp= rep.generate()
        messagebox.showinfo("PDF Export", f"PDF => {pdfp}")

    def save_all_config(self):
        self.config_dict["paths"]["ERP_EXCEL_PATH"]= self.erp_var.get().strip()
        self.config_dict["paths"]["MASTER_ZIP_PATH"]= self.mast_zip_var.get().strip()
        self.config_dict["paths"]["MASTER_TXT_FOLDER"]= self.mast_folder_var.get().strip()
        self.config_dict["paths"]["EXCEPTION_PATH"]= self.exc_var.get().strip()
        self.config_dict["paths"]["OUTPUT_PATH"]= self.out_var.get().strip()
        self.config_dict["paths"]["PARAMETER_PATH"]= self.par_var.get().strip()
        self.config_dict["paths"]["PDF_EXPORT_PATH"]= self.pdf_var.get().strip()

        self.config_dict["trim_key_toggle"]= bool(self.trim_key_var.get())

        e_cfg= self.config_dict.setdefault("erp_grid",{})
        e_cfg["filters"]= self.erp_preview.get_filters()
        e_cfg["future_end_toggle"]= self.erp_preview.get_future_toggle()

        m_cfg= self.config_dict.setdefault("master_grid",{})
        m_cfg["filters"]= self.master_preview.get_filters()
        m_cfg["future_end_toggle"]= self.master_preview.get_future_toggle()

        dash= self.config_dict.setdefault("dashboard",{})
        dash["selected_dims"]= list(self.dashboard_tab.selected_dims)
        dash["selected_attrs"]= list(self.dashboard_tab.selected_attrs)
        dash["top_n"]= self.dashboard_tab.top_n

        cfgp= Path(self.config_dict["paths"].get("CONFIG_PATH","config/ui_config.json"))
        save_config(self.config_dict,cfgp)

    def on_close(self):
        self.save_all_config()
        band_path= self.config_dict["paths"].get("BAND_CHART_JSON_PATH","")
        if band_path and not self.history_df.empty and "RunDate" in self.history_df.columns:
            try:
                outp= Path(band_path)
                date_ct= self.history_df.groupby("RunDate")["Key"].count().reset_index(name="Count")
                date_ct["RunDate_dt"]= pd.to_datetime(date_ct["RunDate"],errors="coerce")
                date_ct.sort_values("RunDate_dt", inplace=True)
                date_ct.reset_index(drop=True,inplace=True)
                date_ct["rolling_mean"]= date_ct["Count"].rolling(3,min_periods=1).mean()
                date_ct["rolling_std"]= date_ct["Count"].rolling(3,min_periods=1).std(ddof=0)
                date_ct["upper_band"]= date_ct["rolling_mean"]+2*date_ct["rolling_std"]
                date_ct["lower_band"]= date_ct["rolling_mean"]-2*date_ct["rolling_std"]
                date_ct["RunDate"]= date_ct["RunDate_dt"].dt.strftime("%Y-%m-%d %H:%M:%S")
                date_ct.drop(columns=["RunDate_dt"],inplace=True)
                date_ct.to_json(outp, orient="records", indent=2)
                logging.info(f"Bollinger => {outp}")
            except Exception as e:
                logging.error(f"Bollinger => {e}")
        self.destroy()


def main():
    app= MainApp()
    app.mainloop()

if __name__=="__main__":
    main()
