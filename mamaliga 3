import os
import sys
import json
import math
import logging
import zipfile
import shutil
import io
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, Set, List

import tkinter as tk
from tkinter import ttk, filedialog, messagebox
import customtkinter as ctk

import pandas as pd
import numpy as np

import matplotlib
matplotlib.use("TkAgg")
import matplotlib.pyplot as plt
from matplotlib.backends.backend_pdf import PdfPages
from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg

try:
    import chardet
except ImportError:
    chardet = None

from openpyxl import Workbook
from openpyxl.styles import PatternFill, Font, Alignment

logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")

# ----------------------------------------------------------------------------
# DEFAULTS & CONFIG
# ----------------------------------------------------------------------------
DEFAULT_PATHS = {
    "ERP_EXCEL_PATH": "data/ERP_Config.xlsx",
    "MASTER_ZIP_PATH": "data/Master_Config.zip",
    "EXCEPTION_PATH": "data/Exception_Table.xlsx",
    "OUTPUT_PATH": "output/missing_items.xlsx",
    "CONFIG_PATH": "config/ui_config.json",
    "PARAMETER_PATH": "data/parameters.xlsx",
    "MASTER_CSV_OUTPUT": "temp_master_csv",
    "PDF_EXPORT_PATH": "output/dashboard_reports",  # folder for PDF
    "HISTORY_PATH": "history_runs",
    "LOGO_PATH": "images/company_logo.png"  # watermark on cover
}

def default_config() -> Dict:
    return {
        "paths": DEFAULT_PATHS.copy(),
        "erp_grid": {"filters": {}},
        "master_grid": {"filters": {}},
        "date_filters": {
            "start_date": (datetime.now() - timedelta(days=30)).strftime("%Y-%m-%d"),
            "end_date": datetime.now().strftime("%Y-%m-%d")
        }
    }

def load_config(path: Path) -> Dict:
    if path.is_file():
        try:
            with open(path, "r", encoding="utf-8") as f:
                return json.load(f)
        except Exception as e:
            logging.warning(f"Could not load config: {e}")
    return default_config()

def save_config(cfg: Dict, path: Path):
    """Convert any sets -> lists for JSON, then save."""
    path.parent.mkdir(parents=True, exist_ok=True)
    try:
        # sets->lists in erp_grid
        if "erp_grid" in cfg and "filters" in cfg["erp_grid"]:
            newf = {}
            for col, svals in cfg["erp_grid"]["filters"].items():
                newf[col] = list(svals)
            cfg["erp_grid"]["filters"] = newf
        # sets->lists in master_grid
        if "master_grid" in cfg and "filters" in cfg["master_grid"]:
            newf = {}
            for col, svals in cfg["master_grid"]["filters"].items():
                newf[col] = list(svals)
            cfg["master_grid"]["filters"] = newf

        with open(path, "w", encoding="utf-8") as f:
            json.dump(cfg, f, indent=2)
        logging.info(f"Saved config to {path}")
    except Exception as e:
        logging.error(f"Error saving config: {e}")

# ----------------------------------------------------------------------------
# LOG HANDLER
# ----------------------------------------------------------------------------
class TextHandler(logging.Handler):
    def __init__(self, widget: ctk.CTkTextbox):
        super().__init__()
        self.widget = widget
    def emit(self, record):
        msg = self.format(record) + "\n"
        self.widget.after(0, self._append, msg)
    def _append(self, msg):
        self.widget.configure(state="normal")
        self.widget.insert("end", msg)
        self.widget.see("end")
        self.widget.configure(state="disabled")

# ----------------------------------------------------------------------------
# PARAM READING
# ----------------------------------------------------------------------------
def read_param_file(path: Path) -> Dict[str, object]:
    """
    param = {
      "dim_erp_keep": set(), "dim_erp_map": {}, "dim_master_map": {},
      "attr_erp_map": {}, "attr_master_map": {}
    }
    """
    param = {
        "dim_erp_keep": set(),
        "dim_erp_map": {},
        "dim_master_map": {},
        "attr_erp_map": {},
        "attr_master_map": {}
    }
    if not path.is_file():
        logging.warning(f"Param file not found => {path}")
        return param
    try:
        import pandas as pd
        dim_df = pd.read_excel(path, sheet_name="Dimension Parameters")
        dim_df.columns = dim_df.columns.astype(str).str.strip()

        def s(x): return str(x).strip() if pd.notna(x) else ""

        for _, row in dim_df.iterrows():
            fn = s(row.get("FileName",""))
            vsc= s(row.get("V S C",""))
            dim= s(row.get("Dimension",""))
            ev = s(row.get("ERP Values",""))
            if ev.lower()=="x" and vsc and dim:
                param["dim_erp_keep"].add(vsc)
            if vsc and dim:
                param["dim_erp_map"][vsc] = dim
            if fn and dim and ev.lower()=="x":
                param["dim_master_map"][fn] = dim

        attr_df = pd.read_excel(path, sheet_name="Attribute Parameters")
        attr_df.columns = attr_df.columns.astype(str).str.strip()
        for _, row in attr_df.iterrows():
            e_orig = s(row.get("ERP Original Attributes",""))
            m_orig = s(row.get("Master Original Attributes",""))
            final_ = s(row.get("Attribute",""))
            onoff  = s(row.get("On/Off",""))
            if onoff.lower()=="x" and final_:
                if e_orig:
                    param["attr_erp_map"][e_orig] = final_
                if m_orig:
                    param["attr_master_map"][m_orig] = final_
        return param
    except Exception as e:
        logging.error(f"Error reading param file => {e}")
        return param

# ----------------------------------------------------------------------------
# ERP
# ----------------------------------------------------------------------------
def read_erp_excel(path: Path) -> pd.DataFrame:
    """Read ERP Excel skipping first 3 rows, keep only Enabled."""
    import pandas as pd
    if not path.is_file():
        logging.warning(f"ERP Excel not found => {path}")
        return pd.DataFrame()
    try:
        df = pd.read_excel(path, skiprows=3)
        df.columns = df.columns.str.strip()
        if "Enabled_Flag" in df.columns:
            df = df[df["Enabled_Flag"]=="Enabled"]
        return df
    except Exception as e:
        logging.error(f"Error reading ERP => {e}")
        return pd.DataFrame()

# ----------------------------------------------------------------------------
# MASTER => read from .txt in ZIP
# ----------------------------------------------------------------------------
def read_txt_2encodings(raw: bytes) -> pd.DataFrame:
    """Try reading with utf-8-sig, then utf-16-le."""
    import io
    import pandas as pd
    for enc in ["utf-8-sig","utf-16-le"]:
        try:
            buf = io.BytesIO(raw)
            df = pd.read_csv(buf, encoding=enc, on_bad_lines="skip", engine="python")
            df.dropna(how="all", axis=0, inplace=True)
            df.dropna(how="all", axis=1, inplace=True)
            df.columns = df.columns.astype(str).str.strip()
            logging.info(f"[read_txt_2encodings] success with {enc}, shape={df.shape}")
            return df
        except Exception as e:
            logging.debug(f"[read_txt_2encodings] fail with {enc} => {e}")
    logging.error("[read_txt_2encodings] cannot parse => empty DF.")
    return pd.DataFrame()

def convert_master_txt_to_csv(zip_path: Path, out_dir: Path) -> List[Path]:
    """Unzip .txt files, read them, produce .csv => returns list of csv paths."""
    import pandas as pd
    if not zip_path.is_file():
        logging.warning(f"[Master] ZIP not found => {zip_path}")
        return []
    if out_dir.exists():
        shutil.rmtree(out_dir, ignore_errors=True)
    out_dir.mkdir(parents=True, exist_ok=True)
    csvs=[]
    with zipfile.ZipFile(zip_path,"r") as z:
        txt_files = [f for f in z.namelist() if f.lower().endswith(".txt")]
        for txtf in txt_files:
            base = os.path.basename(txtf)
            if not base:
                continue
            try:
                with z.open(txtf) as fo:
                    raw = fo.read()
                df = read_txt_2encodings(raw)
                if df.empty:
                    continue
                df["RawFileName"] = base
                if "Name" not in df.columns and len(df.columns)>0:
                    firstcol = df.columns[0]
                    df.rename(columns={firstcol:"Name"}, inplace=True)
                out_csv = out_dir / (base.replace(".txt",".csv"))
                df.to_csv(out_csv, index=False, encoding="utf-8")
                csvs.append(out_csv)
            except Exception as e:
                logging.error(f"[Master] error reading {txtf} => {e}")
    return csvs

def unify_master_csvs(csvs: List[Path]) -> pd.DataFrame:
    """Concatenate all .csv => one DF."""
    import pandas as pd
    frames=[]
    for cp in csvs:
        if not cp.is_file():
            continue
        try:
            df = pd.read_csv(cp, encoding="utf-8", on_bad_lines="skip")
            df.columns = df.columns.str.strip()
            frames.append(df)
        except Exception as e:
            logging.error(f"[unify_master_csvs] => {e}")
    if frames:
        return pd.concat(frames, ignore_index=True)
    return pd.DataFrame()

# ----------------------------------------------------------------------------
# MELTDOWN => meltdown_erp_for_preview, meltdown_master_for_preview => pivot
# ----------------------------------------------------------------------------
def meltdown_erp_for_preview(df: pd.DataFrame, param: Dict[str, object]) -> pd.DataFrame:
    keep = param.get("dim_erp_keep", set())
    dmap = param.get("dim_erp_map", {})
    amap = param.get("attr_erp_map", {})
    if "V_S_C" not in df.columns:
        return pd.DataFrame()
    df2 = df[df["V_S_C"].isin(keep)].copy()
    if df2.empty:
        return pd.DataFrame()
    skip_cols = {"V_S_C","Enabled_Flag"}
    id_vars = []
    if "Value" in df2.columns:
        id_vars.append("Value")
        skip_cols.add("Value")
    df2["DimRaw"] = df2["V_S_C"]
    skip_cols.add("DimRaw")
    id_vars.insert(0,"DimRaw")

    meltdown_cols = [c for c in df2.columns if c not in skip_cols]
    melted = df2.melt(
        id_vars=id_vars,
        value_vars=meltdown_cols,
        var_name="OrigAttr",
        value_name="ValX"
    )

    def rename_dim(v):
        return dmap.get(v, v)
    melted["Dimension"] = melted["DimRaw"].apply(rename_dim)
    if "Value" in id_vars:
        melted.rename(columns={"Value":"Name"}, inplace=True)
    else:
        melted["Name"] = ""

    melted = melted[melted["OrigAttr"].isin(amap.keys())].copy()
    melted["Attribute"] = melted["OrigAttr"].map(amap)

    def strip_t(v):
        if isinstance(v,str) and "T" in v:
            return v.split("T")[0]
        return v
    melted["Value"] = np.where(
        melted["Attribute"].isin(["Start Date","End Date"]),
        melted["ValX"].apply(strip_t),
        melted["ValX"]
    )
    return melted[["Dimension","Name","Attribute","Value"]]

def meltdown_master_for_preview(df: pd.DataFrame, param: Dict[str, object]) -> pd.DataFrame:
    keep_map = param.get("dim_master_map", {})
    amap = param.get("attr_master_map", {})
    if df.empty or "RawFileName" not in df.columns:
        return pd.DataFrame()
    df2 = df[df["RawFileName"].isin(keep_map.keys())].copy()
    if df2.empty:
        return pd.DataFrame()
    df2["DimRaw"] = df2["RawFileName"]
    skip_cols= {"RawFileName","DimRaw"}
    id_vars= ["DimRaw"]
    if "Name" in df2.columns:
        id_vars.append("Name")
        skip_cols.add("Name")

    meltdown_cols = [c for c in df2.columns if c not in skip_cols]
    melted= df2.melt(
        id_vars=id_vars,
        value_vars=meltdown_cols,
        var_name="OrigAttr",
        value_name="ValX"
    )

    def rename_dim(fn):
        return keep_map.get(fn, fn)
    melted["Dimension"] = melted["DimRaw"].apply(rename_dim)
    if "Name" not in melted.columns:
        melted["Name"] = ""

    melted = melted[melted["OrigAttr"].isin(amap.keys())].copy()
    melted["Attribute"] = melted["OrigAttr"].map(amap)

    def strip_t(v):
        if isinstance(v,str) and "T" in v:
            return v.split("T")[0]
        return v
    melted["Value"] = np.where(
        melted["Attribute"].isin(["Start Date","End Date"]),
        melted["ValX"].apply(strip_t),
        melted["ValX"]
    )
    return melted[["Dimension","Name","Attribute","Value"]]

def pivot_for_preview(df: pd.DataFrame) -> pd.DataFrame:
    if df.empty or {"Dimension","Name","Attribute"}.difference(df.columns):
        return df
    df2= df.drop_duplicates(subset=["Dimension","Name","Attribute"]).copy()
    try:
        df2= df2.pivot(index=["Dimension","Name"], columns="Attribute", values="Value").reset_index()
    except Exception as e:
        logging.error(f"Pivot error => {e}")
    return df2

# ----------------------------------------------------------------------------
# MISSING ITEMS COMPARISON
# ----------------------------------------------------------------------------
def melt_back(df: pd.DataFrame) -> pd.DataFrame:
    if df.empty or {"Dimension","Name"}.difference(df.columns):
        return pd.DataFrame()
    meltdown_cols = [c for c in df.columns if c not in ("Dimension","Name")]
    melted= df.melt(
        id_vars=["Dimension","Name"],
        value_vars=meltdown_cols,
        var_name="Attribute",
        value_name="Value"
    )
    return melted

def build_keys(df: pd.DataFrame)-> pd.DataFrame:
    df= df.copy()
    for c in ["Dimension","Name","Attribute","Value"]:
        if c not in df.columns:
            df[c]=""
        df[c]= df[c].fillna("").astype(str).str.strip()
    df["GroupKey"] = df["Dimension"]+" | "+df["Name"]
    df["Key"] = df["Dimension"]+" | "+df["Name"]+" | "+df["Attribute"]+" | "+df["Value"]
    df["Comments_1"]=""
    df["Comments_2"]=""
    df["Action Item"]=""
    df["Missing In"]=""
    return df

def compare_mode2(df_erp: pd.DataFrame, df_mast: pd.DataFrame) -> pd.DataFrame:
    def to_dict(d):
        out={}
        for gk, grp in d.groupby("GroupKey"):
            rec={}
            nm= grp["Name"].iloc[0] if not grp.empty else ""
            rec["Name"] = nm
            for _, row in grp.iterrows():
                rec[row["Attribute"]] = row["Value"]
            out[gk] = rec
        return out
    e_dict = to_dict(df_erp)
    m_dict = to_dict(df_mast)
    all_gk = set(e_dict.keys())| set(m_dict.keys())
    results=[]
    for gk in all_gk:
        dim= gk.split(" | ")[0]
        a_data= e_dict.get(gk,{})
        b_data= m_dict.get(gk,{})
        name_a= a_data.get("Name","")
        name_b= b_data.get("Name","")
        if name_a and name_b and name_a==name_b:
            # compare attributes
            all_attrs= (set(a_data.keys())| set(b_data.keys()))-{"Name"}
            for at in all_attrs:
                va= a_data.get(at,"")
                vb= b_data.get(at,"")
                if va!=vb:
                    if va and not vb:
                        results.append({"Dimension":dim,"Name":name_a,"Attribute":at,"Value":va,"Missing In":"MASTER"})
                    elif vb and not va:
                        results.append({"Dimension":dim,"Name":name_a,"Attribute":at,"Value":vb,"Missing In":"ERP"})
                    else:
                        # difference
                        results.append({"Dimension":dim,"Name":name_a,"Attribute":at,"Value":va,"Missing In":"MASTER"})
                        results.append({"Dimension":dim,"Name":name_a,"Attribute":at,"Value":vb,"Missing In":"ERP"})
        else:
            if name_a and not name_b:
                results.append({"Dimension":dim,"Name":name_a,"Attribute":"Name","Value":name_a,"Missing In":"MASTER"})
            elif name_b and not name_a:
                results.append({"Dimension":dim,"Name":name_b,"Attribute":"Name","Value":name_b,"Missing In":"ERP"})
    df_res= pd.DataFrame(results)
    if not df_res.empty:
        df_res["Key"]= (df_res["Dimension"].str.strip()+" | "+
                        df_res["Name"].str.strip()+" | "+
                        df_res["Attribute"].str.strip()+" | "+
                        df_res["Value"].str.strip())
    return df_res

def read_exception_table(path: Path)-> pd.DataFrame:
    import pandas as pd
    if not path.is_file():
        logging.warning(f"Exception table not found => {path}")
        return pd.DataFrame()
    try:
        df = pd.read_excel(path)
        df.columns= df.columns.astype(str).str.strip()
        return df
    except Exception as e:
        logging.error(f"Error reading exception => {e}")
        return pd.DataFrame()

def merge_exceptions(df: pd.DataFrame, df_exc: pd.DataFrame)-> pd.DataFrame:
    if df.empty or df_exc.empty or "Key" not in df.columns:
        return df
    keep_cols= [c for c in df_exc.columns if c in ("Key","Comments_1","Comments_2","hide exception")]
    if not keep_cols:
        return df
    exc= df_exc[keep_cols].copy()
    exc["Key"] = exc["Key"].astype(str).str.strip()
    merged= df.merge(exc, on="Key", how="left", suffixes=("","_exc"))
    merged["hide exception"] = merged.get("hide exception","").fillna("").str.lower()
    final= merged[merged["hide exception"]!="yes"].copy()
    if "Comments_1_exc" in final.columns:
        final["Comments_1"] = np.where(final["Comments_1_exc"].notna(), final["Comments_1_exc"], final["Comments_1"])
        final.drop(columns=["Comments_1_exc"], inplace=True)
    if "Comments_2_exc" in final.columns:
        final["Comments_2"] = np.where(final["Comments_2_exc"].notna(), final["Comments_2_exc"], final["Comments_2"])
        final.drop(columns=["Comments_2_exc"], inplace=True)
    if "hide exception" in final.columns:
        final.drop(columns=["hide exception"], inplace=True)
    return final

def write_missing_items(df: pd.DataFrame, out_path: Path):
    """Write mismatch results to an Excel 'Missing Items' tab."""
    import pandas as pd
    from openpyxl import Workbook
    from openpyxl.styles import PatternFill, Font, Alignment
    if df.empty:
        logging.info("No missing items => skip writing missing_items.xlsx")
        return
    out_path.parent.mkdir(parents=True, exist_ok=True)
    final_cols= ["Key","Dimension","Name","Attribute","Value","Comments_1","Comments_2","Action Item","Missing In"]
    for c in final_cols:
        if c not in df.columns:
            df[c]=""
    df= df[final_cols].copy()
    wb= Workbook()
    ws= wb.active
    ws.title= "Missing Items"
    ws.append(final_cols)
    for rowvals in df.itertuples(index=False):
        ws.append(rowvals)
    # style header
    header_font= Font(bold=True)
    fill= PatternFill(start_color="DDDDDD", end_color="DDDDDD", fill_type="solid")
    for cell in ws[1]:
        cell.font= header_font
        cell.fill= fill
        cell.alignment= Alignment(horizontal="center")
    # autosize columns
    for col in ws.columns:
        max_len=0
        letter= col[0].column_letter
        for cell in col:
            val= str(cell.value) if cell.value else ""
            max_len= max(max_len, len(val))
        ws.column_dimensions[letter].width= max_len+2
    ws.freeze_panes= "A2"
    wb.save(out_path)
    logging.info(f"Missing items => {out_path}")

# ----------------------------------------------------------------------------
# SIMPLE PREVIEW
# ----------------------------------------------------------------------------
class SimplePreview(ctk.CTkFrame):
    FILTERABLE = {"Start Date","End Date"}
    def __init__(self, parent, name: str, filters_dict=None):
        super().__init__(parent)
        self.name = name
        self.df = pd.DataFrame()
        self.filters: Dict[str, Set] = {}
        if filters_dict:
            for col, val_list in filters_dict.items():
                if isinstance(val_list, list):
                    self.filters[col] = set(val_list)
                else:
                    self.filters[col] = val_list

        self.create_toolbar()
        self.create_table()
        self.create_statusbar()

    def create_toolbar(self):
        bar= ctk.CTkFrame(self, corner_radius=10, fg_color="#f0f0f0")
        bar.pack(fill="x", padx=5, pady=5)
        title_label= ctk.CTkLabel(bar, text=f"{self.name} Preview",
                                  fg_color="#800020", corner_radius=8,
                                  text_color="white",
                                  font=ctk.CTkFont(size=14, weight="bold"))
        title_label.pack(side="left", padx=5)
        ctk.CTkButton(bar, text="ⓘ", width=30, command=self.show_info,
                      fg_color="#800020", hover_color="#a52a2a",
                      text_color="white").pack(side="left", padx=5)
        ctk.CTkButton(bar, text="Clear Date Filters", command=self.clear_filters,
                      fg_color="#800020", hover_color="#a52a2a",
                      text_color="white").pack(side="left", padx=5)

    def show_info(self):
        messagebox.showinfo("Info",
            f"{self.name} data after meltdown & param. Only Start/End Date columns are filterable."
        )

    def create_table(self):
        container= ctk.CTkFrame(self)
        container.pack(fill="both", expand=True, padx=5, pady=5)
        self.tree= ttk.Treeview(container, show="headings")
        vsb= ttk.Scrollbar(container, orient="vertical", command=self.tree.yview)
        hsb= ttk.Scrollbar(container, orient="horizontal", command=self.tree.xview)
        self.tree.configure(yscrollcommand=vsb.set, xscrollcommand=hsb.set)
        self.tree.grid(row=0, column=0, sticky="nsew")
        vsb.grid(row=0, column=1, sticky="ns")
        hsb.grid(row=1, column=0, sticky="ew")
        container.rowconfigure(0, weight=1)
        container.columnconfigure(0, weight=1)

    def create_statusbar(self):
        self.status_label= ctk.CTkLabel(self, text="0 rows", fg_color="#f0f0f0", text_color="black")
        self.status_label.pack(fill="x")

    def set_data(self, df: pd.DataFrame):
        self.df= df.copy()
        self.refresh_table()

    def refresh_table(self):
        for i in self.tree.get_children():
            self.tree.delete(i)
        if self.df.empty:
            self.tree["columns"]=[]
            self.status_label.configure(text="0 rows")
            return
        cols= list(self.df.columns)
        self.tree["columns"] = cols
        for c in cols:
            self.tree.heading(c, text=c, anchor="w",
                              command=lambda col=c: self.on_heading_click(col))
            self.tree.column(c, anchor="w", width=150)
        df_f= self.apply_filters()
        for _, row in df_f.iterrows():
            rowvals= [row.get(c,"") for c in cols]
            self.tree.insert("", "end", values=rowvals)
        self.status_label.configure(text=f"{len(df_f)} rows")

    def apply_filters(self)-> pd.DataFrame:
        df_f= self.df.copy()
        for col, allowed in self.filters.items():
            if col in df_f.columns and len(allowed)>0:
                df_f= df_f[df_f[col].isin(allowed)]
        return df_f

    def on_heading_click(self, col_name: str):
        if col_name in self.FILTERABLE:
            self.show_filter_popup(col_name)

    def show_filter_popup(self, col_name: str):
        if self.df.empty or col_name not in self.df.columns:
            return
        popup= tk.Toplevel(self)
        popup.title(f"Filter: {col_name}")
        popup.geometry("300x400")
        frame= ctk.CTkFrame(popup)
        frame.pack(fill="both", expand=True, padx=5, pady=5)
        unique_vals= self.df[col_name].unique()
        display_map={}
        for v in unique_vals:
            if pd.isna(v):
                dsp= "(NaN)"
            elif isinstance(v,str) and not v.strip():
                dsp= "(blank)"
            else:
                dsp= str(v)
            display_map[v]= dsp
        sorted_vals= sorted(display_map.keys(), key=lambda x: display_map[x].lower())
        all_vals= set(sorted_vals)
        curr_filter= self.filters.get(col_name, all_vals)

        selall_var= tk.BooleanVar(value=True)
        def toggle_all():
            check= selall_var.get()
            for vb in var_dict.values():
                vb.set(check)

        ctk.CTkCheckBox(frame, text="Select All", variable=selall_var, command=toggle_all,
                        fg_color="#800020", hover_color="#a52a2a",
                        text_color="black").pack(anchor="w", pady=5)

        scroll= ctk.CTkScrollableFrame(frame, width=250, height=250)
        scroll.pack(fill="both", expand=True, padx=5, pady=5)
        var_dict={}
        for rv in sorted_vals:
            in_filter= rv in curr_filter
            bvar= tk.BooleanVar(value=in_filter)
            var_dict[rv]= bvar
            ctk.CTkCheckBox(scroll, text=display_map[rv], variable=bvar,
                            fg_color="#800020", hover_color="#a52a2a",
                            text_color="black").pack(anchor="w")

        def apply_():
            sel= {rv for rv,vb in var_dict.items() if vb.get()}
            if sel==all_vals or not sel:
                if col_name in self.filters:
                    del self.filters[col_name]
            else:
                self.filters[col_name]= sel
            popup.destroy()
            self.refresh_table()

        bf= ctk.CTkFrame(frame)
        bf.pack(fill="x", pady=5)
        ctk.CTkButton(bf, text="Apply", command=apply_,
                      fg_color="#800020", hover_color="#a52a2a",
                      text_color="white").pack(side="left", padx=5)
        ctk.CTkButton(bf, text="Cancel", command=popup.destroy,
                      fg_color="#800020", hover_color="#a52a2a",
                      text_color="white").pack(side="left", padx=5)

    def clear_filters(self):
        # remove only date filters
        remove_keys=[]
        for k in self.filters:
            if k in self.FILTERABLE:
                remove_keys.append(k)
        for rk in remove_keys:
            del self.filters[rk]
        self.refresh_table()

    def get_filtered_df(self)-> pd.DataFrame:
        return self.apply_filters()

# ----------------------------------------------------------------------------
# PDF REPORT with Tritanopia palette & new executive summary
# ----------------------------------------------------------------------------
class EnhancedPDFReport:
    """
    Watermark on cover only, 8.5x11 pages.
    Tritanopia-friendly palette for charts.
    """
    def __init__(self, df_current: pd.DataFrame, df_history: pd.DataFrame, config: Dict):
        self.df_current = df_current
        self.df_history = df_history
        self.config = config

        # Tritanopia-friendly palette
        self.palette = {
            "background": "#FFFFFF",
            "title_color": "#000000",
            # A small set of Tritanopia-friendly colors (blues/greens/oranges):
            "color1": "#0072B2",
            "color2": "#009E73",
            "color3": "#D55E00",
            "color4": "#CC79A7",
            "color5": "#F0E442",
        }
        self.logo_path = self.config["paths"].get("LOGO_PATH","images/company_logo.png")

    def generate(self) -> Path:
        pdf_path= self._get_output_path()
        with PdfPages(pdf_path) as pdf:
            self._cover_page(pdf)
            self._exec_summary(pdf)
            self._trend_analysis(pdf)
            # you can add more pages: top dims, top attrs, etc.
        logging.info(f"PDF exported => {pdf_path}")
        return pdf_path

    def _get_output_path(self)-> Path:
        base= self.config["paths"].get("PDF_EXPORT_PATH","output/dashboard_reports")
        outdir= Path(base)
        outdir.mkdir(parents=True, exist_ok=True)
        stamp= datetime.now().strftime("%Y%m%d_%H%M%S")
        fname= f"recon_report_{stamp}.pdf"
        return outdir / fname

    def _cover_page(self, pdf: PdfPages):
        fig= plt.figure(figsize=(8.5,11))
        fig.patch.set_facecolor(self.palette["background"])
        plt.axis('off')
        # watermark only on cover
        self._stamp_logo(fig)
        plt.text(0.5, 0.6, "Ultra-Mega Reconciliation\n(Dashboard & Analysis)",
                 ha="center", fontsize=24, color=self.palette["title_color"], transform=fig.transFigure)
        plt.text(0.5, 0.52, f"Generated on {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
                 ha="center", fontsize=12, color=self.palette["color1"], transform=fig.transFigure)
        pdf.savefig(fig)
        plt.close(fig)

    def _stamp_logo(self, fig):
        if not self.logo_path or not os.path.exists(self.logo_path):
            return
        try:
            import matplotlib.image as mpimg
            img= mpimg.imread(self.logo_path)
            # place at x=72,y=720 => or some offset
            fig.figimage(img, 100, 700, alpha=0.2)
        except Exception as e:
            logging.error(f"Logo error => {e}")

    def _exec_summary(self, pdf: PdfPages):
        fig= plt.figure(figsize=(8.5,11))
        fig.patch.set_facecolor(self.palette["background"])
        plt.axis('off')
        plt.text(0.5, 0.92, "Executive Summary", ha="center", fontsize=18, color=self.palette["title_color"], transform=fig.transFigure)

        y= 0.78
        if self.df_current.empty:
            txt= "No mismatches found in the current run."
            plt.text(0.5, y, txt, ha="center", fontsize=14, color=self.palette["color1"], transform=fig.transFigure)
        else:
            # stats
            total= len(self.df_current)
            cnt_erp= (self.df_current["Missing In"]=="ERP").sum()
            cnt_master= (self.df_current["Missing In"]=="MASTER").sum()
            topdim= "(None)"
            if "Dimension" in self.df_current.columns:
                d= self.df_current["Dimension"].value_counts()
                if not d.empty:
                    topdim= f"{d.index[0]} ({d.iloc[0]})"

            lines= [
                f"Total mismatches: {total}",
                f"Missing in ERP: {cnt_erp}",
                f"Missing in Master: {cnt_master}",
                f"Most affected dimension: {topdim}",
            ]
            bigtxt= "\n".join(lines)
            plt.text(0.5, y, bigtxt, ha="center", fontsize=14, color=self.palette["color2"], transform=fig.transFigure)

        pdf.savefig(fig)
        plt.close(fig)

    def _trend_analysis(self, pdf: PdfPages):
        fig= plt.figure(figsize=(8.5,11))
        fig.patch.set_facecolor(self.palette["background"])
        plt.axis('off')
        plt.text(0.5, 0.92, "Trend Analysis (Historical)", ha="center", fontsize=16,
                 color=self.palette["title_color"], transform=fig.transFigure)

        if self.df_history.empty or "RunDate" not in self.df_history.columns:
            plt.text(0.5, 0.5, "No historical data available.", ha="center", fontsize=12,
                     color=self.palette["color3"], transform=fig.transFigure)
            pdf.savefig(fig)
            plt.close(fig)
            return

        # We group by RunDate
        date_ct= self.df_history.groupby("RunDate")["Key"].count().reset_index(name="Count")
        date_ct.sort_values("RunDate", inplace=True)
        ax= fig.add_axes([0.15, 0.3, 0.7, 0.5])
        try:
            date_ct["RunDate_dt"] = pd.to_datetime(date_ct["RunDate"], errors="coerce")
            ax.plot(date_ct["RunDate_dt"], date_ct["Count"], marker="o", color=self.palette["color3"], label="Missing Count")
            # average line
            avg_val= date_ct["Count"].mean() if len(date_ct)>0 else 0
            ax.axhline(avg_val, color=self.palette["color4"], linestyle="--", label=f"Average={avg_val:.1f}")
            ax.set_title("Historical Mismatch Trend")
            ax.set_xlabel("RunDate")
            ax.set_ylabel("Mismatch Count")
            plt.xticks(rotation=45)
            ax.legend()

            for i, rowv in date_ct.iterrows():
                x= rowv["RunDate_dt"]
                y= rowv["Count"]
                ax.text(x, y, str(y), ha="center", va="bottom", fontsize=8)
        except Exception as e:
            logging.error(f"Trend analysis => {e}")

        pdf.savefig(fig)
        plt.close(fig)

# ----------------------------------------------------------------------------
# HISTORY TAB
# ----------------------------------------------------------------------------
class HistoryTab(ctk.CTkFrame):
    """Lets user browse JSON files in history_runs, open them or show summary."""
    def __init__(self, parent, history_dir: Path):
        super().__init__(parent)
        self.history_dir= history_dir
        self.tree= None
        self.build_ui()

    def build_ui(self):
        lbl= ctk.CTkLabel(self, text="History of Runs", font=("Arial", 16))
        lbl.pack(pady=5)
        self.tree= ttk.Treeview(self, columns=("filename",), show="headings", height=15)
        self.tree.heading("filename", text="History File")
        self.tree.pack(fill="both", expand=True, padx=10, pady=10)
        self.tree.bind("<Double-1>", self.on_open_file)
        btn_frame= ctk.CTkFrame(self)
        btn_frame.pack(fill="x", pady=5)
        ctk.CTkButton(btn_frame, text="Refresh", command=self.refresh_history,
                      fg_color="#800020", hover_color="#a52a2a",
                      text_color="white").pack(side="left", padx=5)
        self.refresh_history()

    def refresh_history(self):
        for i in self.tree.get_children():
            self.tree.delete(i)
        if not self.history_dir.is_dir():
            self.history_dir.mkdir(parents=True, exist_ok=True)
        files= sorted(self.history_dir.glob("*.json"), reverse=True)
        for f in files:
            self.tree.insert("", "end", values=(f.name,))

    def on_open_file(self, event):
        item_id= self.tree.focus()
        if not item_id:
            return
        fname= self.tree.item(item_id, "values")[0]
        path= self.history_dir / fname
        if not path.is_file():
            return
        # Ask user: open raw or summary
        answer= messagebox.askyesno("Open History", "Yes= open raw JSON, No= show summary?")
        try:
            with open(path, "r", encoding="utf-8") as f:
                data= json.load(f)
        except Exception as e:
            logging.error(f"Error reading {path} => {e}")
            return
        if answer:
            # raw
            top= tk.Toplevel(self)
            top.title(f"{fname} (raw)")
            txt= ctk.CTkTextbox(top, width=800, height=600)
            txt.pack(fill="both", expand=True)
            txt.insert("end", json.dumps(data, indent=2))
            txt.configure(state="disabled")
        else:
            # summary
            # we assume data is a list of records or something
            # Show dimension, missing in, etc.
            if not isinstance(data, list):
                # might be a dictionary with "RunDate" etc.
                # Just show
                messagebox.showinfo("Summary", f"JSON structure => {data}")
                return
            df= pd.DataFrame(data)
            if df.empty:
                messagebox.showinfo("Summary", f"No data in {fname}")
            else:
                # Summarize dimension & "Missing In"
                missing_in_ct= df["Missing In"].value_counts() if "Missing In" in df.columns else []
                dim_ct= df["Dimension"].value_counts() if "Dimension" in df.columns else []
                txt= "Summary:\n"
                txt+= f"- Total: {len(df)}\n"
                if isinstance(missing_in_ct, pd.Series) and not missing_in_ct.empty:
                    txt+= f"- Missing In:\n"
                    for idx,v in missing_in_ct.items():
                        txt+= f"   {idx}: {v}\n"
                if isinstance(dim_ct, pd.Series) and not dim_ct.empty:
                    txt+= f"- Top dimension: {dim_ct.index[0]} => {dim_ct.iloc[0]}\n"
                messagebox.showinfo("Summary", txt)

# ----------------------------------------------------------------------------
# MAIN APP
# ----------------------------------------------------------------------------
class MainApp(ctk.CTk):
    def __init__(self):
        super().__init__()
        self.title("Ultra-Mega Reconciliation: Param-based, Full Dashboard")
        self.geometry("1600x900")
        ctk.set_appearance_mode("light")

        # load config
        self.config_dict= load_config(Path(DEFAULT_PATHS["CONFIG_PATH"]))
        # param
        self.param_dict= read_param_file(Path(self.config_dict["paths"].get("PARAMETER_PATH", DEFAULT_PATHS["PARAMETER_PATH"])))
        self.history_df= pd.DataFrame()

        self.tabs= ttk.Notebook(self)
        self.tabs.pack(fill="both", expand=True)

        # Path tab
        self.tab_paths= ctk.CTkFrame(self.tabs)
        self.tabs.add(self.tab_paths, text="Paths")
        self.build_paths_tab(self.tab_paths)

        # ERP preview
        self.tab_erp= ctk.CTkFrame(self.tabs)
        erp_filters= self.config_dict.get("erp_grid",{}).get("filters",{})
        self.erp_preview= SimplePreview(self.tab_erp, "ERP", filters_dict=erp_filters)
        self.erp_preview.pack(fill="both", expand=True)
        self.tabs.add(self.tab_erp, text="ERP Preview")

        # Master preview
        self.tab_master= ctk.CTkFrame(self.tabs)
        master_filters= self.config_dict.get("master_grid",{}).get("filters",{})
        self.master_preview= SimplePreview(self.tab_master, "Master", filters_dict=master_filters)
        self.master_preview.pack(fill="both", expand=True)
        self.tabs.add(self.tab_master, text="Master Preview")

        # Compare tab
        self.tab_compare= ctk.CTkFrame(self.tabs)
        self.build_compare_tab(self.tab_compare)
        self.tabs.add(self.tab_compare, text="Compare")

        # Dashboard
        self.dashboard_tab= AdvancedDashboard(self.tabs)
        self.tabs.add(self.dashboard_tab, text="Dashboard")

        # History tab
        hist_dir= Path(self.config_dict["paths"].get("HISTORY_PATH","history_runs"))
        self.history_tab= HistoryTab(self.tabs, hist_dir)
        self.tabs.add(self.history_tab, text="History")

        # Log box
        self.log_box= ctk.CTkTextbox(self, height=120)
        self.log_box.pack(fill="both")
        self.log_box.configure(state="disabled")
        handler= TextHandler(self.log_box)
        handler.setLevel(logging.INFO)
        logging.getLogger().addHandler(handler)

        self.temp_csv_dir= Path(self.config_dict["paths"].get("MASTER_CSV_OUTPUT","temp_master_csv"))
        self.temp_csv_dir.mkdir(parents=True, exist_ok=True)

        # initial meltdown => preview
        self.refresh_erp()
        self.refresh_master()

        # close button
        ctk.CTkButton(self, text="Close", command=self.quit,
                      fg_color="#800020", hover_color="#a52a2a",
                      text_color="white").pack(pady=5)

    def build_paths_tab(self, parent):
        frm= ctk.CTkFrame(parent)
        frm.pack(fill="both", expand=True, padx=10, pady=10)

        self.erp_var= tk.StringVar(value=self.config_dict["paths"].get("ERP_EXCEL_PATH", DEFAULT_PATHS["ERP_EXCEL_PATH"]))
        self.mast_var= tk.StringVar(value=self.config_dict["paths"].get("MASTER_ZIP_PATH", DEFAULT_PATHS["MASTER_ZIP_PATH"]))
        self.exc_var= tk.StringVar(value=self.config_dict["paths"].get("EXCEPTION_PATH", DEFAULT_PATHS["EXCEPTION_PATH"]))
        self.out_var= tk.StringVar(value=self.config_dict["paths"].get("OUTPUT_PATH", DEFAULT_PATHS["OUTPUT_PATH"]))
        self.cfg_var= tk.StringVar(value=self.config_dict["paths"].get("CONFIG_PATH", DEFAULT_PATHS["CONFIG_PATH"]))
        self.par_var= tk.StringVar(value=self.config_dict["paths"].get("PARAMETER_PATH", DEFAULT_PATHS["PARAMETER_PATH"]))
        self.csv_var= tk.StringVar(value=self.config_dict["paths"].get("MASTER_CSV_OUTPUT", DEFAULT_PATHS["MASTER_CSV_OUTPUT"]))
        self.pdf_var= tk.StringVar(value=self.config_dict["paths"].get("PDF_EXPORT_PATH", DEFAULT_PATHS["PDF_EXPORT_PATH"]))

        def mkrow(lbl, var, is_dir=False):
            rowf= ctk.CTkFrame(frm)
            rowf.pack(fill="x", pady=5)
            ctk.CTkLabel(rowf, text=lbl, width=180).pack(side="left", padx=5)
            e= ctk.CTkEntry(rowf, textvariable=var, width=600)
            e.pack(side="left", padx=5)
            def br():
                if is_dir:
                    p= filedialog.askdirectory()
                else:
                    p= filedialog.askopenfilename()
                if p:
                    var.set(p)
            ctk.CTkButton(rowf, text="Browse", command=br,
                          fg_color="#800020", hover_color="#a52a2a",
                          text_color="white").pack(side="left", padx=5)

        mkrow("ERP Excel:", self.erp_var)
        mkrow("Master ZIP:", self.mast_var)
        mkrow("Exception Path:", self.exc_var)
        mkrow("Missing Items Output:", self.out_var)
        mkrow("JSON Config Path:", self.cfg_var)
        mkrow("Parameter File:", self.par_var)
        mkrow("Master CSV Folder:", self.csv_var, is_dir=True)
        mkrow("PDF Export Folder:", self.pdf_var, is_dir=True)

        bf= ctk.CTkFrame(frm)
        bf.pack(fill="x", pady=10)
        ctk.CTkButton(bf, text="Save Config", command=self.save_all_config,
                      fg_color="#800020", hover_color="#a52a2a",
                      text_color="white").pack(side="left", padx=5)
        ctk.CTkButton(bf, text="Refresh ERP", command=self.refresh_erp,
                      fg_color="#800020", hover_color="#a52a2a",
                      text_color="white").pack(side="left", padx=5)
        ctk.CTkButton(bf, text="Refresh Master", command=self.refresh_master,
                      fg_color="#800020", hover_color="#a52a2a",
                      text_color="white").pack(side="left", padx=5)

    def build_compare_tab(self, parent):
        frm= ctk.CTkFrame(parent)
        frm.pack(fill="both", expand=True, padx=10, pady=10)
        ctk.CTkLabel(frm, text="Generate Missing Items", font=("Arial",16)).pack(pady=5)
        ctk.CTkButton(frm, text="Run Reconciliation", command=self.run_comparison,
                      fg_color="#800020", hover_color="#a52a2a",
                      text_color="white").pack(pady=10)
        ctk.CTkButton(frm, text="Export PDF Report",
                      command=self.export_pdf,
                      fg_color="#800020", hover_color="#a52a2a",
                      text_color="white").pack(pady=10)

    def export_pdf(self):
        if self.history_df.empty:
            messagebox.showinfo("PDF Export", "No mismatch data to export (history is empty).")
            return
        # take last run
        last_run= self.history_df["RunDate"].max()
        df_current= self.history_df[self.history_df["RunDate"]==last_run].copy()
        df_history= self.history_df.copy()
        rep= EnhancedPDFReport(df_current, df_history, self.config_dict)
        pdf_path= rep.generate()
        messagebox.showinfo("PDF Export", f"PDF => {pdf_path}")

    def refresh_erp(self):
        from pathlib import Path
        ep= Path(self.erp_var.get().strip())
        raw= read_erp_excel(ep)
        if raw.empty:
            self.erp_preview.set_data(pd.DataFrame())
            return
        # meltdown
        param= self.param_dict
        erp_melt= meltdown_erp_for_preview(raw, {
            "dim_erp_keep": param.get("dim_erp_keep", set()),
            "dim_erp_map": param.get("dim_erp_map", {}),
            "attr_erp_map": param.get("attr_erp_map", {})
        })
        pivoted= pivot_for_preview(erp_melt)
        self.erp_preview.set_data(pivoted)

    def refresh_master(self):
        from pathlib import Path
        zp= Path(self.mast_var.get().strip())
        outdir= Path(self.csv_var.get().strip())
        csvs= convert_master_txt_to_csv(zp, outdir)
        raw= unify_master_csvs(csvs)
        if raw.empty:
            self.master_preview.set_data(pd.DataFrame())
            return
        param= self.param_dict
        mast_melt= meltdown_master_for_preview(raw, {
            "dim_master_map": param.get("dim_master_map", {}),
            "attr_master_map": param.get("attr_master_map", {})
        })
        pivoted= pivot_for_preview(mast_melt)
        self.master_preview.set_data(pivoted)

    def run_comparison(self):
        df_erp_wide= self.erp_preview.get_filtered_df()
        df_mast_wide= self.master_preview.get_filtered_df()
        erp_long= melt_back(df_erp_wide)
        erp_long= build_keys(erp_long)
        mast_long= melt_back(df_mast_wide)
        mast_long= build_keys(mast_long)

        df_diff= compare_mode2(erp_long, mast_long)
        exc_path= Path(self.exc_var.get().strip())
        df_exc= read_exception_table(exc_path)
        final= merge_exceptions(df_diff, df_exc)

        out_path= Path(self.out_var.get().strip())
        write_missing_items(final, out_path)

        run_date= datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        final["RunDate"]= run_date
        if self.history_df.empty:
            self.history_df= final.copy()
        else:
            self.history_df= pd.concat([self.history_df, final], ignore_index=True)

        # also save to JSON
        hist_dir= Path(self.config_dict["paths"].get("HISTORY_PATH","history_runs"))
        hist_dir.mkdir(parents=True, exist_ok=True)
        fname= f"run_{run_date.replace(' ','_').replace(':','-')}.json"
        try:
            final.to_json(hist_dir/fname, orient="records", indent=2)
        except Exception as e:
            logging.error(f"Error saving run => {e}")

        self.dashboard_tab.update_data(final, self.history_df)
        self.tabs.select(self.dashboard_tab)
        messagebox.showinfo("Done", f"Missing items => {out_path}")

    def save_all_config(self):
        self.config_dict["paths"]["ERP_EXCEL_PATH"]  = self.erp_var.get().strip()
        self.config_dict["paths"]["MASTER_ZIP_PATH"] = self.mast_var.get().strip()
        self.config_dict["paths"]["EXCEPTION_PATH"]  = self.exc_var.get().strip()
        self.config_dict["paths"]["OUTPUT_PATH"]     = self.out_var.get().strip()
        self.config_dict["paths"]["CONFIG_PATH"]     = self.cfg_var.get().strip()
        self.config_dict["paths"]["PARAMETER_PATH"]  = self.par_var.get().strip()
        self.config_dict["paths"]["MASTER_CSV_OUTPUT"]= self.csv_var.get().strip()
        self.config_dict["paths"]["PDF_EXPORT_PATH"] = self.pdf_var.get().strip()

        # Save filters
        self.config_dict.setdefault("erp_grid", {})
        self.config_dict["erp_grid"]["filters"] = self.erp_preview.filters
        self.config_dict.setdefault("master_grid", {})
        self.config_dict["master_grid"]["filters"] = self.master_preview.filters

        save_config(self.config_dict, Path(self.config_dict["paths"]["CONFIG_PATH"]))
        messagebox.showinfo("Saved", "Config & filters saved successfully.")

def main():
    app= MainApp()
    app.mainloop()

if __name__=="__main__":
    main()
