# GEM 2 02-16

"""
Ultra-Mega Reconciliation: Parameter-based with advanced Dashboard (8 charts).

Key Features:

- **Preview Filtering (ERP & Master):**  String-based filtering for "Start Date"
  and "End Date" columns in the preview grids.
- **Dashboard Filtering:** Uses "Start Date" and "End Date" to filter run
  history data for the charts.
- **Run History:** Stores run history in the JSON config file.
- **Configuration Persistence:** Saves and loads:
    - File paths
    - Preview filters (including Start/End Date selections)
    - Run history
    - **Dashboard State:** Selected dimensions/attributes, date range,
      top N setting, and active tab.
- **PDF Export:** Generates a multi-page PDF report.
- **Error Handling:** Handles invalid date formats and other errors.
- **Modular Design:** Uses classes and functions.
"""

import os
import sys
import json
import logging
import zipfile
import shutil
import io
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, Set, List

import tkinter as tk
from tkinter import ttk, filedialog, messagebox
import customtkinter as ctk

import pandas as pd
import numpy as np

import matplotlib
matplotlib.use("TkAgg")
import matplotlib.pyplot as plt
from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg
from matplotlib.backends.backend_pdf import PdfPages

try:
    import chardet
except ImportError:
    chardet = None

try:
    import psutil
except ImportError:
    psutil = None

from openpyxl import Workbook
from openpyxl.styles import PatternFill, Font, Alignment

from PIL import Image

# ----------------------------------------------------------------------------
# LOGGING
# ----------------------------------------------------------------------------
logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")

# ----------------------------------------------------------------------------
# DEFAULT CONFIG & SAVE/LOAD
# ----------------------------------------------------------------------------
DEFAULT_PATHS = {
    "ERP_EXCEL_PATH": "data/ERP_Config.xlsx",
    "Master_ZIP_PATH": "data/Master_Config.zip",
    "EXCEPTION_PATH": "data/Exception_Table.xlsx",
    "OUTPUT_PATH": "output/missing_items.xlsx",
    "CONFIG_PATH": "config/ui_config.json",
    "PARAMETER_PATH": "data/parameters.xlsx",
    "Master_CSV_OUTPUT": "temp_Master_csv",
    "PDF_EXPORT_PATH": "output/dashboard_reports",
    "LOGO_PATH": "images/company_logo.png"
}

# --- DEFAULT DASHBOARD CONFIG ---
DEFAULT_DASHBOARD_CONFIG = {
    "selected_dims": [],  # Store selected dimensions
    "selected_attrs": [], # Store selected attributes
    "date_range": {
        "start_date": (datetime.now() - timedelta(days=30)).strftime("%Y-%m-%d"),
        "end_date": datetime.now().strftime("%Y-%m-%d")
    },
    "top_n": 10,  # Store whether showing top 10 or all
    "active_tab": 0  # Store active dashboard tab
}

def default_config() -> Dict:
    return {
        "paths": DEFAULT_PATHS.copy(),
        "ERP_grid": {"filters": {}},
        "Master_grid": {"filters": {}},
        "run_history": [],
        "dashboard": DEFAULT_DASHBOARD_CONFIG.copy()  # Include dashboard config
    }

def load_config(path: Path) -> Dict:
    if path.is_file():
        try:
            with open(path, "r", encoding="utf-8") as f:
                config = json.load(f)
                # Ensure all expected sections exist, merging with defaults
                config = {**default_config(), **config}
                return config
        except Exception as e:
            logging.warning(f"Could not load config: {e}")
    return default_config()

def save_config(cfg: Dict, path: Path):
    path.parent.mkdir(parents=True, exist_ok=True)
    try:
        # Convert sets -> lists in ERP/Master filters and dashboard selections
        for grid_name in ["ERP_grid", "Master_grid"]:
            if grid_name in cfg and "filters" in cfg[grid_name]:
                new_filters = {}
                for col, svals in cfg[grid_name]["filters"].items():
                    new_filters[col] = list(svals)  # Convert set to list
                cfg[grid_name]["filters"] = new_filters

        # Ensure dashboard config exists
        if "dashboard" not in cfg:
            cfg["dashboard"] = DEFAULT_DASHBOARD_CONFIG.copy()

        # Convert sets to lists within dashboard config (if they exist)
        for key in ["selected_dims", "selected_attrs"]:
            if key in cfg["dashboard"] and isinstance(cfg["dashboard"][key], set):
                cfg["dashboard"][key] = list(cfg["dashboard"][key])

        with open(path, "w", encoding="utf-8") as f:
            json.dump(cfg, f, indent=2)
        logging.info(f"Saved config to {path}")
    except Exception as e:
        logging.error(f"Error saving config: {e}")

# ----------------------------------------------------------------------------
# TEXT LOGGER HANDLER
# ----------------------------------------------------------------------------
class TextHandler(logging.Handler):
    def __init__(self, widget: ctk.CTkTextbox):
        super().__init__()
        self.widget = widget

    def emit(self, record):
        msg = self.format(record) + "\n"
        self.widget.after(0, self._append, msg)

    def _append(self, msg):
        self.widget.configure(state="normal")
        self.widget.insert("end", msg)
        self.widget.see("end")
        self.widget.configure(state="disabled")

# ----------------------------------------------------------------------------
# PARAMETER READING
# ----------------------------------------------------------------------------
def read_param_file(path: Path) -> Dict[str, object]:
    param = {
        "dim_ERP_keep": set(),
        "dim_ERP_map": {},
        "dim_Master_map": {},
        "attr_ERP_map": {},
        "attr_Master_map": {}
    }
    if not path.is_file():
        logging.warning(f"Param file not found => {path}")
        return param
    try:
        dim_df = pd.read_excel(path, sheet_name="Dimension Parameters")
        dim_df.columns = dim_df.columns.astype(str).str.strip()
        def s(x): return str(x).strip() if pd.notna(x) else ""
        for _, row in dim_df.iterrows():
            fn = s(row.get("FileName", ""))
            vsc = s(row.get("V S C", ""))
            dim = s(row.get("Dimension", ""))
            ev  = s(row.get("ERP Values", ""))
            if ev.lower() == "x" and vsc and dim:
                param["dim_ERP_keep"].add(vsc)
            if vsc and dim:
                param["dim_ERP_map"][vsc] = dim
            if fn and dim and ev.lower() == "x":
                param["dim_Master_map"][fn] = dim
        attr_df = pd.read_excel(path, sheet_name="Attribute Parameters")
        attr_df.columns = attr_df.columns.astype(str).str.strip()
        for _, row in attr_df.iterrows():
            e_orig = s(row.get("ERP Original Attributes", ""))
            m_orig = s(row.get("Master Original Attributes", ""))
            final_ = s(row.get("Attribute", ""))
            onoff  = s(row.get("On/Off", ""))
            if onoff.lower() == "x" and final_:
                if e_orig:
                    param["attr_ERP_map"][e_orig] = final_
                if m_orig:
                    param["attr_Master_map"][m_orig] = final_
        return param
    except Exception as e:
        logging.error(f"Error reading param file => {e}")
        return param

# ----------------------------------------------------------------------------
# ERP & Master READING
# ----------------------------------------------------------------------------
def read_ERP_excel(path: Path) -> pd.DataFrame:
    if not path.is_file():
        logging.warning(f"ERP Excel not found => {path}")
        return pd.DataFrame()
    try:
        df = pd.read_excel(path, skiprows=3)
        df.columns = df.columns.str.strip()
        if "Enabled_Flag" in df.columns:
            df = df[df["Enabled_Flag"]=="Enabled"]
        return df
    except Exception as e:
        logging.error(f"Error reading ERP => {e}")
        return pd.DataFrame()

def read_txt_2encodings(raw: bytes) -> pd.DataFrame:
    import io
    for enc in ["utf-8-sig", "utf-16-le"]:
        try:
            buf = io.BytesIO(raw)
            df = pd.read_csv(buf, encoding=enc, on_bad_lines="skip", engine="python")
            df.dropna(how="all", axis=0, inplace=True)
            df.dropna(how="all", axis=1, inplace=True)
            df.columns = df.columns.astype(str).str.strip()
            logging.info(f"[read_txt_2encodings] success with {enc}, shape={df.shape}")
            return df
        except Exception as e:
            logging.debug(f"[read_txt_2encodings] fail with {enc} => {e}")
    logging.error("[read_txt_2encodings] cannot parse .txt => empty.")
    return pd.DataFrame()

def convert_Master_txt_to_csv(zip_path: Path, out_dir: Path) -> List[Path]:
    if not zip_path.is_file():
        logging.warning(f"[Master] ZIP not found => {zip_path}")
        return []
    if out_dir.exists():
        shutil.rmtree(out_dir, ignore_errors=True)
    out_dir.mkdir(parents=True, exist_ok=True)
    csvs = []
    with zipfile.ZipFile(zip_path, "r") as z:
        txt_files = [f for f in z.namelist() if f.lower().endswith(".txt")]
        for txt_file in txt_files:
            base_name = os.path.basename(txt_file)
            if not base_name:
                continue
            try:
                with z.open(txt_file) as fo:
                    raw = fo.read()
                df = read_txt_2encodings(raw)
                if df.empty:
                    continue
                df["RawFileName"] = base_name
                if "Name" not in df.columns and len(df.columns) > 0:
                    first_col = df.columns[0]
                    df.rename(columns={first_col:"Name"}, inplace=True)
                out_csv = out_dir / (base_name.replace(".txt", ".csv"))
                df.to_csv(out_csv, index=False, encoding="utf-8")
                csvs.append(out_csv)
            except Exception as e:
                logging.error(f"[Master] error reading {txt_file} => {e}")
    return csvs

def unify_Master_csvs(csvs: List[Path]) -> pd.DataFrame:
    frames = []
    for cp in csvs:
        if not cp.is_file():
            continue
        try:
            df = pd.read_csv(cp, encoding="utf-8", on_bad_lines="skip")
            df.columns = df.columns.str.strip()
            frames.append(df)
        except Exception as e:
            logging.error(f"[unify_Master_csvs] reading {cp} => {e}")
    if frames:
        return pd.concat(frames, ignore_index=True)
    return pd.DataFrame()

# ----------------------------------------------------------------------------
# MELTDOWN FUNCTIONS (to convert wide to long)
# ----------------------------------------------------------------------------
def meltdown_ERP_for_preview(df: pd.DataFrame, param: Dict[str, object]) -> pd.DataFrame:
    if "V_S_C" not in df.columns:
        return pd.DataFrame()
    keep = param.get("dim_ERP_keep", set())
    dmap = param.get("dim_ERP_map", {})
    amap = param.get("attr_ERP_map", {})

    df2 = df[df["V_S_C"].isin(keep)].copy()
    if df2.empty:
        return pd.DataFrame()

    skip_cols = {"V_S_C", "Enabled_Flag"}
    id_vars = []
    if "Value" in df2.columns:
        id_vars.append("Value")
        skip_cols.add("Value")
    df2["DimRaw"] = df2["V_S_C"]
    skip_cols.add("DimRaw")
    id_vars.insert(0, "DimRaw")

    meltdown_cols = [c for c in df2.columns if c not in skip_cols]
    melted = df2.melt(id_vars=id_vars, value_vars=meltdown_cols,
                      var_name="OrigAttr", value_name="ValX")
    def rename_dim(v):
        return dmap.get(v, v)
    melted["Dimension"] = melted["DimRaw"].apply(rename_dim)
    if "Value" in id_vars:
        melted.rename(columns={"Value": "Name"}, inplace=True)
    else:
        melted["Name"] = ""
    melted = melted[melted["OrigAttr"].isin(amap.keys())].copy()
    melted["Attribute"] = melted["OrigAttr"].map(amap)
    # Keep original date values, don't strip 'T' for preview
    melted["Value"] = melted["ValX"]
    return melted[["Dimension", "Name", "Attribute", "Value"]]

def meltdown_Master_for_preview(df: pd.DataFrame, param: Dict[str, object]) -> pd.DataFrame:
    if df.empty or "RawFileName" not in df.columns:
        return pd.DataFrame()
    keep_map = param.get("dim_Master_map", {})
    amap = param.get("attr_Master_map", {})

    df2 = df[df["RawFileName"].isin(keep_map.keys())].copy()
    if df2.empty:
        return pd.DataFrame()

    df2["DimRaw"] = df2["RawFileName"]

    skip_cols = {"RawFileName", "DimRaw"}
    id_vars = ["DimRaw"]
    if "Name" in df2.columns:
        id_vars.append("Name")
        skip_cols.add("Name")

    meltdown_cols = [c for c in df2.columns if c not in skip_cols]
    melted = df2.melt(id_vars=id_vars, value_vars=meltdown_cols,
                      var_name="OrigAttr", value_name="ValX")
    def rename_dim(fn):
        return keep_map.get(fn, fn)
    melted["Dimension"] = melted["DimRaw"].apply(rename_dim)
    if "Name" in id_vars:
        melted.rename(columns={"Name": "Name"}, inplace=True)
    else:
        melted["Name"] = ""
    melted = melted[melted["OrigAttr"].isin(amap.keys())].copy()
    melted["Attribute"] = melted["OrigAttr"].map(amap)
    # Keep original date values, don't strip 'T' for preview
    melted["Value"] = melted["ValX"]
    return melted[["Dimension", "Name", "Attribute", "Value"]]

def pivot_for_preview(df: pd.DataFrame) -> pd.DataFrame:
    if not df.empty and {"Dimension", "Name", "Attribute"}.issubset(df.columns):
        df = df.drop_duplicates(subset=["Dimension", "Name", "Attribute"])
        try:
            df = df.pivot(index=["Dimension", "Name"], columns="Attribute", values="Value").reset_index()
        except Exception as e:
            logging.error(f"Pivot error => {e}")
    return df
# ----------------------------------------------------------------------------
# Compare Functions: Melt back wide data and produce missing items
# ----------------------------------------------------------------------------
def melt_back(df: pd.DataFrame) -> pd.DataFrame:
    if df.empty or "Dimension" not in df.columns or "Name" not in df.columns:
        return pd.DataFrame()
    skip_cols = {"Dimension", "Name"}
    meltdown_cols = [c for c in df.columns if c not in skip_cols]
    melted = df.melt(id_vars=["Dimension", "Name"], value_vars=meltdown_cols,
                     var_name="Attribute", value_name="Value")
    # Strip 'T' from dates *before* comparison
    def strip_t(val):
        if isinstance(val, str) and "T" in val:
            return val.split("T")[0]
        return val
    melted["Value"] = np.where(melted["Attribute"].isin(["Start Date", "End Date"]),
                               melted["Value"].apply(strip_t), melted["Value"])

    return melted[["Dimension", "Name", "Attribute", "Value"]]

def build_keys(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    for c in ["Dimension", "Name", "Attribute", "Value"]:
        if c not in df.columns:
            df[c] = ""
        df[c] = df[c].fillna("").astype(str).str.strip()
    df["GroupKey"] = df["Dimension"] + " | " + df["Name"]
    df["Key"] = df["Dimension"] + " | " + df["Name"] + " | " + df["Attribute"] + " | " + df["Value"]
    df["Comments_1"] = ""
    df["Comments_2"] = ""
    df["Action Item"] = ""
    df["Missing In"] = ""
    return df

def compare_mode2(df_ERP: pd.DataFrame, df_mst: pd.DataFrame) -> pd.DataFrame:
    def to_dict(d):
        out = {}
        for gk, grp in d.groupby("GroupKey"):
            rec = {}
            nm = grp["Name"].iloc[0] if not grp.empty else ""
            rec["Name"] = nm
            for _, row in grp.iterrows():
                rec[row["Attribute"]] = row["Value"]
            out[gk] = rec
        return out
    e_dict = to_dict(df_ERP)
    m_dict = to_dict(df_mst)
    all_gk = set(e_dict.keys()) | set(m_dict.keys())
    results = []
    for gk in all_gk:
        dim = gk.split(" | ")[0]
        a_data = e_dict.get(gk, {})
        b_data = m_dict.get(gk, {})
        name_a = a_data.get("Name", "")
        name_b = b_data.get("Name", "")
        if name_a and name_b and name_a == name_b:
            all_attrs = (set(a_data.keys()) | set(b_data.keys())) - {"Name"}
            for at in all_attrs:
                va = a_data.get(at, "")
                vb = b_data.get(at, "")
                if va != vb:
                    if va and not vb:
                        results.append({"Dimension": dim, "Name": name_a, "Attribute": at, "Value": va, "Missing In": "Master"})
                    elif vb and not va:
                        results.append({"Dimension": dim, "Name": name_a, "Attribute": at, "Value": vb, "Missing In": "ERP"})
                    else:
                        results.append({"Dimension": dim, "Name": name_a, "Attribute": at, "Value": va, "Missing In": "Master"})
                        results.append({"Dimension": dim, "Name": name_a, "Attribute": at, "Value": vb, "Missing In": "ERP"})
        else:
            if name_a and not name_b:
                results.append({"Dimension": dim, "Name": name_a, "Attribute": "Name", "Value": name_a, "Missing In": "Master"})
            elif name_b and not name_a:
                results.append({"Dimension": dim, "Name": name_b, "Attribute": "Name", "Value": name_b, "Missing In": "ERP"})
    df_res = pd.DataFrame(results)
    if not df_res.empty:
        df_res["Key"] = (df_res["Dimension"].str.strip() + " | " +
                         df_res["Name"].str.strip() + " | " +
                         df_res["Attribute"].str.strip() + " | " +
                         df_res["Value"].str.strip())
    return df_res

def read_exception_table(path: Path)-> pd.DataFrame:
    if not path.is_file():
        logging.warning(f"Exception table not found => {path}")
        return pd.DataFrame()
    try:
        df = pd.read_excel(path)
        df.columns = df.columns.astype(str).str.strip()
        return df
    except Exception as e:
        logging.error(f"Error reading exception => {e}")
        return pd.DataFrame()

def merge_exceptions(df: pd.DataFrame, df_exc: pd.DataFrame)-> pd.DataFrame:
    if df.empty or df_exc.empty or "Key" not in df.columns:
        return df
    keep = [c for c in df_exc.columns if c in ["Key","Comments_1","Comments_2","hide exception"]]
    if not keep:
        return df
    exc = df_exc[keep].copy()
    exc["Key"] = exc["Key"].astype(str).str.strip()

    merged = df.merge(exc, on="Key", how="left", suffixes=("","_exc"))
    merged["hide exception"] = merged.get("hide exception","").fillna("").str.lower()

    final = merged[merged["hide exception"]!="yes"].copy()
    if "Comments_1_exc" in final.columns:
        final["Comments_1"] = np.where(final["Comments_1_exc"].notna(), final["Comments_1_exc"], final["Comments_1"])
        final.drop(columns=["Comments_1_exc"], inplace=True)
    if "Comments_2_exc" in final.columns:
        final["Comments_2"] = np.where(final["Comments_2_exc"].notna(), final["Comments_2_exc"], final["Comments_2"])
        final.drop(columns=["Comments_2_exc"], inplace=True)
    if "hide exception" in final.columns:
        final.drop(columns=["hide exception"], inplace=True)
    return final

def write_missing_items(df: pd.DataFrame, out_path: Path):
    if df.empty:
        logging.info("No missing items => skip writing.")
        return
    out_path.parent.mkdir(parents=True, exist_ok=True)
    final_cols= ["Key","Dimension","Name","Attribute","Value","Comments_1","Comments_2","Action Item","Missing In"]
    for c in final_cols:
        if c not in df.columns:
            df[c] = ""
    df = df[final_cols]

    wb= Workbook()
    ws= wb.active
    ws.title= "Missing Items"
    ws.append(final_cols)

    for rowvals in df.itertuples(index=False):
        ws.append(rowvals)

    header_font= Font(bold=True)
    fill= PatternFill(start_color="DDDDDD", end_color="DDDDDD", fill_type="solid")
    for cell in ws[1]:
        cell.font= header_font
        cell.fill= fill
        cell.alignment= Alignment(horizontal="center")

    # auto-size columns
    for col in ws.columns:
        max_len=0
        letter= col[0].column_letter
        for cell in col:
            val = str(cell.value) if cell.value else ""
            max_len= max(max_len, len(val))
        ws.column_dimensions[letter].width = max_len+2
    ws.freeze_panes = "A2"

    wb.save(out_path)
    logging.info(f"Missing items => {out_path}")

# ----------------------------------------------------------------------------
# SIMPLE PREVIEW (for ERP/Master previews)
# ----------------------------------------------------------------------------
class SimplePreview(ctk.CTkFrame):
    # Only "Start Date" and "End Date" are filterable in this preview.
    FILTERABLE = {"Start Date", "End Date"}
    def __init__(self, parent, name: str):
        super().__init__(parent)
        self.name = name
        self.df = pd.DataFrame()
        self.filters: Dict[str, Set] = {}  # Column filters (string-based)
        self.create_toolbar()
        self.create_table()
        self.create_statusbar()

    def create_toolbar(self):
        bar = ctk.CTkFrame(self, corner_radius=10, fg_color="#f0f0f0")
        bar.pack(fill="x", padx=5, pady=5)
        ctk.CTkLabel(bar, text=f"{self.name} Preview", fg_color="#800020", corner_radius=8).pack(side="left", padx=5)
        ctk.CTkButton(bar, text="ⓘ", width=30, command=self.show_info,
                      fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)
        ctk.CTkButton(bar, text="Clear Filters", command=self.clear_filters, # Clear all filters
                      fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)


    def show_info(self):
        messagebox.showinfo("Info", f"{self.name} data after meltdown & param.\nOnly Start/End Date columns are filterable.")

    def create_table(self):
        container = ctk.CTkFrame(self)
        container.pack(fill="both", expand=True, padx=5, pady=5)
        self.tree = ttk.Treeview(container, show="headings")
        vsb = ttk.Scrollbar(container, orient="vertical", command=self.tree.yview)
        hsb = ttk.Scrollbar(container, orient="horizontal", command=self.tree.xview)
        self.tree.configure(yscrollcommand=vsb.set, xscrollcommand=hsb.set)
        self.tree.grid(row=0, column=0, sticky="nsew")
        vsb.grid(row=0, column=1, sticky="ns")
        hsb.grid(row=1, column=0, sticky="ew")
        container.rowconfigure(0, weight=1)
        container.columnconfigure(0, weight=1)

    def create_statusbar(self):
        self.status_label = ctk.CTkLabel(self, text="0 rows")
        self.status_label.pack(fill="x")

    def set_data(self, df: pd.DataFrame):
        self.filters.clear()  # reset filters each time new data is set
        self.df = df.copy()
        self.refresh_table()

    def refresh_table(self):
        for i in self.tree.get_children():
            self.tree.delete(i)
        if self.df.empty:
            self.tree["columns"] = []
            self.status_label.configure(text="0 rows")
            return
        cols = list(self.df.columns)
        self.tree["columns"] = cols
        for c in cols:
            self.tree.heading(c, text=c, anchor="w",
                              command=lambda col=c: self.on_heading_click(col))
            self.tree.column(c, anchor="w", width=150)
        df_f = self.apply_filters()
        for _, row in df_f.iterrows():
            rowvals = [row[c] for c in cols]
            self.tree.insert("", "end", values=rowvals)
        self.status_label.configure(text=f"{len(df_f)} rows")

    def apply_filters(self) -> pd.DataFrame:
        """Applies all column filters, including Start/End Date."""
        df_f = self.df.copy()
        for col, allowed_values in self.filters.items():
            if col in df_f.columns:
                df_f = df_f[df_f[col].isin(allowed_values)]
        return df_f


    def on_heading_click(self, col_name: str):
        if col_name in self.FILTERABLE:
            self.show_filter_popup(col_name)

    def show_filter_popup(self, col_name: str):
        if self.df.empty or col_name not in self.df.columns:
            return
        popup = tk.Toplevel(self)
        popup.title(f"Filter: {col_name}")
        popup.geometry("300x400")
        frame = ctk.CTkFrame(popup)
        frame.pack(fill="both", expand=True, padx=5, pady=5)

        # Get unique values and sort them (important for dates)
        unique_vals = sorted(self.df[col_name].dropna().unique())
        display_map = {str(v): str(v) for v in unique_vals}  # Display as strings
        sorted_vals = list(display_map.keys())

        # Get current filter for this column (if any)
        curr_filter = self.filters.get(col_name, set(sorted_vals))

        selall_var = tk.BooleanVar(value=True)
        def toggle_all():
            check = selall_var.get()
            for vb in var_dict.values():
                vb.set(check)

        ctk.CTkCheckBox(frame, text="Select All", variable=selall_var, command=toggle_all,
                        fg_color="#800020", hover_color="#a52a2a").pack(anchor="w", pady=5)
        scroll = ctk.CTkScrollableFrame(frame, width=250, height=250)
        scroll.pack(fill="both", expand=True, padx=5, pady=5)

        var_dict = {}  # Store BooleanVars for each value
        for rv in sorted_vals:
            in_filter = rv in curr_filter
            bvar = tk.BooleanVar(value=in_filter)
            var_dict[rv] = bvar
            ctk.CTkCheckBox(scroll, text=display_map[rv], variable=bvar,
                            fg_color="#800020", hover_color="#a52a2a").pack(anchor="w")

        def apply_():
            selected_values = {rv for rv, vb in var_dict.items() if vb.get()}
            # If all or none are selected, remove the filter.  Otherwise, update it.
            if selected_values == set(sorted_vals) or not selected_values:
                self.filters.pop(col_name, None)
            else:
                self.filters[col_name] = selected_values
            popup.destroy()
            self.refresh_table()

        bf = ctk.CTkFrame(frame)
        bf.pack(fill="x", pady=5)
        ctk.CTkButton(bf, text="Apply", command=apply_,
                      fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)
        ctk.CTkButton(bf, text="Cancel", command=popup.destroy,
                      fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)

    def clear_filters(self):
        """Clears all filters in the preview."""
        self.filters.clear()
        self.refresh_table()

    def get_filtered_df(self) -> pd.DataFrame:
        """Returns the DataFrame after applying all filters."""
        return self.apply_filters()

# ----------------------------------------------------------------------------
# ENHANCED PDF REPORT
# ----------------------------------------------------------------------------
class EnhancedPDFReport:
    """
    Creates a PDF report with letter-sized pages (8.5×11 in). Each page (except the cover,
    summary, and top dims/attrs) displays one chart in a single axes that fills the page with
    1-inch margins.
    """
    def __init__(self, df_current: pd.DataFrame, df_history: pd.DataFrame, config: Dict):
        self.df_current = df_current
        self.df_history = df_history
You're on the right track with saving the dashboard state! Let's integrate these excellent ideas into the full, runnable script. Here's the complete, updated code, with detailed explanations and improvements:

#!/usr/bin/env python3
"""
Ultra-Mega Reconciliation: Parameter-based with advanced Dashboard (8 charts).

Key Features:

- **Preview Filtering (ERP & Master):**  String-based filtering for "Start Date"
  and "End Date" columns in the preview grids.
- **Dashboard Filtering:** Uses "Start Date" and "End Date" to filter run
  history data for the charts.
- **Run History:** Stores run history in the JSON config file.
- **Configuration Persistence:** Saves and loads:
    - File paths
    - Preview filters (including Start/End Date selections)
    - Run history
    - **Dashboard State:** Selected dimensions/attributes, date range,
      top N setting, and active tab.
- **PDF Export:** Generates a multi-page PDF report.
- **Error Handling:** Handles invalid date formats and other errors.
- **Modular Design:** Uses classes and functions.
"""

import os
import sys
import json
import logging
import zipfile
import shutil
import io
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, Set, List

import tkinter as tk
from tkinter import ttk, filedialog, messagebox
import customtkinter as ctk

import pandas as pd
import numpy as np

import matplotlib
matplotlib.use("TkAgg")
import matplotlib.pyplot as plt
from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg
from matplotlib.backends.backend_pdf import PdfPages

try:
    import chardet
except ImportError:
    chardet = None

try:
    import psutil
except ImportError:
    psutil = None

from openpyxl import Workbook
from openpyxl.styles import PatternFill, Font, Alignment

from PIL import Image

# ----------------------------------------------------------------------------
# LOGGING
# ----------------------------------------------------------------------------
logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")

# ----------------------------------------------------------------------------
# DEFAULT CONFIG & SAVE/LOAD
# ----------------------------------------------------------------------------
DEFAULT_PATHS = {
    "ERP_EXCEL_PATH": "data/ERP_Config.xlsx",
    "Master_ZIP_PATH": "data/Master_Config.zip",
    "EXCEPTION_PATH": "data/Exception_Table.xlsx",
    "OUTPUT_PATH": "output/missing_items.xlsx",
    "CONFIG_PATH": "config/ui_config.json",
    "PARAMETER_PATH": "data/parameters.xlsx",
    "Master_CSV_OUTPUT": "temp_Master_csv",
    "PDF_EXPORT_PATH": "output/dashboard_reports",
    "LOGO_PATH": "images/company_logo.png"
}

# --- DEFAULT DASHBOARD CONFIG ---
DEFAULT_DASHBOARD_CONFIG = {
    "selected_dims": [],  # Store selected dimensions
    "selected_attrs": [], # Store selected attributes
    "date_range": {
        "start_date": (datetime.now() - timedelta(days=30)).strftime("%Y-%m-%d"),
        "end_date": datetime.now().strftime("%Y-%m-%d")
    },
    "top_n": 10,  # Store whether showing top 10 or all
    "active_tab": 0  # Store active dashboard tab
}

def default_config() -> Dict:
    return {
        "paths": DEFAULT_PATHS.copy(),
        "ERP_grid": {"filters": {}},
        "Master_grid": {"filters": {}},
        "run_history": [],
        "dashboard": DEFAULT_DASHBOARD_CONFIG.copy()  # Include dashboard config
    }

def load_config(path: Path) -> Dict:
    if path.is_file():
        try:
            with open(path, "r", encoding="utf-8") as f:
                config = json.load(f)
                # Ensure all expected sections exist, merging with defaults
                config = {**default_config(), **config}
                return config
        except Exception as e:
            logging.warning(f"Could not load config: {e}")
    return default_config()

def save_config(cfg: Dict, path: Path):
    path.parent.mkdir(parents=True, exist_ok=True)
    try:
        # Convert sets -> lists in ERP/Master filters and dashboard selections
        for grid_name in ["ERP_grid", "Master_grid"]:
            if grid_name in cfg and "filters" in cfg[grid_name]:
                new_filters = {}
                for col, svals in cfg[grid_name]["filters"].items():
                    new_filters[col] = list(svals)  # Convert set to list
                cfg[grid_name]["filters"] = new_filters

        # Ensure dashboard config exists
        if "dashboard" not in cfg:
            cfg["dashboard"] = DEFAULT_DASHBOARD_CONFIG.copy()

        # Convert sets to lists within dashboard config (if they exist)
        for key in ["selected_dims", "selected_attrs"]:
            if key in cfg["dashboard"] and isinstance(cfg["dashboard"][key], set):
                cfg["dashboard"][key] = list(cfg["dashboard"][key])

        with open(path, "w", encoding="utf-8") as f:
            json.dump(cfg, f, indent=2)
        logging.info(f"Saved config to {path}")
    except Exception as e:
        logging.error(f"Error saving config: {e}")

# ----------------------------------------------------------------------------
# TEXT LOGGER HANDLER
# ----------------------------------------------------------------------------
class TextHandler(logging.Handler):
    def __init__(self, widget: ctk.CTkTextbox):
        super().__init__()
        self.widget = widget

    def emit(self, record):
        msg = self.format(record) + "\n"
        self.widget.after(0, self._append, msg)

    def _append(self, msg):
        self.widget.configure(state="normal")
        self.widget.insert("end", msg)
        self.widget.see("end")
        self.widget.configure(state="disabled")

# ----------------------------------------------------------------------------
# PARAMETER READING
# ----------------------------------------------------------------------------
def read_param_file(path: Path) -> Dict[str, object]:
    param = {
        "dim_ERP_keep": set(),
        "dim_ERP_map": {},
        "dim_Master_map": {},
        "attr_ERP_map": {},
        "attr_Master_map": {}
    }
    if not path.is_file():
        logging.warning(f"Param file not found => {path}")
        return param
    try:
        dim_df = pd.read_excel(path, sheet_name="Dimension Parameters")
        dim_df.columns = dim_df.columns.astype(str).str.strip()
        def s(x): return str(x).strip() if pd.notna(x) else ""
        for _, row in dim_df.iterrows():
            fn = s(row.get("FileName", ""))
            vsc = s(row.get("V S C", ""))
            dim = s(row.get("Dimension", ""))
            ev  = s(row.get("ERP Values", ""))
            if ev.lower() == "x" and vsc and dim:
                param["dim_ERP_keep"].add(vsc)
            if vsc and dim:
                param["dim_ERP_map"][vsc] = dim
            if fn and dim and ev.lower() == "x":
                param["dim_Master_map"][fn] = dim
        attr_df = pd.read_excel(path, sheet_name="Attribute Parameters")
        attr_df.columns = attr_df.columns.astype(str).str.strip()
        for _, row in attr_df.iterrows():
            e_orig = s(row.get("ERP Original Attributes", ""))
            m_orig = s(row.get("Master Original Attributes", ""))
            final_ = s(row.get("Attribute", ""))
            onoff  = s(row.get("On/Off", ""))
            if onoff.lower() == "x" and final_:
                if e_orig:
                    param["attr_ERP_map"][e_orig] = final_
                if m_orig:
                    param["attr_Master_map"][m_orig] = final_
        return param
    except Exception as e:
        logging.error(f"Error reading param file => {e}")
        return param

# ----------------------------------------------------------------------------
# ERP & Master READING
# ----------------------------------------------------------------------------
def read_ERP_excel(path: Path) -> pd.DataFrame:
    if not path.is_file():
        logging.warning(f"ERP Excel not found => {path}")
        return pd.DataFrame()
    try:
        df = pd.read_excel(path, skiprows=3)
        df.columns = df.columns.str.strip()
        if "Enabled_Flag" in df.columns:
            df = df[df["Enabled_Flag"]=="Enabled"]
        return df
    except Exception as e:
        logging.error(f"Error reading ERP => {e}")
        return pd.DataFrame()

def read_txt_2encodings(raw: bytes) -> pd.DataFrame:
    import io
    for enc in ["utf-8-sig", "utf-16-le"]:
        try:
            buf = io.BytesIO(raw)
            df = pd.read_csv(buf, encoding=enc, on_bad_lines="skip", engine="python")
            df.dropna(how="all", axis=0, inplace=True)
            df.dropna(how="all", axis=1, inplace=True)
            df.columns = df.columns.astype(str).str.strip()
            logging.info(f"[read_txt_2encodings] success with {enc}, shape={df.shape}")
            return df
        except Exception as e:
            logging.debug(f"[read_txt_2encodings] fail with {enc} => {e}")
    logging.error("[read_txt_2encodings] cannot parse .txt => empty.")
    return pd.DataFrame()

def convert_Master_txt_to_csv(zip_path: Path, out_dir: Path) -> List[Path]:
    if not zip_path.is_file():
        logging.warning(f"[Master] ZIP not found => {zip_path}")
        return []
    if out_dir.exists():
        shutil.rmtree(out_dir, ignore_errors=True)
    out_dir.mkdir(parents=True, exist_ok=True)
    csvs = []
    with zipfile.ZipFile(zip_path, "r") as z:
        txt_files = [f for f in z.namelist() if f.lower().endswith(".txt")]
        for txt_file in txt_files:
            base_name = os.path.basename(txt_file)
            if not base_name:
                continue
            try:
                with z.open(txt_file) as fo:
                    raw = fo.read()
                df = read_txt_2encodings(raw)
                if df.empty:
                    continue
                df["RawFileName"] = base_name
                if "Name" not in df.columns and len(df.columns) > 0:
                    first_col = df.columns[0]
                    df.rename(columns={first_col:"Name"}, inplace=True)
                out_csv = out_dir / (base_name.replace(".txt", ".csv"))
                df.to_csv(out_csv, index=False, encoding="utf-8")
                csvs.append(out_csv)
            except Exception as e:
                logging.error(f"[Master] error reading {txt_file} => {e}")
    return csvs

def unify_Master_csvs(csvs: List[Path]) -> pd.DataFrame:
    frames = []
    for cp in csvs:
        if not cp.is_file():
            continue
        try:
            df = pd.read_csv(cp, encoding="utf-8", on_bad_lines="skip")
            df.columns = df.columns.str.strip()
            frames.append(df)
        except Exception as e:
            logging.error(f"[unify_Master_csvs] reading {cp} => {e}")
    if frames:
        return pd.concat(frames, ignore_index=True)
    return pd.DataFrame()

# ----------------------------------------------------------------------------
# MELTDOWN FUNCTIONS (to convert wide to long)
# ----------------------------------------------------------------------------
def meltdown_ERP_for_preview(df: pd.DataFrame, param: Dict[str, object]) -> pd.DataFrame:
    if "V_S_C" not in df.columns:
        return pd.DataFrame()
    keep = param.get("dim_ERP_keep", set())
    dmap = param.get("dim_ERP_map", {})
    amap = param.get("attr_ERP_map", {})

    df2 = df[df["V_S_C"].isin(keep)].copy()
    if df2.empty:
        return pd.DataFrame()

    skip_cols = {"V_S_C", "Enabled_Flag"}
    id_vars = []
    if "Value" in df2.columns:
        id_vars.append("Value")
        skip_cols.add("Value")
    df2["DimRaw"] = df2["V_S_C"]
    skip_cols.add("DimRaw")
    id_vars.insert(0, "DimRaw")

    meltdown_cols = [c for c in df2.columns if c not in skip_cols]
    melted = df2.melt(id_vars=id_vars, value_vars=meltdown_cols,
                      var_name="OrigAttr", value_name="ValX")
    def rename_dim(v):
        return dmap.get(v, v)
    melted["Dimension"] = melted["DimRaw"].apply(rename_dim)
    if "Value" in id_vars:
        melted.rename(columns={"Value": "Name"}, inplace=True)
    else:
        melted["Name"] = ""
    melted = melted[melted["OrigAttr"].isin(amap.keys())].copy()
    melted["Attribute"] = melted["OrigAttr"].map(amap)
    # Keep original date values, don't strip 'T' for preview
    melted["Value"] = melted["ValX"]
    return melted[["Dimension", "Name", "Attribute", "Value"]]

def meltdown_Master_for_preview(df: pd.DataFrame, param: Dict[str, object]) -> pd.DataFrame:
    if df.empty or "RawFileName" not in df.columns:
        return pd.DataFrame()
    keep_map = param.get("dim_Master_map", {})
    amap = param.get("attr_Master_map", {})

    df2 = df[df["RawFileName"].isin(keep_map.keys())].copy()
    if df2.empty:
        return pd.DataFrame()

    df2["DimRaw"] = df2["RawFileName"]

    skip_cols = {"RawFileName", "DimRaw"}
    id_vars = ["DimRaw"]
    if "Name" in df2.columns:
        id_vars.append("Name")
        skip_cols.add("Name")

    meltdown_cols = [c for c in df2.columns if c not in skip_cols]
    melted = df2.melt(id_vars=id_vars, value_vars=meltdown_cols,
                      var_name="OrigAttr", value_name="ValX")
    def rename_dim(fn):
        return keep_map.get(fn, fn)
    melted["Dimension"] = melted["DimRaw"].apply(rename_dim)
    if "Name" in id_vars:
        melted.rename(columns={"Name": "Name"}, inplace=True)
    else:
        melted["Name"] = ""
    melted = melted[melted["OrigAttr"].isin(amap.keys())].copy()
    melted["Attribute"] = melted["OrigAttr"].map(amap)
    # Keep original date values, don't strip 'T' for preview
    melted["Value"] = melted["ValX"]
    return melted[["Dimension", "Name", "Attribute", "Value"]]

def pivot_for_preview(df: pd.DataFrame) -> pd.DataFrame:
    if not df.empty and {"Dimension", "Name", "Attribute"}.issubset(df.columns):
        df = df.drop_duplicates(subset=["Dimension", "Name", "Attribute"])
        try:
            df = df.pivot(index=["Dimension", "Name"], columns="Attribute", values="Value").reset_index()
        except Exception as e:
            logging.error(f"Pivot error => {e}")
    return df
# ----------------------------------------------------------------------------
# Compare Functions: Melt back wide data and produce missing items
# ----------------------------------------------------------------------------
def melt_back(df: pd.DataFrame) -> pd.DataFrame:
    if df.empty or "Dimension" not in df.columns or "Name" not in df.columns:
        return pd.DataFrame()
    skip_cols = {"Dimension", "Name"}
    meltdown_cols = [c for c in df.columns if c not in skip_cols]
    melted = df.melt(id_vars=["Dimension", "Name"], value_vars=meltdown_cols,
                     var_name="Attribute", value_name="Value")
    # Strip 'T' from dates *before* comparison
    def strip_t(val):
        if isinstance(val, str) and "T" in val:
            return val.split("T")[0]
        return val
    melted["Value"] = np.where(melted["Attribute"].isin(["Start Date", "End Date"]),
                               melted["Value"].apply(strip_t), melted["Value"])

    return melted[["Dimension", "Name", "Attribute", "Value"]]

def build_keys(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    for c in ["Dimension", "Name", "Attribute", "Value"]:
        if c not in df.columns:
            df[c] = ""
        df[c] = df[c].fillna("").astype(str).str.strip()
    df["GroupKey"] = df["Dimension"] + " | " + df["Name"]
    df["Key"] = df["Dimension"] + " | " + df["Name"] + " | " + df["Attribute"] + " | " + df["Value"]
    df["Comments_1"] = ""
    df["Comments_2"] = ""
    df["Action Item"] = ""
    df["Missing In"] = ""
    return df

def compare_mode2(df_ERP: pd.DataFrame, df_mst: pd.DataFrame) -> pd.DataFrame:
    def to_dict(d):
        out = {}
        for gk, grp in d.groupby("GroupKey"):
            rec = {}
            nm = grp["Name"].iloc[0] if not grp.empty else ""
            rec["Name"] = nm
            for _, row in grp.iterrows():
                rec[row["Attribute"]] = row["Value"]
            out[gk] = rec
        return out
    e_dict = to_dict(df_ERP)
    m_dict = to_dict(df_mst)
    all_gk = set(e_dict.keys()) | set(m_dict.keys())
    results = []
    for gk in all_gk:
        dim = gk.split(" | ")[0]
        a_data = e_dict.get(gk, {})
        b_data = m_dict.get(gk, {})
        name_a = a_data.get("Name", "")
        name_b = b_data.get("Name", "")
        if name_a and name_b and name_a == name_b:
            all_attrs = (set(a_data.keys()) | set(b_data.keys())) - {"Name"}
            for at in all_attrs:
                va = a_data.get(at, "")
                vb = b_data.get(at, "")
                if va != vb:
                    if va and not vb:
                        results.append({"Dimension": dim, "Name": name_a, "Attribute": at, "Value": va, "Missing In": "Master"})
                    elif vb and not va:
                        results.append({"Dimension": dim, "Name": name_a, "Attribute": at, "Value": vb, "Missing In": "ERP"})
                    else:
                        results.append({"Dimension": dim, "Name": name_a, "Attribute": at, "Value": va, "Missing In": "Master"})
                        results.append({"Dimension": dim, "Name": name_a, "Attribute": at, "Value": vb, "Missing In": "ERP"})
        else:
            if name_a and not name_b:
                results.append({"Dimension": dim, "Name": name_a, "Attribute": "Name", "Value": name_a, "Missing In": "Master"})
            elif name_b and not name_a:
                results.append({"Dimension": dim, "Name": name_b, "Attribute": "Name", "Value": name_b, "Missing In": "ERP"})
    df_res = pd.DataFrame(results)
    if not df_res.empty:
        df_res["Key"] = (df_res["Dimension"].str.strip() + " | " +
                         df_res["Name"].str.strip() + " | " +
                         df_res["Attribute"].str.strip() + " | " +
                         df_res["Value"].str.strip())
    return df_res

def read_exception_table(path: Path)-> pd.DataFrame:
    if not path.is_file():
        logging.warning(f"Exception table not found => {path}")
        return pd.DataFrame()
    try:
        df = pd.read_excel(path)
        df.columns = df.columns.astype(str).str.strip()
        return df
    except Exception as e:
        logging.error(f"Error reading exception => {e}")
        return pd.DataFrame()

def merge_exceptions(df: pd.DataFrame, df_exc: pd.DataFrame)-> pd.DataFrame:
    if df.empty or df_exc.empty or "Key" not in df.columns:
        return df
    keep = [c for c in df_exc.columns if c in ["Key","Comments_1","Comments_2","hide exception"]]
    if not keep:
        return df
    exc = df_exc[keep].copy()
    exc["Key"] = exc["Key"].astype(str).str.strip()

    merged = df.merge(exc, on="Key", how="left", suffixes=("","_exc"))
    merged["hide exception"] = merged.get("hide exception","").fillna("").str.lower()

    final = merged[merged["hide exception"]!="yes"].copy()
    if "Comments_1_exc" in final.columns:
        final["Comments_1"] = np.where(final["Comments_1_exc"].notna(), final["Comments_1_exc"], final["Comments_1"])
        final.drop(columns=["Comments_1_exc"], inplace=True)
    if "Comments_2_exc" in final.columns:
        final["Comments_2"] = np.where(final["Comments_2_exc"].notna(), final["Comments_2_exc"], final["Comments_2"])
        final.drop(columns=["Comments_2_exc"], inplace=True)
    if "hide exception" in final.columns:
        final.drop(columns=["hide exception"], inplace=True)
    return final

def write_missing_items(df: pd.DataFrame, out_path: Path):
    if df.empty:
        logging.info("No missing items => skip writing.")
        return
    out_path.parent.mkdir(parents=True, exist_ok=True)
    final_cols= ["Key","Dimension","Name","Attribute","Value","Comments_1","Comments_2","Action Item","Missing In"]
    for c in final_cols:
        if c not in df.columns:
            df[c] = ""
    df = df[final_cols]

    wb= Workbook()
    ws= wb.active
    ws.title= "Missing Items"
    ws.append(final_cols)

    for rowvals in df.itertuples(index=False):
        ws.append(rowvals)

    header_font= Font(bold=True)
    fill= PatternFill(start_color="DDDDDD", end_color="DDDDDD", fill_type="solid")
    for cell in ws[1]:
        cell.font= header_font
        cell.fill= fill
        cell.alignment= Alignment(horizontal="center")

    # auto-size columns
    for col in ws.columns:
        max_len=0
        letter= col[0].column_letter
        for cell in col:
            val = str(cell.value) if cell.value else ""
            max_len= max(max_len, len(val))
        ws.column_dimensions[letter].width = max_len+2
    ws.freeze_panes = "A2"

    wb.save(out_path)
    logging.info(f"Missing items => {out_path}")

# ----------------------------------------------------------------------------
# SIMPLE PREVIEW (for ERP/Master previews)
# ----------------------------------------------------------------------------
class SimplePreview(ctk.CTkFrame):
    # Only "Start Date" and "End Date" are filterable in this preview.
    FILTERABLE = {"Start Date", "End Date"}
    def __init__(self, parent, name: str):
        super().__init__(parent)
        self.name = name
        self.df = pd.DataFrame()
        self.filters: Dict[str, Set] = {}  # Column filters (string-based)
        self.create_toolbar()
        self.create_table()
        self.create_statusbar()

    def create_toolbar(self):
        bar = ctk.CTkFrame(self, corner_radius=10, fg_color="#f0f0f0")
        bar.pack(fill="x", padx=5, pady=5)
        ctk.CTkLabel(bar, text=f"{self.name} Preview", fg_color="#800020", corner_radius=8).pack(side="left", padx=5)
        ctk.CTkButton(bar, text="ⓘ", width=30, command=self.show_info,
                      fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)
        ctk.CTkButton(bar, text="Clear Filters", command=self.clear_filters, # Clear all filters
                      fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)


    def show_info(self):
        messagebox.showinfo("Info", f"{self.name} data after meltdown & param.\nOnly Start/End Date columns are filterable.")

    def create_table(self):
        container = ctk.CTkFrame(self)
        container.pack(fill="both", expand=True, padx=5, pady=5)
        self.tree = ttk.Treeview(container, show="headings")
        vsb = ttk.Scrollbar(container, orient="vertical", command=self.tree.yview)
        hsb = ttk.Scrollbar(container, orient="horizontal", command=self.tree.xview)
        self.tree.configure(yscrollcommand=vsb.set, xscrollcommand=hsb.set)
        self.tree.grid(row=0, column=0, sticky="nsew")
        vsb.grid(row=0, column=1, sticky="ns")
        hsb.grid(row=1, column=0, sticky="ew")
        container.rowconfigure(0, weight=1)
        container.columnconfigure(0, weight=1)

    def create_statusbar(self):
        self.status_label = ctk.CTkLabel(self, text="0 rows")
        self.status_label.pack(fill="x")

    def set_data(self, df: pd.DataFrame):
        self.filters.clear()  # reset filters each time new data is set
        self.df = df.copy()
        self.refresh_table()

    def refresh_table(self):
        for i in self.tree.get_children():
            self.tree.delete(i)
        if self.df.empty:
            self.tree["columns"] = []
            self.status_label.configure(text="0 rows")
            return
        cols = list(self.df.columns)
        self.tree["columns"] = cols
        for c in cols:
            self.tree.heading(c, text=c, anchor="w",
                              command=lambda col=c: self.on_heading_click(col))
            self.tree.column(c, anchor="w", width=150)
        df_f = self.apply_filters()
        for _, row in df_f.iterrows():
            rowvals = [row[c] for c in cols]
            self.tree.insert("", "end", values=rowvals)
        self.status_label.configure(text=f"{len(df_f)} rows")

    def apply_filters(self) -> pd.DataFrame:
        """Applies all column filters, including Start/End Date."""
        df_f = self.df.copy()
        for col, allowed_values in self.filters.items():
            if col in df_f.columns:
                df_f = df_f[df_f[col].isin(allowed_values)]
        return df_f


    def on_heading_click(self, col_name: str):
        if col_name in self.FILTERABLE:
            self.show_filter_popup(col_name)

    def show_filter_popup(self, col_name: str):
        if self.df.empty or col_name not in self.df.columns:
            return
        popup = tk.Toplevel(self)
        popup.title(f"Filter: {col_name}")
        popup.geometry("300x400")
        frame = ctk.CTkFrame(popup)
        frame.pack(fill="both", expand=True, padx=5, pady=5)

        # Get unique values and sort them (important for dates)
        unique_vals = sorted(self.df[col_name].dropna().unique())
        display_map = {str(v): str(v) for v in unique_vals}  # Display as strings
        sorted_vals = list(display_map.keys())

        # Get current filter for this column (if any)
        curr_filter = self.filters.get(col_name, set(sorted_vals))

        selall_var = tk.BooleanVar(value=True)
        def toggle_all():
            check = selall_var.get()
            for vb in var_dict.values():
                vb.set(check)

        ctk.CTkCheckBox(frame, text="Select All", variable=selall_var, command=toggle_all,
                        fg_color="#800020", hover_color="#a52a2a").pack(anchor="w", pady=5)
        scroll = ctk.CTkScrollableFrame(frame, width=250, height=250)
        scroll.pack(fill="both", expand=True, padx=5, pady=5)

        var_dict = {}  # Store BooleanVars for each value
        for rv in sorted_vals:
            in_filter = rv in curr_filter
            bvar = tk.BooleanVar(value=in_filter)
            var_dict[rv] = bvar
            ctk.CTkCheckBox(scroll, text=display_map[rv], variable=bvar,
                            fg_color="#800020", hover_color="#a52a2a").pack(anchor="w")

        def apply_():
            selected_values = {rv for rv, vb in var_dict.items() if vb.get()}
            # If all or none are selected, remove the filter.  Otherwise, update it.
            if selected_values == set(sorted_vals) or not selected_values:
                self.filters.pop(col_name, None)
            else:
                self.filters[col_name] = selected_values
            popup.destroy()
            self.refresh_table()

        bf = ctk.CTkFrame(frame)
        bf.pack(fill="x", pady=5)
        ctk.CTkButton(bf, text="Apply", command=apply_,
                      fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)
        ctk.CTkButton(bf, text="Cancel", command=popup.destroy,
                      fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)

    def clear_filters(self):
        """Clears all filters in the preview."""
        self.filters.clear()
        self.refresh_table()

    def get_filtered_df(self) -> pd.DataFrame:
        """Returns the DataFrame after applying all filters."""
        return self.apply_filters()

# ----------------------------------------------------------------------------
# ENHANCED PDF REPORT
# ----------------------------------------------------------------------------
class EnhancedPDFReport:
    """
    Creates a PDF report with letter-sized pages (8.5×11 in). Each page (except the cover,
    summary, and top dims/attrs) displays one chart in a single axes that fills the page with
    1-inch margins.
    """
    def __init__(self, df_current: pd.DataFrame, df_history: pd.DataFrame, config: Dict):
        self.df_current = df_current
        self.df_history = df_history
self.config = config

        self.colors = {
            'primary': '#800020',
            'text': '#2C1810',
            'background': '#FFFFFF'
        }
        self.logo_path = self.config["paths"].get("LOGO_PATH", "images/company_logo.png")
        # For letter size at 72 dpi: 8.5×11 inches
        self.PAGE_WIDTH = 8.5
        self.PAGE_HEIGHT = 11
        # Watermark: 1 inch from left, 1 inch from top
        self.WATERMARK_X = 1  # in inches
        self.WATERMARK_Y = 11 - 1  # in inches

    def generate(self) -> Path:
        pdf_dir = Path(self.config["paths"].get("PDF_EXPORT_PATH"))
        pdf_dir.mkdir(parents=True, exist_ok=True)
        stamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        pdf_path = pdf_dir / f"dashboard_report_{stamp}.pdf"
        with PdfPages(pdf_path) as pdf:
            self._add_cover_page(pdf)
            self._add_summary_page(pdf)
            self._add_topdimsattrs_page(pdf)
            self._add_all_charts(pdf)
        logging.info(f"PDF exported => {pdf_path}")
        return pdf_path

    def _stamp_logo(self, fig):
        if not self.logo_path or not os.path.exists(self.logo_path):
            return
        try:
            img = plt.imread(self.logo_path)
            # Convert inches to normalized figure coordinates:
            fig.figimage(img, xo=int(self.WATERMARK_X*72), yo=int((self.PAGE_HEIGHT - self.WATERMARK_Y)*72), alpha=0.15, zorder=10)
        except Exception as e:
            logging.error(f"Watermark error => {e}")

    def _new_page(self):
        fig = plt.figure(figsize=(self.PAGE_WIDTH, self.PAGE_HEIGHT))
        fig.patch.set_facecolor(self.colors['background'])
        plt.axis('off')
        self._stamp_logo(fig)
        return fig

    def _title_at_1inch(self, text, fontsize=18):
        fig = plt.gcf()
        plt.text(0.5, 1 - (1/ self.PAGE_HEIGHT), text, ha='center', fontsize=fontsize, fontweight='bold',
                 color=self.colors['primary'], transform=fig.transFigure)

    def _add_cover_page(self, pdf: PdfPages):
        fig = self._new_page()
        plt.text(0.5, 0.6, "Reconciliation Analysis Report", ha='center', fontsize=24, fontweight='bold',
                 color=self.colors['primary'], transform=fig.transFigure)
        plt.text(0.5, 0.53, f"Generated on {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
                 ha='center', fontsize=12, color=self.colors['text'], transform=fig.transFigure)
        plt.text(0.5, 0.1, "CONFIDENTIAL", ha='center', fontsize=9, color=self.colors['text'], transform=fig.transFigure)
        plt.text(0.5, 0.08, "Ultra-Mega Reconciliation System", ha='center', fontsize=9, color=self.colors['text'], transform=fig.transFigure)
        pdf.savefig(fig)
        plt.close(fig)

    def _add_summary_page(self, pdf: PdfPages):
        fig = self._new_page()
        self._title_at_1inch("Reconciliation Summary", fontsize=18)
        y = 0.75
        if self.df_current.empty:
            plt.text(0.5, y, "No mismatches found this run.", ha='center', fontsize=14, color=self.colors['text'], transform=fig.transFigure)
        else:
            total = len(self.df_current)
            ERP_missing = (self.df_current["Missing In"]=="ERP").sum()
            Master_missing = (self.df_current["Missing In"]=="Master").sum()
            summary = f"Total Mismatches: {total}\nMissing in ERP: {ERP_missing}\nMissing in Master: {Master_missing}"
            plt.text(0.5, y, summary, ha='center', fontsize=14, color=self.colors['text'], transform=fig.transFigure)
        pdf.savefig(fig)
        plt.close(fig)

    def _add_topdimsattrs_page(self, pdf: PdfPages):
        fig = self._new_page()
        self._title_at_1inch("Top Dimensions & Top Attributes", fontsize=18)
        if self.df_current.empty:
            plt.text(0.5, 0.7, "No data for top dims/attrs.", ha='center', fontsize=12, color=self.colors['text'], transform=fig.transFigure)
        else:
            if "Dimension" in self.df_current.columns:
                dims = self.df_current["Dimension"].value_counts().head(5)
                lines = [f"{k} ({v})" for k, v in dims.items()]
                plt.text(0.2, 0.7, "Top Dimensions:\n" + "\n".join(lines), fontsize=12, color=self.colors['text'], transform=fig.transFigure)
            if "Attribute" in self.df_current.columns:
                attrs = self.df_current["Attribute"].value_counts().head(5)
                lines = [f"{k} ({v})" for k, v in attrs.items()]
                plt.text(0.6, 0.7, "Top Attributes:\n" + "\n".join(lines), fontsize=12, color=self.colors['text'], transform=fig.transFigure)
        pdf.savefig(fig)
        plt.close(fig)

    def _add_chart_page(self, pdf: PdfPages, title: str, plot_func, **kwargs):
        # Create a letter-size page with 1-inch margins all around.
        fig = plt.figure(figsize=(self.PAGE_WIDTH, self.PAGE_HEIGHT))
        self._title_at_1inch(title, fontsize=14)
        # Define axes to occupy the area inside 1-inch margins:
        left = 1 / self.PAGE_WIDTH
        bottom = 1 / self.PAGE_HEIGHT
        width = (self.PAGE_WIDTH - 2) / self.PAGE_WIDTH
        height = (self.PAGE_HEIGHT - 2) / self.PAGE_HEIGHT
        ax = fig.add_axes([left, bottom, width, height])
        ax.grid(False)
        try:
            plot_func(ax, **kwargs)
            pdf.savefig(fig)
        except Exception as e:
            logging.error(f"{title} chart error => {e}")
        finally:
            plt.close(fig)

    # Define individual plot functions (using similar methods as in the dashboard)
    def _plot_heatmap(self, ax, pivot):
        im = ax.imshow(pivot, aspect="auto", cmap="Reds")
        ax.set_xticks(range(len(pivot.columns)))
        ax.set_xticklabels(pivot.columns, rotation=45)
        ax.set_yticks(range(len(pivot.index)))
        ax.set_yticklabels(pivot.index)
        plt.colorbar(im, ax=ax)

    def _plot_lollipop(self, ax, cdim):
        ax.hlines(y=cdim.index, xmin=0, xmax=cdim.values, color="skyblue")
        ax.plot(cdim.values, cdim.index, "o", color="skyblue")
        ax.set_xlabel("Missing Count")

    def _plot_circular(self, ax, cattr):
        angles = np.linspace(0, 2*np.pi, len(cattr), endpoint=False)
        ax.set_theta_offset(np.pi/2)
        ax.set_theta_direction(-1)
        ax.set_xticks(angles)
        ax.set_xticklabels(cattr.index, fontsize=9)
        ax.bar(angles, cattr.values, width=0.4, color="orange", alpha=0.6)
    
    def _plot_scatter(self, ax, cdim):
        """Scatter plot for top dimensions."""
        ax.scatter(cdim.index, cdim.values, color='green')
        ax.set_xlabel("Dimension")
        ax.set_ylabel("Missing Count")
        # Rotate x-axis labels for better readability
        plt.setp(ax.get_xticklabels(), rotation=45, ha="right")

    def _plot_radar(self, ax, cattr):
      """Radar chart for top attributes."""
      num_vars = len(cattr)
      angles = np.linspace(0, 2 * np.pi, num_vars, endpoint=False).tolist()
      values = cattr.values.tolist()
      # Close the circle
      angles += angles[:1]
      values += values[:1]

      ax.plot(angles, values, color='red', linewidth=1)
      ax.fill(angles, values, color='red', alpha=0.25)
      ax.set_theta_offset(np.pi / 2)
      ax.set_theta_direction(-1)
      ax.set_xticks(angles[:-1])
      ax.set_xticklabels(cattr.index)
      ax.set_yticklabels([]) # Typically, radar charts don't show y-ticks
      
    def _plot_normal_pie(self, ax, df_m):
      """ Pie chart for distribution of mismatches"""

      dist = df_m["Missing In"].value_counts()
      ax.pie(dist, labels = dist.index, autopct='%1.1f%%', startangle=140)
      ax.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.

    def _plot_normal_bar(self, ax, cattr):
        """Regular Bar Chart"""
        ax.bar(cattr.index, cattr.values, color='blue')
        ax.set_xlabel("Attribute")
        ax.set_ylabel("Missing Count")
        plt.setp(ax.get_xticklabels(), rotation=45, ha="right")
    

    def _plot_bandchart(self, ax, date_ct):
        date_ct["Count_min"] = date_ct["Count"] * 0.9
        date_ct["Count_max"] = date_ct["Count"] * 1.1
        ax.plot(date_ct["RunDate"], date_ct["Count"], color="purple", marker="o", label="Missing Count")
        ax.fill_between(date_ct["RunDate"], date_ct["Count_min"], date_ct["Count_max"],
                        color="purple", alpha=0.2, label="±10% band")
        ax.set_xlabel("RunDate")
        ax.set_ylabel("Missing Count")
        plt.xticks(rotation=45)
        ax.legend()

    def _add_all_charts(self, pdf: PdfPages):
        dfc = self.df_current
        if dfc.empty:
            return
        df_m = dfc[dfc["Missing In"] != ""]
        if not df_m.empty and {"Dimension", "Attribute"}.issubset(df_m.columns):
            pivot = df_m.groupby(["Dimension", "Attribute"]).size().unstack(fill_value=0)
            if not pivot.empty:
                self._add_chart_page(pdf, "Heatmap", self._plot_heatmap, pivot=pivot)
        cdim = df_m.groupby("Dimension")["Key"].count().sort_values(ascending=False).head(10)
        if not cdim.empty:
            self._add_chart_page(pdf, "Lollipop", self._plot_lollipop, cdim=cdim)
        cattr = df_m.groupby("Attribute")["Key"].count().sort_values(ascending=False).head(10)
        if not cattr.empty:
            self._add_chart_page(pdf, "Circular", self._plot_circular, cattr=cattr)
            
        # Scatter
        cdim_scatter = df_m.groupby("Dimension")["Key"].count().sort_values(ascending=False).head(10)
        if not cdim_scatter.empty:
              self._add_chart_page(pdf, "Scatter", self._plot_scatter, cdim=cdim_scatter)

        # Radar
        cattr_radar = df_m.groupby("Attribute")["Key"].count().sort_values(ascending=False).head(5)
        if not cattr_radar.empty:
            self._add_chart_page(pdf, "Radar Chart", self._plot_radar, cattr=cattr_radar)
            
        # Normal Pie
        if not df_m.empty:
            self._add_chart_page(pdf, "Pie Chart of Missing Data", self._plot_normal_pie, df_m=df_m)
            
        # Normal Bar
        cattr_bar = df_m.groupby("Attribute")["Key"].count().sort_values(ascending=False).head(10)
        if not cattr_bar.empty:
             self._add_chart_page(pdf, "Bar Chart of Attributes", self._plot_normal_bar, cattr=cattr_bar)
        
        # Band Chart
        if not self.df_history.empty and "RunDate" in self.df_history.columns:
            date_ct = self.df_history.groupby("RunDate")["Key"].count().reset_index(name="Count")
            date_ct.sort_values("RunDate", inplace=True)
            if not date_ct.empty:
                self._add_chart_page(pdf, "Band Chart Over Time", self._plot_bandchart, date_ct=date_ct)

# ----------------------------------------------------------------------------
# ADVANCED DASHBOARD
# ----------------------------------------------------------------------------
class AdvancedDashboard(ctk.CTkFrame):
    def __init__(self, parent, config):
        super().__init__(parent)
        self.df_current = pd.DataFrame()
        self.df_history = pd.DataFrame()
        self.config = config  # Store the config
        # Load dashboard settings from config, or use defaults
        dash_config = self.config.get("dashboard", DEFAULT_DASHBOARD_CONFIG)
        self.selected_dims = set(dash_config.get("selected_dims", []))
        self.selected_attrs = set(dash_config.get("selected_attrs", []))
        self.top_n = dash_config.get("top_n", 10)
        self.active_tab = dash_config.get("active_tab",0)

        # --- Top Bar ---
        topbar = ctk.CTkFrame(self, corner_radius=10, fg_color="#f0f0f0")
        topbar.pack(fill="x", padx=5, pady=5)

        self.metric_label = ctk.CTkLabel(topbar, text="Metrics: 0 missing, 0 dimension", width=300)
        self.metric_label.pack(side="left", padx=5)

        ctk.CTkButton(topbar, text="Filter Dimension", command=self.show_dimension_filter,
                      fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)
        ctk.CTkButton(topbar, text="Filter Attribute", command=self.show_attribute_filter,
                      fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)

        ctk.CTkButton(topbar, text="Last 7 Days", command=lambda: self.set_quick_range(7),
                      fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)
        ctk.CTkButton(topbar, text="Last 30 Days", command=lambda: self.set_quick_range(30),
                      fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)
        ctk.CTkButton(topbar, text="Last 90 Days", command=lambda: self.set_quick_range(90),
                      fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)
        ctk.CTkButton(topbar, text="All Time", command=lambda: self.set_quick_range(9999),
                      fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)

        # Use stored date range, or default
        start_date_str = dash_config.get("date_range", {}).get("start_date", (datetime.now() - timedelta(days=30)).strftime("%Y-%m-%d"))
        end_date_str = dash_config.get("date_range", {}).get("end_date", datetime.now().strftime("%Y-%m-%d"))

        self.start_date_var = tk.StringVar(value=start_date_str)
        self.end_date_var = tk.StringVar(value=end_date_str)



        ctk.CTkLabel(topbar, text="Start Date:").pack(side="left", padx=5)
        ctk.CTkEntry(topbar, textvariable=self.start_date_var, width=100).pack(side="left", padx=5)
        ctk.CTkLabel(topbar, text="End Date:").pack(side="left", padx=5)
        ctk.CTkEntry(topbar, textvariable=self.end_date_var, width=100).pack(side="left", padx=5)

        ctk.CTkButton(topbar, text="Update Timeline", command=self.update_data_filters,
                      fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)
        self.toggle_button = ctk.CTkButton(topbar, text="Toggle Top 10 / All", command=self.toggle_top_n,
                      fg_color="#800020", hover_color="#a52a2a") #for the toggle
        self.toggle_button.pack(side="left", padx=5)
        ctk.CTkButton(topbar, text="Export PDF", command=self.export_dashboard_pdf,
                      fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)
        
        # --- Chart Notebook ---
        self.notebook = ttk.Notebook(self)
        self.notebook.pack(fill="both", expand=True)

        self.frames = {}
        chart_names = ["Heatmap", "Lollipop", "Circular", "Scatter", "Radar", "Normal Pie", "Normal Bar", "Band Chart"]
        for lbl in chart_names:
            fr = ctk.CTkFrame(self.notebook)
            self.notebook.add(fr, text=lbl)
            self.frames[lbl] = fr

        # Set active tab (load from config)
        self.notebook.select(self.active_tab)
        self.notebook.bind("<<NotebookTabChanged>>", self._on_tab_change)

    def _on_tab_change(self, event):
        """Updates the active_tab and saves the dashboard state."""
        self.active_tab = self.notebook.index(self.notebook.select())
        self.save_dashboard_state()

    def set_quick_range(self, days: int):
        if days > 9000:
            self.start_date_var.set("1900-01-01")
            self.end_date_var.set("2100-12-31")
        else:
            dt_end = datetime.now()
            dt_start = dt_end - timedelta(days=days)
            self.start_date_var.set(dt_start.strftime("%Y-%m-%d"))
            self.end_date_var.set(dt_end.strftime("%Y-%m-%d"))
        self.update_data_filters()

    def show_dimension_filter(self):
        self.show_filter_popup("Dimension")

    def show_attribute_filter(self):
        self.show_filter_popup("Attribute")

    def show_filter_popup(self, col: str):
        base_df = self.df_history if not self.df_history.empty else self.df_current
        if base_df.empty or col not in base_df.columns:
            return
        popup = tk.Toplevel(self)
        popup.title(f"Filter: {col}")
        popup.geometry("300x400")
        frame = ctk.CTkFrame(popup)
        frame.pack(fill="both", expand=True, padx=5, pady=5)
        unique_vals = base_df[col].unique()
        display_map = {}
        for v in unique_vals:
            if pd.isna(v):
                dsp = "(NaN)"
            elif isinstance(v, str) and not v.strip():
                dsp = "(blank)"
            else:
                dsp = str(v)
            display_map[v] = dsp
        sorted_vals = sorted(display_map.keys(), key=lambda x: display_map[x].lower())
        if col == "Dimension":
            curr = self.selected_dims
        else:
            curr = self.selected_attrs
        if not curr:
            curr = set(unique_vals)
        selall_var = tk.BooleanVar(value=True)
        def toggle_all():
            check = selall_var.get()
            for vb in var_dict.values():
                vb.set(check)
        ctk.CTkCheckBox(frame, text="Select All", variable=selall_var, command=toggle_all,
                        fg_color="#800020", hover_color="#a52a2a").pack(anchor="w", pady=5)
        scroll = ctk.CTkScrollableFrame(frame, width=250, height=250)
        scroll.pack(fill="both", expand=True, padx=5, pady=5)
        var_dict = {}
        for rv in sorted_vals:
            in_filter = rv in curr
            bvar = tk.BooleanVar(value=in_filter)
            var_dict[rv] = bvar
            ctk.CTkCheckBox(scroll, text=display_map[rv], variable=bvar,
                            fg_color="#800020", hover_color="#a52a2a").pack(anchor="w")
        def apply_():
            sel = {rv for rv, vb in var_dict.items() if vb.get()}
            if col == "Dimension":
                self.selected_dims = sel
            else:
                self.selected_attrs = sel
            popup.destroy()
            self.update_data_filters()
            self.save_dashboard_state() # Save after filter change

        bf = ctk.CTkFrame(frame)
        bf.pack(fill="x", pady=5)
        ctk.CTkButton(bf, text="Apply", command=apply_,
                      fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)
        ctk.CTkButton(bf, text="Cancel", command=popup.destroy,
                      fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)

    def update_data(self, df_current: pd.DataFrame, df_history: pd.DataFrame):
        self.df_current = df_current.copy()
        self.df_history = df_history.copy()
        self.update_data_filters()
        
    def _filter_by_date(self, df: pd.DataFrame) -> pd.DataFrame:
        """Filters the DataFrame by the start and end dates from the dashboard."""
        if "RunDate" not in df.columns:
            return df

        try:
            start_date = pd.to_datetime(self.start_date_var.get())
            end_date = pd.to_datetime(self.end_date_var.get())
            df["RunDate_dt"] = pd.to_datetime(df["RunDate"], errors="coerce")
            df_filtered = df[(df["RunDate_dt"] >= start_date) & (df["RunDate_dt"] <= end_date)].copy()
            df_filtered.drop(columns=["RunDate_dt"], inplace=True) # Drop temporary column
            return df_filtered
        except ValueError:
            messagebox.showerror("Error", "Invalid date format. Use YYYY-MM-DD.")
            return df  # Return original if there's an error
    

    def update_data_filters(self):
        dfc = self.df_current.copy()
        # Apply dimension and attribute filters
        if not dfc.empty:
            if self.selected_dims:
                dfc = dfc[dfc["Dimension"].isin(self.selected_dims)]
            if self.selected_attrs:
                dfc = dfc[dfc["Attribute"].isin(self.selected_attrs)]
                
        #Apply date filter to current run data
        dfc = self._filter_by_date(dfc)

        mism = len(dfc)
        dims = dfc["Dimension"].nunique() if not dfc.empty and "Dimension" in dfc.columns else 0
        self.metric_label.configure(text=f"Mismatches: {mism}, Dims: {dims}")
        
        # Filter historical data by date range
        df_history_filtered = self._filter_by_date(self.df_history.copy())


        self.plotHeatmap(dfc)
        self.plotLollipop(dfc)
        self.plotCircular(dfc)
        self.plotScatter(dfc)
        self.plotRadar(dfc)
        self.plotNormalPie(dfc)
        self.plotNormalBar(dfc)
        self.plotBandChart(df_history_filtered) # Use filtered historical data

    def plot_chart(self, frame, fig):
        for w in frame.winfo_children():
            w.destroy()
        canvas = FigureCanvasTkAgg(fig, master=frame)  # Corrected 'Master' to 'master'
        canvas.draw()
        canvas.get_tk_widget().pack(fill="both", expand=True)

    def plotHeatmap(self, dfc: pd.DataFrame):
      fr = self.frames["Heatmap"]
      for w in fr.winfo_children():
          w.destroy()
      if dfc.empty or "Missing In" not in dfc.columns:
          return
      df_m = dfc[dfc["Missing In"] != ""]
      if df_m.empty or not {"Dimension", "Attribute"}.issubset(df_m.columns):
          return

      # Aggregate data, handling potential errors
      try:
          pivot = df_m.groupby(["Dimension", "Attribute"]).size().unstack(fill_value=0)
      except KeyError as e:
          logging.error(f"Heatmap: Missing expected column: {e}")
          return

      if pivot.empty:
            logging.warning("Heatmap: Pivot table is empty.")
            return
      fig, ax = plt.subplots(figsize=(6, 5))

      try:
          im = ax.imshow(pivot, aspect="auto", cmap="Reds")
          ax.set_xticks(range(len(pivot.columns)))
          ax.set_xticklabels(pivot.columns, rotation=90)
          ax.set_yticks(range(len(pivot.index)))
          ax.set_yticklabels(pivot.index)
          plt.colorbar(im, ax=ax)
          ax.set_title("Heatmap: Missing Items")
          self.plot_chart(fr, fig)
      except Exception as e:
            logging.error(f"Heatmap: Error during plotting: {e}")
            return
    def plotLollipop(self, dfc: pd.DataFrame):
      fr = self.frames["Lollipop"]
      for w in fr.winfo_children():
          w.destroy()
      if dfc.empty or "Missing In" not in dfc.columns:
          return
      df_m = dfc[dfc["Missing In"] != ""]
      if df_m.empty:
          return
      cdim = df_m.groupby("Dimension")["Key"].count().sort_values(ascending=False).head(self.top_n)
      if cdim.empty:
          return
      fig, ax = plt.subplots(figsize=(6,5))
      ax.hlines(y=cdim.index, xmin=0, xmax=cdim.values, color="skyblue")
      ax.plot(cdim.values, cdim.index, "o", color="skyblue")
      ax.set_title("Lollipop: Missing Dimensions")
      ax.set_xlabel("Missing Count")
      self.plot_chart(fr, fig)

    def plotCircular(self, dfc: pd.DataFrame):
        fr = self.frames["Circular"]
        for w in fr.winfo_children():
            w.destroy()
        if dfc.empty or "Missing In" not in dfc.columns:
            return
        df_m = dfc[dfc["Missing In"] != ""]
        if df_m.empty:
            return
        cattr = df_m.groupby("Attribute")["Key"].count().sort_values(ascending=False).head(self.top_n)
        if cattr.empty:
            return
        fig = plt.figure(figsize=(6,6))
        ax = fig.add_subplot(111, polar=True)
        angles = np.linspace(0, 2*np.pi, len(cattr), endpoint=False)
        ax.set_theta_offset(np.pi/2)
        ax.set_theta_direction(-1)
        ax.set_xticks(angles)
        ax.set_xticklabels(cattr.index, fontsize=9)
        ax.bar(angles, cattr.values, width=0.4, color="orange", alpha=0.6)
        ax.set_title("Circular: Missing Attributes", y=1.05)
        self.plot_chart(fr, fig)

    def plotScatter(self, dfc: pd.DataFrame):
        fr = self.frames["Scatter"]
        for w in fr.winfo_children():
            w.destroy()
        if dfc.empty or "Missing In" not in dfc.columns:
            return
        df_m = dfc[dfc["Missing In"] != ""]
        if df_m.empty:
            return
        cdim = df_m.groupby("Dimension")["Key"].count().reset_index(name="Count")
        cdim.sort_values("Count", ascending=False, inplace=True)
        cdim = cdim.head(self.top_n) # Apply top_n here
        if cdim.empty:
            return
        fig, ax = plt.subplots(figsize=(6,5))
        xvals = np.arange(len(cdim))
        ax.scatter(xvals, cdim["Count"].values, color="green")
        for i, txt in enumerate(cdim["Dimension"].values):
            ax.text(xvals[i], cdim["Count"].values[i], txt, ha="center", va="bottom", rotation=60)
        ax.set_xticks([])
        ax.set_ylabel("Missing Count")
        ax.set_title("Scatter: Missing by Dimension")
        self.plot_chart(fr, fig)

    def plotRadar(self, dfc: pd.DataFrame):
      fr = self.frames["Radar"]
      for w in fr.winfo_children():
          w.destroy()

      if dfc.empty or "Missing In" not in dfc.columns:
          return
      df_m = dfc[dfc["Missing In"] != ""]
      if df_m.empty: return

      # Aggregate and get top N
      cattr = df_m.groupby("Attribute")["Key"].count().sort_values(ascending=False)
      cattr = cattr.head(5)  # Always take top 5 for Radar
      if cattr.empty: return
      labels = cattr.index.to_list()
      values = cattr.values.tolist()
      num_vars = len(labels)
      if num_vars <3 : return

      # Set up angles for radar chart (close the circle)
      angles = np.linspace(0, 2 * np.pi, num_vars, endpoint=False).tolist()
      angles += angles[:1]  # Close the circle
      values += values[:1]

      fig, ax = plt.subplots(figsize=(6, 6), subplot_kw=dict(polar=True))

      # Plot data and fill area
      ax.plot(angles, values, color='red', linewidth=2)
      ax.fill(angles, values, color='red', alpha=0.25)

      # Set axis and labels
      ax.set_theta_offset(np.pi / 2)  # Rotate the chart by 90 degrees
ax.set_theta_direction(-1)  # Make labels go clockwise
      ax.set_xticks(angles[:-1])  # Exclude the last angle (it's the same as the first)
      ax.set_xticklabels(labels)

      ax.set_title("Radar: Top 5 Missing Attributes", y=1.08)
      self.plot_chart(fr, fig)

    def plotNormalPie(self, dfc: pd.DataFrame):
        fr = self.frames["Normal Pie"]
        for w in fr.winfo_children():
            w.destroy()
        if dfc.empty or "Missing In" not in dfc.columns:
            return
        df_m = dfc[dfc["Missing In"] != ""]
        if df_m.empty:
            return
        dist = df_m["Missing In"].value_counts()
        fig, ax = plt.subplots(figsize=(5,5))
        ax.pie(dist.values, labels=dist.index, autopct="%.1f%%", startangle=140)
        ax.set_title("Pie: Missing In Distribution")
        self.plot_chart(fr, fig)

    def plotNormalBar(self, dfc: pd.DataFrame):
      fr = self.frames["Normal Bar"]
      for w in fr.winfo_children():
          w.destroy()

      if dfc.empty or "Missing In" not in dfc.columns: return

      df_m = dfc[dfc["Missing In"] != ""]
      if df_m.empty: return
      cattr = df_m.groupby("Attribute")["Key"].count().sort_values(ascending=False).head(self.top_n)

      if cattr.empty:
          return

      fig, ax = plt.subplots(figsize=(6, 4))
      cattr.plot(kind="bar", ax=ax, color="blue")  # Use plot method for easier customization

      ax.set_ylabel("Missing Count")
      ax.set_title("Bar: Top 10 Missing Attributes")
      ax.tick_params(axis='x', rotation=45)  # Rotate x-axis labels
      self.plot_chart(fr, fig)

    def plotBandChart(self, df_history_filtered):
        fr = self.frames["Band Chart"]
        for w in fr.winfo_children():
            w.destroy()
        if df_history_filtered.empty or "RunDate" not in df_history_filtered.columns:
            return

        date_ct = df_history_filtered.groupby("RunDate")["Key"].count().reset_index(name="Count")
        date_ct.sort_values("RunDate", inplace=True)
        if date_ct.empty:
            return

        date_ct["Count_min"] = date_ct["Count"] * 0.9
        date_ct["Count_max"] = date_ct["Count"] * 1.1

        fig, ax = plt.subplots(figsize=(6, 4))
        ax.plot(date_ct["RunDate"], date_ct["Count"], color="purple", marker="o", label="Missing Count")
        ax.fill_between(date_ct["RunDate"], date_ct["Count_min"], date_ct["Count_max"],
                        color="purple", alpha=0.2, label="±10% band")
        ax.set_title("Band Chart Over Time")
        ax.set_xlabel("RunDate")
        ax.set_ylabel("Missing Count")
        plt.xticks(rotation=45)
        ax.legend()
        for i, row in date_ct.iterrows():
            ax.text(row["RunDate"], row["Count"], str(row["Count"]), ha="center", va="bottom")
        self.plot_chart(fr, fig)

    def export_dashboard_pdf(self):
        # Export all dashboard chart figures to a PDF.
        pdf_dir = Path(self.config["paths"].get("PDF_EXPORT_PATH"))  # Assuming 'self' is the MainApp instance
        pdf_dir.mkdir(parents=True, exist_ok=True)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        pdf_path = pdf_dir / f"dashboard_report_{timestamp}.pdf"
        with PdfPages(pdf_path) as pdf:
            # Cover Page
            fig = plt.figure(figsize=(8.5, 11))
            plt.axis('off')
            plt.text(0.5, 0.8, "Reconciliation Dashboard Report", ha='center', fontsize=16)
            plt.text(0.5, 0.7, f"Generated: {timestamp}", ha='center')
            if not self.df_current.empty:
                plt.text(0.5, 0.6, f"Records in Current Run: {len(self.df_current)}", ha='center')
            pdf.savefig(fig)
            plt.close(fig)
            # For each chart frame, if it contains a FigureCanvasTkAgg, save its figure.
            for key in self.frames:
                frame = self.frames[key]
                for widget in frame.winfo_children():
                    if isinstance(widget, FigureCanvasTkAgg):
                        pdf.savefig(widget.figure)
        messagebox.showinfo("PDF Export", f"Dashboard exported to PDF:\n{pdf_path}")

    def toggle_top_n(self):
        if self.top_n == 10:
            self.top_n = None  # For "All"
            self.toggle_button.configure(text="Show Top 10") #update button
        else:
            self.top_n = 10
            self.toggle_button.configure(text="Show All") #update button
        self.update_data_filters()
        self.save_dashboard_state()  # Save after toggle

    def save_dashboard_state(self):
        """Saves the current dashboard state to the config."""
        self.config["dashboard"]["selected_dims"] = list(self.selected_dims)
        self.config["dashboard"]["selected_attrs"] = list(self.selected_attrs)
        self.config["dashboard"]["date_range"]["start_date"] = self.start_date_var.get()
        self.config["dashboard"]["date_range"]["end_date"] = self.end_date_var.get()
        self.config["dashboard"]["top_n"] = self.top_n
        self.config["dashboard"]["active_tab"] = self.active_tab
        # The main app will call save_config to write to disk.

# ----------------------------------------------------------------------------
# MAIN APP
# ----------------------------------------------------------------------------
class MainApp(ctk.CTk):
    def __init__(self):
        super().__init__()
        self.title("Ultra-Mega Reconciliation: Param-based, Full Dashboard")
        self.geometry("1600x900")
        ctk.set_appearance_mode("light")

        self.config_dict = load_config(Path(DEFAULT_PATHS["CONFIG_PATH"]))
        self.param_dict = read_param_file(Path(self.config_dict["paths"].get("PARAMETER_PATH", DEFAULT_PATHS["PARAMETER_PATH"])))
        self.history_df = pd.DataFrame()

        self.tabs = ttk.Notebook(self)
        self.tabs.pack(fill="both", expand=True)

        # Paths Tab
        self.tab_paths = ctk.CTkFrame(self.tabs)
        self.tabs.add(self.tab_paths, text="Paths")
        self.build_paths_tab(self.tab_paths)

        # ERP Preview
        self.tab_ERP = ctk.CTkFrame(self.tabs)
        self.ERP_preview = SimplePreview(self.tab_ERP, "ERP")
        self.ERP_preview.pack(fill="both", expand=True)
        self.tabs.add(self.tab_ERP, text="ERP Preview")

        # Master Preview
        self.tab_Master = ctk.CTkFrame(self.tabs)
        self.Master_preview = SimplePreview(self.tab_Master, "Master")
        self.Master_preview.pack(fill="both", expand=True)
        self.tabs.add(self.tab_Master, text="Master Preview")

        # Compare
        self.tab_compare = ctk.CTkFrame(self.tabs)
        self.build_compare_tab(self.tab_compare)
        self.tabs.add(self.tab_compare, text="Compare")

        # Dashboard - Pass config to the dashboard
        self.dashboard_tab = AdvancedDashboard(self.tabs, self.config_dict)
        self.tabs.add(self.dashboard_tab, text="Dashboard")

        # Logging
        self.log_box = ctk.CTkTextbox(self, height=120)
        self.log_box.pack(fill="both")
        self.log_box.configure(state="disabled")
        handler = TextHandler(self.log_box)
        handler.setLevel(logging.INFO)
        logging.getLogger().addHandler(handler)

        self.add_status_bar()

        self.temp_csv_dir = Path(self.config_dict["paths"].get("Master_CSV_OUTPUT", "temp_Master_csv"))
        self.temp_csv_dir.mkdir(parents=True, exist_ok=True)
        
        # Load filters from config
        self.ERP_preview.filters = self.config_dict.get("ERP_grid", {}).get("filters", {})
        self.Master_preview.filters = self.config_dict.get("Master_grid", {}).get("filters", {})

        self.refresh_ERP()
        self.refresh_Master()

        # Keyboard shortcuts and session management could be added here as needed.
        self.protocol("WM_DELETE_WINDOW", self.on_close)

    def add_status_bar(self):
        self.status_bar = ctk.CTkFrame(self)
        self.status_bar.pack(fill="x", side="bottom")
        self.status_label = ctk.CTkLabel(self.status_bar, text="Ready")
        self.status_label.pack(side="left", padx=5)
        self.memory_label = ctk.CTkLabel(self.status_bar, text="")
        self.memory_label.pack(side="right", padx=5)
        self.update_status_bar()

    def update_status_bar(self):
        if psutil is not None:
            mem = psutil.Process().memory_info().rss / 1024 / 1024
            self.memory_label.configure(text=f"Memory: {mem:.1f} MB")
        else:
            self.memory_label.configure(text="psutil not installed")
        self.after(1000, self.update_status_bar)

    def build_paths_tab(self, parent):
        frm = ctk.CTkFrame(parent)
        frm.pack(fill="both", expand=True, padx=10, pady=10)
        self.ERP_var = tk.StringVar(value=self.config_dict["paths"].get("ERP_EXCEL_PATH", DEFAULT_PATHS["ERP_EXCEL_PATH"]))
        self.mast_var = tk.StringVar(value=self.config_dict["paths"].get("Master_ZIP_PATH", DEFAULT_PATHS["Master_ZIP_PATH"]))
        self.exc_var = tk.StringVar(value=self.config_dict["paths"].get("EXCEPTION_PATH", DEFAULT_PATHS["EXCEPTION_PATH"]))
        self.out_var = tk.StringVar(value=self.config_dict["paths"].get("OUTPUT_PATH", DEFAULT_PATHS["OUTPUT_PATH"]))
        self.cfg_var = tk.StringVar(value=self.config_dict["paths"].get("CONFIG_PATH", DEFAULT_PATHS["CONFIG_PATH"]))
        self.par_var = tk.StringVar(value=self.config_dict["paths"].get("PARAMETER_PATH", DEFAULT_PATHS["PARAMETER_PATH"]))
        self.csv_var = tk.StringVar(value=self.config_dict["paths"].get("Master_CSV_OUTPUT", DEFAULT_PATHS["Master_CSV_OUTPUT"]))
        self.pdf_var = tk.StringVar(value=self.config_dict["paths"].get("PDF_EXPORT_PATH", DEFAULT_PATHS["PDF_EXPORT_PATH"]))  # Add PDF path
        def mkrow(lbl, var, is_dir=False):
            row = ctk.CTkFrame(frm)
            row.pack(fill="x", pady=5)
            ctk.CTkLabel(row, text=lbl, width=180).pack(side="left", padx=5)
            e = ctk.CTkEntry(row, textvariable=var, width=600)
            e.pack(side="left", padx=5)
            def br():
                p = filedialog.askdirectory() if is_dir else filedialog.askopenfilename()
                if p:
                    var.set(p)
            ctk.CTkButton(row, text="Browse", command=br,
                          fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)
        mkrow("ERP Excel:", self.ERP_var)
        mkrow("Master ZIP:", self.mast_var)
        mkrow("Exception Path:", self.exc_var)
        mkrow("Missing Items Output:", self.out_var)
        mkrow("JSON Config Path:", self.cfg_var)
        mkrow("Parameter File:", self.par_var)
        mkrow("Master CSV Folder:", self.csv_var, is_dir=True)
        mkrow("PDF Export Path:", self.pdf_var, is_dir=True) # Add PDF Path row
        bf = ctk.CTkFrame(frm)
        bf.pack(fill="x", pady=10)
        ctk.CTkButton(bf, text="Save Config", command=self.save_all_config,
                      fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)
        ctk.CTkButton(bf, text="Refresh ERP", command=self.refresh_ERP,
                      fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)
        ctk.CTkButton(bf, text="Refresh Master", command=self.refresh_Master,
                      fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)

    def build_compare_tab(self, parent):
        frm = ctk.CTkFrame(parent)
        frm.pack(fill="both", expand=True, padx=10, pady=10)
        btn_frame = ctk.CTkFrame(frm)
        btn_frame.pack(fill="x", pady=5)
        ctk.CTkButton(btn_frame, text="Refresh All Data", command=self.refresh_all_data,
                      fg_color="#800020", hover_color="#a52a2a", height=40).pack(side="left", padx=5)
        comp_frame = ctk.CTkFrame(frm)
        comp_frame.pack(fill="x", pady=10)
        ctk.CTkLabel(comp_frame, text="Generate Missing Items Report", font=("Arial",16)).pack(pady=5)
        ctk.CTkButton(comp_frame, text="Run Reconciliation", command=self.run_comparison,
                      fg_color="#800020", hover_color="#a52a2a", height=40).pack(pady=5)
        self.status_frame = ctk.CTkFrame(frm)
        self.status_frame.pack(fill="x", pady=5)
        self.last_run_label = ctk.CTkLabel(self.status_frame, text="Last Run: Never")
        self.last_run_label.pack(pady=5)

    def refresh_all_data(self):
        try:
            self.param_dict = read_param_file(Path(self.config_dict["paths"].get("PARAMETER_PATH", DEFAULT_PATHS["PARAMETER_PATH"])))
            self.refresh_ERP()
            self.refresh_Master()
            now = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            self.last_run_label.configure(text=f"Last Refresh: {now}")
            messagebox.showinfo("Success", "All data refreshed successfully!")
        except Exception as e:
            logging.error(f"Error refreshing data: {e}")
            messagebox.showerror("Error", f"Error refreshing data: {str(e)}")

    def refresh_ERP(self):
        ERP_path = Path(self.ERP_var.get().strip()).resolve()
        raw_ERP = read_ERP_excel(ERP_path)
        if raw_ERP.empty:
            self.ERP_preview.set_data(pd.DataFrame())
            return
        param = {
            "dim_ERP_keep": self.param_dict.get("dim_ERP_keep", set()),
            "dim_ERP_map": self.param_dict.get("dim_ERP_map", {}),
            "attr_ERP_map": self.param_dict.get("attr_ERP_map", {})
        }
        melted = meltdown_ERP_for_preview(raw_ERP, param)
        pivoted = pivot_for_preview(melted)
        self.ERP_preview.set_data(pivoted)

    def refresh_Master(self):
        zip_path = Path(self.mast_var.get().strip()).resolve()
        out_dir = Path(self.csv_var.get().strip()).resolve()
        csvs = convert_Master_txt_to_csv(zip_path, out_dir)
        raw_mast = unify_Master_csvs(csvs)
        if raw_mast.empty:
            self.Master_preview.set_data(pd.DataFrame())
            return
        param = {
            "dim_Master_map": self.param_dict.get("dim_Master_map", {}),
            "attr_Master_map": self.param_dict.get("attr_Master_map", {})
        }
        melted = meltdown_Master_for_preview(raw_mast, param)
        pivoted = pivot_for_preview(melted)
        self.Master_preview.set_data(pivoted)

    def run_comparison(self):
        df_ERP_wide = self.ERP_preview.get_filtered_df()
        df_mast_wide = self.Master_preview.get_filtered_df()
        ERP_long = melt_back(df_ERP_wide)
        ERP_long = build_keys(ERP_long)
        mast_long = melt_back(df_mast_wide)
        mast_long = build_keys(mast_long)
        df_diff = compare_mode2(ERP_long, mast_long)
        exc_path = Path(self.config_dict["paths"].get("EXCEPTION_PATH", DEFAULT_PATHS["EXCEPTION_PATH"])).resolve()
        df_exc = read_exception_table(exc_path)
        final = merge_exceptions(df_diff, df_exc)
        out_path = Path(self.config_dict["paths"].get("OUTPUT_PATH", DEFAULT_PATHS["OUTPUT_PATH"])).resolve()
        write_missing_items(final, out_path)
        run_date = datetime.now().strftime("%Y-%m-%d")
        final["RunDate"] = run_date

        # Update run history
        run_summary = {"date": run_date, "missing": len(final)}
        self.config_dict.setdefault("run_history", [])  # Ensure 'run_history' exists
        self.config_dict["run_history"].append(run_summary)

        if self.history_df.empty:
            self.history_df = final.copy()
        else:
            self.history_df = pd.concat([self.history_df, final], ignore_index=True)

        self.dashboard_tab.update_data(final, self.history_df)
        self.last_run_label.configure(text=f"Last Run: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        self.tabs.select(self.dashboard_tab)
        messagebox.showinfo("Done", f"Missing items written to {out_path}")

    def save_all_config(self):
      self.config_dict["paths"]["ERP_EXCEL_PATH"] = self.ERP_var.get().strip()
      self.config_dict["paths"]["Master_ZIP_PATH"] = self.mast_var.get().strip()
      self.config_dict["paths"]["EXCEPTION_PATH"] = self.exc_var.get().strip()
      self.config_dict["paths"]["OUTPUT_PATH"] = self.out_var.get().strip()
      self.config_dict["paths"]["CONFIG_PATH"] = self.cfg_var.get().strip()
      self.config_dict["paths"]["PARAMETER_PATH"] = self.par_var.get().strip()
      self.config_dict["paths"]["Master_CSV_OUTPUT"] = self.csv_var.get().strip()
      self.config_dict["paths"]["PDF_EXPORT_PATH"] = self.pdf_var.get().strip()

      # Store filter selections for previews
      self.config_dict["ERP_grid"]["filters"] = self.ERP_preview.filters
      self.config_dict["Master_grid"]["filters"] = self.Master_preview.filters
      
      self.dashboard_tab.save_dashboard_state() #save the dashboard state

      save_config(self.config_dict, Path(self.config_dict["paths"]["CONFIG_PATH"]))
      messagebox.showinfo("Saved", "Configuration saved successfully.")

    def refresh_all_data(self):
        self.refresh_ERP()
        self.refresh_Master()
        now = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        self.last_run_label.configure(text=f"Last Refresh: {now}")
        messagebox.showinfo("Success", "All data refreshed successfully!")

    def on_close(self):
        # Save all config data on close
        self.save_all_config()
        self.destroy()

def main():
    app = MainApp()
    app.mainloop()

if __name__ == "__main__":
    main()
