#!/usr/bin/env python3
"""
Ultra-Mega Reconciliation: 
- Name-first comparison logic with skip-other-attributes if Name mismatch.
- New beige/yellow color scheme in write_2sheet_excel.
- Future End Date filter includes blank End Dates.
- Full single-file script, nothing omitted.
"""

import os
import sys
import json
import logging
import zipfile
import shutil
import io
from pathlib import Path
from datetime import datetime, date
from typing import Dict, Set, List, Tuple

import tkinter as tk
from tkinter import ttk, filedialog, messagebox
import customtkinter as ctk

import pandas as pd
import numpy as np

import matplotlib
matplotlib.use("TkAgg")
import matplotlib.pyplot as plt
from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg, NavigationToolbar2Tk
from matplotlib.backends.backend_pdf import PdfPages

from openpyxl import Workbook
from openpyxl.styles import PatternFill, Font, Alignment
from openpyxl.worksheet.table import Table, TableStyleInfo
from openpyxl.utils import get_column_letter

logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")


# ----------------------------------------------------------------------------
# DEFAULT PATHS & CONFIG
# ----------------------------------------------------------------------------
DEFAULT_PATHS = {
    "ERP_EXCEL_PATH": "data/ERP_Config.xlsx",
    "MASTER_ZIP_PATH": "data/Master_Config.zip",
    "MASTER_TXT_FOLDER": "",
    "EXCEPTION_PATH": "data/Exception_Table.xlsx",
    "OUTPUT_PATH": "output/missing_items.xlsx",
    "CONFIG_PATH": "config/ui_config.json",
    "PARAMETER_PATH": "data/parameters.xlsx",
    "MASTER_CSV_OUTPUT": "temp_master_csv",
    "PDF_EXPORT_PATH": "output/dashboard_report.pdf",
    "LOGO_PATH": "images/company_logo.png",
    "HISTORY_PATH": "history_runs"
}

def default_config() -> Dict:
    return {
        "paths": DEFAULT_PATHS.copy(),
        "erp_grid": {"filters": {}},
        "master_grid": {"filters": {}},
        "dashboard": {
            "selected_dims": [],
            "selected_attrs": [],
            "top_n": 10
        },
        "trim_key_toggle": False
    }

def load_config(path: Path) -> Dict:
    if path.is_file():
        try:
            with open(path, "r", encoding="utf-8") as f:
                return json.load(f)
        except Exception as e:
            logging.warning(f"Could not load config => {e}")
    return default_config()

def save_config(cfg: Dict, path: Path):
    path.parent.mkdir(parents=True, exist_ok=True)
    try:
        # Convert sets->lists for ERP filters
        if "erp_grid" in cfg and "filters" in cfg["erp_grid"]:
            new_erp={}
            for c,vals in cfg["erp_grid"]["filters"].items():
                new_erp[c] = list(vals)
            cfg["erp_grid"]["filters"] = new_erp

        # Convert sets->lists for Master filters
        if "master_grid" in cfg and "filters" in cfg["master_grid"]:
            new_mast={}
            for c,vals in cfg["master_grid"]["filters"].items():
                new_mast[c] = list(vals)
            cfg["master_grid"]["filters"] = new_mast

        with open(path, "w", encoding="utf-8") as f:
            json.dump(cfg, f, indent=2)
        logging.info(f"Saved config => {path}")
    except Exception as e:
        logging.error(f"Error saving config => {e}")


# ----------------------------------------------------------------------------
# TEXT LOGGER
# ----------------------------------------------------------------------------
class TextHandler(logging.Handler):
    def __init__(self, widget: ctk.CTkTextbox):
        super().__init__()
        self.widget = widget

    def emit(self, record):
        msg = self.format(record) + "\n"
        self.widget.after(0, self._append, msg)

    def _append(self, msg):
        self.widget.configure(state="normal")
        self.widget.insert("end", msg)
        self.widget.see("end")
        self.widget.configure(state="disabled")


# ----------------------------------------------------------------------------
# UTILS
# ----------------------------------------------------------------------------
def read_erp_excel(path: Path)-> pd.DataFrame:
    if not path.is_file():
        logging.warning(f"ERP Excel not found => {path}")
        return pd.DataFrame()
    try:
        df= pd.read_excel(path, skiprows=3)
        df.columns= df.columns.str.strip()
        if "Enabled_Flag" in df.columns:
            df= df[df["Enabled_Flag"]=="Enabled"]
        return df
    except Exception as e:
        logging.error(f"Error reading ERP => {e}")
        return pd.DataFrame()

def try_read_csv_bytes(raw: bytes)-> pd.DataFrame:
    encs= ["utf-8-sig","utf-16-le","utf-16-be","cp1252","latin-1","ascii"]
    import io
    for enc in encs:
        try:
            buf= io.BytesIO(raw)
            df= pd.read_csv(buf, encoding=enc, on_bad_lines="skip", engine="python")
            df.dropna(how="all", axis=0, inplace=True)
            df.dropna(how="all", axis=1, inplace=True)
            df.columns= df.columns.astype(str).str.strip()
            if "Name" not in df.columns and len(df.columns)>0:
                fc= df.columns[0]
                df.rename(columns={fc:"Name"}, inplace=True)
            return df
        except Exception as e:
            logging.debug(f"try_read_csv_bytes => {enc} => fail => {e}")
    logging.error("All encodings failed => returning empty DF.")
    return pd.DataFrame()

def convert_master_txt_to_csv(zip_path: Path, out_dir: Path)-> List[Path]:
    if not zip_path.is_file():
        logging.warning(f"Master ZIP not found => {zip_path}")
        return []
    if out_dir.exists():
        shutil.rmtree(out_dir, ignore_errors=True)
    out_dir.mkdir(parents=True, exist_ok=True)
    csvs=[]
    with zipfile.ZipFile(zip_path,"r") as z:
        txt_files= [f for f in z.namelist() if f.lower().endswith(".txt")]
        for txt_file in txt_files:
            bn= os.path.basename(txt_file)
            if not bn:
                continue
            try:
                with z.open(txt_file) as fo:
                    raw= fo.read()
                df= try_read_csv_bytes(raw)
                if df.empty:
                    continue
                df["RawFileName"]= bn
                out_csv= out_dir/(bn.replace(".txt",".csv"))
                df.to_csv(out_csv, index=False, encoding="utf-8")
                csvs.append(out_csv)
            except Exception as e:
                logging.error(f"Master reading {txt_file} => {e}")
    return csvs

def unify_master_csvs(csvs: List[Path])-> pd.DataFrame:
    frames=[]
    for cp in csvs:
        if not cp.is_file():
            continue
        try:
            df= pd.read_csv(cp, encoding="utf-8", on_bad_lines="skip")
            df.columns= df.columns.str.strip()
            frames.append(df)
        except Exception as e:
            logging.error(f"unify_master_csvs => {cp} => {e}")
    if frames:
        return pd.concat(frames, ignore_index=True)
    return pd.DataFrame()

def unify_master_txt_in_folder(folder: Path)-> pd.DataFrame:
    if not folder.is_dir():
        logging.warning(f"Master folder not found => {folder}")
        return pd.DataFrame()
    txt_files= list(folder.glob("*.txt"))
    if not txt_files:
        logging.warning(f"No .txt found => {folder}")
        return pd.DataFrame()
    frames=[]
    for f in txt_files:
        try:
            raw= f.read_bytes()
            df= try_read_csv_bytes(raw)
            if not df.empty:
                df["RawFileName"]= f.name
                frames.append(df)
        except Exception as e:
            logging.error(f"Reading unzipped {f} => {e}")
    if frames:
        return pd.concat(frames, ignore_index=True)
    return pd.DataFrame()


# ----------------------------------------------------------------------------
# PARAMS
# ----------------------------------------------------------------------------
def read_param_file(path: Path)-> Dict[str,object]:
    param= {
        "dim_erp_keep": set(),
        "dim_erp_map": {},
        "dim_master_map": {},
        "attr_erp_map": {},
        "attr_master_map": {}
    }
    if not path.is_file():
        logging.warning(f"Param file not found => {path}")
        return param
    try:
        dim_df= pd.read_excel(path, sheet_name="Dimension Parameters")
        dim_df.columns= dim_df.columns.astype(str).str.strip()

        def s(x): return str(x).strip() if pd.notna(x) else ""
        for _, row in dim_df.iterrows():
            fn= s(row.get("FileName",""))
            vsc= s(row.get("V S C",""))
            dim= s(row.get("Dimension",""))
            ev= s(row.get("ERP Values",""))
            if ev.lower()=="x" and vsc and dim:
                param["dim_erp_keep"].add(vsc)
            if vsc and dim:
                param["dim_erp_map"][vsc]= dim
            if fn and dim and ev.lower()=="x":
                param["dim_master_map"][fn]= dim

        attr_df= pd.read_excel(path, sheet_name="Attribute Parameters")
        attr_df.columns= attr_df.columns.astype(str).str.strip()
        for _, row in attr_df.iterrows():
            e_orig= s(row.get("ERP Original Attributes",""))
            m_orig= s(row.get("Master Original Attributes",""))
            final_= s(row.get("Attribute",""))
            onoff= s(row.get("On/Off",""))
            if onoff.lower()=="x" and final_:
                if e_orig:
                    param["attr_erp_map"][e_orig]= final_
                if m_orig:
                    param["attr_master_map"][m_orig]= final_
        return param
    except Exception as e:
        logging.error(f"Error reading param => {e}")
        return param


# ----------------------------------------------------------------------------
# MELTDOWN
# ----------------------------------------------------------------------------
def meltdown_erp_for_preview(df: pd.DataFrame, param: Dict[str,object])-> pd.DataFrame:
    if "V_S_C" not in df.columns:
        return pd.DataFrame()
    keep= param["dim_erp_keep"]
    dmap= param["dim_erp_map"]
    amap= param["attr_erp_map"]

    df2= df[df["V_S_C"].isin(keep)].copy()
    if df2.empty:
        return pd.DataFrame()

    skip_cols= {"V_S_C","Enabled_Flag"}
    id_vars=[]
    if "Value" in df2.columns:
        id_vars.append("Value")
        skip_cols.add("Value")
    df2["DimRaw"]= df2["V_S_C"]
    skip_cols.add("DimRaw")
    id_vars.insert(0,"DimRaw")

    meltdown_cols= [c for c in df2.columns if c not in skip_cols]
    melted= df2.melt(
        id_vars=id_vars,
        value_vars=meltdown_cols,
        var_name="OrigAttr",
        value_name="ValX"
    )

    def rename_dim(x):
        return dmap.get(x,x)
    melted["Dimension"]= melted["DimRaw"].apply(rename_dim)

    if "Value" in id_vars:
        melted.rename(columns={"Value":"Name"}, inplace=True)
    else:
        melted["Name"]= ""

    # only keep mapped attributes
    melted= melted[melted["OrigAttr"].isin(amap.keys())].copy()
    melted["Attribute"]= melted["OrigAttr"].map(amap)

    def strip_t(val):
        if isinstance(val,str) and "T" in val:
            return val.split("T")[0]
        return val

    melted["Value"]= np.where(
        melted["Attribute"].isin(["Start Date","End Date"]),
        melted["ValX"].apply(strip_t),
        melted["ValX"]
    )
    return melted[["Dimension","Name","Attribute","Value"]]

def meltdown_master_for_preview(df: pd.DataFrame, param: Dict[str,object])-> pd.DataFrame:
    if df.empty or "RawFileName" not in df.columns:
        return pd.DataFrame()
    keep_map= param["dim_master_map"]
    amap= param["attr_master_map"]

    df2= df[df["RawFileName"].isin(keep_map.keys())].copy()
    if df2.empty:
        return pd.DataFrame()

    df2["DimRaw"]= df2["RawFileName"]
    skip_cols= {"RawFileName","DimRaw"}
    id_vars= ["DimRaw"]
    if "Name" in df2.columns:
        id_vars.append("Name")
        skip_cols.add("Name")

    meltdown_cols= [c for c in df2.columns if c not in skip_cols]
    melted= df2.melt(
        id_vars=id_vars,
        value_vars=meltdown_cols,
        var_name="OrigAttr",
        value_name="ValX"
    )

    def rename_dim(x):
        return keep_map.get(x,x)
    melted["Dimension"]= melted["DimRaw"].apply(rename_dim)

    if "Name" in id_vars:
        melted.rename(columns={"Name":"Name"}, inplace=True)
    else:
        melted["Name"]= ""

    def strip_t(val):
        if isinstance(val,str) and "T" in val:
            return val.split("T")[0]
        return val

    # only keep mapped attributes
    amap_keys= set(amap.keys())
    melted= melted[melted["OrigAttr"].isin(amap_keys)].copy()
    melted["Attribute"]= melted["OrigAttr"].map(amap)
    melted["Value"]= np.where(
        melted["Attribute"].isin(["Start Date","End Date"]),
        melted["ValX"].apply(strip_t),
        melted["ValX"]
    )
    return melted[["Dimension","Name","Attribute","Value"]]

def pivot_for_preview(df: pd.DataFrame)-> pd.DataFrame:
    if df.empty or not {"Dimension","Name","Attribute"}.issubset(df.columns):
        return pd.DataFrame()
    df2= df.drop_duplicates(subset=["Dimension","Name","Attribute"])
    try:
        out= df2.pivot(index=["Dimension","Name"], columns="Attribute", values="Value").reset_index()
        return out
    except Exception as e:
        logging.error(f"pivot_for_preview => {e}")
        return pd.DataFrame()


# ----------------------------------------------------------------------------
# COMPARE => Name-first logic
# ----------------------------------------------------------------------------
def meltdown_to_long(df_wide: pd.DataFrame)-> pd.DataFrame:
    if df_wide.empty or {"Dimension","Name"}.difference(df_wide.columns):
        return pd.DataFrame()
    meltdown_cols= [c for c in df_wide.columns if c not in ("Dimension","Name")]
    melted= df_wide.melt(
        id_vars=["Dimension","Name"],
        value_vars= meltdown_cols,
        var_name="Attribute",
        value_name="Value"
    )
    melted["Value"]= melted["Value"].fillna("")
    return melted

def compare_name_attribute(
    erp_long: pd.DataFrame,
    mast_long: pd.DataFrame,
    trim_key=False
)-> Tuple[pd.DataFrame, pd.DataFrame]:
    """
    Name-first logic with skip-other-attributes if name mismatch:
      1) If 'Name' is missing in Master or ERP => single row => skip other attributes
      2) If 'Name' differs => single row => skip other attributes
      3) If 'Name' is same => compare all other attributes
      4) case-only mismatch => goes to case_df
    """
    def build_dict(d: pd.DataFrame):
        out={}
        for (dim,nm), grp in d.groupby(["Dimension","Name"]):
            amap={}
            for _, row in grp.iterrows():
                amap[row["Attribute"]]= row["Value"]
            out[(dim,nm)] = amap
        return out

    e_dict= build_dict(erp_long)
    m_dict= build_dict(mast_long)

    mismatch_rows=[]
    case_rows=[]

    all_dnm= set(e_dict.keys())| set(m_dict.keys())

    for dnm in all_dnm:
        dim, nm= dnm
        e_map= e_dict.get(dnm,{})
        m_map= m_dict.get(dnm,{})

        # name from each side
        e_name= e_map.get("Name","")
        m_name= m_map.get("Name","")

        name_issue=False

        # Missing in ERP
        if dnm not in e_dict and dnm in m_dict:
            row= {
                "Dimension": dim,
                "Name": nm,
                "Attribute": "Name",
                "Master": m_name,
                "ERP": "",
                "Comments_1": "",
                "Comments_2": "",
                "Status": "Missing in ERP"
            }
            raw_key= f"{dim}|{nm}|Name|{m_name}|".upper()
            if trim_key:
                raw_key= raw_key.replace(" ","")
            row["Key"]= raw_key
            mismatch_rows.append(row)
            name_issue=True

        # Missing in Master
        elif dnm in e_dict and dnm not in m_dict:
            row= {
                "Dimension": dim,
                "Name": nm,
                "Attribute": "Name",
                "Master": "",
                "ERP": e_name,
                "Comments_1": "",
                "Comments_2": "",
                "Status": "Missing in Master"
            }
            raw_key= f"{dim}|{nm}|Name||{e_name}".upper()
            if trim_key:
                raw_key= raw_key.replace(" ","")
            row["Key"]= raw_key
            mismatch_rows.append(row)
            name_issue=True

        # Both exist but differ
        elif e_name and m_name and e_name!= m_name:
            if e_name.lower()== m_name.lower():
                # case difference => case_df
                row= {
                    "Dimension": dim,
                    "Name": nm,
                    "Attribute": "Name",
                    "Master": m_name,
                    "ERP": e_name,
                    "Comments_1": "",
                    "Comments_2": "",
                    "Status": "CASE"
                }
                raw_key= f"{dim}|{nm}|Name|{m_name}|{e_name}".upper()
                if trim_key:
                    raw_key= raw_key.replace(" ","")
                row["Key"]= raw_key
                case_rows.append(row)
            else:
                row= {
                    "Dimension": dim,
                    "Name": nm,
                    "Attribute": "Name",
                    "Master": m_name,
                    "ERP": e_name,
                    "Comments_1": "",
                    "Comments_2": "",
                    "Status": "Difference in both"
                }
                raw_key= f"{dim}|{nm}|Name|{m_name}|{e_name}".upper()
                if trim_key:
                    raw_key= raw_key.replace(" ","")
                row["Key"]= raw_key
                mismatch_rows.append(row)
            name_issue=True

        # skip other attributes if name issue
        if name_issue:
            continue

        # if name matches or both empty => compare other attributes
        all_atts= set(e_map.keys())| set(m_map.keys())
        all_atts.discard("Name")

        for att in all_atts:
            ev= e_map.get(att,"")
            mv= m_map.get(att,"")
            if ev.lower()== mv.lower() and ev!=mv and ev and mv:
                # case difference => case_df
                row= {
                    "Dimension": dim,
                    "Name": nm,
                    "Attribute": att,
                    "Master": mv,
                    "ERP": ev,
                    "Comments_1": "",
                    "Comments_2": "",
                    "Status": "CASE"
                }
                raw_key= f"{dim}|{nm}|{att}|{mv}|{ev}".upper()
                if trim_key:
                    raw_key= raw_key.replace(" ","")
                row["Key"]= raw_key
                case_rows.append(row)
            elif ev!= mv:
                if ev and not mv:
                    status= "Missing in Master"
                elif mv and not ev:
                    status= "Missing in ERP"
                else:
                    status= "Difference in both"

                row= {
                    "Dimension": dim,
                    "Name": nm,
                    "Attribute": att,
                    "Master": mv,
                    "ERP": ev,
                    "Comments_1": "",
                    "Comments_2": "",
                    "Status": status
                }
                raw_key= f"{dim}|{nm}|{att}|{mv}|{ev}".upper()
                if trim_key:
                    raw_key= raw_key.replace(" ","")
                row["Key"]= raw_key
                mismatch_rows.append(row)

    # Build final DFs
    mismatch_cols= ["Key","Dimension","Name","Attribute","Master","ERP","Comments_1","Comments_2","Status"]
    mismatch_df= pd.DataFrame(mismatch_rows) if mismatch_rows else pd.DataFrame(columns=mismatch_cols)
    case_df= pd.DataFrame(case_rows) if case_rows else pd.DataFrame(columns=mismatch_cols)
    return mismatch_df, case_df


# ----------------------------------------------------------------------------
# EXCEPTIONS
# ----------------------------------------------------------------------------
def read_exception_table(path: Path)-> pd.DataFrame:
    if not path.is_file():
        logging.warning(f"Exception table not found => {path}")
        return pd.DataFrame()
    try:
        df= pd.read_excel(path)
        df.columns= df.columns.astype(str).str.strip()
        return df
    except Exception as e:
        logging.error(f"Exception => {e}")
        return pd.DataFrame()

def merge_exceptions(df: pd.DataFrame, df_exc: pd.DataFrame)-> pd.DataFrame:
    if df.empty or df_exc.empty or "Key" not in df.columns:
        return df
    keep= [c for c in ["Key","Comments_1","Comments_2","hide exception"] if c in df_exc.columns]
    if not keep:
        return df
    exc= df_exc[keep].copy()
    exc["Key"]= exc["Key"].astype(str).str.strip()
    merged= df.merge(exc, on="Key", how="left", suffixes=("","_exc"))
    merged["hide exception"]= merged.get("hide exception","").fillna("").str.lower()
    final= merged[merged["hide exception"]!="yes"].copy()
    if "Comments_1_exc" in final.columns:
        final["Comments_1"]= np.where(final["Comments_1_exc"].notna(),
                                      final["Comments_1_exc"],
                                      final["Comments_1"])
        final.drop(columns=["Comments_1_exc"], inplace=True)
    if "Comments_2_exc" in final.columns:
        final["Comments_2"]= np.where(final["Comments_2_exc"].notna(),
                                      final["Comments_2_exc"],
                                      final["Comments_2"])
        final.drop(columns=["Comments_2_exc"], inplace=True)
    if "hide exception" in final.columns:
        final.drop(columns=["hide exception"], inplace=True)
    return final


# ----------------------------------------------------------------------------
# WRITE 2-SHEET => New Beige/Yellow Color
# ----------------------------------------------------------------------------
def write_2sheet_excel(mismatch_df: pd.DataFrame,
                       case_df: pd.DataFrame,
                       out_path: Path):
    """
    2 sheets: Mismatch + Case_Differences
    columns => Key,Dimension,Name,Attribute,Master,ERP,Comments_1,Comments_2,Status

    *Header row*: 
       - Font: Bold black 
       - Fill: #F2D16B (golden/beige)
    *Data rows* in mismatch sheet:
       - "Missing in Master": #FFF2CC (light beige)
       - "Missing in ERP":    #F4B084 (darker beige/orange)
       - "Difference in both":#FFD966 (gold)
       - default:             #FFEB9C (light yellow)
    *Case* sheet has normal data but same header fill

    A timestamped copy is also created.
    """
    out_path.parent.mkdir(parents=True, exist_ok=True)

    columns = ["Key","Dimension","Name","Attribute","Master","ERP","Comments_1","Comments_2","Status"]

    wb = Workbook()
    ws_m = wb.active
    ws_m.title = "Mismatch"
    ws_c = wb.create_sheet("Case_Differences")

    # fill mismatch
    for col in columns:
        if col not in mismatch_df.columns:
            mismatch_df[col]= ""
    ws_m.append(columns)
    for rowvals in mismatch_df[columns].itertuples(index=False):
        ws_m.append(rowvals)

    # fill case
    for col in columns:
        if col not in case_df.columns:
            case_df[col]= ""
    ws_c.append(columns)
    for rowvals in case_df[columns].itertuples(index=False):
        ws_c.append(rowvals)

    # Header style: golden/beige + black
    header_font = Font(bold=True, color="000000")  
    fill_header = PatternFill(start_color="F2D16B", end_color="F2D16B", fill_type="solid")

    # style mismatch header
    for cell in ws_m[1]:
        cell.font = header_font
        cell.fill = fill_header
        cell.alignment = Alignment(horizontal="center")

    # style case header
    for cell in ws_c[1]:
        cell.font = header_font
        cell.fill = fill_header
        cell.alignment = Alignment(horizontal="center")

    # define data row fills
    light_beige  = PatternFill(start_color="FFF2CC", end_color="FFF2CC", fill_type="solid")  
    dark_beige   = PatternFill(start_color="F4B084", end_color="F4B084", fill_type="solid")   
    gold_yellow  = PatternFill(start_color="FFD966", end_color="FFD966", fill_type="solid")  
    light_yellow = PatternFill(start_color="FFEB9C", end_color="FFEB9C", fill_type="solid")  

    if ws_m.max_row>1:
        status_idx= columns.index("Status")+1
        for r in range(2, ws_m.max_row+1):
            st_val= ws_m.cell(r, status_idx).value
            if st_val == "Missing in Master":
                fillc= light_beige
            elif st_val == "Missing in ERP":
                fillc= dark_beige
            elif st_val == "Difference in both":
                fillc= gold_yellow
            else:
                # default
                fillc= light_yellow

            for c_ in range(1, ws_m.max_column+1):
                cell_ = ws_m.cell(r, c_)
                cell_.fill= fillc
                cell_.font= Font(color="000000")  # black text

    # auto-size columns + freeze
    for sheet in [ws_m, ws_c]:
        for col in sheet.columns:
            max_len=0
            letter= col[0].column_letter
            for cell in col:
                val= str(cell.value) if cell.value else ""
                max_len= max(max_len, len(val))
            sheet.column_dimensions[letter].width= max_len+2
        sheet.freeze_panes= "A2"

    # add table
    def add_table(ws, tname):
        if ws.max_row>1:
            last_r= ws.max_row
            last_c= ws.max_column
            ref= f"A1:{get_column_letter(last_c)}{last_r}"
            tb= Table(displayName=tname, ref=ref)
            style= TableStyleInfo(name="TableStyleMedium9", showRowStripes=True,
                                  showColumnStripes=False, showFirstColumn=True)
            tb.tableStyleInfo= style
            ws.add_table(tb)

    add_table(ws_m,"MismatchTable")
    add_table(ws_c,"CaseTable")

    wb.save(out_path)
    logging.info(f"Missing items => {out_path}")

    # also a timestamped copy
    stamp= datetime.now().strftime("%Y%m%d_%H%M%S")
    stamped= out_path.parent / f"{out_path.stem}_{stamp}{out_path.suffix}"
    wb.save(stamped)
    logging.info(f"Timestamped => {stamped}")


# ----------------------------------------------------------------------------
# SIMPLE PREVIEW => future end date + blank handling
# ----------------------------------------------------------------------------
class SimplePreview(ctk.CTkFrame):
    FILTERABLE= {"Start Date","End Date"}

    def __init__(self, parent, name: str, filters_dict=None):
        super().__init__(parent)
        self.name= name
        self.df= pd.DataFrame()
        self.filters: Dict[str,Set[str]]= {}

        if isinstance(filters_dict, dict):
            for col, arr in filters_dict.items():
                if isinstance(arr,list):
                    self.filters[col]= set(arr)

        self.future_end_var= tk.BooleanVar(value=False)
        self.build_ui()

    def build_ui(self):
        topbar= ctk.CTkFrame(self, corner_radius=10, fg_color="#f0f0f0")
        topbar.pack(fill="x", padx=5, pady=5)

        ctk.CTkLabel(
            topbar, text=f"{self.name} Preview",
            fg_color="#800020", corner_radius=8,
            text_color="white",
            font= ctk.CTkFont(size=14, weight="bold")
        ).pack(side="left", padx=5)

        ctk.CTkButton(
            topbar, text="ⓘ", width=30, command=self.show_info,
            fg_color="#800020", hover_color="#a52a2a", text_color="white"
        ).pack(side="left", padx=5)

        ctk.CTkCheckBox(
            topbar, text="Future End Date Filter?",
            variable=self.future_end_var, command=self.refresh_table,
            fg_color="#800020", hover_color="#a52a2a", text_color="black"
        ).pack(side="left", padx=10)

        ctk.CTkButton(
            topbar, text="Clear Date Filters", command=self.clear_filters,
            fg_color="#800020", hover_color="#a52a2a", text_color="white"
        ).pack(side="left", padx=5)

        container= ctk.CTkFrame(self)
        container.pack(fill="both", expand=True, padx=5, pady=5)

        self.tree= ttk.Treeview(container, show="headings")
        vsb= ttk.Scrollbar(container, orient="vertical", command=self.tree.yview)
        hsb= ttk.Scrollbar(container, orient="horizontal", command=self.tree.xview)
        self.tree.configure(yscrollcommand=vsb.set, xscrollcommand=hsb.set)
        self.tree.grid(row=0,column=0,sticky="nsew")
        vsb.grid(row=0,column=1,sticky="ns")
        hsb.grid(row=1,column=0,sticky="ew")
        container.rowconfigure(0,weight=1)
        container.columnconfigure(0,weight=1)

        self.status_label= ctk.CTkLabel(self, text="0 rows", fg_color="#f0f0f0", text_color="black")
        self.status_label.pack(fill="x")

    def show_info(self):
        messagebox.showinfo(
            "Info",
            f"{self.name} meltdown data.\n"
            "Future End Date includes blank, unparseable with year>2200, '9999', or >=today.\n"
            "We also still respect manual filters for Start/End date intersection."
        )

    def set_data(self, df: pd.DataFrame):
        self.df= df.copy()
        self.refresh_table()

    def refresh_table(self):
        for i in self.tree.get_children():
            self.tree.delete(i)
        if self.df.empty:
            self.tree["columns"]=[]
            self.status_label.configure(text="0 rows")
            return

        cols= list(self.df.columns)
        self.tree["columns"]= cols
        for c in cols:
            self.tree.heading(
                c, text=c, anchor="w",
                command= lambda cc=c: self.on_heading_click(cc)
            )
            self.tree.column(c, anchor="w", width=150)

        df_f= self.apply_filters()
        for _, row in df_f.iterrows():
            rowvals= [row.get(c,"") for c in cols]
            self.tree.insert("", "end", values=rowvals)
        self.status_label.configure(text=f"{len(df_f)} rows")

    def apply_filters(self) -> pd.DataFrame:
        df_f = self.df.copy()

        # 1) normal manual filters
        for col, allowed in self.filters.items():
            if col not in df_f.columns:
                continue
            if not allowed:
                df_f = df_f.iloc[0:0]
                return df_f

            def keeper(x):
                if pd.isna(x):
                    return ("<<NaN>>" in allowed)
                elif isinstance(x, str) and not x.strip():
                    return ("<<BLANK>>" in allowed)
                else:
                    return str(x) in allowed

            df_f = df_f[df_f[col].apply(keeper)]

        # 2) future end date
        if self.future_end_var.get() and "End Date" in df_f.columns:
            today_ = date.today()
            future_vals = set()
            all_end = df_f["End Date"].unique()

            for val in all_end:
                # handle blanks
                if pd.isna(val) or (isinstance(val, str) and not val.strip()):
                    # always include blank
                    future_vals.add(val)
                    continue

                sval = str(val).strip()
                if not sval:
                    future_vals.add(val)
                    continue

                keep = False
                try:
                    dtp = datetime.strptime(sval, "%Y-%m-%d")
                    if dtp.date() >= today_ or dtp.year>2200:
                        keep = True
                except:
                    # un-parseable => '9999' or year>2200
                    if "9999" in sval:
                        keep= True
                    else:
                        import re
                        yrs= re.findall(r"\d{4}", sval)
                        for y_ in yrs:
                            try:
                                if int(y_)>2200:
                                    keep= True
                                    break
                            except ValueError:
                                pass
                if keep:
                    future_vals.add(val)

            df_f= df_f[df_f["End Date"].isin(future_vals)]

        return df_f

    def on_heading_click(self, col_name:str):
        if col_name in self.FILTERABLE:
            self.show_filter_popup(col_name)

    def show_filter_popup(self, col_name:str):
        if self.df.empty or col_name not in self.df.columns:
            return
        popup= tk.Toplevel(self)
        popup.title(f"Filter: {col_name}")
        popup.geometry("300x400")

        fr= ctk.CTkFrame(popup)
        fr.pack(fill="both", expand=True, padx=5, pady=5)

        unique_vals= self.df[col_name].unique()
        display_map={}
        reverse_map={}
        for v in unique_vals:
            if pd.isna(v):
                dsp= "(NaN)"
                sen= "<<NaN>>"
            elif isinstance(v,str) and not v.strip():
                dsp= "(blank)"
                sen= "<<BLANK>>"
            else:
                dsp= str(v)
                sen= dsp
            display_map[v]= dsp
            reverse_map[dsp]= sen
        sorted_disps= sorted(display_map.values(), key=lambda x:x.lower())

        curr= self.filters.get(col_name,set())
        all_sens= set(reverse_map.values())
        selall_var= tk.BooleanVar(value=(curr==all_sens or not curr))

        def toggle_all():
            check= selall_var.get()
            for vb in var_dict.values():
                vb.set(check)

        ctk.CTkCheckBox(
            fr, text="Select All", variable=selall_var, command=toggle_all,
            fg_color="#800020", hover_color="#a52a2a", text_color="black"
        ).pack(anchor="w", pady=5)

        scroll= ctk.CTkScrollableFrame(fr, width=250, height=250)
        scroll.pack(fill="both", expand=True, padx=5, pady=5)
        var_dict={}
        for dsp in sorted_disps:
            sen= reverse_map[dsp]
            in_filt= (sen in curr) or (not curr)
            bvar= tk.BooleanVar(value=in_filt)
            var_dict[dsp]= bvar
            ctk.CTkCheckBox(
                scroll, text=dsp, variable=bvar,
                fg_color="#800020", hover_color="#a52a2a", text_color="black"
            ).pack(anchor="w")

        def apply_():
            sel= {reverse_map[d] for d,bv in var_dict.items() if bv.get()}
            if sel==all_sens or not sel:
                if col_name in self.filters:
                    del self.filters[col_name]
            else:
                self.filters[col_name]= sel
            popup.destroy()
            self.refresh_table()

        bf= ctk.CTkFrame(fr)
        bf.pack(fill="x", pady=5)
        ctk.CTkButton(
            bf, text="Apply", command=apply_,
            fg_color="#800020", hover_color="#a52a2a", text_color="white"
        ).pack(side="left", padx=5)
        ctk.CTkButton(
            bf, text="Cancel", command=popup.destroy,
            fg_color="#800020", hover_color="#a52a2a", text_color="white"
        ).pack(side="left", padx=5)

    def clear_filters(self):
        for k in list(self.filters.keys()):
            if k in self.FILTERABLE:
                del self.filters[k]
        self.future_end_var.set(False)
        self.refresh_table()

    def get_filtered_df(self)-> pd.DataFrame:
        return self.apply_filters()


# ----------------------------------------------------------------------------
# PDF => partial
# ----------------------------------------------------------------------------
class EnhancedPDFReport:
    def __init__(self, df_current: pd.DataFrame, df_history: pd.DataFrame, config: Dict):
        self.df_current= df_current
        self.df_history= df_history
        self.config= config
        self.page_count=0
        self.colors= {
            "primary":"#800020",
            "text":"#2C1810",
            "background":"#FFFFFF"
        }
        self.logo_path= self.config["paths"].get("LOGO_PATH","images/company_logo.png")

        self.PAGE_WIDTH= 8.5
        self.PAGE_HEIGHT= 11
        self.CHART_SCALE= 0.7

    def generate(self)-> Path:
        stamp= datetime.now().strftime("%Y%m%d_%H%M%S")
        out_dir= Path("Reconciliation_pdf")
        out_dir.mkdir(parents=True, exist_ok=True)
        pdf_name= f"Reconciliation_{stamp}.pdf"
        pdf_path= out_dir/pdf_name
        with PdfPages(pdf_path) as pdf:
            self._cover_page(pdf)
            self._summary_page(pdf)
            self._topdimsattrs_page(pdf)
        logging.info(f"PDF => {pdf_path}")
        return pdf_path

    def _new_page(self)-> plt.Figure:
        fig= plt.figure(figsize=(self.PAGE_WIDTH,self.PAGE_HEIGHT))
        fig.patch.set_facecolor(self.colors["background"])
        plt.axis("off")
        self.page_count+=1
        if self.logo_path and os.path.exists(self.logo_path):
            try:
                import matplotlib.image as mpimg
                img= mpimg.imread(self.logo_path)
                ax_img= fig.add_axes([0.65,0.75,0.3,0.2])
                ax_img.imshow(img, alpha=0.2)
                ax_img.axis("off")
            except Exception as e:
                logging.error(f"Logo => {e}")
        fig.text(0.5, 0.98, "Reconciliation Report", ha="center", fontsize=10, color="gray")
        fig.text(0.9, 0.03, f"Page {self.page_count}", ha="right", fontsize=8, color="gray")
        fig.text(0.5, 0.02, "© Ultra-Mega Reconciliation", ha="center", fontsize=8, color="gray")
        return fig

    def _cover_page(self, pdf: PdfPages):
        fig= self._new_page()
        plt.text(0.5,0.7,"Reconciliation Analysis Report",
                 ha="center",fontsize=24,fontweight="bold",color=self.colors["primary"],
                 transform=fig.transFigure)
        plt.text(0.5,0.6,f"Generated on {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
                 ha="center",fontsize=12,color=self.colors["text"],
                 transform=fig.transFigure)
        plt.text(0.5,0.15,"CONFIDENTIAL",
                 ha="center",fontsize=9,color=self.colors["text"],
                 transform=fig.transFigure)
        pdf.savefig(fig)
        plt.close(fig)

    def _summary_page(self, pdf: PdfPages):
        fig= self._new_page()
        plt.text(0.5,0.92,"Reconciliation Summary",
                 ha="center",fontsize=18,fontweight="bold",color=self.colors["primary"],
                 transform=fig.transFigure)
        y=0.75
        if self.df_current.empty:
            plt.text(0.5,y,"No mismatches found this run.",
                     ha="center",fontsize=14,color=self.colors["text"],
                     transform=fig.transFigure)
        else:
            total= len(self.df_current)
            c_erp= (self.df_current["Status"]=="Missing in ERP").sum()
            c_mas= (self.df_current["Status"]=="Missing in Master").sum()
            c_both= (self.df_current["Status"]=="Difference in both").sum()
            c_case= (self.df_current["Status"]=="CASE").sum()
            summ= f"Total: {total}\nMissing in ERP: {c_erp}\nMissing in Master: {c_mas}\nDifference in both: {c_both}\nCASE: {c_case}"
            plt.text(0.5,y, summ, ha="center",fontsize=14,color=self.colors["text"],
                     transform=fig.transFigure)
        pdf.savefig(fig)
        plt.close(fig)

    def _topdimsattrs_page(self, pdf: PdfPages):
        fig= self._new_page()
        plt.text(0.5,0.92,"Top Dimensions & Attributes",
                 ha="center",fontsize=18,fontweight="bold",color=self.colors["primary"],
                 transform=fig.transFigure)
        if self.df_current.empty:
            plt.text(0.5,0.7,"No data available.",
                     ha="center",fontsize=12,color=self.colors["text"],
                     transform=fig.transFigure)
        else:
            if "Dimension" in self.df_current.columns:
                topdims= self.df_current["Dimension"].value_counts().head(5)
                lines= [f"- {k} ({v})" for k,v in topdims.items()]
                textdim= "Top Dimensions:\n"+ "\n".join(lines)
                plt.text(0.25,0.7,textdim,fontsize=12,color=self.colors["text"], transform=fig.transFigure)
            if "Attribute" in self.df_current.columns:
                topatts= self.df_current["Attribute"].value_counts().head(5)
                lines= [f"- {k} ({v})" for k,v in topatts.items()]
                textatt= "Top Attributes:\n"+ "\n".join(lines)
                plt.text(0.65,0.7,textatt,fontsize=12,color=self.colors["text"], transform=fig.transFigure)
        pdf.savefig(fig)
        plt.close(fig)


# ----------------------------------------------------------------------------
# ADV DASHBOARD => partial
# ----------------------------------------------------------------------------
class AdvancedDashboard(ctk.CTkFrame):
    def __init__(self, parent, config: Dict):
        super().__init__(parent)
        dash_cfg= config.get("dashboard",{})
        self.config= config
        self.selected_dims: Set[str]= set(dash_cfg.get("selected_dims",[]))
        self.selected_attrs: Set[str]= set(dash_cfg.get("selected_attrs",[]))
        self.top_n= dash_cfg.get("top_n",10)

        self.df_current= pd.DataFrame()
        self.df_history= pd.DataFrame()

        self.topbar= ctk.CTkScrollableFrame(self, orientation="horizontal", height=60)
        self.topbar.pack(fill="x", pady=5)
        self.metric_label= ctk.CTkLabel(self.topbar, text="Metrics: 0 mismatch, 0 dimension", width=300)
        self.metric_label.pack(side="left", padx=5)

        ctk.CTkButton(
            self.topbar, text="Filter Dimension", command=self.show_dimension_filter,
            fg_color="#800020", hover_color="#a52a2a", text_color="white"
        ).pack(side="left", padx=5)
        ctk.CTkButton(
            self.topbar, text="Filter Attribute", command=self.show_attribute_filter,
            fg_color="#800020", hover_color="#a52a2a", text_color="white"
        ).pack(side="left", padx=5)
        ctk.CTkButton(
            self.topbar, text="Toggle Top 10 / All", command=self.toggle_top_n,
            fg_color="#800020", hover_color="#a52a2a", text_color="white"
        ).pack(side="left", padx=5)

        self.notebook= ttk.Notebook(self)
        self.notebook.pack(fill="both", expand=True)

    def toggle_top_n(self):
        if self.top_n==10:
            self.top_n=None
        else:
            self.top_n=10
        self.update_data_filters()

    def show_dimension_filter(self):
        self.show_filter_popup("Dimension")

    def show_attribute_filter(self):
        self.show_filter_popup("Attribute")

    def show_filter_popup(self, col:str):
        base_df= self.df_history if not self.df_history.empty else self.df_current
        if base_df.empty or col not in base_df.columns:
            return
        popup= tk.Toplevel(self)
        popup.title(f"Filter: {col}")
        popup.geometry("300x400")

        fr= ctk.CTkFrame(popup)
        fr.pack(fill="both", expand=True, padx=5, pady=5)

        unique_vals= base_df[col].dropna().unique()
        display_map={}
        for v in unique_vals:
            dsp= str(v) if (isinstance(v,str) and v.strip()) else "(blank)"
            display_map[v]= dsp
        sorted_vals= sorted(display_map.keys(), key=lambda x: display_map[x].lower())
        if col=="Dimension":
            curr= self.selected_dims
        else:
            curr= self.selected_attrs
        if not curr:
            curr= set(sorted_vals)
        all_vals= set(sorted_vals)
        selall_var= tk.BooleanVar(value=(curr==all_vals or not curr))

        def toggle_all():
            check= selall_var.get()
            for vb in var_dict.values():
                vb.set(check)

        ctk.CTkCheckBox(
            fr, text="Select All", variable=selall_var, command=toggle_all,
            fg_color="#800020", hover_color="#a52a2a", text_color="black"
        ).pack(anchor="w", pady=5)

        scroll= ctk.CTkScrollableFrame(fr, width=250, height=250)
        scroll.pack(fill="both", expand=True, padx=5, pady=5)
        var_dict={}
        for rv in sorted_vals:
            in_filter= (rv in curr) or (not curr)
            bvar= tk.BooleanVar(value=in_filter)
            var_dict[rv]= bvar
            ctk.CTkCheckBox(
                scroll, text= display_map[rv], variable=bvar,
                fg_color="#800020", hover_color="#a52a2a", text_color="black"
            ).pack(anchor="w")

        def apply_():
            sel= {rv for rv,bv in var_dict.items() if bv.get()}
            if col=="Dimension":
                self.selected_dims= sel
            else:
                self.selected_attrs= sel
            popup.destroy()
            self.update_data_filters()

        bf= ctk.CTkFrame(fr)
        bf.pack(fill="x", pady=5)
        ctk.CTkButton(
            bf, text="Apply", command=apply_,
            fg_color="#800020", hover_color="#a52a2a", text_color="white"
        ).pack(side="left", padx=5)
        ctk.CTkButton(
            bf, text="Cancel", command=popup.destroy,
            fg_color="#800020", hover_color="#a52a2a", text_color="white"
        ).pack(side="left", padx=5)

    def update_data(self, df_current: pd.DataFrame, df_history: pd.DataFrame):
        self.df_current= df_current.copy()
        self.df_history= df_history.copy()
        self.update_data_filters()

    def update_data_filters(self):
        dfc= self.df_current.copy()
        if not dfc.empty:
            if self.selected_dims:
                dfc= dfc[dfc["Dimension"].isin(self.selected_dims)]
            if self.selected_attrs:
                dfc= dfc[dfc["Attribute"].isin(self.selected_attrs)]
        mism= len(dfc)
        dims= dfc["Dimension"].nunique() if not dfc.empty and "Dimension" in dfc.columns else 0
        self.metric_label.configure(text=f"Mismatches: {mism}, Dims: {dims}")


# ----------------------------------------------------------------------------
# HISTORY
# ----------------------------------------------------------------------------
class HistoryTab(ctk.CTkFrame):
    def __init__(self, parent, hist_dir: Path):
        super().__init__(parent)
        self.history_dir= hist_dir
        self.tree= None
        self.build_ui()

    def build_ui(self):
        lbl= ctk.CTkLabel(self, text="Reconciliation Runs History", font=("Arial",16))
        lbl.pack(pady=5)
        self.tree= ttk.Treeview(self, columns=("Filename",), show="headings", height=15)
        self.tree.heading("Filename", text="History File")
        self.tree.pack(fill="both", expand=True, padx=10, pady=10)

        self.tree.bind("<Double-1>", self.on_double_click)

        btn= ctk.CTkButton(
            self, text="Refresh", command=self.refresh_history,
            fg_color="#800020", hover_color="#a52a2a", text_color="white"
        )
        btn.pack(pady=5)
        self.refresh_history()

    def refresh_history(self):
        for i in self.tree.get_children():
            self.tree.delete(i)
        if not self.history_dir.is_dir():
            self.history_dir.mkdir(parents=True, exist_ok=True)
        files= sorted(self.history_dir.glob("run_*.json"), reverse=True)
        for f in files:
            self.tree.insert("", "end", values=(f.name,))

    def on_double_click(self, event):
        item_id= self.tree.focus()
        if not item_id:
            return
        fn= self.tree.item(item_id,"values")[0]
        path= self.history_dir/fn
        if not path.is_file():
            return
        try:
            with open(path, "r", encoding="utf-8") as ff:
                content= ff.read()
            popup= tk.Toplevel(self)
            popup.title(f"Viewing {fn}")
            txt= ctk.CTkTextbox(popup, width=800, height=600)
            txt.pack(fill="both", expand=True)
            txt.insert("end", content)
            txt.configure(state="disabled")
        except Exception as e:
            logging.error(f"Error opening {path} => {e}")


# ----------------------------------------------------------------------------
# MAIN APP
# ----------------------------------------------------------------------------
class MainApp(ctk.CTk):
    def __init__(self):
        super().__init__()
        self.title("Ultra-Mega Reconciliation (Name-first + Beige Mismatch + FutureEndDate + Full!)")
        self.geometry("1600x900")
        ctk.set_appearance_mode("light")

        self.config_dict= load_config(Path(DEFAULT_PATHS["CONFIG_PATH"]))
        self.param_dict= read_param_file(Path(self.config_dict["paths"].get("PARAMETER_PATH", DEFAULT_PATHS["PARAMETER_PATH"])))
        self.history_df= pd.DataFrame()

        self.tabs= ttk.Notebook(self)
        self.tabs.pack(fill="both", expand=True)

        # 1) Paths
        self.tab_paths= ctk.CTkFrame(self.tabs)
        self.build_paths_tab(self.tab_paths)
        self.tabs.add(self.tab_paths, text="Paths")

        # 2) ERP preview
        self.tab_erp= ctk.CTkFrame(self.tabs)
        ef= self.config_dict.get("erp_grid",{}).get("filters",{})
        self.erp_preview= SimplePreview(self.tab_erp,"ERP", ef)
        self.erp_preview.pack(fill="both", expand=True)
        self.tabs.add(self.tab_erp, text="ERP Preview")

        # 3) Master preview
        self.tab_master= ctk.CTkFrame(self.tabs)
        mf= self.config_dict.get("master_grid",{}).get("filters",{})
        self.master_preview= SimplePreview(self.tab_master,"Master", mf)
        self.master_preview.pack(fill="both", expand=True)
        self.tabs.add(self.tab_master, text="Master Preview")

        # 4) Compare
        self.tab_compare= ctk.CTkFrame(self.tabs)
        self.build_compare_tab(self.tab_compare)
        self.tabs.add(self.tab_compare, text="Compare")

        # 5) Dashboard
        self.dashboard_tab= AdvancedDashboard(self.tabs, self.config_dict)
        self.tabs.add(self.dashboard_tab, text="Dashboard")

        # 6) History
        histp= Path(self.config_dict["paths"].get("HISTORY_PATH","history_runs"))
        self.history_tab= HistoryTab(self.tabs, histp)
        self.tabs.add(self.history_tab, text="History")

        # Logging box
        self.log_box= ctk.CTkTextbox(self, height=120)
        self.log_box.pack(fill="both", side="bottom")
        self.log_box.configure(state="disabled")
        handler= TextHandler(self.log_box)
        handler.setLevel(logging.INFO)
        logging.getLogger().addHandler(handler)

        # temp CSV
        self.temp_csv_dir= Path(self.config_dict["paths"].get("MASTER_CSV_OUTPUT","temp_master_csv"))
        self.temp_csv_dir.mkdir(parents=True, exist_ok=True)

        # load runs => for historical reference
        self.load_all_runs()

        # meltdown => show
        self.refresh_erp()
        self.refresh_master()
        self.dashboard_tab.update_data(pd.DataFrame(), self.history_df)

    def build_paths_tab(self, parent):
        frm= ctk.CTkFrame(parent)
        frm.pack(fill="both", expand=True, padx=10, pady=10)

        self.erp_var= tk.StringVar(value=self.config_dict["paths"].get("ERP_EXCEL_PATH", DEFAULT_PATHS["ERP_EXCEL_PATH"]))
        self.mast_var= tk.StringVar(value=self.config_dict["paths"].get("MASTER_ZIP_PATH", DEFAULT_PATHS["MASTER_ZIP_PATH"]))
        self.mast_folder_var= tk.StringVar(value=self.config_dict["paths"].get("MASTER_TXT_FOLDER",""))
        self.exc_var= tk.StringVar(value=self.config_dict["paths"].get("EXCEPTION_PATH", DEFAULT_PATHS["EXCEPTION_PATH"]))
        self.out_var= tk.StringVar(value=self.config_dict["paths"].get("OUTPUT_PATH", DEFAULT_PATHS["OUTPUT_PATH"]))
        self.par_var= tk.StringVar(value=self.config_dict["paths"].get("PARAMETER_PATH", DEFAULT_PATHS["PARAMETER_PATH"]))
        self.pdf_var= tk.StringVar(value=self.config_dict["paths"].get("PDF_EXPORT_PATH", DEFAULT_PATHS["PDF_EXPORT_PATH"]))

        def mkrow(lbl, var, is_dir=False):
            rowf= ctk.CTkFrame(frm)
            rowf.pack(fill="x", pady=5)
            ctk.CTkLabel(rowf, text=lbl, width=200).pack(side="left", padx=5)
            e= ctk.CTkEntry(rowf, textvariable=var, width=600)
            e.pack(side="left", padx=5)
            def br():
                if is_dir:
                    p= filedialog.askdirectory()
                else:
                    p= filedialog.askopenfilename()
                if p:
                    var.set(p)
            ctk.CTkButton(rowf, text="Browse", command=br,
                          fg_color="#800020", hover_color="#a52a2a", text_color="white").pack(side="left", padx=5)

        mkrow("ERP Excel:", self.erp_var)
        mkrow("Master ZIP:", self.mast_var)
        mkrow("Master TXT Folder:", self.mast_folder_var, is_dir=True)
        mkrow("Exception Path:", self.exc_var)
        mkrow("Missing Items Output:", self.out_var)
        mkrow("Parameter File:", self.par_var)
        mkrow("PDF Export Path:", self.pdf_var)

        bf= ctk.CTkFrame(frm)
        bf.pack(fill="x", pady=10)
        ctk.CTkButton(bf, text="Save Config", command=self.save_all_config,
                      fg_color="#800020", hover_color="#a52a2a", text_color="white").pack(side="left", padx=5)
        ctk.CTkButton(bf, text="Refresh ERP", command=self.refresh_erp,
                      fg_color="#800020", hover_color="#a52a2a", text_color="white").pack(side="left", padx=5)
        ctk.CTkButton(bf, text="Refresh Master", command=self.refresh_master,
                      fg_color="#800020", hover_color="#a52a2a", text_color="white").pack(side="left", padx=5)

    def build_compare_tab(self, parent):
        frm= ctk.CTkFrame(parent)
        frm.pack(fill="both", expand=True, padx=10, pady=10)
        ctk.CTkLabel(frm, text="Generate Missing Items", font=("Arial",16)).pack(pady=5)

        self.trim_key_var= tk.BooleanVar(value=self.config_dict.get("trim_key_toggle",False))
        ctk.CTkCheckBox(
            frm, text="Trim Key? (remove spaces)",
            variable=self.trim_key_var,
            fg_color="#800020", hover_color="#a52a2a", text_color="black"
        ).pack(pady=5)

        ctk.CTkButton(
            frm, text="Run Reconciliation", command=self.run_comparison,
            fg_color="#800020", hover_color="#a52a2a", text_color="white"
        ).pack(pady=10)

        ctk.CTkButton(
            frm, text="Export PDF Report",
            command=self.export_pdf,
            fg_color="#800020", hover_color="#a52a2a", text_color="white"
        ).pack(pady=10)

    def load_all_runs(self):
        histp= Path(self.config_dict["paths"].get("HISTORY_PATH","history_runs"))
        if not histp.is_dir():
            return
        frames=[]
        for jf in histp.glob("run_*.json"):
            try:
                jdata= pd.read_json(jf, orient="records")
                frames.append(jdata)
            except Exception as e:
                logging.error(f"History read => {jf} => {e}")
        if frames:
            big= pd.concat(frames, ignore_index=True).drop_duplicates()
            if self.history_df.empty:
                self.history_df= big
            else:
                self.history_df= pd.concat([self.history_df, big], ignore_index=True).drop_duplicates()
            logging.info(f"Loaded runs => total {len(self.history_df)} records in history")

    def refresh_erp(self):
        p= Path(self.erp_var.get().strip())
        df= read_erp_excel(p)
        if df.empty:
            self.erp_preview.set_data(pd.DataFrame())
            return
        meltdown= meltdown_erp_for_preview(df, self.param_dict)
        pivoted= pivot_for_preview(meltdown)
        self.erp_preview.set_data(pivoted)

    def refresh_master(self):
        folder= self.mast_folder_var.get().strip()
        if folder:
            df_m= unify_master_txt_in_folder(Path(folder))
        else:
            zp= Path(self.mast_var.get().strip())
            outd= self.temp_csv_dir
            csvs= convert_master_txt_to_csv(zp, outd)
            df_m= unify_master_csvs(csvs)
        if df_m.empty:
            self.master_preview.set_data(pd.DataFrame())
            return
        meltdown= meltdown_master_for_preview(df_m, self.param_dict)
        pivoted= pivot_for_preview(meltdown)
        self.master_preview.set_data(pivoted)

    def run_comparison(self):
        df_erp_wide= self.erp_preview.get_filtered_df()
        df_mast_wide= self.master_preview.get_filtered_df()

        e_long= meltdown_to_long(df_erp_wide)
        m_long= meltdown_to_long(df_mast_wide)

        trim_flag= bool(self.trim_key_var.get())
        mismatch_df, case_df= compare_name_attribute(e_long, m_long, trim_key=trim_flag)

        excp= Path(self.config_dict["paths"].get("EXCEPTION_PATH",""))
        df_exc= read_exception_table(excp)
        mismatch_df= merge_exceptions(mismatch_df, df_exc)
        case_df= merge_exceptions(case_df, df_exc)

        outp= Path(self.out_var.get().strip())
        write_2sheet_excel(mismatch_df, case_df, outp)

        # add to history => store mismatch
        run_ts= datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        mismatch_df["RunDate"]= run_ts
        if self.history_df.empty:
            self.history_df= mismatch_df.copy()
        else:
            self.history_df= pd.concat([self.history_df, mismatch_df], ignore_index=True).drop_duplicates()

        histp= Path(self.config_dict["paths"].get("HISTORY_PATH","history_runs"))
        histp.mkdir(parents=True, exist_ok=True)
        run_file= histp / f"run_{run_ts.replace(':','-').replace(' ','_')}.json"
        try:
            mismatch_df.to_json(run_file, orient="records", indent=2)
            logging.info(f"Saved run => {run_file}")
        except Exception as e:
            logging.error(f"Error saving JSON => {e}")

        self.dashboard_tab.update_data(mismatch_df, self.history_df)
        self.history_tab.refresh_history()
        self.tabs.select(self.dashboard_tab)
        messagebox.showinfo("Done", f"Missing items => {outp}")

    def export_pdf(self):
        if self.history_df.empty:
            messagebox.showinfo("PDF Export","No mismatch => history empty.")
            return
        if "RunDate" in self.history_df.columns:
            last_run= self.history_df["RunDate"].max()
            df_curr= self.history_df[self.history_df["RunDate"]== last_run].copy()
        else:
            df_curr= self.history_df.copy()

        rep= EnhancedPDFReport(df_curr, self.history_df, self.config_dict)
        pdfp= rep.generate()
        messagebox.showinfo("PDF Export", f"PDF => {pdfp}")

    def save_all_config(self):
        self.config_dict["paths"]["ERP_EXCEL_PATH"]= self.erp_var.get().strip()
        self.config_dict["paths"]["MASTER_ZIP_PATH"]= self.mast_var.get().strip()
        self.config_dict["paths"]["MASTER_TXT_FOLDER"]= self.mast_folder_var.get().strip()
        self.config_dict["paths"]["EXCEPTION_PATH"]= self.exc_var.get().strip()
        self.config_dict["paths"]["OUTPUT_PATH"]= self.out_var.get().strip()
        self.config_dict["paths"]["PARAMETER_PATH"]= self.par_var.get().strip()
        self.config_dict["paths"]["PDF_EXPORT_PATH"]= self.pdf_var.get().strip()

        self.config_dict["trim_key_toggle"]= bool(self.trim_key_var.get())

        self.config_dict.setdefault("erp_grid",{})
        self.config_dict["erp_grid"]["filters"]= self.erp_preview.filters
        self.config_dict.setdefault("master_grid",{})
        self.config_dict["master_grid"]["filters"]= self.master_preview.filters

        dash_cfg= self.config_dict.setdefault("dashboard",{})
        dash_cfg["selected_dims"]= list(self.dashboard_tab.selected_dims)
        dash_cfg["selected_attrs"]= list(self.dashboard_tab.selected_attrs)
        dash_cfg["top_n"]= self.dashboard_tab.top_n

        cfgp= Path(self.config_dict["paths"].get("CONFIG_PATH","config/ui_config.json"))
        save_config(self.config_dict, cfgp)


def main():
    app= MainApp()
    app.mainloop()

if __name__=="__main__":
    main()
