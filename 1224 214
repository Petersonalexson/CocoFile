#123
"""
Ultra-Mega Reconciliation: Mode=2, Parameter-based

Steps:
 1) ERP: Read an Excel skipping first 3 rows. Filter only rows with Enabled_Flag == "Enabled".
    a) Use param "erp_vsc_keep" to keep only those V S C values that have "x" in ERP Values.
    b) Use param "erp_vsc_map" to rename those V S C to final dimension names.
 2) Master: Unify .txt from a ZIP. For each .txt, read robustly. Add "RawFileName". Then rename dimension
    according to param["master_file_map"].
 3) Previews:
    - Show pivoted wide format. Lock "Dimension" + "Name". Only "Start Date"/"End Date" filter popups.
    - Remove duplicates ([Dimension, Name, Attribute]) before pivoting to avoid pivot errors.
 4) Compare:
    - Melt the wide previews back to long. Compare with mode=2 => produce "missing items".
    - Merge with exceptions. Write out to "missing_items.xlsx".
 5) Dashboard:
    - 8 charts with dimension/attribute/time filtering, plus date range pickers, “Show Today,” etc.
"""

import os, sys, json, logging, zipfile, shutil, io, codecs
from pathlib import Path
from datetime import datetime
from typing import Dict, Set, List

import pandas as pd
import numpy as np
import matplotlib
matplotlib.use("TkAgg")
import matplotlib.pyplot as plt
from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg

try:
    import chardet
except ImportError:
    chardet = None

from openpyxl import Workbook
from openpyxl.styles import PatternFill, Font, Alignment

import tkinter as tk
from tkinter import ttk, filedialog, messagebox, simpledialog
import customtkinter as ctk

# ---------------- LOGGING SETUP ----------------
logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")

# ---------------- DEFAULT CONFIG ----------------
DEFAULT_PATHS = {
    "ERP_EXCEL_PATH": "data/ERP_Config.xlsx",
    "MASTER_ZIP_PATH": "data/Master_Config.zip",
    "EXCEPTION_PATH": "data/Exception_Table.xlsx",
    "OUTPUT_PATH": "output/missing_items.xlsx",
    "CONFIG_PATH": "config/ui_config.json",
    "PARAMETER_PATH": "data/parameters.xlsx",
    "MASTER_CSV_OUTPUT": "temp_master_csv"
}

def default_config() -> Dict:
    return {
        "paths": DEFAULT_PATHS.copy(),
        "erp_grid": {"columns": [], "filters": {}},
        "master_grid": {"columns": [], "filters": {}},
        "comparison_option": 2
    }

def load_config(path: Path) -> Dict:
    if path.is_file():
        try:
            with open(path, "r", encoding="utf-8") as f:
                return json.load(f)
        except Exception as e:
            logging.warning(f"Could not load config: {e}")
    return default_config()

def save_config(cfg: Dict, path: Path):
    path.parent.mkdir(parents=True, exist_ok=True)
    try:
        with open(path, "w", encoding="utf-8") as f:
            json.dump(cfg, f, indent=2)
        logging.info(f"Saved config to {path}")
    except Exception as e:
        logging.error(f"Error saving config: {e}")

# ---------------- TEXT LOGGER HANDLER ----------------
class TextHandler(logging.Handler):
    def __init__(self, widget: ctk.CTkTextbox):
        super().__init__()
        self.widget = widget
    def emit(self, record):
        msg = self.format(record) + "\n"
        self.widget.after(0, self._append, msg)
    def _append(self, msg):
        self.widget.configure(state="normal")
        self.widget.insert("end", msg)
        self.widget.see("end")
        self.widget.configure(state="disabled")

# ---------------- PARAMETER FILE ----------------
def read_parameter_file(path: Path) -> Dict[str, object]:
    """
    Expects an Excel with columns like:
      FileName, Dimension, ERP Values, V S C, ...
    We'll parse:
      param["erp_vsc_map"]: { originalVSC => finalDimension }
      param["erp_vsc_keep"]: set of originalVSC to keep (ERP Values=='x')
      param["master_file_map"]: { fileName => finalDimension }
    """
    param = {
        "erp_vsc_map": {},
        "erp_vsc_keep": set(),
        "master_file_map": {}
    }
    if not path.is_file():
        logging.warning(f"Parameter file not found: {path}")
        return param

    try:
        dfp = pd.read_excel(path, sheet_name=0)
        dfp.columns = dfp.columns.astype(str).str.strip()

        def s(x):
            return str(x).strip() if pd.notna(x) else ""

        for _, row in dfp.iterrows():
            file_ = s(row.get("FileName", ""))
            dim_ = s(row.get("Dimension", ""))
            erp_vsc = s(row.get("V S C", ""))
            erp_vals = s(row.get("ERP Values", ""))

            # fill param
            if file_ and dim_:
                param["master_file_map"][file_] = dim_
            if erp_vsc and dim_:
                param["erp_vsc_map"][erp_vsc] = dim_
            if erp_vsc and erp_vals.lower() == "x":
                param["erp_vsc_keep"].add(erp_vsc)
        return param
    except Exception as e:
        logging.error(f"Error reading parameter file: {e}")
        return param

# ---------------- ERP READING ----------------
def read_erp_enabled(path: Path) -> pd.DataFrame:
    if not path.is_file():
        logging.warning(f"ERP Excel not found: {path}")
        return pd.DataFrame()
    try:
        df = pd.read_excel(path, skiprows=3)
        df.columns = df.columns.str.strip()
        if "Enabled_Flag" in df.columns:
            df = df[df["Enabled_Flag"] == "Enabled"]
        return df
    except Exception as e:
        logging.error(f"Error reading ERP: {e}")
        return pd.DataFrame()

# ---------------- MASTER READING => robust .txt => CSV => unify ----------------
def read_txt_robust_in_memory(raw: bytes) -> pd.DataFrame:
    # Big list of encodings to try
    codecs_to_try = [
        'ascii','big5','big5hkscs','cp037','cp273','cp424','cp437','cp500','cp720','cp737','cp775',
        'cp850','cp852','cp855','cp856','cp857','cp858','cp860','cp861','cp862','cp863','cp864','cp865','cp866',
        'cp869','cp874','cp875','cp932','cp949','cp950','cp1006','cp1026','cp1125','cp1140','cp1250','cp1251','cp1252',
        'cp1253','cp1254','cp1255','cp1256','cp1257','cp1258','euc_jp','euc_jis_2004','euc_jisx0213','euc_kr',
        'gb2312','gbk','gb18030','hz','iso2022_jp','iso2022_jp_1','iso2022_jp_2','iso2022_jp_2004','iso2022_jp_3',
        'iso2022_jp_ext','iso2022_kr','latin_1','iso8859_2','iso8859_3','iso8859_4','iso8859_5','iso8859_6','iso8859_7',
        'iso8859_8','iso8859_9','iso8859_10','iso8859_11','iso8859_13','iso8859_14','iso8859_15','iso8859_16','johab',
        'koi8_r','koi8_t','koi8_u','kz1048','mac_cyrillic','mac_greek','mac_iceland','mac_latin2','mac_roman',
        'mac_turkish','ptcp154','shift_jis','shift_jis_2004','shift_jisx0213','utf_32','utf_32_be','utf_32_le',
        'utf_16','utf_16_be','utf_16_le','utf_7','utf_8','utf_8_sig'
    ]
    for enc in codecs_to_try:
        try:
            buf = io.BytesIO(raw)
            df = pd.read_csv(buf, encoding=enc, on_bad_lines="skip", engine="python")
            df.dropna(how="all", axis=0, inplace=True)
            df.dropna(how="all", axis=1, inplace=True)
            df.columns = df.columns.astype(str).str.strip()
            return df
        except:
            continue
    logging.error("Could not parse .txt with any known encoding.")
    return pd.DataFrame()

def convert_master_txt_to_csv(zip_path: Path, out_dir: Path) -> List[Path]:
    if out_dir.exists():
        shutil.rmtree(out_dir, ignore_errors=True)
    out_dir.mkdir(parents=True, exist_ok=True)
    csvs = []
    if not zip_path.is_file():
        logging.warning(f"[Master] ZIP not found: {zip_path}")
        return csvs
    with zipfile.ZipFile(zip_path, "r") as z:
        txt_files = [f for f in z.namelist() if f.lower().endswith(".txt")]
        for txt_file in txt_files:
            base_name = os.path.basename(txt_file)
            if not base_name:
                continue
            try:
                with z.open(txt_file) as fo:
                    raw = fo.read()
                if not raw:
                    continue
                df = read_txt_robust_in_memory(raw)
                df.columns = df.columns.str.strip()
                df["RawFileName"] = base_name
                if "Name" not in df.columns and len(df.columns) > 0:
                    firstcol = df.columns[0]
                    df.rename(columns={firstcol: "Name"}, inplace=True)
                out_csv = out_dir / base_name.replace(".txt", ".csv")
                df.to_csv(out_csv, index=False, encoding="utf-8")
                csvs.append(out_csv)
            except Exception as e:
                logging.error(f"[Master] Error processing {txt_file}: {e}")
    return csvs

def unify_master_csvs(csvs: List[Path]) -> pd.DataFrame:
    frames = []
    for cp in csvs:
        if not cp.is_file():
            continue
        try:
            df = pd.read_csv(cp, encoding="utf-8", on_bad_lines="skip")
            df.columns = df.columns.str.strip()
            frames.append(df)
        except Exception as e:
            logging.error(f"[Master unify] Error reading {cp}: {e}")
    if frames:
        return pd.concat(frames, ignore_index=True)
    return pd.DataFrame()

# ---------------- MELTDOWN FOR ERP & MASTER ----------------
def meltdown_erp(df: pd.DataFrame, param: Dict[str,object]) -> pd.DataFrame:
    # param keys: "erp_vsc_map" {original->final}, "erp_vsc_keep", ...
    if "V S C" not in df.columns:
        logging.warning("[ERP meltdown] 'V S C' not found => empty.")
        return pd.DataFrame()
    keep = param.get("erp_vsc_keep", set())
    vsc_map = param.get("erp_vsc_map", {})
    df2 = df[df["V S C"].isin(keep)].copy()
    if df2.empty:
        return pd.DataFrame()
    # skip "Enabled_Flag"
    skip_cols = {"V S C","Enabled_Flag"}
    id_vars = []
    # if "Value" is present => Name
    if "Value" in df2.columns:
        id_vars.append("Value")
        skip_cols.add("Value")
    df2["DimRaw"] = df2["V S C"]
    skip_cols.add("DimRaw")

    meltdown_cols = [c for c in df2.columns if c not in skip_cols]
    m = df2.melt(id_vars=["DimRaw"]+ (["Value"] if "Value" in df2.columns else []),
                 value_vars=meltdown_cols, var_name="Attribute", value_name="ValX")
    # rename dimension
    def rename_dim(x):
        return vsc_map[x] if x in vsc_map else x

    m["Dimension"] = m["DimRaw"].apply(rename_dim)
    m.rename(columns={"Value":"RefName"}, inplace=True)
    # strip T if attribute => Start/End date
    def strip_t(val):
        if isinstance(val,str) and "T" in val:
            return val.split("T")[0]
        return val
    m["Value"] = np.where(m["Attribute"].isin(["Start Date","End Date"]),
                          m["ValX"].apply(strip_t),
                          m["ValX"])
    return m[["Dimension","RefName","Attribute","Value"]].copy()

def meltdown_master(df: pd.DataFrame, param: Dict[str,object]) -> pd.DataFrame:
    if df.empty or "RawFileName" not in df.columns:
        logging.warning("[Master meltdown] either empty or missing 'RawFileName'.")
        return pd.DataFrame()
    file_map = param.get("master_file_map", {})
    # rename dimension from "RawFileName" => param
    def rename_dim(fn):
        return file_map[fn] if fn in file_map else fn

    df2 = df.copy()
    df2["Dimension"] = df2["RawFileName"].apply(rename_dim)
    skip_cols = {"RawFileName","Dimension"}
    if "Name" in df2.columns:
        skip_cols.add("Name")
    meltdown_cols = [c for c in df2.columns if c not in skip_cols]

    m = df2.melt(id_vars=["Dimension","Name"], value_vars=meltdown_cols, var_name="Attribute", value_name="ValX")
    def strip_t(val):
        if isinstance(val,str) and "T" in val:
            return val.split("T")[0]
        return val
    m["Value"] = np.where(m["Attribute"].isin(["Start Date","End Date"]),
                          m["ValX"].apply(strip_t),
                          m["ValX"])
    m.rename(columns={"Name":"RefName"}, inplace=True)
    return m[["Dimension","RefName","Attribute","Value"]].copy()

def build_keys(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    for c in ["Dimension","RefName","Attribute","Value"]:
        if c not in df.columns:
            df[c] = ""
        df[c] = df[c].fillna("").astype(str).str.strip()
    df["GroupKey"] = df["Dimension"] + " | " + df["RefName"]
    df["Key"] = df["Dimension"] + " | " + df["RefName"] + " | " + df["Attribute"] + " | " + df["Value"]
    df["Comments_1"] = ""
    df["Comments_2"] = ""
    df["Action Item"] = ""
    df["Missing In"] = ""
    return df

def build_lookup_dict(df: pd.DataFrame) -> Dict[str, Dict[str,str]]:
    out = {}
    for gk, grp in df.groupby("GroupKey"):
        rec = {}
        name_ = grp["RefName"].iloc[0] if not grp.empty else ""
        rec["Name"] = name_
        for _, row in grp.iterrows():
            rec[row["Attribute"]] = row["Value"]
        out[gk] = rec
    return out

def compare_mode2(df_erp: pd.DataFrame, df_mast: pd.DataFrame) -> pd.DataFrame:
    e_dict = build_lookup_dict(df_erp)
    m_dict = build_lookup_dict(df_mast)
    all_keys = set(e_dict.keys()) | set(m_dict.keys())
    results = []
    for gk in all_keys:
        dim = gk.split(" | ")[0]
        a_data = e_dict.get(gk, {})
        b_data = m_dict.get(gk, {})
        name_a = a_data.get("Name","") or a_data.get("RefName","")
        name_b = b_data.get("Name","") or b_data.get("RefName","")
        if name_a and name_b and name_a == name_b:
            all_attrs = (set(a_data.keys()) | set(b_data.keys())) - {"Name","RefName"}
            for at in all_attrs:
                va = a_data.get(at,"")
                vb = b_data.get(at,"")
                if va != vb:
                    if va and not vb:
                        results.append({"Dimension":dim,"Name":name_a,"Attribute":at,"Value":va,"Missing In":"MASTER"})
                    elif vb and not va:
                        results.append({"Dimension":dim,"Name":name_a,"Attribute":at,"Value":vb,"Missing In":"ERP"})
                    else:
                        results.append({"Dimension":dim,"Name":name_a,"Attribute":at,"Value":va,"Missing In":"MASTER"})
                        results.append({"Dimension":dim,"Name":name_a,"Attribute":at,"Value":vb,"Missing In":"ERP"})
        else:
            if name_a and not name_b:
                results.append({"Dimension":dim,"Name":name_a,"Attribute":"Name","Value":name_a,"Missing In":"MASTER"})
            elif name_b and not name_a:
                results.append({"Dimension":dim,"Name":name_b,"Attribute":"Name","Value":name_b,"Missing In":"ERP"})
    df = pd.DataFrame(results)
    if not df.empty:
        df["Key"] = (df["Dimension"].str.strip()+" | "+
                     df["Name"].str.strip()+" | "+
                     df["Attribute"].str.strip()+" | "+
                     df["Value"].str.strip())
    return df

# ---------------- EXCEPTIONS & WRITE RESULTS ----------------
def read_exception_table(path: Path) -> pd.DataFrame:
    if not path.is_file():
        logging.warning(f"Exception table not found: {path}")
        return pd.DataFrame()
    try:
        dfx = pd.read_excel(path)
        dfx.columns = dfx.columns.astype(str).str.strip()
        return dfx
    except Exception as e:
        logging.error(f"Error reading exception table: {e}")
        return pd.DataFrame()

def merge_exceptions(df: pd.DataFrame, df_exc: pd.DataFrame) -> pd.DataFrame:
    if df.empty or df_exc.empty or "Key" not in df.columns:
        return df
    keep = [c for c in df_exc.columns if c in ["Key","Comments_1","Comments_2","hide exception"]]
    if not keep:
        return df
    exc = df_exc[keep].copy()
    exc["Key"] = exc["Key"].astype(str).str.strip()

    merged = df.merge(exc, on="Key", how="left", suffixes=("","_exc"))
    merged["hide exception"] = merged.get("hide exception","").fillna("").str.lower()
    final = merged[merged["hide exception"]!="yes"].copy()
    if "Comments_1_exc" in final.columns:
        final["Comments_1"] = np.where(final["Comments_1_exc"].notna(),
                                       final["Comments_1_exc"],
                                       final["Comments_1"])
        final.drop(columns=["Comments_1_exc"], inplace=True)
    if "Comments_2_exc" in final.columns:
        final["Comments_2"] = np.where(final["Comments_2_exc"].notna(),
                                       final["Comments_2_exc"],
                                       final["Comments_2"])
        final.drop(columns=["Comments_2_exc"], inplace=True)
    if "hide exception" in final.columns:
        final.drop(columns=["hide exception"], inplace=True)
    return final

def write_results(df: pd.DataFrame, out_path: Path):
    if df.empty:
        logging.info("No differences => skip writing missing_items.")
        return
    out_path.parent.mkdir(parents=True, exist_ok=True)
    final_cols = ["Key","Dimension","Name","Attribute","Value","Comments_1","Comments_2","Action Item","Missing In"]
    for c in final_cols:
        if c not in df.columns:
            df[c] = ""
    df = df[final_cols]

    wb = Workbook()
    ws = wb.active
    ws.title = "Missing Items"
    ws.append(final_cols)
    for rowvals in df.itertuples(index=False):
        ws.append(rowvals)
    header_font = Font(bold=True)
    fill = PatternFill(start_color="DDDDDD", end_color="DDDDDD", fill_type="solid")
    for cell in ws[1]:
        cell.font = header_font
        cell.fill = fill
        cell.alignment = Alignment(horizontal="center")
    for col in ws.columns:
        max_len= 0
        col_letter= col[0].column_letter
        for cell in col:
            val = str(cell.value) if cell.value else ""
            max_len= max(max_len, len(val))
        ws.column_dimensions[col_letter].width= max_len+2
    ws.freeze_panes= "A2"
    wb.save(out_path)
    logging.info(f"Missing Items => {out_path}")

# ---------------- Dashboard (8 charts) ----------------
class Dashboard(ctk.CTkFrame):
    def __init__(self, parent):
        super().__init__(parent)
        self.df_current = pd.DataFrame()
        self.df_history = pd.DataFrame()
        # Additional filtering variables if needed
        topbar = ctk.CTkFrame(self)
        topbar.pack(fill="x", padx=5, pady=5)

        # Example controls: "Show Today's Run"
        ctk.CTkButton(topbar, text="Show Today's Run", command=self.show_today).pack(side="left", padx=5)

        # Notebook for charts
        self.notebook = ttk.Notebook(self)
        self.notebook.pack(fill="both", expand=True)

        # 8 frames
        self.frames = {}
        clabs = ["Heatmap","Lollipop","Circular","Scatter","Radar","Normal Pie","Normal Bar","Band Chart"]
        for c_ in clabs:
            f = ctk.CTkFrame(self.notebook)
            self.notebook.add(f, text=c_)
            self.frames[c_] = f

    def show_today(self):
        # If "RunDate" in self.df_history
        if self.df_history.empty or "RunDate" not in self.df_history.columns:
            messagebox.showinfo("Note","No run data or 'RunDate' missing.")
            return
        today_str = datetime.now().strftime("%Y-%m-%d")
        df_tod = self.df_history[self.df_history["RunDate"]== today_str]
        if df_tod.empty:
            messagebox.showinfo("Note","No run for today.")
        else:
            self.update_data(df_tod, self.df_history)

    def update_data(self, df_current: pd.DataFrame, df_history: pd.DataFrame):
        self.df_current = df_current.copy()
        self.df_history = df_history.copy()
        self.plotHeatmap()
        self.plotLollipop()
        self.plotCircular()
        self.plotScatter()
        self.plotRadar()
        self.plotNormalPie()
        self.plotNormalBar()
        self.plotBandChart()

    def plot_chart(self, frame, fig):
        for w in frame.winfo_children():
            w.destroy()
        canvas = FigureCanvasTkAgg(fig, master=frame)
        canvas.draw()
        canvas.get_tk_widget().pack(fill="both", expand=True)

    def plotHeatmap(self):
        frame = self.frames["Heatmap"]
        df_m = self.df_current[self.df_current["Missing In"]!=""]
        if df_m.empty:
            return
        pivoted = df_m.groupby(["Dimension","Attribute"]).size().unstack(fill_value=0)
        fig, ax = plt.subplots(figsize=(6,5))
        cax= ax.imshow(pivoted, aspect="auto", cmap="Reds")
        ax.set_xticks(range(len(pivoted.columns)))
        ax.set_xticklabels(pivoted.columns, rotation=90)
        ax.set_yticks(range(len(pivoted.index)))
        ax.set_yticklabels(pivoted.index)
        fig.colorbar(cax, ax=ax)
        ax.set_title("Heatmap: Missing Items")
        self.plot_chart(frame, fig)

    def plotLollipop(self):
        frame= self.frames["Lollipop"]
        df_m= self.df_current[self.df_current["Missing In"]!=""]
        if df_m.empty:
            return
        cdim= df_m.groupby("Dimension")["Key"].count().sort_values(ascending=False).head(10)
        if cdim.empty:
            return
        fig, ax= plt.subplots(figsize=(6,5))
        ax.hlines(y=cdim.index, xmin=0, xmax=cdim.values, color="skyblue")
        ax.plot(cdim.values, cdim.index, "o", color="skyblue")
        ax.set_title("Lollipop: Missing Dimensions")
        ax.set_xlabel("Missing Count")
        self.plot_chart(frame, fig)

    def plotCircular(self):
        frame= self.frames["Circular"]
        df_m= self.df_current[self.df_current["Missing In"]!=""]
        if df_m.empty:
            return
        cattr= df_m.groupby("Attribute")["Key"].count().sort_values(ascending=False).head(10)
        if cattr.empty:
            return
        cats= cattr.index.tolist()
        vals= cattr.values
        angles= np.linspace(0, 2*np.pi, len(cats), endpoint=False)
        fig= plt.figure(figsize=(6,6))
        ax= fig.add_subplot(111, polar=True)
        ax.set_theta_offset(np.pi/2)
        ax.set_theta_direction(-1)
        ax.set_xticks(angles)
        ax.set_xticklabels(cats, fontsize=9)
        ax.bar(angles, vals, width=0.4, color="orange", alpha=0.6)
        ax.set_title("Circular Barplot: Missing Attributes", y=1.05)
        self.plot_chart(frame, fig)

    def plotScatter(self):
        frame= self.frames["Scatter"]
        df_m= self.df_current[self.df_current["Missing In"]!=""]
        if df_m.empty:
            return
        cdim= df_m.groupby("Dimension")["Key"].count().reset_index(name="Count")
        cdim.sort_values("Count", ascending=False, inplace=True)
        if cdim.empty:
            return
        xvals= np.arange(len(cdim))
        yvals= cdim["Count"].values
        labels= cdim["Dimension"].values
        fig, ax= plt.subplots(figsize=(6,5))
        ax.scatter(xvals, yvals, color="green")
        for i, txt in enumerate(labels):
            ax.text(xvals[i], yvals[i], txt, ha="center", va="bottom", rotation=60)
        ax.set_xticks([])
        ax.set_ylabel("Missing Count")
        ax.set_title("Scatter: Missing by Dimension")
        self.plot_chart(frame, fig)

    def plotRadar(self):
        frame= self.frames["Radar"]
        df_m= self.df_current[self.df_current["Missing In"]!=""]
        if df_m.empty:
            return
        cdim= df_m.groupby("Dimension")["Key"].count().sort_values(ascending=False).head(5)
        if cdim.empty:
            return
        cats= cdim.index.tolist()
        vals= cdim.values.tolist()
        N= len(cats)
        angles= np.linspace(0,2*np.pi,N,endpoint=False).tolist()
        angles+= angles[:1]
        vals+= vals[:1]
        fig= plt.figure(figsize=(6,6))
        ax= fig.add_subplot(111, polar=True)
        ax.set_theta_offset(np.pi/2)
        ax.set_theta_direction(-1)
        ax.set_xticks(angles[:-1])
        ax.set_xticklabels(cats, fontsize=9)
        ax.plot(angles, vals, color="red", linewidth=2)
        ax.fill(angles, vals, color="red", alpha=0.3)
        ax.set_title("Radar: Top 5 Missing Dimensions", y=1.08)
        self.plot_chart(frame, fig)

    def plotNormalPie(self):
        frame= self.frames["Normal Pie"]
        df_m= self.df_current[self.df_current["Missing In"]!=""]
        if df_m.empty:
            return
        dist= df_m["Missing In"].value_counts()
        fig, ax= plt.subplots(figsize=(5,5))
        ax.pie(dist.values, labels=dist.index, autopct="%.1f%%", startangle=140)
        ax.set_title("Pie: Missing In Distribution")
        self.plot_chart(frame, fig)

    def plotNormalBar(self):
        frame= self.frames["Normal Bar"]
        df_m= self.df_current[self.df_current["Missing In"]!=""]
        if df_m.empty:
            return
        cattr= df_m.groupby("Attribute")["Key"].count().sort_values(ascending=False).head(10)
        fig, ax= plt.subplots(figsize=(6,4))
        cattr.plot(kind="bar", ax=ax, color="blue")
        ax.set_ylabel("Missing Count")
        ax.set_title("Bar: Top 10 Missing Attributes")
        self.plot_chart(frame, fig)

    def plotBandChart(self):
        frame= self.frames["Band Chart"]
        df_m= self.df_history
        if df_m.empty or "RunDate" not in df_m.columns:
            return
        date_counts= df_m.groupby("RunDate")["Key"].count().reset_index(name="Count")
        date_counts.sort_values("RunDate", inplace=True)
        date_counts["Count_min"]= date_counts["Count"]*0.9
        date_counts["Count_max"]= date_counts["Count"]*1.1
        fig, ax= plt.subplots(figsize=(6,4))
        ax.plot(date_counts["RunDate"], date_counts["Count"], color="purple", marker="o", label="Missing Count")
        ax.fill_between(date_counts["RunDate"], date_counts["Count_min"], date_counts["Count_max"],
                        color="purple", alpha=0.2, label="±10% band")
        ax.set_title("Band Chart Over Days")
        ax.set_xlabel("RunDate")
        ax.set_ylabel("Missing Count")
        plt.xticks(rotation=45)
        ax.legend()
        for i, row in date_counts.iterrows():
            ax.text(row["RunDate"], row["Count"], str(row["Count"]), ha="center", va="bottom")
        self.plot_chart(frame, fig)

# ---------------- EXCELGRID (only Start/End Date filterable) ----------------
class ExcelGrid(ctk.CTkFrame):
    FILTERABLE_COLS = {"Start Date", "End Date"}
    def __init__(self, parent, config_block: Dict, name: str):
        super().__init__(parent)
        self.name = name
        self.df = pd.DataFrame()
        self.col_defs = config_block.get("columns", [])
        self.filters: Dict[str, Set] = {k: set(v) for k, v in config_block.get("filters", {}).items()}
        self.create_toolbar()
        self.create_table()
        self.create_statusbar()

    def create_toolbar(self):
        tb = ctk.CTkFrame(self, corner_radius=10, fg_color="#f0f0f0")
        tb.pack(fill="x", padx=5, pady=5)
        ctk.CTkButton(tb, text="Manage Columns", command=self.show_column_manager,
                      fg_color="#800020", hover_color="#a52a2a", cursor="hand2").pack(side="left", padx=5)
        ctk.CTkButton(tb, text="Clear Filters", command=self.clear_filters,
                      fg_color="#800020", hover_color="#a52a2a", cursor="hand2").pack(side="left", padx=5)

    def create_table(self):
        container = ctk.CTkFrame(self)
        container.pack(fill="both", expand=True, padx=5, pady=5)

        self.tree = ttk.Treeview(container, show="headings")
        vsb = ttk.Scrollbar(container, orient="vertical", command=self.tree.yview)
        hsb = ttk.Scrollbar(container, orient="horizontal", command=self.tree.xview)
        self.tree.configure(yscrollcommand=vsb.set, xscrollcommand=hsb.set)
        self.tree.grid(row=0, column=0, sticky="nsew")
        vsb.grid(row=0, column=1, sticky="ns")
        hsb.grid(row=1, column=0, sticky="ew")

        container.rowconfigure(0, weight=1)
        container.columnconfigure(0, weight=1)

    def create_statusbar(self):
        self.status_label = ctk.CTkLabel(self, text="Ready")
        self.status_label.pack(fill="x")

    def set_data(self, df: pd.DataFrame):
        """
        Remove duplicates [Dimension,Name,Attribute] if present, then pivot if 'Attribute' is in columns.
        """
        self.df = df.copy(deep=True)
        # remove duplicates
        if not self.df.empty and {"Dimension","RefName","Attribute"}.issubset(self.df.columns):
            self.df.drop_duplicates(subset=["Dimension","RefName","Attribute"], inplace=True)

        # if we see "Attribute" => pivot => wide
        if not self.df.empty and "Attribute" in self.df.columns:
            try:
                self.df = self.df.pivot(index=["Dimension","RefName"], columns="Attribute", values="Value").reset_index()
            except Exception as e:
                logging.error(f"Error pivoting data for {self.name}: {e}")

        # ensure col_defs updated
        existing_ids = [c["id"] for c in self.col_defs]
        for col in self.df.columns:
            if col not in existing_ids:
                self.col_defs.append({
                    "id": col,
                    "name": col,
                    "locked": False,
                    "visible": True,
                    "renameable": True
                })
        self.refresh_table()

    def get_config_block(self)-> Dict:
        return {
            "columns": self.col_defs,
            "filters": {cid: sorted(list(vals)) for cid, vals in self.filters.items()}
        }

    def get_filtered_df(self)-> pd.DataFrame:
        if self.df.empty:
            return self.df
        df_f = self.df.copy()

        def passes(x, allowed):
            if pd.isna(x):
                return any(pd.isna(a) for a in allowed)
            else:
                return x in allowed

        for col_id, allowed_vals in self.filters.items():
            if col_id in df_f.columns and allowed_vals:
                df_f = df_f[df_f[col_id].apply(lambda z: passes(z, allowed_vals))]

        # figure out visible columns
        vis_ids = [c["id"] for c in self.col_defs if c.get("visible", True)]
        vis_ids = [c for c in vis_ids if c in df_f.columns]
        return df_f[vis_ids]

    def refresh_table(self):
        for item in self.tree.get_children():
            self.tree.delete(item)

        visible_cols= [c for c in self.col_defs if c.get("visible",True)]
        self.tree["columns"]= [c["id"] for c in visible_cols]

        for col_def in visible_cols:
            col_txt= col_def["name"]
            if col_def.get("locked",False):
                col_txt+=" \U0001F512"
            self.tree.heading(col_def["id"],
                              text=col_txt,
                              anchor="w",
                              command=lambda c=col_def: self.on_heading_click(c))
            self.tree.column(col_def["id"], anchor="w", width=150)

        df_f= self.get_filtered_df()
        for _, row in df_f.iterrows():
            rowvals= [row[c["id"]] if c["id"] in df_f.columns else "" for c in visible_cols]
            self.tree.insert("", "end", values=rowvals)
        self.status_label.configure(text=f"{len(df_f)} rows")

    def on_heading_click(self, col_def: Dict):
        # only show filter if col_def["name"] in FILTERABLE_COLS
        if col_def["name"] in self.FILTERABLE_COLS:
            self.show_filter_popup(col_def)
        else:
            pass  # no filter popup

    def show_filter_popup(self, col_def: Dict):
        col_id = col_def["id"]
        if self.df.empty or col_id not in self.df.columns:
            return
        popup = tk.Toplevel(self)
        popup.title(f"Filter: {col_def['name']}")
        popup.geometry("300x400")
        frame = ctk.CTkFrame(popup)
        frame.pack(fill="both", expand=True, padx=5, pady=5)

        unique_vals = self.df[col_id].unique()
        display_map = {}
        for v in unique_vals:
            if pd.isna(v):
                dsp = "(NaN)"
            elif isinstance(v,str) and not v.strip():
                dsp= "(blank)"
            else:
                dsp= str(v)
            display_map[v] = dsp

        sorted_vals = sorted(display_map.keys(), key=lambda x: display_map[x].lower())
        curr_filter = self.filters.get(col_id, set(unique_vals))
        if not curr_filter:
            curr_filter = set(unique_vals)

        select_all_var= tk.BooleanVar(value=True)
        def toggle_all():
            check= select_all_var.get()
            for vb in var_dict.values():
                vb.set(check)

        ctk.CTkCheckBox(frame, text="Select All", variable=select_all_var, command=toggle_all,
                        fg_color="#800020", hover_color="#a52a2a", cursor="hand2").pack(anchor="w", pady=5)

        scroll= ctk.CTkScrollableFrame(frame, width=250, height=250)
        scroll.pack(fill="both", expand=True, padx=5, pady=5)

        var_dict={}
        for rv in sorted_vals:
            if pd.isna(rv):
                in_filter = any(pd.isna(a) for a in curr_filter)
            else:
                in_filter = (rv in curr_filter)
            bvar= tk.BooleanVar(value=in_filter)
            var_dict[rv] = bvar
            ctk.CTkCheckBox(scroll, text=display_map[rv], variable=bvar,
                            fg_color="#800020", hover_color="#a52a2a", cursor="hand2").pack(anchor="w")

        def apply_():
            sel= set(rv for rv, vb in var_dict.items() if vb.get())
            self.filters[col_id]= sel
            popup.destroy()
            self.refresh_table()

        bf= ctk.CTkFrame(frame)
        bf.pack(fill="x", pady=5)
        ctk.CTkButton(bf, text="Apply", command=apply_,
                      fg_color="#800020", hover_color="#a52a2a", cursor="hand2").pack(side="left", padx=5)
        ctk.CTkButton(bf, text="Cancel", command=popup.destroy,
                      fg_color="#800020", hover_color="#a52a2a", cursor="hand2").pack(side="left", padx=5)

    def show_column_manager(self):
        cm= tk.Toplevel(self)
        cm.title(f"{self.name} Column Manager")
        scrolled= ctk.CTkScrollableFrame(cm, width=600, height=500)
        scrolled.pack(fill="both", expand=True)

        for i, col_def in enumerate(self.col_defs):
            rowf= ctk.CTkFrame(scrolled)
            rowf.pack(fill="x", pady=2)

            if col_def.get("locked",False):
                txt= col_def["name"]+" \U0001F512"
                ctk.CTkLabel(rowf, text=txt).pack(side="left", padx=5)
                continue

            var_vis= tk.BooleanVar(value= col_def.get("visible",True))
            def toggler(c=col_def,v=var_vis):
                c["visible"]= v.get()
                self.refresh_table()
            ctk.CTkCheckBox(rowf, text="", variable=var_vis, command=toggler).pack(side="left")

            if col_def.get("renameable",True):
                ctk.CTkButton(rowf, text=col_def["name"], command=lambda c=col_def: self.rename_column(c)).pack(side="left", padx=5)
            else:
                ctk.CTkLabel(rowf, text=col_def["name"]).pack(side="left", padx=5)

            ctk.CTkButton(rowf, text="↑", width=30, command=lambda idx=i:self.move_column(idx,-1)).pack(side="right", padx=2)
            ctk.CTkButton(rowf, text="↓", width=30, command=lambda idx=i:self.move_column(idx,1)).pack(side="right", padx=2)

    def rename_column(self, col_def: Dict):
        old_name= col_def["name"]
        new_name= simpledialog.askstring("Rename Column", f"New name for {old_name}:", initialvalue=old_name)
        if new_name:
            col_def["name"]= new_name
            self.refresh_table()

    def move_column(self, idx: int, delta: int):
        new_idx= idx+ delta
        if 0 <= new_idx< len(self.col_defs):
            self.col_defs[idx], self.col_defs[new_idx]= self.col_defs[new_idx], self.col_defs[idx]
            self.refresh_table()

    def clear_filters(self):
        self.filters.clear()
        self.refresh_table()

# ---------------- MAIN APP ----------------
class MainApp(ctk.CTk):
    def __init__(self):
        super().__init__()
        self.title("Ultra-Mega Reconciliation: Mode=2, Param-based (V S C for ERP, FileName for Master)")
        self.geometry("1600x900")
        ctk.set_appearance_mode("light")

        self.config_dict = load_config(Path(DEFAULT_PATHS["CONFIG_PATH"]))
        self.history_df = pd.DataFrame()

        # read param
        self.param_dict = read_parameter_file(Path(self.config_dict["paths"].get("PARAMETER_PATH", DEFAULT_PATHS["PARAMETER_PATH"])))

        self.notebook= ttk.Notebook(self)
        self.notebook.pack(fill="both", expand=True)

        # 1) Paths
        self.tab_paths= ctk.CTkFrame(self.notebook)
        self.notebook.add(self.tab_paths, text="Paths")
        self.build_paths_tab(self.tab_paths)

        # 2) ERP
        self.tab_erp= ctk.CTkFrame(self.notebook)
        self.notebook.add(self.tab_erp, text="ERP")
        self.erp_grid= ExcelGrid(self.tab_erp, self.config_dict.get("erp_grid",{}), "ERP")
        self.erp_grid.pack(fill="both", expand=True)

        # 3) Master
        self.tab_master= ctk.CTkFrame(self.notebook)
        self.notebook.add(self.tab_master, text="Master")
        self.master_grid= ExcelGrid(self.tab_master, self.config_dict.get("master_grid",{}), "Master")
        self.master_grid.pack(fill="both", expand=True)

        # 4) Compare
        self.tab_compare= ctk.CTkFrame(self.notebook)
        self.notebook.add(self.tab_compare, text="Compare")
        self.build_compare_tab(self.tab_compare)

        # 5) Dashboard
        self.tab_dashboard= Dashboard(self.notebook)
        self.notebook.add(self.tab_dashboard, text="Dashboard")

        # Logging
        self.log_box= ctk.CTkTextbox(self, height=120)
        self.log_box.pack(fill="both", expand=False)
        self.log_box.configure(state="disabled")
        handler= TextHandler(self.log_box)
        handler.setLevel(logging.INFO)
        logging.getLogger().addHandler(handler)

        # Master CSV folder
        self.temp_csv_dir= Path(self.config_dict["paths"].get("MASTER_CSV_OUTPUT", DEFAULT_PATHS["MASTER_CSV_OUTPUT"]))
        self.temp_csv_dir.mkdir(exist_ok=True)

        self.refresh_erp_data()
        self.refresh_master_data()

    def build_paths_tab(self, parent):
        frm= ctk.CTkFrame(parent)
        frm.pack(fill="both", expand=True, padx=10, pady=10)
        self.erp_var= tk.StringVar(value=self.config_dict["paths"].get("ERP_EXCEL_PATH", DEFAULT_PATHS["ERP_EXCEL_PATH"]))
        self.mst_var= tk.StringVar(value=self.config_dict["paths"].get("MASTER_ZIP_PATH", DEFAULT_PATHS["MASTER_ZIP_PATH"]))
        self.exc_var= tk.StringVar(value=self.config_dict["paths"].get("EXCEPTION_PATH", DEFAULT_PATHS["EXCEPTION_PATH"]))
        self.out_var= tk.StringVar(value=self.config_dict["paths"].get("OUTPUT_PATH", DEFAULT_PATHS["OUTPUT_PATH"]))
        self.cfg_var= tk.StringVar(value=self.config_dict["paths"].get("CONFIG_PATH", DEFAULT_PATHS["CONFIG_PATH"]))
        self.par_var= tk.StringVar(value=self.config_dict["paths"].get("PARAMETER_PATH", DEFAULT_PATHS["PARAMETER_PATH"]))
        self.csv_var= tk.StringVar(value=self.config_dict["paths"].get("MASTER_CSV_OUTPUT", DEFAULT_PATHS["MASTER_CSV_OUTPUT"]))

        def mkrow(lbl,var,is_dir=False):
            rowf= ctk.CTkFrame(frm)
            rowf.pack(fill="x", pady=5)
            ctk.CTkLabel(rowf, text=lbl, width=180).pack(side="left", padx=5)
            e= ctk.CTkEntry(rowf, textvariable=var, width=600)
            e.pack(side="left", padx=5)
            def br():
                if is_dir:
                    p= filedialog.askdirectory()
                else:
                    p= filedialog.askopenfilename()
                if p:
                    var.set(p)
            ctk.CTkButton(rowf, text="Browse", command=br,
                          fg_color="#800020", hover_color="#a52a2a", cursor="hand2").pack(side="left", padx=5)

        mkrow("ERP Excel Path:", self.erp_var)
        mkrow("Master ZIP Path:", self.mst_var)
        mkrow("Exception Path:", self.exc_var)
        mkrow("Output XLSX Path:", self.out_var)
        mkrow("JSON Config Path:", self.cfg_var)
        mkrow("Parameter File Path:", self.par_var)
        mkrow("Master CSV Folder:", self.csv_var, is_dir=True)

    def build_compare_tab(self, parent):
        frm= ctk.CTkFrame(parent)
        frm.pack(fill="both", expand=True, padx=10, pady=10)
        ctk.CTkLabel(frm, text="Mode=2 Comparison", font=("Arial",16)).pack(pady=5)
        btnf= ctk.CTkFrame(frm)
        btnf.pack(fill="x", pady=5)
        ctk.CTkButton(btnf, text="Run Comparison", command=self.run_comparison,
                      fg_color="#800020", hover_color="#a52a2a", cursor="hand2").pack(side="left", padx=5)
        ctk.CTkButton(btnf, text="Save Config", command=self.save_all_config,
                      fg_color="#800020", hover_color="#a52a2a", cursor="hand2").pack(side="left", padx=5)

    def refresh_erp_data(self):
        path= Path(self.erp_var.get().strip())
        df_raw = read_erp_enabled(path)
        # no meltdown here => show raw in preview. user will meltdown in compare
        self.erp_grid.set_data(df_raw)

    def refresh_master_data(self):
        zip_path= Path(self.mst_var.get().strip())
        out_dir= Path(self.csv_var.get().strip())
        csvs= convert_master_txt_to_csv(zip_path, out_dir)
        df_m= unify_master_csvs(csvs)
        # no meltdown => show raw
        self.master_grid.set_data(df_m)

    def run_comparison(self):
        # update config paths
        self.config_dict["paths"]["ERP_EXCEL_PATH"]= self.erp_var.get().strip()
        self.config_dict["paths"]["MASTER_ZIP_PATH"]= self.mst_var.get().strip()
        self.config_dict["paths"]["EXCEPTION_PATH"]= self.exc_var.get().strip()
        self.config_dict["paths"]["OUTPUT_PATH"]= self.out_var.get().strip()
        self.config_dict["paths"]["CONFIG_PATH"]= self.cfg_var.get().strip()
        self.config_dict["paths"]["PARAMETER_PATH"]= self.par_var.get().strip()
        self.config_dict["paths"]["MASTER_CSV_OUTPUT"]= self.csv_var.get().strip()

        self.config_dict["comparison_option"]= 2
        newparam= read_parameter_file(Path(self.par_var.get().strip()))

        # meltdown ERP
        erp_wide= self.erp_grid.get_filtered_df()
        # meltdown_erp wants columns: "V S C", "Value" for name, ignoring "Enabled_Flag"
        erp_long= meltdown_erp(erp_wide, newparam)
        erp_ready= build_keys(erp_long)

        # meltdown Master
        mst_wide= self.master_grid.get_filtered_df()
        mst_long= meltdown_master(mst_wide, newparam)
        mst_ready= build_keys(mst_long)

        # compare
        df_diff= compare_mode2(erp_ready, mst_ready)

        # exceptions
        exc_path= Path(self.exc_var.get().strip())
        df_exc= read_exception_table(exc_path)
        final= merge_exceptions(df_diff, df_exc)

        out_path= Path(self.out_var.get().strip())
        write_results(final, out_path)

        # update dash
        run_date= datetime.now().strftime("%Y-%m-%d")
        final["RunDate"]= run_date
        if self.history_df.empty:
            self.history_df= final.copy()
        else:
            self.history_df= pd.concat([self.history_df, final], ignore_index=True)

        self.notebook.select(self.tab_dashboard)
        self.tab_dashboard.update_data(final, self.history_df)

        messagebox.showinfo("Done", f"Comparison done => {out_path}")

    def save_all_config(self):
        self.config_dict["erp_grid"]= self.erp_grid.get_config_block()
        self.config_dict["master_grid"]= self.master_grid.get_config_block()
        self.config_dict["paths"]["ERP_EXCEL_PATH"]= self.erp_var.get().strip()
        self.config_dict["paths"]["MASTER_ZIP_PATH"]= self.mst_var.get().strip()
        self.config_dict["paths"]["EXCEPTION_PATH"]= self.exc_var.get().strip()
        self.config_dict["paths"]["OUTPUT_PATH"]= self.out_var.get().strip()
        self.config_dict["paths"]["CONFIG_PATH"]= self.cfg_var.get().strip()
        self.config_dict["paths"]["PARAMETER_PATH"]= self.par_var.get().strip()
        self.config_dict["paths"]["MASTER_CSV_OUTPUT"]= self.csv_var.get().strip()
        self.config_dict["comparison_option"]=2
        save_config(self.config_dict, Path(self.cfg_var.get()))
        messagebox.showinfo("Saved","Config saved successfully.")

def main():
    app= MainApp()
    app.mainloop()

if __name__=="__main__":
    main()
