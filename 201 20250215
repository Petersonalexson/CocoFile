# 201 20250215
"""
Ultra-Mega Reconciliation: Parameter-based with advanced Dashboard (8 charts),
showing final dimension/attribute names in the preview, only date columns filterable.

No emojis, minimal Apple-like style in light mode with burgundy (#800020) accents.
We allow toggle between Top 10 or All items in certain charts.

PDF export with optional logo watermark on cover page; the PDF export path
and logo path are stored in the config. The logo path is not shown in the GUI.

Changes:
- For Start/End date filter popups in ERP/Master previews, text is dark on light
  with a burgundy highlight (fg_color="#e0e0e0", hover_color="#c0c0c0").
- Dashboard top bar is in a horizontal scrollable frame if needed.
- The PDF export button now only exists in the "Compare" tab (removed from the dashboard).
- We can filter End/Start Date in the preview (including `(NaN)`).

"""

import os
import sys
import json
import logging
import zipfile
import shutil
import io
from pathlib import Path
from datetime import datetime, timedelta
from typing import Dict, Set, List

import tkinter as tk
from tkinter import ttk, filedialog, messagebox
import customtkinter as ctk

import pandas as pd
import numpy as np

import matplotlib
matplotlib.use("TkAgg")
import matplotlib.pyplot as plt
from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg
from matplotlib.backends.backend_pdf import PdfPages

try:
    import chardet
except ImportError:
    chardet = None

from openpyxl import Workbook
from openpyxl.styles import PatternFill, Font, Alignment

from PIL import Image

# ----------------------------------------------------------------------------
# LOGGING
# ----------------------------------------------------------------------------
logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")

# ----------------------------------------------------------------------------
# DEFAULT PATHS & CONFIG
# ----------------------------------------------------------------------------
DEFAULT_PATHS = {
    "ERP_EXCEL_PATH": "data/ERP_Config.xlsx",
    "MASTER_ZIP_PATH": "data/Master_Config.zip",
    "EXCEPTION_PATH": "data/Exception_Table.xlsx",
    "OUTPUT_PATH": "output/missing_items.xlsx",
    "CONFIG_PATH": "config/ui_config.json",
    "PARAMETER_PATH": "data/parameters.xlsx",
    "MASTER_CSV_OUTPUT": "temp_master_csv",
    "PDF_EXPORT_PATH": "output/dashboard_report.pdf",
    # LOGO_PATH is set in code (not displayed in GUI)
    "LOGO_PATH": "images/company_logo.png"
}

def default_config() -> Dict:
    return {
        "paths": DEFAULT_PATHS.copy(),
        "comparison_option": 2,
        "erp_grid": {"columns": [], "filters": {}},
        "master_grid": {"columns": [], "filters": {}}
    }

def load_config(path: Path) -> Dict:
    if path.is_file():
        try:
            with open(path, "r", encoding="utf-8") as f:
                return json.load(f)
        except Exception as e:
            logging.warning(f"Could not load config: {e}")
    return default_config()

def save_config(cfg: Dict, path: Path):
    path.parent.mkdir(parents=True, exist_ok=True)
    try:
        with open(path, "w", encoding="utf-8") as f:
            json.dump(cfg, f, indent=2)
        logging.info(f"Saved config to {path}")
    except Exception as e:
        logging.error(f"Error saving config: {e}")

# ----------------------------------------------------------------------------
# TEXT LOGGER HANDLER
# ----------------------------------------------------------------------------
class TextHandler(logging.Handler):
    """Send logging output to a ctk.CTkTextbox."""
    def __init__(self, widget: ctk.CTkTextbox):
        super().__init__()
        self.widget = widget

    def emit(self, record):
        msg = self.format(record) + "\n"
        self.widget.after(0, self._append, msg)

    def _append(self, msg):
        self.widget.configure(state="normal")
        self.widget.insert("end", msg)
        self.widget.see("end")
        self.widget.configure(state="disabled")

# ----------------------------------------------------------------------------
# PARAM FILE (two sheets)
# ----------------------------------------------------------------------------
def read_param_file(path: Path) -> Dict[str, object]:
    """
    Dimension sheet => [FileName, V S C, Dimension, ERP Values]
      - if ERP Values=='x', keep dimension
    Attribute sheet => [ERP Original Attributes, Master Original Attributes, Attribute, On/Off]
      - if On/Off=='x', keep
    """
    param = {
        "dim_erp_keep": set(),
        "dim_erp_map": {},
        "dim_master_map": {},
        "attr_erp_map": {},
        "attr_master_map": {}
    }
    if not path.is_file():
        logging.warning(f"Param file not found => {path}")
        return param
    try:
        dim_df = pd.read_excel(path, sheet_name="Dimension Parameters")
        dim_df.columns = dim_df.columns.astype(str).str.strip()

        def s(x): return str(x).strip() if pd.notna(x) else ""

        for _, row in dim_df.iterrows():
            fn = s(row.get("FileName",""))
            vsc = s(row.get("V S C",""))
            dim = s(row.get("Dimension",""))
            ev  = s(row.get("ERP Values",""))

            if ev.lower() == "x" and vsc and dim:
                param["dim_erp_keep"].add(vsc)
            if vsc and dim:
                param["dim_erp_map"][vsc] = dim
            if fn and dim and ev.lower() == "x":
                param["dim_master_map"][fn] = dim

        attr_df = pd.read_excel(path, sheet_name="Attribute Parameters")
        attr_df.columns = attr_df.columns.astype(str).str.strip()
        for _, row in attr_df.iterrows():
            e_orig = s(row.get("ERP Original Attributes",""))
            m_orig = s(row.get("Master Original Attributes",""))
            final_ = s(row.get("Attribute",""))
            onoff  = s(row.get("On/Off",""))
            if onoff.lower()=="x" and final_:
                if e_orig:
                    param["attr_erp_map"][e_orig] = final_
                if m_orig:
                    param["attr_master_map"][m_orig] = final_
        return param
    except Exception as e:
        logging.error(f"Error reading param file => {e}")
        return param

# ----------------------------------------------------------------------------
# ERP => skip 3 => keep Enabled
# ----------------------------------------------------------------------------
def read_erp_excel(path: Path) -> pd.DataFrame:
    if not path.is_file():
        logging.warning(f"ERP Excel not found => {path}")
        return pd.DataFrame()
    try:
        df = pd.read_excel(path, skiprows=3)
        df.columns = df.columns.str.strip()
        if "Enabled_Flag" in df.columns:
            df = df[df["Enabled_Flag"]=="Enabled"]
        return df
    except Exception as e:
        logging.error(f"Error reading ERP => {e}")
        return pd.DataFrame()

# ----------------------------------------------------------------------------
# MASTER => .txt => only try 'utf-8-sig' and 'utf-16-le'
# ----------------------------------------------------------------------------
def read_txt_2encodings(raw: bytes) -> pd.DataFrame:
    import io
    for enc in ["utf-8-sig","utf-16-le"]:
        try:
            buf = io.BytesIO(raw)
            df = pd.read_csv(buf, encoding=enc, on_bad_lines="skip", engine="python")
            df.dropna(how="all", axis=0, inplace=True)
            df.dropna(how="all", axis=1, inplace=True)
            df.columns = df.columns.astype(str).str.strip()
            logging.info(f"[read_txt_2encodings] success with {enc}, shape={df.shape}")
            return df
        except Exception as e:
            logging.debug(f"[read_txt_2encodings] fail with {enc} => {e}")
    logging.error("[read_txt_2encodings] cannot parse .txt => empty.")
    return pd.DataFrame()

def convert_master_txt_to_csv(zip_path: Path, out_dir: Path) -> List[Path]:
    if not zip_path.is_file():
        logging.warning(f"[Master] ZIP not found => {zip_path}")
        return []
    if out_dir.exists():
        shutil.rmtree(out_dir, ignore_errors=True)
    out_dir.mkdir(parents=True, exist_ok=True)
    csvs = []
    with zipfile.ZipFile(zip_path,"r") as z:
        txt_files= [f for f in z.namelist() if f.lower().endswith(".txt")]
        for txt_file in txt_files:
            base_name = os.path.basename(txt_file)
            if not base_name:
                continue
            try:
                with z.open(txt_file) as fo:
                    raw = fo.read()
                df = read_txt_2encodings(raw)
                if df.empty:
                    continue
                df["RawFileName"] = base_name
                if "Name" not in df.columns and len(df.columns)>0:
                    first_col= df.columns[0]
                    df.rename(columns={first_col:"Name"}, inplace=True)
                out_csv = out_dir / (base_name.replace(".txt",".csv"))
                df.to_csv(out_csv, index=False, encoding="utf-8")
                csvs.append(out_csv)
            except Exception as e:
                logging.error(f"[Master] error reading {txt_file} => {e}")
    return csvs

def unify_master_csvs(csvs: List[Path]) -> pd.DataFrame:
    frames=[]
    for cp in csvs:
        if not cp.is_file():
            continue
        try:
            df = pd.read_csv(cp, encoding="utf-8", on_bad_lines="skip")
            df.columns = df.columns.str.strip()
            frames.append(df)
        except Exception as e:
            logging.error(f"[unify_master_csvs] reading {cp} => {e}")
    if frames:
        return pd.concat(frames, ignore_index=True)
    return pd.DataFrame()

# ----------------------------------------------------------------------------
# MELTDOWN => Param Filter => Previews
# ----------------------------------------------------------------------------
def meltdown_erp_for_preview(df: pd.DataFrame, param: Dict[str, object]) -> pd.DataFrame:
    """
    Filter rows => only V_S_C in param["dim_erp_keep"]
    Then rename dimension => param["dim_erp_map"][vsc]
    Only keep attributes that are in param["attr_erp_map"]
    """
    if "V_S_C" not in df.columns:
        return pd.DataFrame()
    keep = param.get("dim_erp_keep", set())
    dmap = param.get("dim_erp_map", {})
    amap = param.get("attr_erp_map", {})

    df2 = df[df["V_S_C"].isin(keep)].copy()
    if df2.empty:
        return pd.DataFrame()

    skip_cols = {"V_S_C","Enabled_Flag"}
    id_vars= []
    if "Value" in df2.columns:
        id_vars.append("Value")
        skip_cols.add("Value")
    df2["DimRaw"] = df2["V_S_C"]
    skip_cols.add("DimRaw")
    id_vars.insert(0, "DimRaw")

    meltdown_cols = [c for c in df2.columns if c not in skip_cols]
    melted = df2.melt(
        id_vars=id_vars,
        value_vars=meltdown_cols,
        var_name="OrigAttr",
        value_name="ValX"
    )

    def rename_dim(v):
        return dmap.get(v, v)
    melted["Dimension"] = melted["DimRaw"].apply(rename_dim)
    if "Value" in id_vars:
        melted.rename(columns={"Value":"Name"}, inplace=True)
    else:
        melted["Name"] = ""

    # only keep mapped attributes
    melted = melted[melted["OrigAttr"].isin(amap.keys())].copy()
    melted["Attribute"] = melted["OrigAttr"].map(amap)

    def strip_t(val):
        if isinstance(val,str) and "T" in val:
            return val.split("T")[0]
        return val
    melted["Value"] = np.where(
        melted["Attribute"].isin(["Start Date","End Date"]),
        melted["ValX"].apply(strip_t),
        melted["ValX"]
    )
    return melted[["Dimension","Name","Attribute","Value"]]

def meltdown_master_for_preview(df: pd.DataFrame, param: Dict[str, object]) -> pd.DataFrame:
    """
    Filter rows => only keep those with RawFileName in param["dim_master_map"]
    Then rename dimension => param["dim_master_map"][filename]
    Only keep attributes => param["attr_master_map"]
    """
    if df.empty or "RawFileName" not in df.columns:
        return pd.DataFrame()
    keep_map = param.get("dim_master_map", {})
    amap = param.get("attr_master_map", {})

    df2 = df[df["RawFileName"].isin(keep_map.keys())].copy()
    if df2.empty:
        return pd.DataFrame()

    df2["DimRaw"] = df2["RawFileName"]

    skip_cols = {"RawFileName","DimRaw"}
    id_vars = ["DimRaw"]
    if "Name" in df2.columns:
        id_vars.append("Name")
        skip_cols.add("Name")

    meltdown_cols = [c for c in df2.columns if c not in skip_cols]
    melted = df2.melt(
        id_vars=id_vars,
        value_vars=meltdown_cols,
        var_name="OrigAttr",
        value_name="ValX"
    )

    def rename_dim(fn):
        return keep_map.get(fn, fn)
    melted["Dimension"] = melted["DimRaw"].apply(rename_dim)

    if "Name" in id_vars:
        melted.rename(columns={"Name":"Name"}, inplace=True)
    else:
        melted["Name"] = ""

    # only keep those attributes that are in attr_master_map
    melted = melted[melted["OrigAttr"].isin(amap.keys())].copy()
    melted["Attribute"] = melted["OrigAttr"].map(amap)

    def strip_t(val):
        if isinstance(val,str) and "T" in val:
            return val.split("T")[0]
        return val
    melted["Value"] = np.where(
        melted["Attribute"].isin(["Start Date","End Date"]),
        melted["ValX"].apply(strip_t),
        melted["ValX"]
    )
    return melted[["Dimension","Name","Attribute","Value"]]

def pivot_for_preview(df: pd.DataFrame) -> pd.DataFrame:
    """
    Convert long => wide, with Dimension and Name as index, pivot on Attribute => Value
    """
    if not df.empty and {"Dimension","Name","Attribute"}.issubset(df.columns):
        df = df.drop_duplicates(subset=["Dimension","Name","Attribute"])
        try:
            df = df.pivot(
                index=["Dimension","Name"],
                columns="Attribute",
                values="Value"
            ).reset_index()
        except Exception as e:
            logging.error(f"Pivot error => {e}")
    return df

# ----------------------------------------------------------------------------
# Compare => meltdown => produce missing items
# ----------------------------------------------------------------------------
def melt_back(df: pd.DataFrame) -> pd.DataFrame:
    """
    Melt wide preview data back to long so we can compare.
    """
    if df.empty or "Dimension" not in df.columns or "Name" not in df.columns:
        return pd.DataFrame()
    skip_cols = {"Dimension","Name"}
    meltdown_cols = [c for c in df.columns if c not in skip_cols]
    melted = df.melt(
        id_vars=["Dimension","Name"],
        value_vars=meltdown_cols,
        var_name="Attribute",
        value_name="Value"
    )
    return melted[["Dimension","Name","Attribute","Value"]]

def build_keys(df: pd.DataFrame)-> pd.DataFrame:
    """
    Add GroupKey, Key columns for easier comparison + placeholders for Comments/Action
    """
    df = df.copy()
    for c in ["Dimension","Name","Attribute","Value"]:
        if c not in df.columns:
            df[c] = ""
        df[c] = df[c].fillna("").astype(str).str.strip()
    df["GroupKey"] = df["Dimension"] + " | " + df["Name"]
    df["Key"] = df["Dimension"] + " | " + df["Name"] + " | " + df["Attribute"] + " | " + df["Value"]
    df["Comments_1"] = ""
    df["Comments_2"] = ""
    df["Action Item"] = ""
    df["Missing In"] = ""
    return df

def compare_mode2(df_erp: pd.DataFrame, df_mst: pd.DataFrame) -> pd.DataFrame:
    """
    Compare logic: For each dimension|name, compare attribute sets. 
    If name/attribute differs => mismatch is flagged as Missing In MASTER or ERP.
    """
    def to_dict(d):
        out={}
        for gk, grp in d.groupby("GroupKey"):
            rec={}
            nm= grp["Name"].iloc[0] if not grp.empty else ""
            rec["Name"] = nm
            for _, row in grp.iterrows():
                rec[row["Attribute"]] = row["Value"]
            out[gk] = rec
        return out

    e_dict = to_dict(df_erp)
    m_dict = to_dict(df_mst)
    all_gk = set(e_dict.keys()) | set(m_dict.keys())
    results=[]
    for gk in all_gk:
        dim= gk.split(" | ")[0]
        a_data= e_dict.get(gk,{})
        b_data= m_dict.get(gk,{})
        name_a= a_data.get("Name","")
        name_b= b_data.get("Name","")

        if name_a and name_b and name_a==name_b:
            # compare all attributes
            all_attrs= (set(a_data.keys())| set(b_data.keys())) - {"Name"}
            for at in all_attrs:
                va= a_data.get(at,"")
                vb= b_data.get(at,"")
                if va!=vb:
                    if va and not vb:
                        results.append({"Dimension":dim,"Name":name_a,"Attribute":at,"Value":va,"Missing In":"MASTER"})
                    elif vb and not va:
                        results.append({"Dimension":dim,"Name":name_a,"Attribute":at,"Value":vb,"Missing In":"ERP"})
                    else:
                        # both exist but differ => mismatch in both
                        results.append({"Dimension":dim,"Name":name_a,"Attribute":at,"Value":va,"Missing In":"MASTER"})
                        results.append({"Dimension":dim,"Name":name_a,"Attribute":at,"Value":vb,"Missing In":"ERP"})
        else:
            # name mismatch => entirely missing in one side
            if name_a and not name_b:
                results.append({"Dimension":dim,"Name":name_a,"Attribute":"Name","Value":name_a,"Missing In":"MASTER"})
            elif name_b and not name_a:
                results.append({"Dimension":dim,"Name":name_b,"Attribute":"Name","Value":name_b,"Missing In":"ERP"})
    df_res= pd.DataFrame(results)
    if not df_res.empty:
        df_res["Key"]= (df_res["Dimension"].str.strip()+" | "+
                        df_res["Name"].str.strip()+" | "+
                        df_res["Attribute"].str.strip()+" | "+
                        df_res["Value"].str.strip())
    return df_res

def read_exception_table(path: Path)-> pd.DataFrame:
    if not path.is_file():
        logging.warning(f"Exception table not found => {path}")
        return pd.DataFrame()
    try:
        df = pd.read_excel(path)
        df.columns = df.columns.astype(str).str.strip()
        return df
    except Exception as e:
        logging.error(f"Error reading exception => {e}")
        return pd.DataFrame()

def merge_exceptions(df: pd.DataFrame, df_exc: pd.DataFrame)-> pd.DataFrame:
    """
    If Key in exception => hide if "hide exception"==yes, else merge Comments_1, Comments_2
    """
    if df.empty or df_exc.empty or "Key" not in df.columns:
        return df
    keep = [c for c in df_exc.columns if c in ["Key","Comments_1","Comments_2","hide exception"]]
    if not keep:
        return df
    exc = df_exc[keep].copy()
    exc["Key"] = exc["Key"].astype(str).str.strip()

    merged = df.merge(exc, on="Key", how="left", suffixes=("","_exc"))
    merged["hide exception"] = merged.get("hide exception","").fillna("").str.lower()

    final = merged[merged["hide exception"]!="yes"].copy()
    if "Comments_1_exc" in final.columns:
        final["Comments_1"] = np.where(final["Comments_1_exc"].notna(), final["Comments_1_exc"], final["Comments_1"])
        final.drop(columns=["Comments_1_exc"], inplace=True)
    if "Comments_2_exc" in final.columns:
        final["Comments_2"] = np.where(final["Comments_2_exc"].notna(), final["Comments_2_exc"], final["Comments_2"])
        final.drop(columns=["Comments_2_exc"], inplace=True)
    if "hide exception" in final.columns:
        final.drop(columns=["hide exception"], inplace=True)
    return final

def write_missing_items(df: pd.DataFrame, out_path: Path):
    """
    Write missing items to Excel, single sheet "Missing Items"
    """
    if df.empty:
        logging.info("No missing items => skip writing.")
        return
    out_path.parent.mkdir(parents=True, exist_ok=True)
    final_cols= ["Key","Dimension","Name","Attribute","Value","Comments_1","Comments_2","Action Item","Missing In"]
    for c in final_cols:
        if c not in df.columns:
            df[c] = ""
    df = df[final_cols]

    wb= Workbook()
    ws= wb.active
    ws.title= "Missing Items"
    ws.append(final_cols)

    for rowvals in df.itertuples(index=False):
        ws.append(rowvals)

    header_font= Font(bold=True)
    fill= PatternFill(start_color="DDDDDD", end_color="DDDDDD", fill_type="solid")
    for cell in ws[1]:
        cell.font= header_font
        cell.fill= fill
        cell.alignment= Alignment(horizontal="center")

    # auto-size columns
    for col in ws.columns:
        max_len=0
        letter= col[0].column_letter
        for cell in col:
            val = str(cell.value) if cell.value else ""
            max_len= max(max_len, len(val))
        ws.column_dimensions[letter].width = max_len+2
    ws.freeze_panes = "A2"

    wb.save(out_path)
    logging.info(f"Missing items => {out_path}")

# ----------------------------------------------------------------------------
# SIMPLE PREVIEW
# ----------------------------------------------------------------------------
class SimplePreview(ctk.CTkFrame):
    """
    Displays wide data, only Start/End Date columns filterable (including NaN).
    """
    FILTERABLE = {"Start Date","End Date"}

    def __init__(self, parent, name: str):
        super().__init__(parent)
        self.name = name
        self.df = pd.DataFrame()
        self.filters: Dict[str, Set] = {}

        self.create_toolbar()
        self.create_table()
        self.create_statusbar()

    def create_toolbar(self):
        bar= ctk.CTkFrame(self, corner_radius=10, fg_color="#f0f0f0")
        bar.pack(fill="x", padx=5, pady=5)

        # Title label
        title_label = ctk.CTkLabel(
            bar, text=f"{self.name} Preview",
            fg_color="#800020", corner_radius=8,
            text_color="white",
            font=ctk.CTkFont(size=14, weight="bold")
        )
        title_label.pack(side="left", padx=5)

        # Info
        ctk.CTkButton(
            bar, text="ⓘ", width=30, command=self.show_info,
            fg_color="#800020", hover_color="#a52a2a", text_color="white"
        ).pack(side="left", padx=5)

        # Clear filters
        ctk.CTkButton(
            bar, text="Clear Date Filters", command=self.clear_filters,
            fg_color="#800020", hover_color="#a52a2a", text_color="white"
        ).pack(side="left", padx=5)

    def show_info(self):
        messagebox.showinfo(
            "Info",
            f"{self.name} data after meltdown & param.\nOnly Start/End Date columns are filterable.\nIncluding rows with NaN."
        )

    def create_table(self):
        container = ctk.CTkFrame(self)
        container.pack(fill="both", expand=True, padx=5, pady=5)

        self.tree = ttk.Treeview(container, show="headings")
        vsb = ttk.Scrollbar(container, orient="vertical", command=self.tree.yview)
        hsb = ttk.Scrollbar(container, orient="horizontal", command=self.tree.xview)

        self.tree.configure(yscrollcommand=vsb.set, xscrollcommand=hsb.set)
        self.tree.grid(row=0, column=0, sticky="nsew")
        vsb.grid(row=0, column=1, sticky="ns")
        hsb.grid(row=1, column=0, sticky="ew")

        container.rowconfigure(0, weight=1)
        container.columnconfigure(0, weight=1)

    def create_statusbar(self):
        self.status_label = ctk.CTkLabel(self, text="0 rows", fg_color="#f0f0f0", text_color="black")
        self.status_label.pack(fill="x")

    def set_data(self, df: pd.DataFrame):
        self.filters.clear()
        self.df = df.copy()
        self.refresh_table()

    def refresh_table(self):
        for i in self.tree.get_children():
            self.tree.delete(i)
        if self.df.empty:
            self.tree["columns"] = []
            self.status_label.configure(text="0 rows")
            return

        cols = list(self.df.columns)
        self.tree["columns"] = cols
        for c in cols:
            self.tree.heading(
                c, text=c, anchor="w",
                command=lambda col=c: self.on_heading_click(col)
            )
            self.tree.column(c, anchor="w", width=150)

        df_f = self.apply_filters()
        for _, row in df_f.iterrows():
            rowvals = [row[c] for c in cols]
            self.tree.insert("", "end", values=rowvals)

        self.status_label.configure(text=f"{len(df_f)} rows")

    def apply_filters(self) -> pd.DataFrame:
        df_f = self.df.copy()
        for col, allowed in self.filters.items():
            if col in df_f.columns:
                df_f = df_f[df_f[col].isin(allowed)]
        return df_f

    def on_heading_click(self, col_name: str):
        if col_name in self.FILTERABLE:
            self.show_filter_popup(col_name)

    def show_filter_popup(self, col_name: str):
        if self.df.empty or col_name not in self.df.columns:
            return

        popup = tk.Toplevel(self)
        popup.title(f"Filter: {col_name}")
        popup.geometry("300x400")

        frame = ctk.CTkFrame(popup)
        frame.pack(fill="both", expand=True, padx=5, pady=5)

        unique_vals = self.df[col_name].unique()
        display_map = {}
        for v in unique_vals:
            if pd.isna(v):
                dsp = "(NaN)"
            elif isinstance(v,str) and not v.strip():
                dsp = "(blank)"
            else:
                dsp = str(v)
            display_map[v] = dsp

        sorted_vals = sorted(display_map.keys(), key=lambda x: display_map[x].lower())
        curr_filter = self.filters.get(col_name, set(unique_vals))

        selall_var = tk.BooleanVar(value=True)
        def toggle_all():
            check = selall_var.get()
            for vb in var_dict.values():
                vb.set(check)

        # Dark text on light background with burgundy highlight
        ctk.CTkCheckBox(
            frame, text="Select All", variable=selall_var, command=toggle_all,
            fg_color="#e0e0e0", hover_color="#c0c0c0", text_color="black"
        ).pack(anchor="w", pady=5)

        scroll= ctk.CTkScrollableFrame(frame, width=250, height=250)
        scroll.pack(fill="both", expand=True, padx=5, pady=5)

        var_dict = {}
        for rv in sorted_vals:
            in_filter = rv in curr_filter
            bvar = tk.BooleanVar(value=in_filter)
            var_dict[rv] = bvar
            ctk.CTkCheckBox(
                scroll, text=display_map[rv], variable=bvar,
                fg_color="#e0e0e0", hover_color="#c0c0c0", text_color="black"
            ).pack(anchor="w")

        def apply_():
            sel = {rv for rv,vb in var_dict.items() if vb.get()}
            if sel == set(sorted_vals) or not sel:
                self.filters.pop(col_name, None)
            else:
                self.filters[col_name] = sel
            popup.destroy()
            self.refresh_table()

        bf = ctk.CTkFrame(frame)
        bf.pack(fill="x", pady=5)
        ctk.CTkButton(
            bf, text="Apply", command=apply_,
            fg_color="#800020", hover_color="#a52a2a", text_color="white"
        ).pack(side="left", padx=5)
        ctk.CTkButton(
            bf, text="Cancel", command=popup.destroy,
            fg_color="#800020", hover_color="#a52a2a", text_color="white"
        ).pack(side="left", padx=5)

    def clear_filters(self):
        self.filters.clear()
        self.refresh_table()

    def get_filtered_df(self) -> pd.DataFrame:
        return self.apply_filters()

# ----------------------------------------------------------------------------
# PDF REPORT
# ----------------------------------------------------------------------------
class EnhancedPDFReport:
    """
    Professional PDF report generator with advanced formatting, optional logo watermark.
    Generates a cover page, executive summary with key indicators, and then 8 charts 
    on subsequent pages.
    """
    def __init__(self, df_current: pd.DataFrame, df_history: pd.DataFrame, config: Dict):
        self.df_current = df_current
        self.df_history = df_history
        self.config = config
        self.timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # Professional color scheme
        self.colors = {
            'primary': '#800020',
            'secondary': '#A52A2A',
            'text': '#2C1810',
            'accent': '#4A90E2',
            'background': '#FFFFFF'
        }

    def generate(self) -> Path:
        """Generates a multi-page PDF."""
        pdf_path = self._get_output_path()
        
        with PdfPages(pdf_path) as pdf:
            # Cover page
            self._add_cover_page(pdf)

            # Executive summary + "key indicators" subplots
            self._add_executive_summary(pdf)

            # Then add the 8 advanced charts on separate pages
            self._add_all_charts(pdf)

        logging.info(f"PDF exported => {pdf_path}")
        return pdf_path
        
    def _get_output_path(self) -> Path:
        """Determines the PDF output path from config or default location."""
        base_path = self.config["paths"].get("PDF_EXPORT_PATH", "output/dashboard_report.pdf")
        outp = Path(base_path)
        outp.parent.mkdir(parents=True, exist_ok=True)
        return outp

    def _add_cover_page(self, pdf: PdfPages):
        """Adds a cover page with the logo watermark placed higher."""
        fig = plt.figure(figsize=(8.5, 11))
        fig.patch.set_facecolor(self.colors['background'])
        plt.axis('off')

        # Watermark / logo
        logo_path = self.config["paths"].get("LOGO_PATH","images/company_logo.png")
        if logo_path and os.path.exists(logo_path):
            import matplotlib.image as mpimg
            img = mpimg.imread(logo_path)
            # Scale & place the logo higher with alpha=0.25
            h, w = img.shape[0], img.shape[1]
            scale = 0.7
            new_w = int(w*scale)
            new_h = int(h*scale)
            pil_img = Image.fromarray((img*255).astype(np.uint8))
            pil_img = pil_img.resize((new_w,new_h), Image.ANTIALIAS)
            img = np.array(pil_img)/255.0

            # place near top
            fig.figimage(img, 80, 600, alpha=0.25, zorder=10)

        plt.text(0.5, 0.82, "Reconciliation Analysis Report",
                 ha='center', fontsize=24, fontweight='bold',
                 color=self.colors['primary'])
        plt.text(0.5, 0.75, f"Generated on {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
                 ha='center', fontsize=12, color=self.colors['text'])

        if not self.df_current.empty:
            total = len(self.df_current)
            dims  = self.df_current["Dimension"].nunique() if "Dimension" in self.df_current.columns else 0
            plt.text(0.5, 0.60,
                     f"Total Mismatches: {total}",
                     ha='center', fontsize=10, color=self.colors['text'])
            plt.text(0.5, 0.55,
                     f"Unique Dimensions: {dims}",
                     ha='center', fontsize=10, color=self.colors['text'])

        plt.text(0.5, 0.1, "CONFIDENTIAL",
                 ha='center', fontsize=8, color=self.colors['text'])
        plt.text(0.5, 0.08, "Ultra-Mega Reconciliation System",
                 ha='center', fontsize=8, color=self.colors['text'])

        pdf.savefig()
        plt.close()

    def _add_executive_summary(self, pdf: PdfPages):
        """
        Adds an executive summary with summary text, optional trend chart,
        and a "Key Indicators" subplot (Top 10 dims, Missing In distribution, top 10 attributes).
        """
        fig = plt.figure(figsize=(8.5, 11))
        fig.patch.set_facecolor(self.colors['background'])
        plt.axis('off')

        plt.text(0.5, 0.95, "Executive Summary",
                 ha='center', fontsize=20, fontweight='bold',
                 color=self.colors['primary'])

        # Summary text
        if self.df_current.empty:
            summary = "No mismatches found in the current run."
        else:
            total = len(self.df_current)
            erp_missing = (self.df_current["Missing In"]=="ERP").sum()
            master_missing = (self.df_current["Missing In"]=="MASTER").sum()
            summary = (
                f"In this run, we have identified {total} mismatches.\n"
                f"{erp_missing} are missing in ERP, {master_missing} are missing in Master.\n"
                f"Below are key indicators; subsequent pages have more detail."
            )
        plt.text(0.1, 0.88, summary, fontsize=10, color=self.colors['text'], wrap=True)

        # Trend chart (top half)
        if not self.df_history.empty and "RunDate" in self.df_history.columns:
            ax = plt.axes([0.1, 0.65, 0.8, 0.15])
            hist_ct = self.df_history.groupby("RunDate")["Key"].count().reset_index(name="Count")
            hist_ct.sort_values("RunDate", inplace=True)
            ax.plot(hist_ct["RunDate"], hist_ct["Count"], marker="o", color=self.colors['accent'])
            ax.set_title("Trend of Mismatches Over Time", fontsize=11)
            ax.set_xlabel("RunDate")
            ax.set_ylabel("Mismatch Count")
            plt.setp(ax.get_xticklabels(), rotation=45, ha='right')

        # Key Indicators subplots in the bottom
        if not self.df_current.empty:
            ax1 = plt.axes([0.1, 0.35, 0.35, 0.25])
            ax2 = plt.axes([0.55, 0.35, 0.35, 0.25])
            ax3 = plt.axes([0.1, 0.05, 0.8, 0.22])

            # 1) Top 10 Dimensions
            if "Dimension" in self.df_current.columns:
                dim_ct = self.df_current["Dimension"].value_counts().head(10)
                ax1.bar(dim_ct.index, dim_ct.values, color="blue")
                ax1.set_title("Top 10 Dimensions", fontsize=9, color=self.colors['text'])
                ax1.tick_params(axis='x', rotation=45, labelsize=7)
            else:
                ax1.text(0.5, 0.5, "No Dimension data", ha='center')

            # 2) distribution of Missing In
            if "Missing In" in self.df_current.columns:
                mis_ct = self.df_current["Missing In"].value_counts()
                ax2.pie(mis_ct.values, labels=mis_ct.index, autopct="%.1f%%", startangle=140, textprops={'fontsize':7})
                ax2.set_title("Distribution of Missing In", fontsize=9, color=self.colors['text'])
            else:
                ax2.text(0.5, 0.5, "No 'Missing In'", ha='center')

            # 3) top 10 attributes
            if "Attribute" in self.df_current.columns:
                attr_ct = self.df_current["Attribute"].value_counts().head(10)
                ax3.bar(attr_ct.index, attr_ct.values, color="orange")
                ax3.set_title("Top 10 Attributes Mismatched", fontsize=9, color=self.colors['text'])
                ax3.tick_params(axis='x', rotation=45, labelsize=7)
            else:
                ax3.text(0.5, 0.5, "No attribute data", ha='center')
        else:
            plt.text(0.1, 0.3, "No mismatch data for key indicators.", fontsize=10, color=self.colors['text'])

        pdf.savefig()
        plt.close()

    def _add_all_charts(self, pdf: PdfPages):
        """
        Generate 8 advanced charts on separate pages, based on df_current (and df_history).
        """
        dfc = self.df_current
        if dfc.empty:
            return

        # 1) Heatmap
        if "Missing In" in dfc.columns:
            df_m = dfc[dfc["Missing In"]!=""]
            if not df_m.empty and {"Dimension","Attribute"}.issubset(df_m.columns):
                pivot= df_m.groupby(["Dimension","Attribute"]).size().unstack(fill_value=0)
                fig, ax= plt.subplots(figsize=(6,5))
                cax= ax.imshow(pivot, aspect="auto", cmap="Reds")
                ax.set_xticks(range(len(pivot.columns)))
                ax.set_xticklabels(pivot.columns, rotation=90)
                ax.set_yticks(range(len(pivot.index)))
                ax.set_yticklabels(pivot.index)
                fig.colorbar(cax, ax=ax)
                ax.set_title("Heatmap: Missing Items")
                pdf.savefig(fig)
                plt.close(fig)

        # 2) Lollipop
        if "Missing In" in dfc.columns:
            df_m = dfc[dfc["Missing In"]!=""]
            if not df_m.empty:
                cdim = df_m.groupby("Dimension")["Key"].count().sort_values(ascending=False).head(10)
                if not cdim.empty:
                    fig, ax= plt.subplots(figsize=(6,5))
                    ax.hlines(y=cdim.index, xmin=0, xmax=cdim.values, color="skyblue")
                    ax.plot(cdim.values, cdim.index, "o", color="skyblue")
                    ax.set_title("Lollipop: Missing Dimensions")
                    ax.set_xlabel("Missing Count")
                    pdf.savefig(fig)
                    plt.close(fig)

        # 3) Circular
        if "Missing In" in dfc.columns:
            df_m= dfc[dfc["Missing In"]!=""]
            if not df_m.empty:
                cattr= df_m.groupby("Attribute")["Key"].count().sort_values(ascending=False).head(10)
                if not cattr.empty:
                    cat= cattr.index.tolist()
                    val= cattr.values
                    angles= np.linspace(0,2*np.pi,len(cat), endpoint=False)
                    fig= plt.figure(figsize=(6,6))
                    ax= fig.add_subplot(111, polar=True)
                    ax.set_theta_offset(np.pi/2)
                    ax.set_theta_direction(-1)
                    ax.set_xticks(angles)
                    ax.set_xticklabels(cat, fontsize=9)
                    ax.bar(angles, val, width=0.4, color="orange", alpha=0.6)
                    ax.set_title("Circular: Missing Attributes", y=1.05)
                    pdf.savefig(fig)
                    plt.close(fig)

        # 4) Scatter
        if "Missing In" in dfc.columns:
            df_m= dfc[dfc["Missing In"]!=""]
            if not df_m.empty:
                cdim= df_m.groupby("Dimension")["Key"].count().reset_index(name="Count")
                cdim.sort_values("Count", ascending=False, inplace=True)
                cdim = cdim.head(10)
                if not cdim.empty:
                    xvals= np.arange(len(cdim))
                    yvals= cdim["Count"].values
                    labels= cdim["Dimension"].values
                    fig, ax= plt.subplots(figsize=(6,5))
                    ax.scatter(xvals,yvals,color="green")
                    for i, txt in enumerate(labels):
                        ax.text(xvals[i], yvals[i], txt, ha="center", va="bottom", rotation=60)
                    ax.set_xticks([])
                    ax.set_ylabel("Missing Count")
                    ax.set_title("Scatter: Missing by Dimension")
                    pdf.savefig(fig)
                    plt.close(fig)

        # 5) Radar
        if "Missing In" in dfc.columns:
            df_m= dfc[dfc["Missing In"]!=""]
            if not df_m.empty:
                cdim= df_m.groupby("Dimension")["Key"].count().sort_values(ascending=False).head(10)
                if not cdim.empty:
                    cat= cdim.index.tolist()
                    val= cdim.values.tolist()
                    N= len(cat)
                    if N>1:
                        angles= np.linspace(0,2*np.pi,N, endpoint=False).tolist()
                        angles+= angles[:1]
                        val= list(val) + [val[0]]
                        fig= plt.figure(figsize=(6,6))
                        ax= fig.add_subplot(111, polar=True)
                        ax.set_theta_offset(np.pi/2)
                        ax.set_theta_direction(-1)
                        ax.set_xticks(angles[:-1])
                        ax.set_xticklabels(cat, fontsize=9)
                        ax.plot(angles, val, color="red", linewidth=2)
                        ax.fill(angles, val, color="red", alpha=0.3)
                        ax.set_title("Radar: Missing Dims", y=1.08)
                        pdf.savefig(fig)
                        plt.close(fig)

        # 6) Normal Pie
        if "Missing In" in dfc.columns:
            df_m= dfc[dfc["Missing In"]!=""]
            if not df_m.empty:
                dist= df_m["Missing In"].value_counts()
                fig, ax= plt.subplots(figsize=(5,5))
                ax.pie(dist.values, labels=dist.index, autopct="%.1f%%", startangle=140)
                ax.set_title("Pie: Missing In distribution")
                pdf.savefig(fig)
                plt.close(fig)

        # 7) Normal Bar
        if "Missing In" in dfc.columns:
            df_m= dfc[dfc["Missing In"]!=""]
            if not df_m.empty:
                cattr= df_m.groupby("Attribute")["Key"].count().sort_values(ascending=False).head(10)
                if not cattr.empty:
                    fig, ax= plt.subplots(figsize=(6,4))
                    bars = ax.bar(range(len(cattr)), cattr.values, color="blue")
                    ax.set_xticks(range(len(cattr)))
                    ax.set_xticklabels(cattr.index, rotation=45, ha="right")
                    ax.set_ylabel("Missing Count")
                    ax.set_title("Bar: Missing attributes")
                    for bar in bars:
                        height = bar.get_height()
                        ax.text(bar.get_x() + bar.get_width()/2., height,
                                f'{int(height)}',
                                ha='center', va='bottom', fontsize=8)
                    plt.tight_layout()
                    pdf.savefig(fig)
                    plt.close(fig)

        # 8) Band Chart
        if not self.df_history.empty and "RunDate" in self.df_history.columns:
            date_ct= self.df_history.groupby("RunDate")["Key"].count().reset_index(name="Count")
            date_ct.sort_values("RunDate", inplace=True)
            if not date_ct.empty:
                date_ct["Count_min"] = date_ct["Count"]*0.9
                date_ct["Count_max"] = date_ct["Count"]*1.1
                fig, ax= plt.subplots(figsize=(6,4))
                ax.plot(date_ct["RunDate"], date_ct["Count"], color="purple", marker="o", label="Missing Count")
                ax.fill_between(date_ct["RunDate"], date_ct["Count_min"], date_ct["Count_max"],
                                color="purple", alpha=0.2, label="±10% band")
                ax.set_title("Band Chart Over Time")
                ax.set_xlabel("RunDate")
                ax.set_ylabel("Missing Count")
                plt.xticks(rotation=45)
                ax.legend()
                for i, row in date_ct.iterrows():
                    ax.text(row["RunDate"], row["Count"], str(row["Count"]), ha="center", va="bottom", fontsize=8)
                pdf.savefig(fig)
                plt.close(fig)

# ----------------------------------------------------------------------------
# ADVANCED DASHBOARD (WITHOUT PDF BUTTON)
# ----------------------------------------------------------------------------
class AdvancedDashboard(ctk.CTkFrame):
    """
    8 charts, dimension/attribute/time filter, date range quick filter,
    and a horizontal scrollable top bar if needed.
    We removed the PDF export button from here, so it only appears in Compare tab.
    """
    def __init__(self, parent):
        super().__init__(parent)
        self.df_current = pd.DataFrame()
        self.df_history = pd.DataFrame()
        self.selected_dims: Set[str] = set()
        self.selected_attrs: Set[str] = set()

        # If top_n = 10 => show top 10, if top_n=None => show all
        self.top_n = 10

        # Scrollable top bar
        self.topbar_scroll = ctk.CTkScrollableFrame(self, orientation="horizontal", height=60)
        self.topbar_scroll.pack(fill="x", pady=5)

        # Metric label
        self.metric_label = ctk.CTkLabel(self.topbar_scroll, text="Metrics: 0 missing, 0 dimension", width=300)
        self.metric_label.pack(side="left", padx=5)

        ctk.CTkButton(
            self.topbar_scroll, text="Filter Dimension", command=self.show_dimension_filter,
            fg_color="#800020", hover_color="#a52a2a", text_color="white"
        ).pack(side="left", padx=5)

        ctk.CTkButton(
            self.topbar_scroll, text="Filter Attribute", command=self.show_attribute_filter,
            fg_color="#800020", hover_color="#a52a2a", text_color="white"
        ).pack(side="left", padx=5)

        # Quick date filters
        ctk.CTkButton(
            self.topbar_scroll, text="Last 7 Days", command=lambda: self.set_quick_range(7),
            fg_color="#800020", hover_color="#a52a2a", text_color="white"
        ).pack(side="left", padx=5)
        ctk.CTkButton(
            self.topbar_scroll, text="Last 30 Days", command=lambda: self.set_quick_range(30),
            fg_color="#800020", hover_color="#a52a2a", text_color="white"
        ).pack(side="left", padx=5)
        ctk.CTkButton(
            self.topbar_scroll, text="Last 90 Days", command=lambda: self.set_quick_range(90),
            fg_color="#800020", hover_color="#a52a2a", text_color="white"
        ).pack(side="left", padx=5)
        ctk.CTkButton(
            self.topbar_scroll, text="All Time", command=lambda: self.set_quick_range(9999),
            fg_color="#800020", hover_color="#a52a2a", text_color="white"
        ).pack(side="left", padx=5)

        self.start_date_var = tk.StringVar(value=(datetime.now()-timedelta(days=30)).strftime("%Y-%m-%d"))
        self.end_date_var = tk.StringVar(value=datetime.now().strftime("%Y-%m-%d"))

        ctk.CTkEntry(self.topbar_scroll, textvariable=self.start_date_var,
                     width=100, text_color="black").pack(side="left", padx=5)
        ctk.CTkEntry(self.topbar_scroll, textvariable=self.end_date_var,
                     width=100, text_color="black").pack(side="left", padx=5)

        ctk.CTkButton(
            self.topbar_scroll, text="Update Timeline", command=self.update_data_filters,
            fg_color="#800020", hover_color="#a52a2a", text_color="white"
        ).pack(side="left", padx=5)

        # Toggle top n
        ctk.CTkButton(
            self.topbar_scroll, text="Toggle Top 10 / All", command=self.toggle_top_n,
            fg_color="#800020", hover_color="#a52a2a", text_color="white"
        ).pack(side="left", padx=5)

        # Notebook for 8 charts
        self.notebook = ttk.Notebook(self)
        self.notebook.pack(fill="both", expand=True)

        self.frames = {}
        chart_names = ["Heatmap","Lollipop","Circular","Scatter","Radar","Normal Pie","Normal Bar","Band Chart"]
        for lbl in chart_names:
            fr = ctk.CTkFrame(self.notebook)
            self.notebook.add(fr, text=lbl)
            self.frames[lbl] = fr

    def toggle_top_n(self):
        if self.top_n == 10:
            self.top_n = None
        else:
            self.top_n = 10
        self.update_data_filters()

    def set_quick_range(self, days: int):
        if days>9000:
            self.start_date_var.set("1900-01-01")
            self.end_date_var.set("2100-12-31")
        else:
            dt_end = datetime.now()
            dt_start = dt_end - timedelta(days=days)
            self.start_date_var.set(dt_start.strftime("%Y-%m-%d"))
            self.end_date_var.set(dt_end.strftime("%Y-%m-%d"))
        self.update_data_filters()

    def show_dimension_filter(self):
        self.show_filter_popup("Dimension")

    def show_attribute_filter(self):
        self.show_filter_popup("Attribute")

    def show_filter_popup(self, col: str):
        base_df = self.df_history if not self.df_history.empty else self.df_current
        if base_df.empty or col not in base_df.columns:
            return
        popup = tk.Toplevel(self)
        popup.title(f"Filter: {col}")
        popup.geometry("300x400")

        frame= ctk.CTkFrame(popup)
        frame.pack(fill="both", expand=True, padx=5, pady=5)

        unique_vals= base_df[col].unique()
        display_map={}
        for v in unique_vals:
            if pd.isna(v):
                dsp= "(NaN)"
            elif isinstance(v,str) and not v.strip():
                dsp= "(blank)"
            else:
                dsp= str(v)
            display_map[v]= dsp
        sorted_vals= sorted(display_map.keys(), key=lambda x: display_map[x].lower())

        if col=="Dimension":
            curr = self.selected_dims
        else:
            curr = self.selected_attrs

        if not curr:
            curr = set(unique_vals)

        selall_var= tk.BooleanVar(value=True)
        def toggle_all():
            check= selall_var.get()
            for vb in var_dict.values():
                vb.set(check)

        ctk.CTkCheckBox(
            frame, text="Select All", variable=selall_var, command=toggle_all,
            fg_color="#800020", hover_color="#a52a2a", text_color="white"
        ).pack(anchor="w", pady=5)

        scroll= ctk.CTkScrollableFrame(frame, width=250, height=250)
        scroll.pack(fill="both", expand=True, padx=5, pady=5)
        var_dict={}
        for rv in sorted_vals:
            in_filter= rv in curr
            bvar= tk.BooleanVar(value=in_filter)
            var_dict[rv]= bvar
            ctk.CTkCheckBox(
                scroll, text=display_map[rv], variable=bvar,
                fg_color="#800020", hover_color="#a52a2a", text_color="white"
            ).pack(anchor="w")

        def apply_():
            sel= {rv for rv,vb in var_dict.items() if vb.get()}
            if col=="Dimension":
                self.selected_dims = sel
            else:
                self.selected_attrs = sel
            popup.destroy()
            self.update_data_filters()

        bf= ctk.CTkFrame(frame)
        bf.pack(fill="x", pady=5)
        ctk.CTkButton(
            bf, text="Apply", command=apply_,
            fg_color="#800020", hover_color="#a52a2a", text_color="white"
        ).pack(side="left", padx=5)
        ctk.CTkButton(
            bf, text="Cancel", command=popup.destroy,
            fg_color="#800020", hover_color="#a52a2a", text_color="white"
        ).pack(side="left", padx=5)

    def update_data(self, df_current: pd.DataFrame, df_history: pd.DataFrame):
        self.df_current = df_current.copy()
        self.df_history = df_history.copy()
        self.update_data_filters()

    def update_data_filters(self):
        dfc = self.df_current.copy()
        if not dfc.empty:
            if self.selected_dims:
                dfc = dfc[dfc["Dimension"].isin(self.selected_dims)]
            if self.selected_attrs:
                dfc = dfc[dfc["Attribute"].isin(self.selected_attrs)]
            if "RunDate" in dfc.columns:
                try:
                    s_val = self.start_date_var.get()
                    e_val = self.end_date_var.get()
                    if s_val and e_val:
                        start = datetime.strptime(s_val, "%Y-%m-%d")
                        end = datetime.strptime(e_val, "%Y-%m-%d")
                        dfc["RunDate_dt"] = pd.to_datetime(dfc["RunDate"], errors="coerce")
                        dfc = dfc[(dfc["RunDate_dt"]>= start) & (dfc["RunDate_dt"]<= end)]
                except Exception as e:
                    logging.error(f"Date filter error => {e}")

        mism = len(dfc)
        dims = dfc["Dimension"].nunique() if not dfc.empty and "Dimension" in dfc.columns else 0
        self.metric_label.configure(text=f"Mismatches: {mism}, Dims: {dims}")

        self.plotHeatmap(dfc)
        self.plotLollipop(dfc)
        self.plotCircular(dfc)
        self.plotScatter(dfc)
        self.plotRadar(dfc)
        self.plotNormalPie(dfc)
        self.plotNormalBar(dfc)
        self.plotBandChart()

    def plot_chart(self, frame, fig):
        for w in frame.winfo_children():
            w.destroy()
        canvas = FigureCanvasTkAgg(fig, master=frame)
        canvas.draw()
        canvas.get_tk_widget().pack(fill="both", expand=True)

    def _head_if_needed(self, series: pd.Series) -> pd.Series:
        if self.top_n == 10:
            return series.head(10)
        else:
            return series

    def plotHeatmap(self, dfc: pd.DataFrame):
        fr= self.frames["Heatmap"]
        for w in fr.winfo_children():
            w.destroy()
        if dfc.empty or "Missing In" not in dfc.columns:
            return
        df_m = dfc[dfc["Missing In"]!=""]
        if df_m.empty or not {"Dimension","Attribute"}.issubset(df_m.columns):
            return
        pivot= df_m.groupby(["Dimension","Attribute"]).size().unstack(fill_value=0)
        fig, ax= plt.subplots(figsize=(6,5))
        cax= ax.imshow(pivot, aspect="auto", cmap="Reds")
        ax.set_xticks(range(len(pivot.columns)))
        ax.set_xticklabels(pivot.columns, rotation=90)
        ax.set_yticks(range(len(pivot.index)))
        ax.set_yticklabels(pivot.index)
        fig.colorbar(cax, ax=ax)
        ax.set_title("Heatmap: Missing Items")
        self.plot_chart(fr, fig)

    def plotLollipop(self, dfc: pd.DataFrame):
        fr= self.frames["Lollipop"]
        for w in fr.winfo_children():
            w.destroy()
        if dfc.empty or "Missing In" not in dfc.columns:
            return
        df_m = dfc[dfc["Missing In"]!=""]
        if df_m.empty:
            return
        cdim = df_m.groupby("Dimension")["Key"].count().sort_values(ascending=False)
        cdim = self._head_if_needed(cdim)
        if cdim.empty:
            return
        fig, ax= plt.subplots(figsize=(6,5))
        ax.hlines(y=cdim.index, xmin=0, xmax=cdim.values, color="skyblue")
        ax.plot(cdim.values, cdim.index, "o", color="skyblue")
        ax.set_title("Lollipop: Missing Dimensions")
        ax.set_xlabel("Missing Count")
        self.plot_chart(fr, fig)

    def plotCircular(self, dfc: pd.DataFrame):
        fr= self.frames["Circular"]
        for w in fr.winfo_children():
            w.destroy()
        if dfc.empty or "Missing In" not in dfc.columns:
            return
        df_m= dfc[dfc["Missing In"]!=""]
        if df_m.empty:
            return
        cattr= df_m.groupby("Attribute")["Key"].count().sort_values(ascending=False)
        cattr= self._head_if_needed(cattr)
        if cattr.empty:
            return
        cat= cattr.index.tolist()
        val= cattr.values
        angles= np.linspace(0,2*np.pi,len(cat), endpoint=False)
        fig= plt.figure(figsize=(6,6))
        ax= fig.add_subplot(111, polar=True)
        ax.set_theta_offset(np.pi/2)
        ax.set_theta_direction(-1)
        ax.set_xticks(angles)
        ax.set_xticklabels(cat, fontsize=9)
        ax.bar(angles, val, width=0.4, color="orange", alpha=0.6)
        ax.set_title("Circular: Missing Attributes", y=1.05)
        self.plot_chart(fr, fig)

    def plotScatter(self, dfc: pd.DataFrame):
        fr= self.frames["Scatter"]
        for w in fr.winfo_children():
            w.destroy()
        if dfc.empty or "Missing In" not in dfc.columns:
            return
        df_m= dfc[dfc["Missing In"]!=""]
        if df_m.empty:
            return
        cdim= df_m.groupby("Dimension")["Key"].count().reset_index(name="Count")
        cdim.sort_values("Count", ascending=False, inplace=True)
        if self.top_n == 10:
            cdim = cdim.head(10)
        if cdim.empty:
            return
        xvals= np.arange(len(cdim))
        yvals= cdim["Count"].values
        labels= cdim["Dimension"].values
        fig, ax= plt.subplots(figsize=(6,5))
        ax.scatter(xvals,yvals,color="green")
        for i, txt in enumerate(labels):
            ax.text(xvals[i], yvals[i], txt, ha="center", va="bottom", rotation=60)
        ax.set_xticks([])
        ax.set_ylabel("Missing Count")
        ax.set_title("Scatter: Missing by Dimension")
        self.plot_chart(fr, fig)

    def plotRadar(self, dfc: pd.DataFrame):
        fr= self.frames["Radar"]
        for w in fr.winfo_children():
            w.destroy()
        if dfc.empty or "Missing In" not in dfc.columns:
            return
        df_m= dfc[dfc["Missing In"]!=""]
        if df_m.empty:
            return
        cdim= df_m.groupby("Dimension")["Key"].count().sort_values(ascending=False)
        if self.top_n == 10:
            cdim = cdim.head(10)
        if cdim.empty:
            return
        cat= cdim.index.tolist()
        val= cdim.values.tolist()
        N= len(cat)
        if N<2:
            return
        angles= np.linspace(0,2*np.pi,N, endpoint=False).tolist()
        angles+= angles[:1]
        val+= val[:1]
        fig= plt.figure(figsize=(6,6))
        ax= fig.add_subplot(111, polar=True)
        ax.set_theta_offset(np.pi/2)
        ax.set_theta_direction(-1)
        ax.set_xticks(angles[:-1])
        ax.set_xticklabels(cat, fontsize=9)
        ax.plot(angles, val, color="red", linewidth=2)
        ax.fill(angles, val, color="red", alpha=0.3)
        ax.set_title("Radar: Missing Dims", y=1.08)
        self.plot_chart(fr, fig)

    def plotNormalPie(self, dfc: pd.DataFrame):
        fr= self.frames["Normal Pie"]
        for w in fr.winfo_children():
            w.destroy()
        if dfc.empty or "Missing In" not in dfc.columns:
            return
        df_m= dfc[dfc["Missing In"]!=""]
        if df_m.empty:
            return
        dist= df_m["Missing In"].value_counts()
        fig, ax= plt.subplots(figsize=(5,5))
        ax.pie(dist.values, labels=dist.index, autopct="%.1f%%", startangle=140)
        ax.set_title("Pie: Missing In distribution")
        self.plot_chart(fr, fig)

    def plotNormalBar(self, dfc: pd.DataFrame):
        fr= self.frames["Normal Bar"]
        for w in fr.winfo_children():
            w.destroy()
        if dfc.empty or "Missing In" not in dfc.columns:
            return
        df_m= dfc[dfc["Missing In"]!=""]
        if df_m.empty:
            return
        cattr= df_m.groupby("Attribute")["Key"].count().sort_values(ascending=False)
        if self.top_n == 10:
            cattr= cattr.head(10)
        if cattr.empty:
            return
        fig, ax= plt.subplots(figsize=(6,4))
        bars = ax.bar(range(len(cattr)), cattr.values, color="blue")
        ax.set_xticks(range(len(cattr)))
        ax.set_xticklabels(cattr.index, rotation=45, ha="right")
        ax.set_ylabel("Missing Count")
        ax.set_title("Bar: Missing attributes")

        for bar in bars:
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2., height,
                    f'{int(height)}',
                    ha='center', va='bottom')

        plt.tight_layout()
        self.plot_chart(fr, fig)

    def plotBandChart(self):
        fr= self.frames["Band Chart"]
        for w in fr.winfo_children():
            w.destroy()
        if self.df_history.empty or "RunDate" not in self.df_history.columns:
            return
        date_ct= self.df_history.groupby("RunDate")["Key"].count().reset_index(name="Count")
        date_ct.sort_values("RunDate", inplace=True)
        if date_ct.empty:
            return
        date_ct["Count_min"] = date_ct["Count"]*0.9
        date_ct["Count_max"] = date_ct["Count"]*1.1
        fig, ax= plt.subplots(figsize=(6,4))
        ax.plot(date_ct["RunDate"], date_ct["Count"], color="purple", marker="o", label="Missing Count")
        ax.fill_between(date_ct["RunDate"], date_ct["Count_min"], date_ct["Count_max"],
                        color="purple", alpha=0.2, label="±10% band")
        ax.set_title("Band Chart Over Time")
        ax.set_xlabel("RunDate")
        ax.set_ylabel("Missing Count")
        plt.xticks(rotation=45)
        ax.legend()
        for i, row in date_ct.iterrows():
            ax.text(row["RunDate"], row["Count"], str(row["Count"]), ha="center", va="bottom")
        self.plot_chart(fr, fig)

# ----------------------------------------------------------------------------
# MAIN APP
# ----------------------------------------------------------------------------
class MainApp(ctk.CTk):
    def __init__(self):
        super().__init__()
        self.title("Ultra-Mega Reconciliation: Param-based, Full Dashboard")
        self.geometry("1600x900")
        ctk.set_appearance_mode("light")

        # Load config + param
        self.config_dict = load_config(Path(DEFAULT_PATHS["CONFIG_PATH"]))
        self.param_dict = read_param_file(
            Path(self.config_dict["paths"].get("PARAMETER_PATH", DEFAULT_PATHS["PARAMETER_PATH"]))
        )
        self.history_df = pd.DataFrame()

        self.tabs = ttk.Notebook(self)
        self.tabs.pack(fill="both", expand=True)

        # 1) Paths Tab
        self.tab_paths = ctk.CTkFrame(self.tabs)
        self.tabs.add(self.tab_paths, text="Paths")
        self.build_paths_tab(self.tab_paths)

        # 2) ERP Preview
        self.tab_erp = ctk.CTkFrame(self.tabs)
        self.erp_preview = SimplePreview(self.tab_erp, "ERP")
        self.erp_preview.pack(fill="both", expand=True)
        self.tabs.add(self.tab_erp, text="ERP Preview")

        # 3) Master Preview
        self.tab_master = ctk.CTkFrame(self.tabs)
        self.master_preview = SimplePreview(self.tab_master, "Master")
        self.master_preview.pack(fill="both", expand=True)
        self.tabs.add(self.tab_master, text="Master Preview")

        # 4) Compare
        self.tab_compare = ctk.CTkFrame(self.tabs)
        self.build_compare_tab(self.tab_compare)
        self.tabs.add(self.tab_compare, text="Compare")

        # 5) Dashboard
        # Notice: PDF Export button is removed from the Dashboard
        self.dashboard_tab = AdvancedDashboard(self.tabs)
        self.tabs.add(self.dashboard_tab, text="Dashboard")

        # Logging
        self.log_box = ctk.CTkTextbox(self, height=120)
        self.log_box.pack(fill="both")
        self.log_box.configure(state="disabled")
        handler = TextHandler(self.log_box)
        handler.setLevel(logging.INFO)
        logging.getLogger().addHandler(handler)

        # Master CSV dir
        self.temp_csv_dir = Path(self.config_dict["paths"].get("MASTER_CSV_OUTPUT","temp_master_csv"))
        self.temp_csv_dir.mkdir(parents=True, exist_ok=True)

        # Auto load meltdown => pivot => preview
        self.refresh_erp()
        self.refresh_master()

    def build_paths_tab(self, parent):
        """
        Build a form for browsing ERP Excel, Master ZIP, Exception, Output, JSON config,
        Param file, Master CSV, PDF Export path.
        """
        frm= ctk.CTkFrame(parent)
        frm.pack(fill="both", expand=True, padx=10, pady=10)

        self.erp_var= tk.StringVar(value=self.config_dict["paths"].get("ERP_EXCEL_PATH", DEFAULT_PATHS["ERP_EXCEL_PATH"]))
        self.mast_var= tk.StringVar(value=self.config_dict["paths"].get("MASTER_ZIP_PATH", DEFAULT_PATHS["MASTER_ZIP_PATH"]))
        self.exc_var= tk.StringVar(value=self.config_dict["paths"].get("EXCEPTION_PATH", DEFAULT_PATHS["EXCEPTION_PATH"]))
        self.out_var= tk.StringVar(value=self.config_dict["paths"].get("OUTPUT_PATH", DEFAULT_PATHS["OUTPUT_PATH"]))
        self.cfg_var= tk.StringVar(value=self.config_dict["paths"].get("CONFIG_PATH", DEFAULT_PATHS["CONFIG_PATH"]))
        self.par_var= tk.StringVar(value=self.config_dict["paths"].get("PARAMETER_PATH", DEFAULT_PATHS["PARAMETER_PATH"]))
        self.csv_var= tk.StringVar(value=self.config_dict["paths"].get("MASTER_CSV_OUTPUT", DEFAULT_PATHS["MASTER_CSV_OUTPUT"]))
        self.pdf_var= tk.StringVar(value=self.config_dict["paths"].get("PDF_EXPORT_PATH", DEFAULT_PATHS["PDF_EXPORT_PATH"]))

        def mkrow(lbl, var, is_dir=False):
            rowf= ctk.CTkFrame(frm)
            rowf.pack(fill="x", pady=5)
            ctk.CTkLabel(rowf, text=lbl, width=180).pack(side="left", padx=5)
            e = ctk.CTkEntry(rowf, textvariable=var, width=600)
            e.pack(side="left", padx=5)

            def br():
                if is_dir:
                    p= filedialog.askdirectory()
                else:
                    p= filedialog.askopenfilename()
                if p:
                    var.set(p)

            ctk.CTkButton(rowf, text="Browse", command=br,
                          fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)

        mkrow("ERP Excel:", self.erp_var)
        mkrow("Master ZIP:", self.mast_var)
        mkrow("Exception Path:", self.exc_var)
        mkrow("Missing Items Output:", self.out_var)
        mkrow("JSON Config Path:", self.cfg_var)
        mkrow("Parameter File:", self.par_var)
        mkrow("Master CSV Folder:", self.csv_var, is_dir=True)
        mkrow("PDF Export Path:", self.pdf_var, is_dir=False)

        bf= ctk.CTkFrame(frm)
        bf.pack(fill="x", pady=10)
        ctk.CTkButton(bf, text="Save Config", command=self.save_all_config,
                      fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)
        ctk.CTkButton(bf, text="Refresh ERP", command=self.refresh_erp,
                      fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)
        ctk.CTkButton(bf, text="Refresh Master", command=self.refresh_master,
                      fg_color="#800020", hover_color="#a52a2a").pack(side="left", padx=5)

    def build_compare_tab(self, parent):
        frm= ctk.CTkFrame(parent)
        frm.pack(fill="both", expand=True, padx=10, pady=10)
        ctk.CTkLabel(frm, text="Generate Missing Items", font=("Arial",16)).pack(pady=5)
        ctk.CTkButton(frm, text="Run Reconciliation", command=self.run_comparison,
                      fg_color="#800020", hover_color="#a52a2a").pack(pady=10)

        # PDF export button (only here)
        ctk.CTkButton(frm, text="Export PDF Report",
                      command=self.export_pdf,
                      fg_color="#800020", hover_color="#a52a2a").pack(pady=10)

    def export_pdf(self):
        """Export the PDF using EnhancedPDFReport with the current mismatch data."""
        if self.history_df.empty:
            messagebox.showinfo("PDF Export", "No mismatch data to export (history is empty).")
            return

        last_date = self.history_df["RunDate"].max()
        df_current = self.history_df[self.history_df["RunDate"]==last_date].copy()
        df_history = self.history_df.copy()

        rep = EnhancedPDFReport(df_current, df_history, self.config_dict)
        pdf_path = rep.generate()
        messagebox.showinfo("PDF Export", f"PDF exported => {pdf_path}")

    def refresh_erp(self):
        erp_path= Path(self.erp_var.get().strip())
        raw_erp = read_erp_excel(erp_path)
        if raw_erp.empty:
            self.erp_preview.set_data(pd.DataFrame())
            return
        param = {
            "dim_erp_keep": self.param_dict.get("dim_erp_keep", set()),
            "dim_erp_map": self.param_dict.get("dim_erp_map", {}),
            "attr_erp_map": self.param_dict.get("attr_erp_map", {})
        }
        melted = meltdown_erp_for_preview(raw_erp, param)
        pivoted = pivot_for_preview(melted)
        self.erp_preview.set_data(pivoted)

    def refresh_master(self):
        zip_path= Path(self.mast_var.get().strip())
        out_dir= Path(self.csv_var.get().strip())
        csvs= convert_master_txt_to_csv(zip_path, out_dir)
        raw_mast = unify_master_csvs(csvs)
        if raw_mast.empty:
            self.master_preview.set_data(pd.DataFrame())
            return
        param = {
            "dim_master_map": self.param_dict.get("dim_master_map", {}),
            "attr_master_map": self.param_dict.get("attr_master_map", {})
        }
        melted = meltdown_master_for_preview(raw_mast, param)
        pivoted = pivot_for_preview(melted)
        self.master_preview.set_data(pivoted)

    def run_comparison(self):
        df_erp_wide = self.erp_preview.get_filtered_df()
        df_mast_wide= self.master_preview.get_filtered_df()

        erp_long = melt_back(df_erp_wide)
        erp_long = build_keys(erp_long)
        mast_long= melt_back(df_mast_wide)
        mast_long= build_keys(mast_long)

        df_diff= compare_mode2(erp_long, mast_long)

        exc_path= Path(self.exc_var.get().strip())
        df_exc= read_exception_table(exc_path)
        final= merge_exceptions(df_diff, df_exc)

        out_path= Path(self.out_var.get().strip())
        write_missing_items(final, out_path)

        # update dash
        run_date= datetime.now().strftime("%Y-%m-%d")
        final["RunDate"] = run_date
        if self.history_df.empty:
            self.history_df= final.copy()
        else:
            self.history_df= pd.concat([self.history_df, final], ignore_index=True)

        self.dashboard_tab.update_data(final, self.history_df)
        self.tabs.select(self.dashboard_tab)

        messagebox.showinfo("Done", f"Missing items => {out_path}")

    def save_all_config(self):
        self.config_dict["paths"]["ERP_EXCEL_PATH"] = self.erp_var.get().strip()
        self.config_dict["paths"]["MASTER_ZIP_PATH"] = self.mast_var.get().strip()
        self.config_dict["paths"]["EXCEPTION_PATH"] = self.exc_var.get().strip()
        self.config_dict["paths"]["OUTPUT_PATH"] = self.out_var.get().strip()
        self.config_dict["paths"]["CONFIG_PATH"] = self.cfg_var.get().strip()
        self.config_dict["paths"]["PARAMETER_PATH"] = self.par_var.get().strip()
        self.config_dict["paths"]["MASTER_CSV_OUTPUT"] = self.csv_var.get().strip()
        self.config_dict["paths"]["PDF_EXPORT_PATH"] = self.pdf_var.get().strip()
        # We do not show or overwrite LOGO_PATH in the GUI

        save_config(self.config_dict, Path(self.config_dict["paths"]["CONFIG_PATH"]))
        messagebox.showinfo("Saved", "Paths & Config saved successfully.")

def main():
    app= MainApp()
    app.mainloop()

if __name__=="__main__":
    main()
