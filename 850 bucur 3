#!/usr/bin/env python3
"""
Ultra-Mega Reconciliation 
 - Name-first logic => 2-sheets (Mismatch + Case)
 - SHIFTED PDF with burgundy Excel for Mismatch
 - "missing_items.xlsx" for immediate results + a timestamped copy
 - Optional local folder for Master .txt or .zip
 - Trim Key toggle
 - AdvancedDashboard for mismatch only
 - HistoryTab
 - Name as an attribute (if missing/diff => skip other attributes)
"""

import os
import sys
import json
import logging
import zipfile
import shutil
import io
from pathlib import Path
from datetime import datetime, date
from typing import Dict, Set, List, Tuple

import tkinter as tk
from tkinter import ttk, filedialog, messagebox
import customtkinter as ctk

import pandas as pd
import numpy as np

import matplotlib
matplotlib.use("TkAgg")
import matplotlib.pyplot as plt
from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg, NavigationToolbar2Tk
from matplotlib.backends.backend_pdf import PdfPages

from openpyxl import Workbook
from openpyxl.styles import PatternFill, Font, Alignment
from openpyxl.utils import get_column_letter
from openpyxl.worksheet.table import Table, TableStyleInfo

logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")


# ----------------------------------------------------------------------------
# DEFAULTS + CONFIG
# ----------------------------------------------------------------------------
DEFAULT_PATHS = {
    "ERP_EXCEL_PATH": "data/ERP_Config.xlsx",
    "MASTER_ZIP_PATH": "data/Master_Config.zip",
    "MASTER_TXT_FOLDER": "",
    "EXCEPTION_PATH": "data/Exception_Table.xlsx",
    "OUTPUT_PATH": "output/missing_items.xlsx",
    "CONFIG_PATH": "config/ui_config.json",
    "PARAMETER_PATH": "data/parameters.xlsx",
    "MASTER_CSV_OUTPUT": "temp_master_csv",
    "PDF_EXPORT_PATH": "output/dashboard_report.pdf",
    "LOGO_PATH": "images/company_logo.png",
    "HISTORY_PATH": "history_runs",
    "BAND_CHART_JSON_PATH": "data/bollinger_data.json"
}

def default_config() -> Dict:
    return {
        "paths": DEFAULT_PATHS.copy(),
        "erp_grid": {
            "filters": {}
        },
        "master_grid": {
            "filters": {}
        },
        "dashboard": {
            "selected_dims": [],
            "selected_attrs": [],
            "top_n": 10
        },
        "trim_key_toggle": False
    }

def load_config(path: Path)->Dict:
    if path.is_file():
        try:
            with open(path,"r",encoding="utf-8") as f:
                return json.load(f)
        except Exception as e:
            logging.warning(f"Could not load config => {e}")
    return default_config()

def save_config(cfg: Dict, path: Path):
    path.parent.mkdir(parents=True, exist_ok=True)
    try:
        # sets->lists in erp_grid
        if "erp_grid" in cfg and "filters" in cfg["erp_grid"]:
            new_erp={}
            for col,valset in cfg["erp_grid"]["filters"].items():
                new_erp[col]= list(valset)
            cfg["erp_grid"]["filters"]= new_erp
        # sets->lists in master_grid
        if "master_grid" in cfg and "filters" in cfg["master_grid"]:
            new_m={}
            for col,valset in cfg["master_grid"]["filters"].items():
                new_m[col]= list(valset)
            cfg["master_grid"]["filters"]= new_m

        with open(path,"w",encoding="utf-8") as f:
            json.dump(cfg,f,indent=2)
        logging.info(f"Saved config => {path}")
    except Exception as e:
        logging.error(f"save_config => {e}")


# ----------------------------------------------------------------------------
# TEXT LOGGER
# ----------------------------------------------------------------------------
class TextHandler(logging.Handler):
    def __init__(self, widget: ctk.CTkTextbox):
        super().__init__()
        self.widget= widget
    def emit(self, record):
        msg= self.format(record)+ "\n"
        self.widget.after(0, self._append, msg)
    def _append(self, msg):
        self.widget.configure(state="normal")
        self.widget.insert("end", msg)
        self.widget.see("end")
        self.widget.configure(state="disabled")


# ----------------------------------------------------------------------------
# READ PARAM
# ----------------------------------------------------------------------------
def read_param_file(path: Path)-> Dict[str, object]:
    param= {
        "dim_erp_keep": set(),
        "dim_erp_map": {},
        "dim_master_map": {},
        "attr_erp_map": {},
        "attr_master_map": {}
    }
    if not path.is_file():
        logging.warning(f"Param => {path} not found")
        return param
    try:
        dim_df= pd.read_excel(path, sheet_name="Dimension Parameters")
        dim_df.columns= dim_df.columns.astype(str).str.strip()

        def s(x)->str: return str(x).strip() if pd.notna(x) else ""
        for _, row in dim_df.iterrows():
            fn= s(row.get("FileName",""))
            vsc= s(row.get("V S C",""))
            dim= s(row.get("Dimension",""))
            ev= s(row.get("ERP Values",""))
            if ev.lower()=="x" and vsc and dim:
                param["dim_erp_keep"].add(vsc)
            if vsc and dim:
                param["dim_erp_map"][vsc]= dim
            if fn and dim and ev.lower()=="x":
                param["dim_master_map"][fn]= dim

        attr_df= pd.read_excel(path, sheet_name="Attribute Parameters")
        attr_df.columns= attr_df.columns.astype(str).str.strip()
        for _, row in attr_df.iterrows():
            e_orig= s(row.get("ERP Original Attributes",""))
            m_orig= s(row.get("Master Original Attributes",""))
            final_= s(row.get("Attribute",""))
            onoff= s(row.get("On/Off",""))
            if onoff.lower()=="x" and final_:
                if e_orig:
                    param["attr_erp_map"][e_orig]= final_
                if m_orig:
                    param["attr_master_map"][m_orig]= final_
        return param
    except Exception as e:
        logging.error(f"read_param_file => {e}")
        return param


# ----------------------------------------------------------------------------
# ERP
# ----------------------------------------------------------------------------
def read_erp_excel(path: Path)-> pd.DataFrame:
    if not path.is_file():
        logging.warning(f"ERP Excel => {path} not exist")
        return pd.DataFrame()
    try:
        df= pd.read_excel(path, skiprows=3)
        df.columns= df.columns.str.strip()
        if "Enabled_Flag" in df.columns:
            df= df[df["Enabled_Flag"]=="Enabled"]
        return df
    except Exception as e:
        logging.error(f"read_erp_excel => {e}")
        return pd.DataFrame()

# ----------------------------------------------------------------------------
# MASTER => local folder or zip
# ----------------------------------------------------------------------------
def try_read_csv_bytes(raw: bytes)-> pd.DataFrame:
    encs= ["utf-8-sig","utf-16-le","utf-16-be","cp1252","latin-1","ascii"]
    import io
    for enc in encs:
        try:
            buf= io.BytesIO(raw)
            df= pd.read_csv(buf, encoding=enc, on_bad_lines="skip", engine="python")
            df.dropna(how="all", axis=0, inplace=True)
            df.dropna(how="all", axis=1, inplace=True)
            df.columns= df.columns.astype(str).str.strip()
            if "Name" not in df.columns and len(df.columns)>0:
                fc= df.columns[0]
                df.rename(columns={fc:"Name"}, inplace=True)
            return df
        except:
            pass
    logging.error("All enc fail => returning empty DF")
    return pd.DataFrame()

def unify_master_txt_in_folder(folder: Path)-> pd.DataFrame:
    if not folder.is_dir():
        logging.warning(f"Master folder => {folder} not exist")
        return pd.DataFrame()
    txts= list(folder.glob("*.txt"))
    if not txts:
        logging.warning(f"No txt => {folder}")
        return pd.DataFrame()
    frames=[]
    for f in txts:
        try:
            raw= f.read_bytes()
            df= try_read_csv_bytes(raw)
            if not df.empty:
                df["RawFileName"]= f.name
                frames.append(df)
        except Exception as e:
            logging.error(f"unify_master_txt_in_folder => {f} => {e}")
    if frames:
        return pd.concat(frames,ignore_index=True)
    return pd.DataFrame()

def convert_master_txt_to_csv(zip_path: Path, out_dir: Path)-> List[Path]:
    if not zip_path.is_file():
        logging.warning(f"Master ZIP => {zip_path} not found")
        return []
    if out_dir.exists():
        shutil.rmtree(out_dir, ignore_errors=True)
    out_dir.mkdir(parents=True,exist_ok=True)
    csvs=[]
    with zipfile.ZipFile(zip_path,"r") as z:
        txt_files= [f for f in z.namelist() if f.lower().endswith(".txt")]
        for txtf in txt_files:
            bn= os.path.basename(txtf)
            if not bn:
                continue
            try:
                with z.open(txtf) as fo:
                    raw= fo.read()
                df= try_read_csv_bytes(raw)
                if df.empty:
                    continue
                df["RawFileName"]= bn
                out_csv= out_dir/(bn.replace(".txt",".csv"))
                df.to_csv(out_csv,index=False,encoding="utf-8")
                csvs.append(out_csv)
            except Exception as e:
                logging.error(f"Reading {txtf} => {e}")
    return csvs

def unify_master_csvs(csvs: List[Path])-> pd.DataFrame:
    frames=[]
    for c in csvs:
        if not c.is_file():
            continue
        try:
            df= pd.read_csv(c, encoding="utf-8", on_bad_lines="skip")
            df.columns= df.columns.str.strip()
            frames.append(df)
        except Exception as e:
            logging.error(f"unify_master_csvs => {c} => {e}")
    if frames:
        return pd.concat(frames, ignore_index=True)
    return pd.DataFrame()


# ----------------------------------------------------------------------------
# MELTDOWN => we have meltdown_erp_for_preview & meltdown_master_for_preview
# ----------------------------------------------------------------------------
def meltdown_erp_for_preview(df: pd.DataFrame, param: Dict[str,object])-> pd.DataFrame:
    if "V_S_C" not in df.columns:
        return pd.DataFrame()
    keep= param["dim_erp_keep"]
    dmap= param["dim_erp_map"]
    amap= param["attr_erp_map"]

    df2= df[df["V_S_C"].isin(keep)].copy()
    if df2.empty:
        return pd.DataFrame()

    skip_cols= {"V_S_C","Enabled_Flag"}
    id_vars=[]
    if "Value" in df2.columns:
        id_vars.append("Value")
        skip_cols.add("Value")
    df2["DimRaw"]= df2["V_S_C"]
    skip_cols.add("DimRaw")
    id_vars.insert(0,"DimRaw")

    meltdown_cols= [c for c in df2.columns if c not in skip_cols]
    melted= df2.melt(
        id_vars=id_vars,
        value_vars= meltdown_cols,
        var_name="OrigAttr",
        value_name="ValX"
    )

    def rename_dim(x):
        return dmap.get(x,x)
    melted["Dimension"]= melted["DimRaw"].apply(rename_dim)

    if "Value" in id_vars:
        melted.rename(columns={"Value":"Name"}, inplace=True)
    else:
        melted["Name"]= ""

    # filter attributes
    melted= melted[melted["OrigAttr"].isin(amap.keys())].copy()
    melted["Attribute"]= melted["OrigAttr"].map(amap)

    def strip_t(val):
        if isinstance(val,str) and "T" in val:
            return val.split("T")[0]
        return val

    melted["Value"]= np.where(
        melted["Attribute"].isin(["Start Date","End Date"]),
        melted["ValX"].apply(strip_t),
        melted["ValX"]
    )
    return melted[["Dimension","Name","Attribute","Value"]]

def meltdown_master_for_preview(df: pd.DataFrame, param: Dict[str,object])-> pd.DataFrame:
    if df.empty or "RawFileName" not in df.columns:
        return pd.DataFrame()
    keep_map= param["dim_master_map"]
    amap= param["attr_master_map"]

    df2= df[df["RawFileName"].isin(keep_map.keys())].copy()
    if df2.empty:
        return pd.DataFrame()

    df2["DimRaw"]= df2["RawFileName"]
    skip_cols= {"RawFileName","DimRaw"}
    id_vars= ["DimRaw"]
    if "Name" in df2.columns:
        id_vars.append("Name")
        skip_cols.add("Name")

    meltdown_cols= [c for c in df2.columns if c not in skip_cols]
    melted= df2.melt(
        id_vars=id_vars,
        value_vars= meltdown_cols,
        var_name="OrigAttr",
        value_name="ValX"
    )

    def rename_dim(x):
        return keep_map.get(x,x)
    melted["Dimension"]= melted["DimRaw"].apply(rename_dim)

    if "Name" in id_vars:
        melted.rename(columns={"Name":"Name"}, inplace=True)
    else:
        melted["Name"]= ""

    # filter attributes
    melted= melted[melted["OrigAttr"].isin(amap.keys())].copy()
    melted["Attribute"]= melted["OrigAttr"].map(amap)

    def strip_t(val):
        if isinstance(val,str) and "T" in val:
            return val.split("T")[0]
        return val

    melted["Value"]= np.where(
        melted["Attribute"].isin(["Start Date","End Date"]),
        melted["ValX"].apply(strip_t),
        melted["ValX"]
    )
    return melted[["Dimension","Name","Attribute","Value"]]


def pivot_for_preview(df: pd.DataFrame)-> pd.DataFrame:
    if df.empty or not {"Dimension","Name","Attribute"}.issubset(df.columns):
        return pd.DataFrame()
    df2= df.drop_duplicates(subset=["Dimension","Name","Attribute"])
    try:
        out= df2.pivot(index=["Dimension","Name"], columns="Attribute", values="Value").reset_index()
        return out
    except Exception as e:
        logging.error(f"pivot_for_preview => {e}")
        return pd.DataFrame()


# ----------------------------------------------------------------------------
# COMPARISON => Name-first => mismatch + case
# ----------------------------------------------------------------------------
def meltdown_to_long(df_wide: pd.DataFrame)-> pd.DataFrame:
    if df_wide.empty or {"Dimension","Name"}.difference(df_wide.columns):
        return pd.DataFrame()
    meltdown_cols= [c for c in df_wide.columns if c not in ("Dimension","Name")]
    melted= df_wide.melt(
        id_vars=["Dimension","Name"],
        value_vars= meltdown_cols,
        var_name="Attribute",
        value_name="Value"
    )
    melted["Value"]= melted["Value"].fillna("")
    return melted

def compare_name_first(erp_long: pd.DataFrame, mast_long: pd.DataFrame, trim_key=False) -> Tuple[pd.DataFrame,pd.DataFrame]:
    """
    Name-first logic => mismatch + case:
      - If Name is missing or differs => single row => skip other attributes
      - If Name matches => compare other attributes
      - case-only => goes to case df
    """
    def build_dict(d: pd.DataFrame):
        out={}
        for (dim,nm), grp in d.groupby(["Dimension","Name"]):
            rec={}
            for _, row in grp.iterrows():
                rec[row["Attribute"]]= row["Value"]
            out[(dim,nm)]= rec
        return out

    mismatch_rows=[]
    case_rows=[]
    e_dict= build_dict(erp_long)
    m_dict= build_dict(mast_long)
    all_pairs= set(e_dict.keys())| set(m_dict.keys())

    for pr in all_pairs:
        dim,nm= pr
        e_map= e_dict.get(pr,{})
        m_map= m_dict.get(pr,{})
        e_name= e_map.get("Name","")
        m_name= m_map.get("Name","")

        name_issue= False
        # missing in ERP
        if pr not in e_dict and pr in m_dict:
            row= {
                "Dimension":dim,"Name":nm,
                "Attribute":"Name",
                "Master":m_name,
                "ERP":"",
                "Comments_1":"",
                "Comments_2":"",
                "Gap In":"ERP"
            }
            raw= f"{dim}|{nm}|Name|{m_name}|".upper()
            if trim_key:
                raw= raw.replace(" ","")
            row["Key"]= raw
            mismatch_rows.append(row)
            name_issue= True
        # missing in Master
        elif pr in e_dict and pr not in m_dict:
            row= {
                "Dimension":dim,"Name":nm,
                "Attribute":"Name",
                "Master":"",
                "ERP":e_name,
                "Comments_1":"",
                "Comments_2":"",
                "Gap In":"MASTER"
            }
            raw= f"{dim}|{nm}|Name||{e_name}".upper()
            if trim_key:
                raw= raw.replace(" ","")
            row["Key"]= raw
            mismatch_rows.append(row)
            name_issue= True
        # both => name differ
        elif e_name and m_name and e_name!= m_name:
            # check if case only
            if e_name.lower()== m_name.lower():
                # case
                row= {
                    "Dimension":dim,"Name":nm,
                    "Attribute":"Name",
                    "Master":m_name,
                    "ERP":e_name,
                    "Comments_1":"",
                    "Comments_2":"",
                    "Gap In":"CASE"
                }
                raw= f"{dim}|{nm}|Name|{m_name}|{e_name}".upper()
                if trim_key:
                    raw= raw.replace(" ","")
                row["Key"]= raw
                case_rows.append(row)
            else:
                # mismatch
                row= {
                    "Dimension":dim,"Name":nm,
                    "Attribute":"Name",
                    "Master":m_name,
                    "ERP":e_name,
                    "Comments_1":"",
                    "Comments_2":"",
                    "Gap In":"BOTH"
                }
                raw= f"{dim}|{nm}|Name|{m_name}|{e_name}".upper()
                if trim_key:
                    raw= raw.replace(" ","")
                row["Key"]= raw
                mismatch_rows.append(row)
            name_issue= True

        if name_issue:
            continue

        # if name matches or both empty => compare other attributes
        all_atts= set(e_map.keys())| set(m_map.keys())
        all_atts.discard("Name")
        for at in all_atts:
            ev= e_map.get(at,"")
            mv= m_map.get(at,"")
            if ev.lower()== mv.lower() and ev!= mv and ev and mv:
                # case only
                row= {
                    "Dimension":dim,"Name":nm,"Attribute":at,
                    "Master":mv,"ERP":ev,
                    "Comments_1":"","Comments_2":"",
                    "Gap In":"CASE"
                }
                raw= f"{dim}|{nm}|{at}|{mv}|{ev}".upper()
                if trim_key:
                    raw= raw.replace(" ","")
                row["Key"]= raw
                case_rows.append(row)
            else:
                if ev== mv:
                    continue
                if ev and not mv:
                    gp= "MASTER"
                    ms= ""
                    es= ev
                elif mv and not ev:
                    gp= "ERP"
                    ms= mv
                    es= ""
                else:
                    gp= "BOTH"
                    ms= mv
                    es= ev
                row= {
                    "Dimension":dim,"Name":nm,"Attribute":at,
                    "Master":ms,"ERP":es,
                    "Comments_1":"","Comments_2":"",
                    "Gap In":gp
                }
                raw= f"{dim}|{nm}|{at}|{ms}|{es}".upper()
                if trim_key:
                    raw= raw.replace(" ","")
                row["Key"]= raw
                mismatch_rows.append(row)

    mismatch_cols= ["Key","Dimension","Name","Attribute","Master","ERP","Comments_1","Comments_2","Gap In"]
    mismatch_df= pd.DataFrame(mismatch_rows, columns=mismatch_cols) if mismatch_rows else pd.DataFrame(columns=mismatch_cols)
    case_df= pd.DataFrame(case_rows, columns=mismatch_cols) if case_rows else pd.DataFrame(columns=mismatch_cols)
    return mismatch_df, case_df


# ----------------------------------------------------------------------------
# EXCEPTIONS + Merge => final
# ----------------------------------------------------------------------------
def read_exception_table(path: Path)-> pd.DataFrame:
    if not path.is_file():
        logging.warning(f"Exception => {path} not found")
        return pd.DataFrame()
    try:
        df= pd.read_excel(path)
        df.columns= df.columns.astype(str).str.strip()
        return df
    except:
        return pd.DataFrame()

def merge_exceptions(df: pd.DataFrame, df_exc: pd.DataFrame)-> pd.DataFrame:
    if df.empty or df_exc.empty or "Key" not in df.columns:
        return df
    keep= [c for c in df_exc.columns if c in ("Key","Comments_1","Comments_2","hide exception")]
    if not keep:
        return df
    exc= df_exc[keep].copy()
    exc["Key"]= exc["Key"].astype(str).str.strip()

    merged= df.merge(exc, on="Key", how="left", suffixes=("","_exc"))
    merged["hide exception"]= merged.get("hide exception","").fillna("").str.lower()

    final= merged[merged["hide exception"]!="yes"].copy()
    if "Comments_1_exc" in final.columns:
        final["Comments_1"]= np.where(final["Comments_1_exc"].notna(),
                                      final["Comments_1_exc"],
                                      final["Comments_1"])
        final.drop(columns=["Comments_1_exc"], inplace=True)
    if "Comments_2_exc" in final.columns:
        final["Comments_2"]= np.where(final["Comments_2_exc"].notna(),
                                      final["Comments_2_exc"],
                                      final["Comments_2"])
        final.drop(columns=["Comments_2_exc"], inplace=True)
    if "hide exception" in final.columns:
        final.drop(columns=["hide exception"], inplace=True)
    return final


# ----------------------------------------------------------------------------
# BURGUNDY HEADERS => 2-sheet with Table => "Power BI friendly"
# plus a live "missing_items.xlsx" + timestamped
# ----------------------------------------------------------------------------
def write_2sheet_excel(mismatch_df: pd.DataFrame,
                       case_df: pd.DataFrame,
                       out_path: Path):
    """
    Writes 2 sheets => Mismatch + Case, with burgundy headers, 
    then also saves a timestamped copy. We also add 'Excel Table' for each sheet => Power BI-friendly.
    """
    if mismatch_df.empty and case_df.empty:
        logging.info("No mismatches => skip writing xlsx.")
        return
    out_path.parent.mkdir(parents=True,exist_ok=True)

    columns= ["Key","Dimension","Name","Attribute","Master","ERP","Comments_1","Comments_2","Gap In"]
    for c in columns:
        if c not in mismatch_df.columns:
            mismatch_df[c]= ""
        if c not in case_df.columns:
            case_df[c]= ""

    wb= Workbook()
    ws_m= wb.active
    ws_m.title= "Mismatch"

    ws_c= wb.create_sheet("Case_Differences")

    # fill Mismatch
    ws_m.append(columns)
    for rowvals in mismatch_df[columns].itertuples(index=False):
        ws_m.append(rowvals)
    # fill Case
    ws_c.append(columns)
    for rowvals in case_df[columns].itertuples(index=False):
        ws_c.append(rowvals)

    # burgundy header
    head_font= Font(bold=True,color="FFFFFF")
    head_fill= PatternFill(start_color="800020",end_color="800020",fill_type="solid") # burgundy

    def style_sheet(sheet):
        for cell in sheet[1]:
            cell.font= head_font
            cell.fill= head_fill
            cell.alignment= Alignment(horizontal="center")

        # white data rows
        # we could do row-specific coloring, 
        # but let's keep it white for clarity
        # You can do conditional coloring if you wish

        # auto-size & freeze
        for col in sheet.columns:
            max_len=0
            letter= col[0].column_letter
            for cell in col:
                val= str(cell.value) if cell.value else ""
                max_len= max(max_len,len(val))
            sheet.column_dimensions[letter].width= max_len+2
        sheet.freeze_panes= "A2"

        # add Table => "Power BI friendly"
        last_row= sheet.max_row
        last_col= sheet.max_column
        if last_row>1:
            ref= f"A1:{get_column_letter(last_col)}{last_row}"
            if sheet==ws_m:
                tb= Table(displayName="MismatchTable",ref=ref)
            else:
                tb= Table(displayName="CaseTable",ref=ref)
            style= TableStyleInfo(name="TableStyleMedium9", showRowStripes=True, showColumnStripes=False, showFirstColumn=True)
            tb.tableStyleInfo= style
            sheet.add_table(tb)

    style_sheet(ws_m)
    style_sheet(ws_c)

    wb.save(out_path)
    logging.info(f"Missing items => {out_path}")
    # also a timestamped
    stamp= datetime.now().strftime("%Y%m%d_%H%M%S")
    stamped= out_path.parent/f"{out_path.stem}_{stamp}{out_path.suffix}"
    wb.save(stamped)
    logging.info(f"Timestamped => {stamped}")


# ----------------------------------------------------------------------------
# PDF SHIFT => partial
# ----------------------------------------------------------------------------
class EnhancedPDFReport:
    def __init__(self, df_current: pd.DataFrame, df_history: pd.DataFrame, config: Dict):
        self.df_current= df_current
        self.df_history= df_history
        self.config= config
        self.page_count=0
        self.colors= {
            "primary":"#800020",
            "text":"#2C1810",
            "background":"#FFFFFF"
        }
        self.logo_path= self.config["paths"].get("LOGO_PATH","images/company_logo.png")

        self.PAGE_WIDTH= 8.5
        self.PAGE_HEIGHT= 11
        # SHIFT CHART ~1 inch => we'll do 0.30 left margin

    def generate(self)-> Path:
        stamp= datetime.now().strftime("%Y%m%d_%H%M%S")
        out_dir= Path("Reconciliation_pdf")
        out_dir.mkdir(parents=True,exist_ok=True)
        pdf_name= f"Reconciliation_{stamp}.pdf"
        pdf_path= out_dir/pdf_name
        with PdfPages(pdf_path) as pdf:
            self._cover_page(pdf)
            self._summary_page(pdf)
            self._all_charts(pdf)
        logging.info(f"PDF => {pdf_path}")
        return pdf_path

    def _new_page(self)-> plt.Figure:
        fig= plt.figure(figsize=(self.PAGE_WIDTH,self.PAGE_HEIGHT))
        fig.patch.set_facecolor(self.colors["background"])
        plt.axis("off")
        self.page_count+=1
        if self.logo_path and os.path.exists(self.logo_path):
            try:
                import matplotlib.image as mpimg
                img= mpimg.imread(self.logo_path)
                ax_img= fig.add_axes([0.65,0.75,0.3,0.2])
                ax_img.imshow(img, alpha=0.2)
                ax_img.axis("off")
            except:
                pass
        fig.text(0.5, 0.98, "Reconciliation Report",ha="center",fontsize=10,color="gray")
        fig.text(0.9, 0.03, f"Page {self.page_count}",ha="right",fontsize=8,color="gray")
        fig.text(0.5, 0.02, "© Ultra-Mega Reconciliation",ha="center",fontsize=8,color="gray")
        return fig

    def _cover_page(self, pdf: PdfPages):
        fig= self._new_page()
        plt.text(0.5,0.7,"Reconciliation Analysis Report",
                 ha="center",fontsize=24,fontweight="bold",color=self.colors["primary"],
                 transform=fig.transFigure)
        plt.text(0.5,0.6,f"Generated on {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
                 ha="center",fontsize=12,color=self.colors["text"],
                 transform=fig.transFigure)
        plt.text(0.5,0.15,"CONFIDENTIAL",
                 ha="center",fontsize=9,color=self.colors["text"],
                 transform=fig.transFigure)
        pdf.savefig(fig)
        plt.close(fig)

    def _summary_page(self, pdf: PdfPages):
        fig= self._new_page()
        plt.text(0.5,0.92,"Summary",
                 ha="center",fontsize=18,fontweight="bold",color=self.colors["primary"],
                 transform=fig.transFigure)
        if self.df_current.empty:
            plt.text(0.5,0.75,"No mismatches found.",
                     ha="center",fontsize=14,color=self.colors["text"],
                     transform=fig.transFigure)
        else:
            tot= len(self.df_current)
            c_erp= (self.df_current["Gap In"]=="ERP").sum()
            c_mas= (self.df_current["Gap In"]=="MASTER").sum()
            c_both= (self.df_current["Gap In"]=="BOTH").sum()
            text= f"Total: {tot}\nMissing in ERP: {c_erp}\nMissing in Master: {c_mas}\nDiff in Both: {c_both}"
            plt.text(0.5,0.75,text,ha="center",fontsize=14,color=self.colors["text"],
                     transform=fig.transFigure)
        pdf.savefig(fig)
        plt.close(fig)

    def _chart_page(self, pdf: PdfPages, title:str, plot_func, **kwargs):
        fig= self._new_page()
        fig.suptitle(title, fontsize=14, fontweight="bold", color=self.colors["primary"], y=0.93)

        ax= fig.add_axes([0.30, 0.2, 0.65, 0.55])  # SHIFT ~1" left
        try:
            plot_func(ax, **kwargs)
            pdf.savefig(fig)
        except Exception as e:
            logging.error(f"{title} => {e}")
        plt.close(fig)

    def _all_charts(self, pdf: PdfPages):
        dfc= self.df_current.copy()
        if dfc.empty:
            return
        # The same snippet => example Heatmap or Bollinger
        # We'll do a simple single chart => Bollinger if we want
        if not self.df_history.empty and "RunDate" in self.df_history.columns:
            date_ct= self.df_history.groupby("RunDate")["Key"].count().reset_index(name="Count")
            date_ct.sort_values("RunDate", inplace=True)
            if not date_ct.empty:
                self._chart_page(pdf,"Bollinger Over Time", self._plot_bollinger, date_ct=date_ct)

    def _plot_bollinger(self, ax, date_ct):
        date_ct["RunDate_dt"]= pd.to_datetime(date_ct["RunDate"], errors="coerce")
        date_ct.sort_values("RunDate_dt", inplace=True)
        date_ct.reset_index(drop=True, inplace=True)
        date_ct["rolling_mean"]= date_ct["Count"].rolling(3,min_periods=1).mean()
        date_ct["rolling_std"]= date_ct["Count"].rolling(3,min_periods=1).std(ddof=0)
        date_ct["upper_band"]= date_ct["rolling_mean"]+2*date_ct["rolling_std"]
        date_ct["lower_band"]= date_ct["rolling_mean"]-2*date_ct["rolling_std"]
        xvals= np.arange(len(date_ct))
        ax.plot(xvals, date_ct["rolling_mean"], color="blue", label="Mean")
        ax.fill_between(xvals, date_ct["lower_band"], date_ct["upper_band"], color="blue", alpha=0.2)
        ax.scatter(xvals, date_ct["Count"], color="red", label="Count")
        ax.set_xticks(xvals)
        xlabels= [d.strftime("%Y-%m-%d") if not pd.isna(d) else "" for d in date_ct["RunDate_dt"]]
        ax.set_xticklabels(xlabels, rotation=45, ha="right")
        ax.set_xlabel("RunDate")
        ax.set_ylabel("Mismatch Count")
        ax.set_title("Bollinger Chart")
        ax.legend()


# ----------------------------------------------------------------------------
# ADV DASHBOARD => mismatch only
# ----------------------------------------------------------------------------
class AdvancedDashboard(ctk.CTkFrame):
    def __init__(self, parent, config: Dict):
        super().__init__(parent)
        dash= config.get("dashboard",{})
        self.config= config
        self.selected_dims= set(dash.get("selected_dims",[]))
        self.selected_attrs= set(dash.get("selected_attrs",[]))
        self.top_n= dash.get("top_n",10)

        self.df_current= pd.DataFrame()
        self.df_history= pd.DataFrame()

        top= ctk.CTkScrollableFrame(self, orientation="horizontal", height=60)
        top.pack(fill="x",pady=5)
        self.metric_label= ctk.CTkLabel(top,text="Metrics: 0 mismatch, 0 dimension",width=300)
        self.metric_label.pack(side="left",padx=5)

        ctk.CTkButton(
            top,text="Filter Dimension",command=self.show_dim_filter,
            fg_color="#800020",hover_color="#a52a2a",text_color="white"
        ).pack(side="left",padx=5)
        ctk.CTkButton(
            top,text="Filter Attribute",command=self.show_attr_filter,
            fg_color="#800020",hover_color="#a52a2a",text_color="white"
        ).pack(side="left",padx=5)
        ctk.CTkButton(
            top,text="Toggle Top10/All",command=self.toggle_top_n,
            fg_color="#800020",hover_color="#a52a2a",text_color="white"
        ).pack(side="left",padx=5)

        main= ctk.CTkFrame(self)
        main.pack(fill="both",expand=True)
        self.tree= ttk.Treeview(main, show="headings")
        vsb= ttk.Scrollbar(main,orient="vertical",command=self.tree.yview)
        hsb= ttk.Scrollbar(main,orient="horizontal",command=self.tree.xview)
        self.tree.configure(yscrollcommand=vsb.set,xscrollcommand=hsb.set)

        self.tree.grid(row=0,column=0,sticky="nsew")
        vsb.grid(row=0,column=1,sticky="ns")
        hsb.grid(row=1,column=0,sticky="ew")
        main.rowconfigure(0,weight=1)
        main.columnconfigure(0,weight=1)

    def toggle_top_n(self):
        if self.top_n==10:
            self.top_n=None
        else:
            self.top_n=10
        self.update_data_filters()

    def show_dim_filter(self):
        self.show_filter("Dimension")

    def show_attr_filter(self):
        self.show_filter("Attribute")

    def show_filter(self,col:str):
        base= self.df_history if not self.df_history.empty else self.df_current
        if base.empty or col not in base.columns:
            return
        pop= tk.Toplevel(self)
        pop.title(f"Filter: {col}")
        pop.geometry("300x400")

        fr= ctk.CTkFrame(pop)
        fr.pack(fill="both",expand=True,padx=5,pady=5)

        unq= base[col].dropna().unique()
        dsp_map={}
        for v in unq:
            dsp= str(v) if (isinstance(v,str) and v.strip()) else "(blank)"
            dsp_map[v]= dsp
        svals= sorted(dsp_map.keys(), key=lambda x:dsp_map[x].lower())

        if col=="Dimension":
            curr= self.selected_dims
        else:
            curr= self.selected_attrs
        if not curr:
            curr= set(svals)
        all_vals= set(svals)

        selall_var= tk.BooleanVar(value=(curr==all_vals or not curr))

        def toggle_all():
            c= selall_var.get()
            for vb in var_map.values():
                vb.set(c)

        ctk.CTkCheckBox(
            fr, text="Select All", variable=selall_var, command=toggle_all,
            fg_color="#800020", hover_color="#a52a2a", text_color="black"
        ).pack(anchor="w",pady=5)

        scr= ctk.CTkScrollableFrame(fr, width=250, height=250)
        scr.pack(fill="both",expand=True,padx=5,pady=5)
        var_map={}
        for v in svals:
            in_f= (v in curr) or (not curr)
            bvar= tk.BooleanVar(value=in_f)
            var_map[v]= bvar
            ctk.CTkCheckBox(
                scr,text=dsp_map[v],variable=bvar,
                fg_color="#800020",hover_color="#a52a2a",text_color="black"
            ).pack(anchor="w")

        def apply_():
            sel= {k for k,bv in var_map.items() if bv.get()}
            if col=="Dimension":
                self.selected_dims= sel
            else:
                self.selected_attrs= sel
            pop.destroy()
            self.update_data_filters()

        bf= ctk.CTkFrame(fr)
        bf.pack(fill="x",pady=5)
        ctk.CTkButton(
            bf, text="Apply", command=apply_,
            fg_color="#800020", hover_color="#a52a2a", text_color="white"
        ).pack(side="left",padx=5)
        ctk.CTkButton(
            bf, text="Cancel", command=pop.destroy,
            fg_color="#800020", hover_color="#a52a2a", text_color="white"
        ).pack(side="left",padx=5)

    def update_data(self, df_current: pd.DataFrame, df_history: pd.DataFrame):
        self.df_current= df_current.copy()
        self.df_history= df_history.copy()
        self.update_data_filters()

    def update_data_filters(self):
        dfc= self.df_current.copy()
        if not dfc.empty:
            if self.selected_dims:
                dfc= dfc[dfc["Dimension"].isin(self.selected_dims)]
            if self.selected_attrs:
                dfc= dfc[dfc["Attribute"].isin(self.selected_attrs)]
        mism= len(dfc)
        dims= dfc["Dimension"].nunique() if not dfc.empty and "Dimension" in dfc.columns else 0
        self.metric_label.configure(text=f"Mismatches: {mism}, Dims: {dims}")

        # show in tree
        for i in self.tree.get_children():
            self.tree.delete(i)
        if dfc.empty:
            self.tree["columns"]=[]
            return
        cols= list(dfc.columns)
        self.tree["columns"]= cols
        for c in cols:
            self.tree.heading(c,text=c,anchor="w")
            self.tree.column(c,anchor="w",width=150)
        for _,row in dfc.iterrows():
            rowvals= [row.get(cc,"") for cc in cols]
            self.tree.insert("", "end", values=rowvals)


# ----------------------------------------------------------------------------
# HISTORY TAB
# ----------------------------------------------------------------------------
class HistoryTab(ctk.CTkFrame):
    def __init__(self, parent, hist_dir: Path):
        super().__init__(parent)
        self.history_dir= hist_dir
        self.tree= None
        self.build_ui()

    def build_ui(self):
        lbl= ctk.CTkLabel(self,text="Reconciliation Runs History",font=("Arial",16))
        lbl.pack(pady=5)
        self.tree= ttk.Treeview(self,columns=("Filename",),show="headings",height=15)
        self.tree.heading("Filename", text="History File")
        self.tree.pack(fill="both",expand=True,padx=10,pady=10)

        self.tree.bind("<Double-1>",self.on_double_click)

        ctk.CTkButton(self,text="Refresh",command=self.refresh_history,
                      fg_color="#800020",hover_color="#a52a2a",text_color="white").pack(pady=5)
        self.refresh_history()

    def refresh_history(self):
        for i in self.tree.get_children():
            self.tree.delete(i)
        if not self.history_dir.is_dir():
            self.history_dir.mkdir(parents=True,exist_ok=True)
        files= sorted(self.history_dir.glob("run_*.json"),reverse=True)
        for f in files:
            self.tree.insert("", "end", values=(f.name,))

    def on_double_click(self,event):
        it= self.tree.focus()
        if not it:
            return
        fn= self.tree.item(it,"values")[0]
        path= self.history_dir/fn
        if not path.is_file():
            return
        try:
            with open(path,"r",encoding="utf-8") as ff:
                content= ff.read()
            pop= tk.Toplevel(self)
            pop.title(f"Viewing {fn}")
            txt= ctk.CTkTextbox(pop,width=800,height=600)
            txt.pack(fill="both",expand=True)
            txt.insert("end",content)
            txt.configure(state="disabled")
        except Exception as e:
            logging.error(f"HistoryTab => {e}")


# ----------------------------------------------------------------------------
# MAIN APP
# ----------------------------------------------------------------------------
class MainApp(ctk.CTk):
    def __init__(self):
        super().__init__()
        self.title("Ultra-Mega Reconciliation => Name-first, 2sheet, SHIFTED PDF, trimKey, burgundy Excel")
        self.geometry("1600x900")
        ctk.set_appearance_mode("light")

        self.config_dict= load_config(Path(DEFAULT_PATHS["CONFIG_PATH"]))
        self.param_dict= read_param_file(Path(self.config_dict["paths"].get("PARAMETER_PATH",DEFAULT_PATHS["PARAMETER_PATH"])))
        self.history_df= pd.DataFrame()

        self.tabs= ttk.Notebook(self)
        self.tabs.pack(fill="both", expand=True)

        # 1) Paths
        self.tab_paths= ctk.CTkFrame(self.tabs)
        self.build_paths_tab(self.tab_paths)
        self.tabs.add(self.tab_paths, text="Paths")

        # 2) ERP
        self.tab_erp= ctk.CTkFrame(self.tabs)
        e_filt= self.config_dict.get("erp_grid",{}).get("filters",{})
        self.erp_preview= SimplePreview(self.tab_erp, "ERP", filters_dict=e_filt)
        self.erp_preview.pack(fill="both", expand=True)
        self.tabs.add(self.tab_erp, text="ERP Preview")

        # 3) Master
        self.tab_master= ctk.CTkFrame(self.tabs)
        m_filt= self.config_dict.get("master_grid",{}).get("filters",{})
        self.master_preview= SimplePreview(self.tab_master, "Master", filters_dict=m_filt)
        self.master_preview.pack(fill="both", expand=True)
        self.tabs.add(self.tab_master, text="Master Preview")

        # 4) Compare => 2-sheets
        self.tab_compare= ctk.CTkFrame(self.tabs)
        self.build_compare_tab(self.tab_compare)
        self.tabs.add(self.tab_compare, text="Compare")

        # 5) Dashboard => mismatch only
        self.dashboard_tab= AdvancedDashboard(self.tabs, self.config_dict)
        self.tabs.add(self.dashboard_tab, text="Dashboard")

        # 6) History
        histp= Path(self.config_dict["paths"].get("HISTORY_PATH","history_runs"))
        self.history_tab= HistoryTab(self.tabs, histp)
        self.tabs.add(self.history_tab, text="History")

        # Logging
        self.log_box= ctk.CTkTextbox(self, height=120)
        self.log_box.pack(fill="both", side="bottom")
        self.log_box.configure(state="disabled")
        handler= TextHandler(self.log_box)
        handler.setLevel(logging.INFO)
        logging.getLogger().addHandler(handler)

        # ephemeral CSV dir for Master
        self.temp_csv_dir= Path(self.config_dict["paths"].get("MASTER_CSV_OUTPUT","temp_master_csv"))
        self.temp_csv_dir.mkdir(parents=True,exist_ok=True)

        self.load_runs()
        self.refresh_erp()
        self.refresh_master()
        self.dashboard_tab.update_data(pd.DataFrame(), self.history_df)

    def build_paths_tab(self, parent):
        frm= ctk.CTkFrame(parent)
        frm.pack(fill="both", expand=True, padx=10, pady=10)

        self.erp_var= tk.StringVar(value=self.config_dict["paths"].get("ERP_EXCEL_PATH", DEFAULT_PATHS["ERP_EXCEL_PATH"]))
        self.mast_zip_var= tk.StringVar(value=self.config_dict["paths"].get("MASTER_ZIP_PATH", DEFAULT_PATHS["MASTER_ZIP_PATH"]))
        self.mast_folder_var= tk.StringVar(value=self.config_dict["paths"].get("MASTER_TXT_FOLDER",""))
        self.exc_var= tk.StringVar(value=self.config_dict["paths"].get("EXCEPTION_PATH", DEFAULT_PATHS["EXCEPTION_PATH"]))
        self.out_var= tk.StringVar(value=self.config_dict["paths"].get("OUTPUT_PATH", DEFAULT_PATHS["OUTPUT_PATH"]))
        self.par_var= tk.StringVar(value=self.config_dict["paths"].get("PARAMETER_PATH", DEFAULT_PATHS["PARAMETER_PATH"]))
        self.pdf_var= tk.StringVar(value=self.config_dict["paths"].get("PDF_EXPORT_PATH", DEFAULT_PATHS["PDF_EXPORT_PATH"]))

        def mkrow(lbl,var,is_dir=False):
            rowf= ctk.CTkFrame(frm)
            rowf.pack(fill="x",pady=5)
            ctk.CTkLabel(rowf,text=lbl,width=200).pack(side="left",padx=5)
            e= ctk.CTkEntry(rowf,textvariable=var,width=600)
            e.pack(side="left",padx=5)
            def br():
                if is_dir:
                    p= filedialog.askdirectory()
                else:
                    p= filedialog.askopenfilename()
                if p:
                    var.set(p)
            ctk.CTkButton(rowf,text="Browse",command=br,
                          fg_color="#800020",hover_color="#a52a2a",text_color="white").pack(side="left",padx=5)

        mkrow("ERP Excel:", self.erp_var)
        mkrow("Master ZIP:", self.mast_zip_var)
        mkrow("Master Folder (txt):", self.mast_folder_var, is_dir=True)
        mkrow("Exception Path:", self.exc_var)
        mkrow("Missing Items Output:", self.out_var)
        mkrow("Parameter File:", self.par_var)
        mkrow("PDF Export Path:", self.pdf_var)

        bf= ctk.CTkFrame(frm)
        bf.pack(fill="x",pady=10)
        ctk.CTkButton(
            bf, text="Save Config", command=self.save_all_config,
            fg_color="#800020", hover_color="#a52a2a", text_color="white"
        ).pack(side="left", padx=5)
        ctk.CTkButton(
            bf, text="Refresh ERP", command=self.refresh_erp,
            fg_color="#800020", hover_color="#a52a2a", text_color="white"
        ).pack(side="left", padx=5)
        ctk.CTkButton(
            bf, text="Refresh Master", command=self.refresh_master,
            fg_color="#800020", hover_color="#a52a2a", text_color="white"
        ).pack(side="left", padx=5)

    def build_compare_tab(self, parent):
        frm= ctk.CTkFrame(parent)
        frm.pack(fill="both", expand=True, padx=10, pady=10)

        ctk.CTkLabel(frm, text="Run Reconciliation (2-sheets: mismatch + case)", font=("Arial",16)).pack(pady=5)

        self.trim_key_var= tk.BooleanVar(value=self.config_dict.get("trim_key_toggle",False))
        ctk.CTkCheckBox(
            frm, text="Trim Key?", variable=self.trim_key_var,
            fg_color="#800020", hover_color="#a52a2a", text_color="black"
        ).pack(pady=5)

        ctk.CTkButton(
            frm, text="Run Reconciliation", command=self.run_comparison,
            fg_color="#800020", hover_color="#a52a2a", text_color="white"
        ).pack(pady=10)

        ctk.CTkButton(
            frm, text="Export PDF", command=self.export_pdf,
            fg_color="#800020", hover_color="#a52a2a", text_color="white"
        ).pack(pady=10)

    def load_runs(self):
        histp= Path(self.config_dict["paths"].get("HISTORY_PATH","history_runs"))
        if not histp.is_dir():
            return
        frames=[]
        for jf in histp.glob("run_*.json"):
            try:
                dfj= pd.read_json(jf, orient="records")
                frames.append(dfj)
            except Exception as e:
                logging.error(f"History => {jf} => {e}")
        if frames:
            big= pd.concat(frames,ignore_index=True).drop_duplicates()
            if self.history_df.empty:
                self.history_df= big
            else:
                self.history_df= pd.concat([self.history_df,big],ignore_index=True).drop_duplicates()
            logging.info(f"Loaded runs => total {len(self.history_df)} records in history")

    def refresh_erp(self):
        p= Path(self.erp_var.get().strip())
        df= read_erp_excel(p)
        if df.empty:
            self.erp_preview.set_data(pd.DataFrame())
            return
        meltdown= meltdown_erp_for_preview(df, self.param_dict)
        pivoted= pivot_for_preview(meltdown)
        self.erp_preview.set_data(pivoted)

    def refresh_master(self):
        folder= self.mast_folder_var.get().strip()
        zip_= self.mast_zip_var.get().strip()
        if folder:
            dfm= unify_master_txt_in_folder(Path(folder))
        else:
            outd= self.temp_csv_dir
            zf= Path(zip_)
            cfiles= convert_master_txt_to_csv(zf,outd)
            dfm= unify_master_csvs(cfiles)
        if dfm.empty:
            self.master_preview.set_data(pd.DataFrame())
            return
        meltdown= meltdown_master_for_preview(dfm, self.param_dict)
        pivoted= pivot_for_preview(meltdown)
        self.master_preview.set_data(pivoted)

    def run_comparison(self):
        from meltdown_to_long import meltdown_to_long 
        # but we define meltdown_to_long above => do inline.

        df_erp_w= self.erp_preview.get_filtered_df()
        df_mast_w= self.master_preview.get_filtered_df()

        e_long= meltdown_to_long(df_erp_w)
        m_long= meltdown_to_long(df_mast_w)

        trim_flag= bool(self.trim_key_var.get())
        mismatch_df, case_df= compare_name_first(e_long,m_long,trim_key=trim_flag)

        excp= Path(self.config_dict["paths"].get("EXCEPTION_PATH",""))
        df_exc= read_exception_table(excp)
        mismatch_df= merge_exceptions(mismatch_df, df_exc)
        case_df= merge_exceptions(case_df, df_exc)

        outp= Path(self.config_dict["paths"].get("OUTPUT_PATH","output/missing_items.xlsx"))
        write_2sheet_excel(mismatch_df, case_df, outp)

        run_ts= datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        # unify mismatch+case in final => or store mismatch only
        # Let's unify so we can see all in the Bollinger
        all_run= pd.concat([mismatch_df,case_df],ignore_index=True).drop_duplicates()
        all_run["RunDate"]= run_ts

        if self.history_df.empty:
            self.history_df= all_run
        else:
            self.history_df= pd.concat([self.history_df,all_run],ignore_index=True).drop_duplicates()

        histp= Path(self.config_dict["paths"].get("HISTORY_PATH","history_runs"))
        histp.mkdir(parents=True,exist_ok=True)
        run_file= histp/f"run_{run_ts.replace(':','-').replace(' ','_')}.json"
        try:
            all_run.to_json(run_file, orient="records", indent=2)
            logging.info(f"Saved run => {run_file}")
        except Exception as e:
            logging.error(f"Error => {e}")

        # mismatch only => dashboard
        self.dashboard_tab.update_data(mismatch_df, self.history_df)
        self.history_tab.refresh_history()
        self.tabs.select(self.dashboard_tab)
        messagebox.showinfo("Done", f"Missing items => {outp}")

    def export_pdf(self):
        if self.history_df.empty:
            messagebox.showinfo("PDF Export","No mismatch => empty history.")
            return
        if "RunDate" in self.history_df.columns:
            last_run= self.history_df["RunDate"].max()
            df_curr= self.history_df[self.history_df["RunDate"]== last_run].copy()
        else:
            df_curr= self.history_df.copy()
        rep= EnhancedPDFReport(df_curr, self.history_df, self.config_dict)
        pdfp= rep.generate()
        messagebox.showinfo("PDF Export", f"PDF => {pdfp}")

    def save_all_config(self):
        self.config_dict["paths"]["ERP_EXCEL_PATH"]= self.erp_var.get().strip()
        self.config_dict["paths"]["MASTER_ZIP_PATH"]= self.mast_zip_var.get().strip()
        self.config_dict["paths"]["MASTER_TXT_FOLDER"]= self.mast_folder_var.get().strip()
        self.config_dict["paths"]["EXCEPTION_PATH"]= self.exc_var.get().strip()
        self.config_dict["paths"]["OUTPUT_PATH"]= self.out_var.get().strip()
        self.config_dict["paths"]["PARAMETER_PATH"]= self.par_var.get().strip()
        self.config_dict["paths"]["PDF_EXPORT_PATH"]= self.pdf_var.get().strip()

        self.config_dict["trim_key_toggle"]= bool(self.trim_key_var.get())

        self.config_dict.setdefault("erp_grid",{})
        self.config_dict["erp_grid"]["filters"]= self.erp_preview.filters
        self.config_dict.setdefault("master_grid",{})
        self.config_dict["master_grid"]["filters"]= self.master_preview.filters

        dash= self.config_dict.setdefault("dashboard",{})
        dash["selected_dims"]= list(self.dashboard_tab.selected_dims)
        dash["selected_attrs"]= list(self.dashboard_tab.selected_attrs)
        dash["top_n"]= self.dashboard_tab.top_n

        cfgp= Path(self.config_dict["paths"].get("CONFIG_PATH","config/ui_config.json"))
        save_config(self.config_dict,cfgp)

    def on_close(self):
        self.save_all_config()
        # band chart => store Bollinger
        band_path= self.config_dict["paths"].get("BAND_CHART_JSON_PATH","")
        if band_path and not self.history_df.empty and "RunDate" in self.history_df.columns:
            try:
                outp= Path(band_path)
                date_ct= self.history_df.groupby("RunDate")["Key"].count().reset_index(name="Count")
                date_ct["RunDate_dt"]= pd.to_datetime(date_ct["RunDate"],errors="coerce")
                date_ct.sort_values("RunDate_dt", inplace=True)
                date_ct.reset_index(drop=True,inplace=True)
                date_ct["rolling_mean"]= date_ct["Count"].rolling(3,min_periods=1).mean()
                date_ct["rolling_std"]= date_ct["Count"].rolling(3,min_periods=1).std(ddof=0)
                date_ct["upper_band"]= date_ct["rolling_mean"]+2*date_ct["rolling_std"]
                date_ct["lower_band"]= date_ct["rolling_mean"]-2*date_ct["rolling_std"]
                date_ct["RunDate"]= date_ct["RunDate_dt"].dt.strftime("%Y-%m-%d %H:%M:%S")
                date_ct.drop(columns=["RunDate_dt"],inplace=True)
                date_ct.to_json(outp,orient="records",indent=2)
                logging.info(f"Bollinger => {outp}")
            except Exception as e:
                logging.error(f"Bollinger => {e}")
        self.destroy()


def main():
    app= MainApp()
    app.mainloop()

if __name__=="__main__":
    main()
