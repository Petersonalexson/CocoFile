
"""
Ultra-Mega Reconciliation (Mode=2, Parameter-based, No Column Rename, 8 Dashboard Charts)
----------------------------------------------------------------------------------------
- Reads Master .txt from a ZIP in memory (robust multi-encoding).
- Reads an Excel parameter file specifying allowed & rename sets for dimension/attribute.
- Hard-coded transformation: "Enabled_Flag" => meltdown attribute "Enabled" in ERP.
- Date columns strip "T..." suffix.
- GUI only allows filtering columns (including date columns, NaN).
- Compare in Mode=2 (Name-missing => entire record missing, else compare attributes).
- Dashboard: heatmap, lollipop, circular barplot, scatter, radar, normal pie, normal bar, band chart.

Author: Al pacino
Date: 2025
"""

import os
import json
import logging
import zipfile
import time
from pathlib import Path
from typing import Dict, List, Set, Tuple
from datetime import datetime

import tkinter as tk
from tkinter import ttk, filedialog, messagebox, simpledialog

import customtkinter as ctk
import pandas as pd
import numpy as np

try:
    import chardet
except ImportError:
    chardet = None

from openpyxl import Workbook
from openpyxl.styles import PatternFill, Font, Alignment

import matplotlib
matplotlib.use("TkAgg")
import matplotlib.pyplot as plt
from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg

# ------------------------------------------------------------------------------
# 1) LOGGING
# ------------------------------------------------------------------------------
def setup_logger():
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s [%(levelname)s] %(message)s"
    )
setup_logger()

# ------------------------------------------------------------------------------
# 2) DEFAULT CONFIG
# ------------------------------------------------------------------------------
DEFAULT_PATHS = {
    "ERP_EXCEL_PATH": "data/ERP_Config.xlsx",
    "MASTER_ZIP_PATH": "data/Master_Config.zip",
    "EXCEPTION_PATH": "data/Exception_Table.xlsx",
    "OUTPUT_PATH": "output/Reconciliation.xlsx",
    "PARAMETER_PATH": "data/parameters.xlsx",
    "CONFIG_PATH": "config/ui_config.json"
}

def default_config() -> Dict:
    # We store minimal "erp_grid"/"master_grid" since we do not let the user rename/hide columns,
    # but they can filter any column. We'll keep "Dimension" & "Value" always present/locked in meltdown.
    return {
        "paths": {
            "ERP_EXCEL_PATH": DEFAULT_PATHS["ERP_EXCEL_PATH"],
            "MASTER_ZIP_PATH": DEFAULT_PATHS["MASTER_ZIP_PATH"],
            "EXCEPTION_PATH": DEFAULT_PATHS["EXCEPTION_PATH"],
            "OUTPUT_PATH": DEFAULT_PATHS["OUTPUT_PATH"],
            "PARAMETER_PATH": DEFAULT_PATHS["PARAMETER_PATH"],
            "CONFIG_PATH": DEFAULT_PATHS["CONFIG_PATH"]
        },
        "erp_grid": {
            "columns": [],
            "filters": {}
        },
        "master_grid": {
            "columns": [],
            "filters": {}
        },
        "comparison_option": 2
    }

def load_config(path: Path) -> Dict:
    if path.is_file():
        try:
            with open(path, "r", encoding="utf-8") as f:
                return json.load(f)
        except Exception as e:
            logging.warning(f"Could not load config from {path}: {e}")
    return default_config()

def save_config(cfg: Dict, path: Path):
    path.parent.mkdir(parents=True, exist_ok=True)
    try:
        with open(path, "w", encoding="utf-8") as f:
            json.dump(cfg, f, indent=2)
        logging.info(f"Saved config to {path}")
    except Exception as e:
        logging.error(f"Error saving config: {e}")

# ------------------------------------------------------------------------------
# 3) TEXT LOGGER HANDLER
# ------------------------------------------------------------------------------
class TextHandler(logging.Handler):
    def __init__(self, widget: ctk.CTkTextbox):
        super().__init__()
        self.widget = widget

    def emit(self, record):
        msg = self.format(record) + "\n"
        self.widget.after(0, self._append, msg)

    def _append(self, msg):
        self.widget.configure(state="normal")
        self.widget.insert("end", msg)
        self.widget.see("end")
        self.widget.configure(state="disabled")

# ------------------------------------------------------------------------------
# 4) PARAMETER FILE
# ------------------------------------------------------------------------------
def read_parameters_excel(path: Path) -> Dict[str, object]:
    """
    Example param file columns (can rename them if needed):
     - Master Allowed Dimensions
     - Master Allowed Attributes
     - ERP Allowed Dimensions
     - ERP Allowed Attributes
     - Master Orig Dim, Master Ren Dim
     - Master Orig Attr, Master Ren Attr
     - ERP Orig Dim, ERP Ren Dim
     - ERP Orig Attr, ERP Ren Attr
    Returns dict with:
     {
       "master_dim_allow": set(...),
       "master_attr_allow": set(...),
       "erp_dim_allow": set(...),
       "erp_attr_allow": set(...),
       "master_dim_map": {...},
       "master_attr_map": {...},
       "erp_dim_map": {...},
       "erp_attr_map": {...}
     }
    """
    if not path.is_file():
        logging.warning(f"Parameter file not found: {path}")
        return {
            "master_dim_allow": set(),
            "master_attr_allow": set(),
            "erp_dim_allow": set(),
            "erp_attr_allow": set(),
            "master_dim_map": {},
            "master_attr_map": {},
            "erp_dim_map": {},
            "erp_attr_map": {}
        }
    try:
        df = pd.read_excel(path)
        df.columns = df.columns.str.strip()

        safe_str = lambda x: str(x).strip() if pd.notna(x) else ""
        param = {
            "master_dim_allow": set(),
            "master_attr_allow": set(),
            "erp_dim_allow": set(),
            "erp_attr_allow": set(),
            "master_dim_map": {},
            "master_attr_map": {},
            "erp_dim_map": {},
            "erp_attr_map": {}
        }

        if "Master Allowed Dimensions" in df.columns:
            param["master_dim_allow"] = set(df["Master Allowed Dimensions"].dropna().unique())
        if "Master Allowed Attributes" in df.columns:
            param["master_attr_allow"] = set(df["Master Allowed Attributes"].dropna().unique())
        if "ERP Allowed Dimensions" in df.columns:
            param["erp_dim_allow"] = set(df["ERP Allowed Dimensions"].dropna().unique())
        if "ERP Allowed Attributes" in df.columns:
            param["erp_attr_allow"] = set(df["ERP Allowed Attributes"].dropna().unique())

        for _, row in df.iterrows():
            m_od = safe_str(row.get("Master Orig Dim",""))
            m_rd = safe_str(row.get("Master Ren Dim",""))
            if m_od and m_rd and m_od!=m_rd:
                param["master_dim_map"][m_od] = m_rd

            m_oa = safe_str(row.get("Master Orig Attr",""))
            m_ra = safe_str(row.get("Master Ren Attr",""))
            if m_oa and m_ra and m_oa!=m_ra:
                param["master_attr_map"][m_oa] = m_ra

            e_od = safe_str(row.get("ERP Orig Dim",""))
            e_rd = safe_str(row.get("ERP Ren Dim",""))
            if e_od and e_rd and e_od!=e_rd:
                param["erp_dim_map"][e_od] = e_rd

            e_oa = safe_str(row.get("ERP Orig Attr",""))
            e_ra = safe_str(row.get("ERP Ren Attr",""))
            if e_oa and e_ra and e_oa!=e_ra:
                param["erp_attr_map"][e_oa] = e_ra

        return param
    except Exception as e:
        logging.error(f"Error reading parameters: {e}")
        return {
            "master_dim_allow": set(),
            "master_attr_allow": set(),
            "erp_dim_allow": set(),
            "erp_attr_allow": set(),
            "master_dim_map": {},
            "master_attr_map": {},
            "erp_dim_map": {},
            "erp_attr_map": {}
        }

# ------------------------------------------------------------------------------
# 5) READ ERP
# ------------------------------------------------------------------------------
def read_erp_excel(path: Path) -> pd.DataFrame:
    if not path.is_file():
        logging.warning(f"ERP Excel not found: {path}")
        return pd.DataFrame()
    try:
        df = pd.read_excel(path, skiprows=3)
        df.columns = df.columns.str.strip()
        # parse date columns => strip T
        for c in df.columns:
            if "Date" in c:
                df[c] = df[c].astype(str).apply(lambda x: x.split("T")[0] if "T" in x else x)
        return df
    except Exception as e:
        logging.error(f"Error reading ERP Excel: {e}")
        return pd.DataFrame()

# ------------------------------------------------------------------------------
# 6) READ MASTER ZIP
# ------------------------------------------------------------------------------
def read_master_zip(path: Path) -> pd.DataFrame:
    if not path.is_file():
        logging.warning(f"Master ZIP not found: {path}")
        return pd.DataFrame()
    frames = []
    with zipfile.ZipFile(path, "r") as z:
        txt_files = [f for f in z.namelist() if f.lower().endswith(".txt")]
        for txt_file in txt_files:
            base_name = os.path.basename(txt_file)
            try:
                with z.open(txt_file) as fo:
                    raw = fo.read()
                if not raw:
                    continue
                df_part = read_txt_in_memory_robust(raw)
                df_part.columns = df_part.columns.str.strip()
                # parse date col => strip T
                for c in df_part.columns:
                    if "Date" in c:
                        df_part[c] = df_part[c].astype(str).apply(lambda x: x.split("T")[0] if "T" in x else x)
                frames.append(df_part)
            except Exception as e:
                logging.error(f"Error reading {txt_file} from ZIP: {e}")
    if frames:
        return pd.concat(frames, ignore_index=True)
    else:
        return pd.DataFrame()

def read_txt_in_memory_robust(raw: bytes) -> pd.DataFrame:
    import csv
    import io
    encodings = [
        'utf-8-sig','utf-8','utf-16','utf-16-le','utf-16-be','utf-32','utf-32-le','utf-32-be',
        'cp1250','cp1251','cp1252','cp1254','cp1256','cp932','cp949',
        'latin1','iso-8859-1','iso-8859-2','windows-1250','windows-1251',
        'windows-1252','windows-1254','windows-1256','shift_jis',
        'euc_jp','euc_kr','big5','big5hkscs','gb2312','gbk','gb18030'
    ]
    for enc in encodings:
        try:
            buf = io.BytesIO(raw)
            df = pd.read_csv(
                buf,
                encoding=enc,
                sep=",",
                on_bad_lines="skip",
                quoting=csv.QUOTE_MINIMAL,
                engine="python"
            )
            df.dropna(axis=0, how="all", inplace=True)
            df.dropna(axis=1, how="all", inplace=True)
            return df
        except:
            pass
    logging.error("Could not parse Master .txt in memory with known encodings.")
    return pd.DataFrame()

# ------------------------------------------------------------------------------
# 7) MELTDOWN
# ------------------------------------------------------------------------------
def meltdown_erp(df: pd.DataFrame,
                 erp_dim_map: Dict[str,str],
                 erp_attr_map: Dict[str,str],
                 erp_dim_allow: Set[str],
                 erp_attr_allow: Set[str]) -> pd.DataFrame:
    if df.empty:
        return df
    # If "Enabled_Flag" => meltdown attribute "Enabled"
    # We'll copy that column => "Enabled" then drop the original
    if "Enabled_Flag" in df.columns:
        df["Enabled"] = df["Enabled_Flag"].astype(str)
        df.drop(columns=["Enabled_Flag"], inplace=True)

    # Ensure "Dimension" & "Value"
    if "Dimension" not in df.columns:
        df["Dimension"] = ""
    if "Value" not in df.columns:
        # fallback if "Name" or "RefName"
        for c in ["Name","RefName"]:
            if c in df.columns:
                df.rename(columns={c:"Value"}, inplace=True)
                break
        if "Value" not in df.columns:
            df["Value"] = ""

    keep_cols = df.columns.tolist()
    id_vars = ["Dimension","Value"]
    value_vars = [c for c in keep_cols if c not in id_vars]

    melted = df.melt(id_vars=id_vars, value_vars=value_vars,
                     var_name="Attribute", value_name="Value_melted")
    # rename dimension => erp_dim_map
    melted["Dimension"] = melted["Dimension"].replace(erp_dim_map)
    # rename attribute => erp_attr_map
    melted["Attribute"] = melted["Attribute"].replace(erp_attr_map)

    # filter dimension if erp_dim_allow is non-empty
    if erp_dim_allow:
        melted = melted[melted["Dimension"].isin(erp_dim_allow)]
    # filter attribute if erp_attr_allow is non-empty
    if erp_attr_allow:
        melted = melted[melted["Attribute"].isin(erp_attr_allow)]

    melted.rename(columns={"Value":"RefName","Value_melted":"Value"}, inplace=True)
    return melted[["Dimension","RefName","Attribute","Value"]].copy()

def meltdown_master(df: pd.DataFrame,
                    mst_dim_map: Dict[str,str],
                    mst_attr_map: Dict[str,str],
                    mst_dim_allow: Set[str],
                    mst_attr_allow: Set[str]) -> pd.DataFrame:
    if df.empty:
        return df
    if "Dimension" not in df.columns:
        df["Dimension"] = ""
    if "Value" not in df.columns:
        for c in ["Name","RefName"]:
            if c in df.columns:
                df.rename(columns={c:"Value"}, inplace=True)
                break
        if "Value" not in df.columns:
            df["Value"] = ""
    keep_cols = df.columns.tolist()
    id_vars = ["Dimension","Value"]
    value_vars= [c for c in keep_cols if c not in id_vars]

    melted = df.melt(id_vars=id_vars, value_vars=value_vars,
                     var_name="Attribute", value_name="Value_melted")

    melted["Dimension"] = melted["Dimension"].replace(mst_dim_map)
    melted["Attribute"] = melted["Attribute"].replace(mst_attr_map)

    if mst_dim_allow:
        melted = melted[melted["Dimension"].isin(mst_dim_allow)]
    if mst_attr_allow:
        melted = melted[melted["Attribute"].isin(mst_attr_allow)]

    melted.rename(columns={"Value":"RefName","Value_melted":"Value"}, inplace=True)
    return melted[["Dimension","RefName","Attribute","Value"]].copy()

def build_keys(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    for c in ["Dimension","RefName","Attribute","Value"]:
        if c not in df.columns:
            df[c] = ""
        df[c] = df[c].fillna("").astype(str).str.strip()
    df["GroupKey"] = df["Dimension"] + " | " + df["RefName"]
    df["Key"] = df["Dimension"] + " | " + df["RefName"] + " | " + df["Attribute"] + " | " + df["Value"]
    df["Comments_1"] = ""
    df["Comments_2"] = ""
    df["Action Item"] = ""
    df["Missing In"] = ""
    return df

# ------------------------------------------------------------------------------
# 8) COMPARE MODE=2
# ------------------------------------------------------------------------------
def compare_mode2(df_erp: pd.DataFrame, df_mst: pd.DataFrame) -> pd.DataFrame:
    erp_dict = build_lookup_dict(df_erp)
    mst_dict = build_lookup_dict(df_mst)
    all_keys = set(erp_dict.keys()) | set(mst_dict.keys())
    results = []
    for gk in all_keys:
        dim = gk.split(" | ")[0]
        a_data = erp_dict.get(gk,{})
        b_data = mst_dict.get(gk,{})
        name_a = a_data.get("Name","")
        name_b = b_data.get("Name","")
        if name_a and name_b and (name_a==name_b):
            # partial compare
            all_attrs = (set(a_data.keys()) | set(b_data.keys())) - {"Name"}
            for attr in all_attrs:
                va = a_data.get(attr,"")
                vb = b_data.get(attr,"")
                if va != vb:
                    if va and not vb:
                        results.append({"Dimension": dim, "Name": name_a, "Attribute": attr, "Value": va, "Missing In": "MASTER"})
                    elif vb and not va:
                        results.append({"Dimension": dim, "Name": name_a, "Attribute": attr, "Value": vb, "Missing In": "ERP"})
                    else:
                        results.append({"Dimension": dim, "Name": name_a, "Attribute": attr, "Value": va, "Missing In": "MASTER"})
                        results.append({"Dimension": dim, "Name": name_a, "Attribute": attr, "Value": vb, "Missing In": "ERP"})
        else:
            if name_a and not name_b:
                results.append({"Dimension": dim, "Name": name_a, "Attribute": "Name", "Value": name_a, "Missing In":"MASTER"})
            elif name_b and not name_a:
                results.append({"Dimension": dim, "Name": name_b, "Attribute": "Name", "Value": name_b, "Missing In":"ERP"})
    df_diff = pd.DataFrame(results)
    if not df_diff.empty:
        df_diff["Key"] = (
            df_diff["Dimension"].str.strip() + " | " +
            df_diff["Name"].str.strip() + " | " +
            df_diff["Attribute"].str.strip() + " | " +
            df_diff["Value"].str.strip()
        )
    return df_diff

def build_lookup_dict(df: pd.DataFrame) -> Dict[str,Dict[str,str]]:
    lookup={}
    for gk, grp in df.groupby("GroupKey"):
        rec={}
        name_= grp["RefName"].iloc[0] if not grp.empty else ""
        rec["Name"] = name_
        for _, row in grp.iterrows():
            rec[row["Attribute"]] = row["Value"]
        lookup[gk]= rec
    return lookup

# ------------------------------------------------------------------------------
# 9) EXCEPTIONS
# ------------------------------------------------------------------------------
def read_exception_table(path: Path) -> pd.DataFrame:
    if path.is_file():
        try:
            dfx = pd.read_excel(path)
            dfx.columns = dfx.columns.astype(str).str.strip()
            return dfx
        except Exception as e:
            logging.error(f"Error reading exceptions: {e}")
    return pd.DataFrame()

def merge_exceptions(df: pd.DataFrame, df_exc: pd.DataFrame) -> pd.DataFrame:
    if df.empty or df_exc.empty or "Key" not in df.columns:
        return df
    keep = [c for c in df_exc.columns if c in ["Key","Comments_1","Comments_2","hide exception"]]
    if not keep:
        return df
    exc = df_exc[keep].copy()
    exc["Key"] = exc["Key"].astype(str).str.strip()

    merged = df.merge(exc, on="Key", how="left", suffixes=("", "_exc"))
    merged["hide exception"] = merged.get("hide exception","").fillna("").str.lower()
    final = merged[merged["hide exception"]!="yes"].copy()
    if "Comments_1_exc" in final.columns:
        final["Comments_1"] = np.where(final["Comments_1_exc"].notna(), final["Comments_1_exc"], final["Comments_1"])
        final.drop(columns=["Comments_1_exc"], inplace=True)
    if "Comments_2_exc" in final.columns:
        final["Comments_2"] = np.where(final["Comments_2_exc"].notna(), final["Comments_2_exc"], final["Comments_2"])
        final.drop(columns=["Comments_2_exc"], inplace=True)
    if "hide exception" in final.columns:
        final.drop(columns=["hide exception"], inplace=True)
    return final

# ------------------------------------------------------------------------------
# 10) WRITE RESULTS
# ------------------------------------------------------------------------------
def write_results(df: pd.DataFrame, out_path: Path):
    if df.empty:
        logging.info("No differences => skip writing.")
        return
    out_path.parent.mkdir(parents=True, exist_ok=True)

    final_cols = ["Key","Dimension","Name","Attribute","Value","Comments_1","Comments_2","Action Item","Missing In"]
    for c in final_cols:
        if c not in df.columns:
            df[c] = ""
    df = df[final_cols]

    wb = Workbook()
    ws = wb.active
    ws.title = "Results"
    ws.append(final_cols)
    for row in df.itertuples(index=False):
        ws.append(row)

    header_font = Font(bold=True)
    fill = PatternFill(start_color="DDDDDD", end_color="DDDDDD", fill_type="solid")
    for cell in ws[1]:
        cell.font = header_font
        cell.fill = fill
        cell.alignment = Alignment(horizontal="center")

    for col in ws.columns:
        max_len = 0
        col_letter = col[0].column_letter
        for cell in col:
            val = str(cell.value) if cell.value is not None else ""
            max_len = max(max_len, len(val))
        ws.column_dimensions[col_letter].width = max_len + 2

    ws.freeze_panes = "A2"
    wb.save(out_path)
    logging.info(f"Results => {out_path}")

# ------------------------------------------------------------------------------
# 11) DASHBOARD
# ------------------------------------------------------------------------------
class Dashboard(ctk.CTkFrame):
    """
    8 chart frames:
     1) Heatmap
     2) Lollipop
     3) Circular barplot
     4) Scatter
     5) Radar
     6) Normal pie
     7) Normal bar
     8) Band chart
    We'll demonstrate each with missing items from df_current, plus a run history df_history for the band chart, etc.
    """
    def __init__(self, parent):
        super().__init__(parent)
        self.df_current = pd.DataFrame()
        self.df_history = pd.DataFrame()

        self.notebook = ttk.Notebook(self)
        self.notebook.pack(fill="both", expand=True)

        self.frame_heatmap   = ctk.CTkFrame(self.notebook)
        self.frame_lollipop  = ctk.CTkFrame(self.notebook)
        self.frame_circular  = ctk.CTkFrame(self.notebook)
        self.frame_scatter   = ctk.CTkFrame(self.notebook)
        self.frame_radar     = ctk.CTkFrame(self.notebook)
        self.frame_normalpie = ctk.CTkFrame(self.notebook)
        self.frame_normalbar = ctk.CTkFrame(self.notebook)
        self.frame_bandchart = ctk.CTkFrame(self.notebook)

        self.notebook.add(self.frame_heatmap,   text="Heatmap")
        self.notebook.add(self.frame_lollipop,  text="Lollipop Dim")
        self.notebook.add(self.frame_circular,  text="Circular Attr")
        self.notebook.add(self.frame_scatter,   text="Scatter")
        self.notebook.add(self.frame_radar,     text="Radar")
        self.notebook.add(self.frame_normalpie, text="Normal Pie")
        self.notebook.add(self.frame_normalbar, text="Normal Bar")
        self.notebook.add(self.frame_bandchart, text="Band Chart")

    def update_data(self, df_current: pd.DataFrame, df_history: pd.DataFrame):
        self.df_current = df_current.copy()
        self.df_history = df_history.copy()

        self.plot_heatmap()
        self.plot_lollipop()
        self.plot_circular()
        self.plot_scatter()
        self.plot_radar()
        self.plot_normal_pie()
        self.plot_normal_bar()
        self.plot_band_chart()

    def plot_heatmap(self):
        for w in self.frame_heatmap.winfo_children():
            w.destroy()
        if self.df_current.empty:
            return
        df_m = self.df_current[self.df_current["Missing In"]!=""]
        if df_m.empty:
            return
        pivoted = df_m.groupby(["Dimension","Attribute"]).size().unstack(fill_value=0)
        fig, ax = plt.subplots(figsize=(6,5))
        cax = ax.imshow(pivoted, aspect="auto", cmap="Reds")
        ax.set_xticks(range(len(pivoted.columns)))
        ax.set_xticklabels(pivoted.columns, rotation=90)
        ax.set_yticks(range(len(pivoted.index)))
        ax.set_yticklabels(pivoted.index)
        fig.colorbar(cax, ax=ax)
        ax.set_title("Heatmap: Dimension x Attribute Missing")
        canvas = FigureCanvasTkAgg(fig, master=self.frame_heatmap)
        canvas.draw()
        canvas.get_tk_widget().pack(fill="both", expand=True)

    def plot_lollipop(self):
        for w in self.frame_lollipop.winfo_children():
            w.destroy()
        df_m = self.df_current[self.df_current["Missing In"]!=""]
        if df_m.empty:
            return
        count_dim = df_m.groupby("Dimension")["Key"].count().sort_values(ascending=False).head(10)
        fig, ax = plt.subplots(figsize=(6,5))
        ax.hlines(y=count_dim.index, xmin=0, xmax=count_dim.values, color="skyblue")
        ax.plot(count_dim.values, count_dim.index, "o", color="skyblue")
        ax.set_title("Lollipop: Missing Dimensions")
        ax.set_xlabel("Missing Count")
        canvas = FigureCanvasTkAgg(fig, master=self.frame_lollipop)
        canvas.draw()
        canvas.get_tk_widget().pack(fill="both", expand=True)

    def plot_circular(self):
        for w in self.frame_circular.winfo_children():
            w.destroy()
        df_m = self.df_current[self.df_current["Missing In"]!=""]
        if df_m.empty:
            return
        count_attr = df_m.groupby("Attribute")["Key"].count().sort_values(ascending=False).head(10)
        if count_attr.empty:
            return

        # circular bar
        categories = count_attr.index.tolist()
        values = count_attr.values
        N = len(categories)
        angles = np.linspace(0, 2*np.pi, N, endpoint=False).tolist()
        # typical approach is a polar bar
        fig = plt.figure(figsize=(6,6))
        ax = fig.add_subplot(111, polar=True)
        ax.set_theta_offset(np.pi/2)
        ax.set_theta_direction(-1)
        ax.set_xticks(angles)
        ax.set_xticklabels(categories, fontsize=9)
        # bars
        ax.bar(angles, values, width=0.4, color="orange", alpha=0.6)
        ax.set_title("Circular Barplot: Missing Attributes", y=1.05)
        canvas = FigureCanvasTkAgg(fig, master=self.frame_circular)
        canvas.draw()
        canvas.get_tk_widget().pack(fill="both", expand=True)

    def plot_scatter(self):
        for w in self.frame_scatter.winfo_children():
            w.destroy()
        df_m = self.df_current[self.df_current["Missing In"]!=""]
        if df_m.empty:
            return
        count_dim = df_m.groupby("Dimension")["Key"].count().reset_index(name="Count")
        if count_dim.empty:
            return
        count_dim.sort_values("Count", ascending=False, inplace=True)
        xvals = np.arange(len(count_dim))
        yvals = count_dim["Count"].values
        labels= count_dim["Dimension"].values

        fig, ax = plt.subplots(figsize=(6,5))
        ax.scatter(xvals, yvals, color="green")
        for i, txt in enumerate(labels):
            ax.text(xvals[i], yvals[i], txt, ha="center", va="bottom", rotation=60)
        ax.set_xticks([])
        ax.set_ylabel("Missing Count")
        ax.set_title("Scatter: Missing by Dimension")
        canvas = FigureCanvasTkAgg(fig, master=self.frame_scatter)
        canvas.draw()
        canvas.get_tk_widget().pack(fill="both", expand=True)

    def plot_radar(self):
        for w in self.frame_radar.winfo_children():
            w.destroy()
        df_m = self.df_current[self.df_current["Missing In"]!=""]
        if df_m.empty:
            return
        count_dim = df_m.groupby("Dimension")["Key"].count().sort_values(ascending=False).head(5)
        if count_dim.empty:
            return
        categories = count_dim.index.tolist()
        values = count_dim.values.tolist()
        N = len(categories)
        angles = np.linspace(0,2*np.pi,N,endpoint=False).tolist()
        angles += angles[:1]
        values += values[:1]

        fig = plt.figure(figsize=(6,6))
        ax = fig.add_subplot(111, polar=True)
        ax.set_theta_offset(np.pi/2)
        ax.set_theta_direction(-1)
        ax.set_xticks(angles[:-1])
        ax.set_xticklabels(categories, fontsize=9)
        ax.plot(angles, values, color="red", linewidth=2)
        ax.fill(angles, values, color="red", alpha=0.3)
        ax.set_title("Radar Chart (Top 5 Dimensions Missing)", y=1.08)
        canvas = FigureCanvasTkAgg(fig, master=self.frame_radar)
        canvas.draw()
        canvas.get_tk_widget().pack(fill="both", expand=True)

    def plot_normal_pie(self):
        """
        Normal pie chart for distribution of Missing In
        """
        for w in self.frame_normalpie.winfo_children():
            w.destroy()
        df_m = self.df_current[self.df_current["Missing In"]!=""]
        if df_m.empty:
            return
        dist = df_m["Missing In"].value_counts()
        fig, ax = plt.subplots(figsize=(5,5))
        ax.pie(dist.values, labels=dist.index, autopct="%.1f%%", startangle=140)
        ax.set_title("Normal Pie: Missing In distribution")
        canvas = FigureCanvasTkAgg(fig, master=self.frame_normalpie)
        canvas.draw()
        canvas.get_tk_widget().pack(fill="both", expand=True)

    def plot_normal_bar(self):
        """
        Normal bar chart for top 10 Attributes missing, or something else
        """
        for w in self.frame_normalbar.winfo_children():
            w.destroy()
        df_m = self.df_current[self.df_current["Missing In"]!=""]
        if df_m.empty:
            return
        count_attr = df_m.groupby("Attribute")["Key"].count().sort_values(ascending=False).head(10)
        fig, ax = plt.subplots(figsize=(6,4))
        count_attr.plot(kind="bar", ax=ax, color="blue")
        ax.set_title("Normal Bar Chart: Top 10 Missing Attributes")
        ax.set_ylabel("Missing Count")
        canvas = FigureCanvasTkAgg(fig, master=self.frame_normalbar)
        canvas.draw()
        canvas.get_tk_widget().pack(fill="both", expand=True)

    def plot_band_chart(self):
        """
        A band chart or "confidence band" style using the run history data.
        We'll pretend each run is a point, the "missing count" is the line,
        and we create a +/- band around it.
        """
        for w in self.frame_bandchart.winfo_children():
            w.destroy()
        if self.df_history.empty or "RunDate" not in self.df_history.columns:
            return
        df_m = self.df_history[self.df_history["Missing In"]!=""]
        if df_m.empty:
            return

        date_counts = df_m.groupby("RunDate")["Key"].count().reset_index()
        date_counts.sort_values("RunDate", inplace=True)

        # create a band: mean +/-10% for demonstration
        date_counts["Count_min"] = date_counts["Key"]*0.9
        date_counts["Count_max"] = date_counts["Key"]*1.1

        fig, ax = plt.subplots(figsize=(6,4))
        ax.plot(date_counts["RunDate"], date_counts["Key"], color="purple", label="Missing Count")
        ax.fill_between(date_counts["RunDate"], date_counts["Count_min"], date_counts["Count_max"],
                        color="purple", alpha=0.2, label="±10% band")
        ax.set_title("Band Chart Over Runs")
        ax.set_xlabel("RunDate")
        ax.set_ylabel("Missing Count")
        plt.xticks(rotation=45)
        ax.legend()

        # annotate points
        for i, row in date_counts.iterrows():
            ax.text(row["RunDate"], row["Key"], str(row["Key"]), ha="center", va="bottom")

        canvas = FigureCanvasTkAgg(fig, master=self.frame_bandchart)
        canvas.draw()
        canvas.get_tk_widget().pack(fill="both", expand=True)

# ------------------------------------------------------------------------------
# 12) EXCEL GRID (GUI) - NO RENAME, ONLY FILTER
# ------------------------------------------------------------------------------
class ExcelGrid(ctk.CTkFrame):
    """
    A read-only grid (no column rename/hide), but the user can filter columns (including date) via heading click.
    """
    def __init__(self, parent, config_block: Dict, name: str):
        super().__init__(parent)
        self.name = name
        self.col_defs = config_block.get("columns", [])  # we won't do rename/hide
        self.filters: Dict[str,Set] = {k:set(v) for k,v in config_block.get("filters",{}).items()}
        self.df = pd.DataFrame()

        self.create_toolbar()
        self.create_table()
        self.create_statusbar()

    def create_toolbar(self):
        tb = ctk.CTkFrame(self)
        tb.pack(fill="x", padx=5, pady=5)
        ctk.CTkButton(tb, text="Clear Filters", command=self.clear_filters).pack(side="left", padx=5)

    def create_table(self):
        container = ctk.CTkFrame(self)
        container.pack(fill="both", expand=True, padx=5, pady=5)

        self.tree = ttk.Treeview(container, show="headings")
        vsb = ttk.Scrollbar(container, orient="vertical", command=self.tree.yview)
        hsb = ttk.Scrollbar(container, orient="horizontal", command=self.tree.xview)
        self.tree.configure(yscrollcommand=vsb.set, xscrollcommand=hsb.set)

        self.tree.grid(row=0, column=0, sticky="nsew")
        vsb.grid(row=0, column=1, sticky="ns")
        hsb.grid(row=1, column=0, sticky="ew")
        container.rowconfigure(0, weight=1)
        container.columnconfigure(0, weight=1)

    def create_statusbar(self):
        self.status_label = ctk.CTkLabel(self, text="Ready")
        self.status_label.pack(fill="x")

    def set_data(self, df: pd.DataFrame):
        self.df = df.copy(deep=True)
        existing_ids = [c["id"] for c in self.col_defs]
        for col in self.df.columns:
            if col not in existing_ids:
                # add a new col_def
                self.col_defs.append({
                    "id": col,
                    "name": col,
                    "visible": True
                })
        self.refresh_table()

    def refresh_table(self):
        for item in self.tree.get_children():
            self.tree.delete(item)

        visible_cols = [c for c in self.col_defs if c.get("visible",True)]
        self.tree["columns"] = [c["id"] for c in visible_cols]

        for col_def in visible_cols:
            self.tree.heading(
                col_def["id"],
                text=col_def["name"],
                anchor="w",
                command=lambda c=col_def: self.show_filter_popup(c)  # Filter on heading click
            )
            self.tree.column(col_def["id"], anchor="w", width=150)

        df_f = self.get_filtered_df()
        for _, row in df_f.iterrows():
            vals = [row[c["id"]] for c in visible_cols]
            self.tree.insert("", "end", values=vals)

        self.status_label.configure(text=f"{len(df_f)} rows")

    def get_filtered_df(self) -> pd.DataFrame:
        if self.df.empty:
            return self.df
        df_f = self.df.copy()

        def passes(x, allowed):
            if pd.isna(x):
                # True if any is also NaN
                return any(pd.isna(a) for a in allowed)
            else:
                return x in allowed

        for col_id, allowed_vals in self.filters.items():
            if col_id in df_f.columns and allowed_vals:
                df_f = df_f[df_f[col_id].apply(lambda x: passes(x, allowed_vals))]

        visible_ids = [c["id"] for c in self.col_defs if c.get("visible",True)]
        visible_ids = [c for c in visible_ids if c in df_f.columns]
        return df_f[visible_ids]

    def show_filter_popup(self, col_def: Dict):
        col_id = col_def["id"]
        if self.df.empty or col_id not in self.df.columns:
            return
        popup = tk.Toplevel(self)
        popup.title(f"Filter: {col_def['name']}")
        popup.geometry("320x500")

        frame = ctk.CTkFrame(popup)
        frame.pack(fill="both", expand=True, padx=5, pady=5)

        unique_vals = self.df[col_id].unique()
        display_map = {}
        for v in unique_vals:
            if pd.isna(v):
                dsp = "(NaN)"
            elif isinstance(v,str) and not v.strip():
                dsp = "(blank)"
            else:
                dsp = str(v)
            display_map[v] = dsp

        sorted_vals = sorted(display_map.keys(), key=lambda x: display_map[x].lower())
        current_filter = self.filters.get(col_id, set())
        if not current_filter:
            current_filter = set(unique_vals)

        all_var = tk.BooleanVar(value=True)
        def toggle_all():
            c_ = all_var.get()
            for vb in var_dict.values():
                vb.set(c_)

        ctk.CTkCheckBox(frame, text="Select All", variable=all_var, command=toggle_all).pack(anchor="w", pady=5)

        scroll = ctk.CTkScrollableFrame(frame, width=280, height=320)
        scroll.pack(fill="both", expand=True, padx=5, pady=5)

        var_dict = {}
        for rv in sorted_vals:
            # check if rv in current_filter
            if pd.isna(rv):
                in_filter = any(pd.isna(a) for a in current_filter)
            else:
                in_filter = (rv in current_filter)
            bvar = tk.BooleanVar(value=in_filter)
            var_dict[rv] = bvar
            ctk.CTkCheckBox(scroll, text=display_map[rv], variable=bvar).pack(anchor="w")

        def apply_():
            sel = set()
            for rv, vb in var_dict.items():
                if vb.get():
                    sel.add(rv)
            self.filters[col_id] = sel
            popup.destroy()
            self.refresh_table()

        bf = ctk.CTkFrame(frame)
        bf.pack(fill="x", pady=5)
        ctk.CTkButton(bf, text="Apply", command=apply_).pack(side="left", padx=5)
        ctk.CTkButton(bf, text="Cancel", command=popup.destroy).pack(side="left", padx=5)

    def clear_filters(self):
        self.filters.clear()
        self.refresh_table()

    def get_config_block(self) -> Dict:
        return {
            "columns": self.col_defs,
            "filters": {col_id: sorted(list(vals)) for col_id, vals in self.filters.items()}
        }

# ------------------------------------------------------------------------------
# 13) MAIN APP
# ------------------------------------------------------------------------------
class MainApp(ctk.CTk):
    """
    - Single ERP & Single Master tab (no rename/hide, only filter)
    - Parameter file to define dimension/attribute rename & allowed sets
    - Hard-coded "Enabled_Flag" => meltdown attribute "Enabled"
    - Compare => mode2 only
    - Dashboard => 8 chart frames
    """
    def __init__(self):
        super().__init__()
        self.title("Ultra-Mega Reconciliation: Mode=2, No Column Rename, 8 Charts")
        self.geometry("1600x900")

        self.config_dict = load_config(Path(DEFAULT_PATHS["CONFIG_PATH"]))
        self.history_df = pd.DataFrame()

        # read param file
        param_path = Path(self.config_dict["paths"].get("PARAMETER_PATH", DEFAULT_PATHS["PARAMETER_PATH"]))
        self.param_dict = read_parameters_excel(param_path)

        # build UI
        self.notebook = ttk.Notebook(self)
        self.notebook.pack(fill="both", expand=True)

        # 1) Paths
        self.tab_paths = ctk.CTkFrame(self.notebook)
        self.notebook.add(self.tab_paths, text="Paths")
        self.build_paths_tab(self.tab_paths)

        # 2) ERP
        self.tab_erp = ctk.CTkFrame(self.notebook)
        self.notebook.add(self.tab_erp, text="ERP")
        self.erp_grid = ExcelGrid(self.tab_erp, self.config_dict["erp_grid"], "ERP")
        self.erp_grid.pack(fill="both", expand=True)

        # 3) Master
        self.tab_master = ctk.CTkFrame(self.notebook)
        self.notebook.add(self.tab_master, text="Master")
        self.master_grid = ExcelGrid(self.tab_master, self.config_dict["master_grid"], "Master")
        self.master_grid.pack(fill="both", expand=True)

        # 4) Compare & Exceptions
        self.tab_compare = ctk.CTkFrame(self.notebook)
        self.notebook.add(self.tab_compare, text="Compare & Exceptions")
        self.build_compare_tab(self.tab_compare)

        # 5) Dashboard
        self.tab_dashboard = Dashboard(self.notebook)
        self.notebook.add(self.tab_dashboard, text="Dashboard")

        # Logging
        self.log_box = ctk.CTkTextbox(self, height=100)
        self.log_box.pack(fill="both", expand=False)
        self.log_box.configure(state="disabled")
        handler = TextHandler(self.log_box)
        handler.setLevel(logging.INFO)
        logging.getLogger().addHandler(handler)

        # load data
        self.refresh_erp_data()
        self.refresh_master_data()

    def build_paths_tab(self, parent):
        frm = ctk.CTkFrame(parent)
        frm.pack(fill="both", expand=True, padx=10, pady=10)

        self.erp_path_var = tk.StringVar(value=self.config_dict["paths"].get("ERP_EXCEL_PATH", DEFAULT_PATHS["ERP_EXCEL_PATH"]))
        self.mst_path_var = tk.StringVar(value=self.config_dict["paths"].get("MASTER_ZIP_PATH", DEFAULT_PATHS["MASTER_ZIP_PATH"]))
        self.exc_path_var = tk.StringVar(value=self.config_dict["paths"].get("EXCEPTION_PATH", DEFAULT_PATHS["EXCEPTION_PATH"]))
        self.out_path_var = tk.StringVar(value=self.config_dict["paths"].get("OUTPUT_PATH", DEFAULT_PATHS["OUTPUT_PATH"]))
        self.param_path_var = tk.StringVar(value=self.config_dict["paths"].get("PARAMETER_PATH", DEFAULT_PATHS["PARAMETER_PATH"]))
        self.cfg_path_var = tk.StringVar(value=self.config_dict["paths"].get("CONFIG_PATH", DEFAULT_PATHS["CONFIG_PATH"]))

        def mkrow(lbl, var):
            rowf = ctk.CTkFrame(frm)
            rowf.pack(fill="x", pady=5)
            ctk.CTkLabel(rowf, text=lbl, width=180).pack(side="left", padx=5)
            e = ctk.CTkEntry(rowf, textvariable=var, width=700)
            e.pack(side="left", padx=5)
            def br():
                p = filedialog.askopenfilename()
                if p:
                    var.set(p)
            ctk.CTkButton(rowf, text="Browse", command=br).pack(side="left", padx=5)

        mkrow("ERP Excel Path:", self.erp_path_var)
        mkrow("Master ZIP Path:", self.mst_path_var)
        mkrow("Exception Path:", self.exc_path_var)
        mkrow("Output Path:", self.out_path_var)
        mkrow("Parameter Path:", self.param_path_var)
        mkrow("JSON Config Path:", self.cfg_path_var)

    def build_compare_tab(self, parent):
        frm = ctk.CTkFrame(parent)
        frm.pack(fill="both", expand=True, padx=10, pady=10)

        ctk.CTkLabel(frm, text="Compare: Mode=2 only.").pack(pady=5)

        row = ctk.CTkFrame(frm)
        row.pack(fill="x", pady=5)
        ctk.CTkButton(row, text="Run Comparison", command=self.run_comparison).pack(side="left", padx=5)
        ctk.CTkButton(row, text="Save Config", command=self.save_all_config).pack(side="left", padx=5)

    def refresh_erp_data(self):
        df_erp = read_erp_excel(Path(self.erp_path_var.get().strip()))
        self.erp_grid.set_data(df_erp)

    def refresh_master_data(self):
        df_mst = read_master_zip(Path(self.mst_path_var.get().strip()))
        self.master_grid.set_data(df_mst)

    def run_comparison(self):
        # update config with new paths
        self.config_dict["paths"]["ERP_EXCEL_PATH"] = self.erp_path_var.get().strip()
        self.config_dict["paths"]["MASTER_ZIP_PATH"] = self.mst_path_var.get().strip()
        self.config_dict["paths"]["EXCEPTION_PATH"] = self.exc_path_var.get().strip()
        self.config_dict["paths"]["OUTPUT_PATH"] = self.out_path_var.get().strip()
        self.config_dict["paths"]["PARAMETER_PATH"] = self.param_path_var.get().strip()
        self.config_dict["paths"]["CONFIG_PATH"] = self.cfg_path_var.get().strip()
        self.config_dict["comparison_option"] = 2  # forced

        # meltdown ERP
        df_erp_filt = self.erp_grid.get_filtered_df()
        erp_m = meltdown_erp(
            df_erp_filt,
            erp_dim_map=self.param_dict.get("erp_dim_map",{}),
            erp_attr_map=self.param_dict.get("erp_attr_map",{}),
            erp_dim_allow=self.param_dict.get("erp_dim_allow", set()),
            erp_attr_allow=self.param_dict.get("erp_attr_allow", set())
        )
        erp_ready = build_keys(erp_m)

        # meltdown Master
        df_mst_filt = self.master_grid.get_filtered_df()
        mst_m = meltdown_master(
            df_mst_filt,
            mst_dim_map=self.param_dict.get("master_dim_map",{}),
            mst_attr_map=self.param_dict.get("master_attr_map",{}),
            mst_dim_allow=self.param_dict.get("master_dim_allow", set()),
            mst_attr_allow=self.param_dict.get("master_attr_allow", set())
        )
        mst_ready = build_keys(mst_m)

        # compare (mode2)
        df_diff = compare_mode2(erp_ready, mst_ready)

        # exceptions
        df_exc = read_exception_table(Path(self.exc_path_var.get().strip()))
        final = merge_exceptions(df_diff, df_exc)

        # write
        out_path = Path(self.out_path_var.get().strip())
        write_results(final, out_path)

        # dashboard
        run_date = datetime.now().strftime("%Y-%m-%d")
        final["RunDate"] = run_date
        self.history_df = pd.concat([self.history_df, final], ignore_index=True)

        self.notebook.select(self.tab_dashboard)
        self.tab_dashboard.update_data(final, self.history_df)

        messagebox.showinfo("Done", f"Comparison done for {run_date}. Output => {out_path}")

    def save_all_config(self):
        # store grid states
        self.config_dict["erp_grid"] = self.erp_grid.get_config_block()
        self.config_dict["master_grid"] = self.master_grid.get_config_block()

        # store paths
        self.config_dict["paths"]["ERP_EXCEL_PATH"] = self.erp_path_var.get().strip()
        self.config_dict["paths"]["MASTER_ZIP_PATH"] = self.mst_path_var.get().strip()
        self.config_dict["paths"]["EXCEPTION_PATH"] = self.exc_path_var.get().strip()
        self.config_dict["paths"]["OUTPUT_PATH"] = self.out_path_var.get().strip()
        self.config_dict["paths"]["PARAMETER_PATH"] = self.param_path_var.get().strip()
        self.config_dict["paths"]["CONFIG_PATH"] = self.cfg_path_var.get().strip()
        self.config_dict["comparison_option"] = 2

        save_config(self.config_dict, Path(self.cfg_path_var.get().strip()))
        messagebox.showinfo("Saved", "All config saved successfully.")

# ------------------------------------------------------------------------------
# 14) MAIN
# ------------------------------------------------------------------------------
def main():
    app = MainApp()
    app.mainloop()

if __name__ == "__main__":
    main()
